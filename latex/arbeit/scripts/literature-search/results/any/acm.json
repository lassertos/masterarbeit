[
  {
    "DOI": "10.1145/3441852.3476553",
    "ISBN": "9781450383066",
    "URL": "https://doi.org/10.1145/3441852.3476553",
    "abstract": "Introduction of computational thinking training in early childhood potentiates cognitive development and better prepares children to live and prosper in a future heavily computational society. Programming environments are now widely adopted in classrooms to teach programming concepts. However, these tools are often reliant on visual interaction, making them inaccessible to children with visual impairments. Also, programming environments in general are usually designed to promote individual experiences, wasting the potential benefits of group collaborative activities. We propose the design of a programming environment that leverages asymmetric roles to foster collaborative computational thinking activities for children with visual impairments, in particular mixed-visual-ability classes. The multimodal system comprises the use of tangible blocks and auditory feedback, while children have to collaborate to program a robot. We conducted a remote online study, collecting valuable feedback on the limitations and opportunities for future work, aiming to potentiate education and social inclusion.",
    "author": [
      {
        "family": "Rocha",
        "given": "Filipa"
      },
      {
        "family": "Guimarães",
        "given": "Guilherme"
      },
      {
        "family": "Gonçalves",
        "given": "David"
      },
      {
        "family": "Pires",
        "given": "Ana Cristina"
      },
      {
        "family": "Abreu",
        "given": "Lúcia Verónica"
      },
      {
        "family": "Guerreiro",
        "given": "Tiago"
      }
    ],
    "collection-title": "ASSETS ’21",
    "container-title": "Proceedings of the 23rd international ACM SIGACCESS conference on computers and accessibility",
    "id": "10.1145/3441852.3476553",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "accessible, children, collaboration, robot, tangible, visually impaired",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Fostering collaboration with asymmetric roles in accessible programming environments for children with mixed-visual-abilities",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3568812.3603446",
    "ISBN": "9781450399753",
    "URL": "https://doi.org/10.1145/3568812.3603446",
    "abstract": "Pair programming is a common collaboration method used in primary and secondary computer science (CS) education. Despite its many benefits, pair programming has been found to create inequitable learning environments in these settings. In this proposal, I discuss my plan to investigate the equity and effectiveness of a new pair programming method for block-based programming environments, called Puzzle. When using this method, the blocks in the programming environment are partitioned between two students. I will use a mixed methods approach to analyze student attitudes, self-assessed behaviors, learning gains, and conversational dialog. I expect this new method to increase students’ enjoyment when learning to program and to increase student interest in CS.",
    "author": [
      {
        "family": "Gransbury",
        "given": "Isabella"
      }
    ],
    "collection-title": "ICER ’23",
    "container-title": "Proceedings of the 2023 ACM conference on international computing education research - volume 2",
    "id": "10.1145/3568812.3603446",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "page": "92-94",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A new way to pair program: The puzzle method",
    "title-short": "A new way to pair program",
    "type": "paper-conference"
  },
  {
    "ISBN": "9783540740230",
    "URL": "https://doi.org/10.1007/978-3-540-74024-7_12",
    "abstract": "Robot building projects are increasingly used in schools and universities to raise the interest of students in technical subjects. They can especially be used to teach the three mechatronics areas at the same time: mechanics, electronics, and software. However, it is hard to find reusable, robust, modular and cost-effective robot development kits in the market. Here, we present &lt;em&gt;qfix&lt;/em&gt;, a modular construction kit for edutainment robotics and mechatronics experiments which fulfills all of the above requirements and receives strong interest from schools and universities. The outstanding advantages of this kit family are the solid aluminium elements, the modular controller boards, and the programming tools which reach from an easy-to-use graphical programming environment to a powerful C++ library for the GNU compiler collection.",
    "author": [
      {
        "family": "Enderle",
        "given": "Stefan"
      }
    ],
    "container-title": "RoboCup 2006: Robot soccer world cup x",
    "id": "10.1007/978-3-540-74024-7_12",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "page": "134-145",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "The robotics and mechatronics kit \"qfix\"",
    "type": "chapter"
  },
  {
    "DOI": "10.1007/s10639-023-12024-9",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-023-12024-9",
    "abstract": "Microcontroller programming competencies contribute to the sustainable employability of engineering graduates of both higher and secondary education. To develop the required programming skills, one of the challenges for educators is to determine which programming environments should be implemented in introductory programming courses. Conceptually, graphical (e.g. iconic or diagrammatic) environments appear to be very different from textual environments. Our study focused on a programming course in a mechatronics vocational training programme at the secondary school level in Slovenia. To investigate the expectations of potential employers towards our graduates, we surveyed local companies. Out of 104 respondents, 90 (86.5",
    "author": [
      {
        "family": "Vrbančič",
        "given": "Franc"
      },
      {
        "family": "Kocijančič",
        "given": "Slavko"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-023-12024-9",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2023,
          7
        ]
      ]
    },
    "keyword": "Introductory programming, Secondary education, Textual vs graphical environment, Teaching/learning strategies, Improving classroom teaching",
    "page": "5115-5137",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Strategy for learning microcontroller programming—a graphical or a textual start?",
    "type": "article-journal",
    "volume": "29"
  },
  {
    "DOI": "10.1145/3328778.3366924",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3366924",
    "abstract": "Recent years have seen an increasing interest in identifying common student misconceptions during introductory programming. In a parallel development, block-based programming environments for novice programmers have grown in popularity, especially in introductory courses. While these environments eliminate many syntax-related errors faced by novice programmers, there has been limited work that investigates the types of misconceptions students might exhibit in these environments. Developing a better understanding of these misconceptions will enable these programming environments and instructors to more effectively tailor feedback to students, such as prompts and hints, when they face challenges. In this paper, we present results from a cluster analysis of student programs from interactions with programming activities in a block-based programming environment for introductory computer science education. Using the interaction data from students’ programming activities, we identify three families of student misconceptions and discuss their implications for refinement of the activities as well as design of future activities. We then examine the value of block counts, block sequence counts, and system interaction counts as programming features for clustering block-based programs. These clusters can help researchers identify which students would benefit from feedback or interventions and what kind of feedback provides the most benefit to that particular student.",
    "author": [
      {
        "family": "Emerson",
        "given": "Andrew"
      },
      {
        "family": "Smith",
        "given": "Andy"
      },
      {
        "family": "Rodriguez",
        "given": "Fernando J."
      },
      {
        "family": "Wiebe",
        "given": "Eric N."
      },
      {
        "family": "Mott",
        "given": "Bradford W."
      },
      {
        "family": "Boyer",
        "given": "Kristy Elizabeth"
      },
      {
        "family": "Lester",
        "given": "James C."
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3366924",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "introductory programming education, cluster analysis, block-based programming",
    "page": "825-831",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Cluster-based analysis of novice coding misconceptions in block-based programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-642-02774-1_52",
    "ISBN": "9783642027734",
    "URL": "https://doi.org/10.1007/978-3-642-02774-1_52",
    "abstract": "This paper addresses the question how to optimally support projects of students and employees of a higher education institution of computer science by means of a special software environment. At first the motivation to introduce such a supportive system is examined by describing the current situation in the authors’ department of computer science, which is typical for many colleges and universities. On the one hand problems are pointed out, which hamper students and employees in their project work, on the other hand the additional possibilities of a supportive system, which far exceed the ones of a traditional approach, are drafted. The paper shows how a mutual value for students and employees can be generated from the projects by using social software. After the requirements are described we suggest an architecture for such a supportive system and finally the challenges for the implementation and application, which determine the success or failure of the system, are discussed.",
    "author": [
      {
        "family": "Kadenbach",
        "given": "Daniel"
      },
      {
        "family": "Kleiner",
        "given": "Carsten"
      }
    ],
    "collection-title": "OCSC ’09",
    "container-title": "Proceedings of the 3d international conference on online communities and social computing: Held as part of HCI international 2009",
    "id": "10.1007/978-3-642-02774-1_52",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "page": "479-487",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Benefits and challenges of using collaborative development environments with social software in higher computer science education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3631802.3631825",
    "ISBN": "9798400716539",
    "URL": "https://doi.org/10.1145/3631802.3631825",
    "abstract": "The block-based programming paradigm has gained popularity across various application areas, including programming education, physical computing, and creative arts and media. While initially targeting young learners, environments such as Scratch have demonstrated the versatility of this paradigm beyond its original audience. This paper explores the potential application of block-based code manipulation in the field of low-level programming, which is a fundamental component of many computer science curricula. However, existing visualization tools for teaching low-level computing do not leverage the benefits of block-based programming, such as eliminating the need to memorize syntax. This paper presents Blocksambler, a prototype of a block-based programming environment for teaching low-level computing. The purpose of this paper is two-fold, in the first theoretical part we explore the potential application of block-based code manipulation in the field of low-level programming, which is a fundamental component of many computer science curricula. In the second part, we introduce Blocksambler, a prototype of a block-based programming environment for teaching low-level computing. Blocksambler is built upon Blockly, a JavaScript library designed for creating customized block-based programming tools and for the purpose of teaching low-level computing. Reflecting the relevance, benefits, and limitations of Blocksambler for educational purposes, we conclude the discussion started in the first part of the paper and outline further steps.",
    "author": [
      {
        "family": "Wörister",
        "given": "Florian"
      },
      {
        "family": "Knobelsdorf",
        "given": "Maria"
      }
    ],
    "collection-title": "Koli calling ’23",
    "container-title": "Proceedings of the 23rd koli calling international conference on computing education research",
    "id": "10.1145/3631802.3631825",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "block-based programming, computer science education, low-level computing",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A block-based programming environment for teaching low-level computing (discussion paper)",
    "type": "paper-conference"
  },
  {
    "ISBN": "076950275X",
    "abstract": "This paper explores technical issues in the design of programming tools, development environments, simulations, code examples, user interface frameworks and pedagogies for a university-level course on object-oriented software development. The course, M206 \"Computing: An Object-oriented Approach\" has been specifically developed for distance learning, and is enrolling over 5,000 students per year (average age 37) in the UK, Europe and Singapore. The course introduces computing via an object-oriented approach. M206 is substantial in extent, representing one sixth of a degree. It embodies a practical, industry-oriented view of computing and includes programming, analysis, design, and group working. Considerable effort has been invested in making the simplicity, consistency and power of object technology accessible to and capable of being applied by beginners. A diverse set of educational media, such as CD-ROMs, TV and the Web, have been deployed as learning resources. The paper describes the agenda for the course, its object-oriented pedagogy and our strategy for delivery.We explain measures taken to avoid misconceptions about objects, our analysis and design method, and the Smalltalk programming environment we have developed specifically for learners and which is crucial to our approach. The paper outlines how our adherence to the separation of view and domain model leads to technical innovations. Concluding remarks reflect on the benefits a reflexive strategy, both in education and training.",
    "author": [
      {
        "family": "Woodman",
        "given": "Mark"
      },
      {
        "family": "Griffiths",
        "given": "Rob"
      },
      {
        "family": "Holland",
        "given": "Simon"
      },
      {
        "family": "Robinson",
        "given": "Hugh"
      },
      {
        "family": "Macgregor",
        "given": "Malcolm"
      }
    ],
    "collection-title": "TOOLS ’99",
    "container-title": "Proceedings of the technology of object-oriented languages and systems",
    "id": "10.5555/832256.832950",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "page": "371",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Employing object technology to expose fundamental object concepts",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/988316.988319",
    "ISSN": "0362-1340",
    "URL": "https://doi.org/10.1145/988316.988319",
    "abstract": "While languages based upon threaded interpretive systems have been used for a variety of applications, these systems have been generally ignored by serious students of programming languages. We describe research here at the University of South Florida where we are investigating the suitability of these systems for implementing a programming environment - specifically an environment to support programming in a functional style.We hypothesize that threaded interpretive systems may have merit as the basis for more ambitious language implementations than have yet been attempted - and that such languages may offer a reasonable compromise between the flexability of more interpretive systems and the efficiency of compilers that generate native code. We describe extensions to a threaded language which provide the kernel of a functional style language. Our goal is to gain insight into the real and apparent capabilities of threaded languages and to evaluate the potential of such systems for support of functional programming environments.",
    "author": [
      {
        "family": "Glass",
        "given": "Harvey"
      }
    ],
    "container-title": "SIGPLAN Not.",
    "id": "10.1145/988316.988319",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1985,
          4
        ]
      ]
    },
    "page": "24-32",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Threaded interpretive systems and functional programming environments",
    "type": "article-journal",
    "volume": "20"
  },
  {
    "DOI": "10.1145/2960310.2960322",
    "ISBN": "9781450344494",
    "URL": "https://doi.org/10.1145/2960310.2960322",
    "abstract": "Computing education researchers have become increasingly interested in leveraging log data automatically collected within computer programming environments in order to understand students’ learning processes and tailor instruction to student needs. While data on students’ programming activities has been positively correlated with their learning outcomes, those data tell only part of the story. Another part of the story lies in students’ social activities, which, according to social learning theory, can also be predictive of students’ learning outcomes. In order to gain further insight into how computing students’ learning processes influence their learning outcomes, we present an empirical study that explores the interplay of students’ social activities, programming activities, and course outcomes in an early computing course. By analyzing log data collected through a programming environment augmented with a social networking-style activity stream, we found that answers to questions posed through the activity stream were positively correlated with students’ ability to make programming progress, and their eventual success in the course. Based on our findings, we present recommendations for the design of pedagogical environments to support a more social programming process.",
    "author": [
      {
        "family": "Carter",
        "given": "Adam S."
      },
      {
        "family": "Hundhausen",
        "given": "Christopher D."
      }
    ],
    "collection-title": "ICER ’16",
    "container-title": "Proceedings of the 2016 ACM conference on international computing education research",
    "id": "10.1145/2960310.2960322",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "human factors., experimentation, design",
    "page": "201-209",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "With a little help from my friends: An empirical study of the interplay of students’ social activities, programming activities, and course success",
    "title-short": "With a little help from my friends",
    "type": "paper-conference"
  },
  {
    "ISBN": "9608457432",
    "abstract": "We have investigated collaborative problem solving in a teaching experiment, which was organized for 32 senior university students in the computerized collaborative problem solving learning environment. The participating teacher was trained by us and students had available kits, interfaces and computers equipped with 8051 micro chip programming tools. Student activities were video recorded and the analysis proceeded through writing video protocols, edited into episodes and then classified into categories. Categories were mainly derived empirically. In the analysis, we used concepts such as collaboration and problem solving, in accordance with social constructivism. The data showed that typical learning processes were collaborative (51",
    "author": [
      {
        "family": "Yang",
        "given": "Hung-Jen"
      },
      {
        "family": "Yang",
        "given": "Hsieh-Hua"
      },
      {
        "family": "Wang",
        "given": "Cheng Chung"
      },
      {
        "family": "Huang",
        "given": "Kuo-Yan"
      }
    ],
    "collection-title": "ACOS’06",
    "container-title": "Proceedings of the 5th WSEAS international conference on applied computer science",
    "id": "10.5555/1973598.1973643",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "keyword": "social interactions, problem solving, computerized, collaborative learning",
    "page": "227-233",
    "publisher": "World Scientific; Engineering Academy; Society (WSEAS)",
    "publisher-place": "Stevens Point, Wisconsin, USA",
    "title": "Social interactions of the computerized collaborative problem solving on micro chip",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2801081.2801094",
    "ISBN": "9781450333351",
    "URL": "https://doi.org/10.1145/2801081.2801094",
    "abstract": "Specially designed programming environments have been used for decades to support the novice programmers learning programming. In this paper, we present various forms of Educational Technology that have guided the design of educational programming environments the last two decades. The design and aspirations of three distinct programming environments developed at the University of Macedonia are presented. These include a Programming Microworld, an Educational Game and a Distributed Pair Programming system. The potential benefits of the different features of the three environments are presented along with results from their evaluation. Conclusions are drawn regarding the technologies incorporated in these different programming environments. Specifically, emphasis is given on technologies and features that seem to be important for motivating and engaging students in learning programming and should be taken into account by researchers designing new educational programming environments.",
    "author": [
      {
        "family": "Xinogalos",
        "given": "Stelios"
      },
      {
        "family": "Malliarakis",
        "given": "Christos"
      },
      {
        "family": "Tsompanoudi",
        "given": "Despina"
      },
      {
        "family": "Satratzemi",
        "given": "Maya"
      }
    ],
    "collection-title": "BCI ’15",
    "container-title": "Proceedings of the 7th balkan conference on informatics conference",
    "id": "10.1145/2801081.2801094",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "structure editors, programming microworlds, educational games, distributed pair programming, collaboration scripts, Novice programmer",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Microworlds, games and collaboration: Three effective approaches to support novices in learning programming",
    "title-short": "Microworlds, games and collaboration",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.compedu.2019.103646",
    "ISSN": "0360-1315",
    "URL": "https://doi.org/10.1016/j.compedu.2019.103646",
    "author": [
      {
        "family": "Weintrop",
        "given": "David"
      },
      {
        "family": "Wilensky",
        "given": "Uri"
      }
    ],
    "container-title": "Comput. Educ.",
    "id": "10.1016/j.compedu.2019.103646",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          12
        ]
      ]
    },
    "keyword": "Teaching/learning strategies, Secondary education, Programming and programming languages, Interactive learning environments, Evaluation of CAL systems",
    "publisher": "Elsevier Science Ltd.",
    "publisher-place": "GBR",
    "title": "Transitioning from introductory block-based and text-based environments to professional programming languages in high school computer science classrooms",
    "type": "article-journal",
    "volume": "142"
  },
  {
    "ISBN": "013374163X",
    "abstract": "Prelude to Programming is appropriate for Pre-Programming and Introductory Programming courses in community colleges, 4-year colleges, and universities. No prior computer or programming experience is necessary although readers are expected to be familiar with college entry-level mathematics. Prelude to Programming provides beginning students with a language-independent framework for learning core programming concepts and effective design techniques. This approach gives students the foundation they need to understand the logic behind program design and to establish effective programming skills. The Sixth Edition offers students a lively and accessible presentation as they learn core programming concepts including data types, control structures, data files and arrays, and program design techniques such as top-down modular design and proper program documentation and style. Problem-solving skills are developed when students learn how to use basic programming tools and algorithms, which include data validation, defensive programming, calculating sums and averages, and searching and sorting lists. Teaching and Learning Experience This program presents a better teaching and learning experiencefor you and your students. It provides: A Language-Independent, Flexible Presentation: The text has been designed so that instructors can use it for students at various levels. Features that Help Solidify Concepts: Examples, exercises, and programming challenges help students understand how concepts in the text apply to real-life programs. Real Programming Experience with RAPTOR: Students gain first-hand programming experience through the optional use of RAPTOR, a free flowchart-based programming environment. Support Learning: Resources are available to expand on the topics presented in the text.",
    "author": [
      {
        "family": "Venit",
        "given": "Stewart"
      },
      {
        "family": "Drake",
        "given": "Elizabeth"
      }
    ],
    "edition": "6th",
    "id": "10.5555/2636689",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Prelude to programming",
    "type": "book"
  },
  {
    "DOI": "10.1145/2023607.2023610",
    "ISBN": "9781450309172",
    "URL": "https://doi.org/10.1145/2023607.2023610",
    "abstract": "Web 2.0 has enabled Web users to create and share a variety of hyper-text based artifacts including embedded images, sound, and video on the Web. Creating Web-based interactive artifacts such as computer games, however, has remained a challenge: to end users due to the lack of end user programming tools; and to programmers due to the poor interactivity performance of the Web. With the emergence of HTML5 and improving performance of JavaScript engines, professional Web programmers have only just begun to develop Web-native interactive artifacts. Today’s standard Web technologies make the Web a hospitable platform for efficient interactive applications both for professional programmers and end-users. With proper support, in tools and languages, end-user programming of interactive applications is feasible. In this paper, we review the current state of Web application development and the possibilities and potential benefits of end-user programming on the Web. We will use a case study, AgentWeb, a Web-based end-user development environment, as a representative of interactive Web applications. It is based completely on open Web technologies, rather than on any proprietary technologies. Given that 2D graphic interactive applications may be developed and efficiently executed on the Web, we discuss some of the potential applications in educational settings, including individual and collaborative learning.",
    "author": [
      {
        "family": "Jazayeri",
        "given": "Mehdi"
      },
      {
        "family": "Ahmadi",
        "given": "Navid"
      }
    ],
    "collection-title": "CompSysTech ’11",
    "container-title": "Proceedings of the 12th international conference on computer systems and technologies",
    "id": "10.1145/2023607.2023610",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "keyword": "web programming, web native applications, web applications, open web, end-user programming, World Wide Web, HTML5",
    "page": "11-16",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "End-user programming of web-native interactive applications",
    "type": "paper-conference"
  },
  {
    "ISBN": "3540424997",
    "abstract": "This paper presents the benefits of using a generic FPGA tool set developed at the university of Brest for programming virtual FPGA. From a high level description of the FPGA architecture, the basic tools such a placer, a router or an editor are automatically generated. The description is not constrained by any model, so that abstract architectures, such as virtual FPGAs, can directly exploit the tool set as their basic programming tools.",
    "author": [
      {
        "family": "Lagadec",
        "given": "Loı̈c"
      },
      {
        "family": "Lavenier",
        "given": "Dominique"
      },
      {
        "family": "Fabiani",
        "given": "Erwan"
      },
      {
        "family": "Pottier",
        "given": "Bernard"
      }
    ],
    "collection-title": "FPL ’01",
    "container-title": "Proceedings of the 11th international conference on field-programmable logic and applications",
    "id": "10.5555/647928.740044",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "page": "357-366",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Placing, routing, and editing virtual FPGAs",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1868358.1868361",
    "URL": "https://doi.org/10.1145/1868358.1868361",
    "abstract": "Greenfoot is an educational integrated development environment aimed at learning and teaching programming. It is aimed at a target audience of students from about 14 years old upwards, and is also suitable for college- and university-level education. Greenfoot combines graphical, interactive output with programming in Java, a standard, text-based object-oriented programming language. This article first describes Greenfoot and then goes on to discuss design goals and motivations, strengths and weaknesses of the system, and its relation to two environments with similar goals, Scratch and Alice.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/1868358.1868361",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2010,
          11
        ]
      ]
    },
    "keyword": "programming environment, programming education, Greenfoot",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The greenfoot programming environment",
    "type": "article-journal",
    "volume": "10"
  },
  {
    "DOI": "10.1016/j.comnet.2010.07.016",
    "ISSN": "1389-1286",
    "URL": "https://doi.org/10.1016/j.comnet.2010.07.016",
    "abstract": "This paper presents iPlumber, a user-oriented management system for ubiquitous computing environments. Different from previous low-benefit ”zero-configuration” systems or high cognitive-cost ”end user programming” tools, our work attempts to attain a better balance between user benefits and cost by exploring the meta-design approach. A set of typical management activities in ubicomp environments are supported, from basic-level software sharing, foraging, and low-cost software configuration to advanced-level cooperative software co-design and error handling. These activities are elaborated through a smart home control scenario. The usability of our system is validated through an initial user study with a total of 33 subjects to test the management activities from an open exhibition environment and a controlled university environment.",
    "author": [
      {
        "family": "Guo",
        "given": "Bin"
      },
      {
        "family": "Zhang",
        "given": "Daqing"
      },
      {
        "family": "Imai",
        "given": "Michita"
      }
    ],
    "container-title": "Comput. Netw.",
    "id": "10.1016/j.comnet.2010.07.016",
    "issue": "16",
    "issued": {
      "date-parts": [
        [
          2010,
          11
        ]
      ]
    },
    "keyword": "Wireless sensor network, Ubiquitous computing management, Smart object, Semantic Web, Meta-design, End user development, Cooperation",
    "page": "2840-2855",
    "publisher": "Elsevier North-Holland, Inc.",
    "publisher-place": "USA",
    "title": "Enabling user-oriented management for ubiquitous computing: The meta-design approach",
    "title-short": "Enabling user-oriented management for ubiquitous computing",
    "type": "article-journal",
    "volume": "54"
  },
  {
    "DOI": "10.1145/236452.236537",
    "ISBN": "089791757X",
    "URL": "https://doi.org/10.1145/236452.236537",
    "abstract": "Teaching object-oriented programming has clearly become an important part of computer science education. We agree with many others that the best place to teach it is in the CS1 introductory course. Many problems with this have been reported in the literature. These mainly result from inadequate languages and environments. Blue is a new language and integrated programming environment, currently under development explicitly for object-oriented teaching. We expect clear advantages from the use of Blue for first year teaching compared to using other available languages. This paper describes the design principles on which the language was based and the most important aspects of the language itself.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      },
      {
        "family": "Rosenberg",
        "given": "John"
      }
    ],
    "collection-title": "SIGCSE ’96",
    "container-title": "Proceedings of the twenty-seventh SIGCSE technical symposium on computer science education",
    "id": "10.1145/236452.236537",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "page": "190-194",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Blue—a language for teaching object-oriented programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3059009.3059035",
    "ISBN": "9781450347044",
    "URL": "https://doi.org/10.1145/3059009.3059035",
    "abstract": "This article discusses an emerging phenomenon of streaming programming to a live audience who in turn can interact with the streamer. In essence, this means broadcasting the programming environment and typically a web camera feed of the streamer to viewers. Streaming programming bears many similarities with live-streaming playing of video games, which has become extremely popular among gamers over the recent years. In fact, streaming programming often use the same web services as streaming gaming, and the audiences overlap.In this article, we describe this novel approach to programming and situate it in the broader context of computer science education. To gain a deeper insight into this phenomena, we analyzed viewer discussions during a particular programming stream broadcasted during a game programming competition. Finally, we discuss the benefits this approach could offer to computer science education.",
    "author": [
      {
        "family": "Haaranen",
        "given": "Lassi"
      }
    ],
    "collection-title": "ITiCSE ’17",
    "container-title": "Proceedings of the 2017 ACM conference on innovation and technology in computer science education",
    "id": "10.1145/3059009.3059035",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "streaming, online communities, game-based learning, computer science education",
    "page": "353-358",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Programming as a performance: Live-streaming and its implications for computer science education",
    "title-short": "Programming as a performance",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/29650.29662",
    "ISBN": "0897912357",
    "URL": "https://doi.org/10.1145/29650.29662",
    "abstract": "As part of Rice University’s project to build a programming environment for scientific software, we have built a facility for program execution that solves some of the problems inherent in debugging large, computationally intensive programs. By their very nature such programs do not lend themselves to full-scale interpretation. In moderation however, interpretation can be extremely useful during the debugging process. In addition to discussing the particular benefits that we expect from interpretation, this paper addresses how interpretive techniques can be effectively used in conjunction with the execution of compiled code. The same implementation technique that permits interpretation to be incorporated as part of execution will also permit the execution facility to be used for debugging parallel programs running on a remote machine.",
    "author": [
      {
        "family": "Chase",
        "given": "B. B."
      },
      {
        "family": "Hood",
        "given": "R. T."
      }
    ],
    "collection-title": "SIGPLAN ’87",
    "container-title": "Papers of the symposium on interpreters and interpretive techniques",
    "id": "10.1145/29650.29662",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "page": "113-124",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Selective interpretation as a technique for debugging computationally intensive programs",
    "type": "paper-conference"
  },
  {
    "ISBN": "0780398025",
    "abstract": "We present a new parallel programming tool environment that is (1) accessible and executable “anytime, anywhere,” through standard Web browsers and (2) integrated in that it provides tools which adhere to a common underlying methodology for parallel programming and performance tuning. The environment is based on a new network computing infrastructure developed at Purdue University. We evaluate our environment qualitatively by comparing our tool access method with conventional schemes of software download and installation. We also quantitatively evaluate the efficiency of interactive tool access in our environment. We do this by measuring the response times of various functions of the Ursa Minor tool and compare them with those of a Java Applet-based \"anytime, anywhere\" tool access method. We found that our environment offers significant advantages in terms of tool accessibility, integration, and efficiency.",
    "author": [
      {
        "family": "Park",
        "given": "Insung"
      },
      {
        "family": "Kapadia",
        "given": "Nirav H."
      },
      {
        "family": "Figueiredo",
        "given": "Renato J."
      },
      {
        "family": "Eigenmann",
        "given": "Rudolf"
      },
      {
        "family": "Fortes",
        "given": "José A. B."
      }
    ],
    "collection-title": "SC ’00",
    "container-title": "Proceedings of the 2000 ACM/IEEE conference on supercomputing",
    "id": "10.5555/370049.370067",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "page": "9-es",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Towards an integrated, web-executable parallel programming tool environment",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ETCS.2009.672",
    "ISBN": "9780769535579",
    "URL": "https://doi.org/10.1109/ETCS.2009.672",
    "abstract": "This paper analyzes the applications of modern educational technologies for students with disabilities in higher special education. In recent years, modern educational technologies have been utilized rapidly in special education. When used, student’s role is often to work as a user of technologies instead of the role of doer, controller or creator of a technology. The high utilization of educational technologies in the special education reflects the situation that students with individual needs have the potential to learn programming or to take advantage of technology in general. Educational technology refers to technology tools and software that have been created to support learning and teaching. In this study educational technology is mainly focused on mind storming tools for planning, physical tools such as computers, documentation tools, and software such as a programming environment.",
    "author": [
      {
        "family": "Bian",
        "given": "Li"
      }
    ],
    "collection-title": "ETCS ’09",
    "container-title": "Proceedings of the 2009 first international workshop on education technology and computer science - volume 03",
    "id": "10.1109/ETCS.2009.672",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "students with disabilities, modern educational technologies, higher special education",
    "page": "622-625",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Modern education technologies in higher special education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3149572.3149601",
    "ISBN": "9781450353373",
    "URL": "https://doi.org/10.1145/3149572.3149601",
    "abstract": "Due to the impact of high performance customer service, many organizations attempt to improve customer support services using helpdesk systems. The objective of this study is to develop a Central Trouble Ticketing (CTT) system for effective information dissemination, efficient management of operations and to resolve challenges of Center of Training and Learning (CTL) through using e-learning website at a University. As for implementation phase, the Hypertext Preprocessor (PHP) was used as the server side programming tool and MySQL database as backend. The benefits of the Central Trouble Ticketing system include creation of a medium for lecturers to pass their complaints or messages to the technical department for speedy attention; and provision of better and faster operational processes which will reduce time spent on documentation. The system is more reliable, effective and convenient than the manual method in reporting cases of complain within the university technical community.",
    "author": [
      {
        "family": "ahmadpour",
        "given": "Sima"
      },
      {
        "family": "Khaleghi",
        "given": "Ali"
      }
    ],
    "collection-title": "ICIME 2017",
    "container-title": "Proceedings of the 9th international conference on information management and engineering",
    "id": "10.1145/3149572.3149601",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "information management system, helpdesk systems, Trouble ticketing",
    "page": "91-95",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Central trouble ticketing (CTT) system as a communication tool between stakeholders of center of training and learning (CTL)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1565799.1565822",
    "ISBN": "9781605582177",
    "URL": "https://doi.org/10.1145/1565799.1565822",
    "abstract": "Statistics for underrepresented minority groups and women continue to show low numbers in enrollment and rates of retention in academic computer science programs. A new approach to increase student interest in computer science in a first year program is introduced.Laboratory modules for an introductory programming course have been developed at the University of Alabama with the goal to increase student motivation and understanding of fundamental programming concepts. The course utilizes robots and Alice, a 3D graphical programming environment. The drag and drop interface of Alice allows students to program real robots using instructions that correspond to statements of programming languages such as Java, C++, and C#. Students gain programming experience that is transferable to upper level courses by engaging in a stimulating and less frustrating environment using Alice interfaced with robots.",
    "author": [
      {
        "family": "Wellman",
        "given": "Briana Lowe"
      },
      {
        "family": "Davis",
        "given": "James"
      },
      {
        "family": "Anderson",
        "given": "Monica"
      }
    ],
    "collection-title": "TAPIA ’09",
    "container-title": "The fifth richard tapia celebration of diversity in computing conference: Intellect, initiatives, insight, and innovations",
    "id": "10.1145/1565799.1565822",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "education, diversity, computer science",
    "page": "98-102",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Alice and robotics in introductory CS courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3544548.3580981",
    "ISBN": "9781450394215",
    "URL": "https://doi.org/10.1145/3544548.3580981",
    "abstract": "Computational thinking (CT) education reaches only a fraction of young children, in part because CT learning tools often require expensive hardware or fluent literacy. Block-based programming environments address these challenges through symbolic graphical interfaces, but users often need instructor support to advance. Alternatively, voice-based tools provide direct instruction on CT concepts but can present memory and navigation challenges to users. In this work, we present Visual StoryCoder, a multimodal tablet application that combines the strengths of each of these approaches to overcome their respective weaknesses. Visual StoryCoder introduces children ages 5–8 to CT through creative storytelling, offers direct instruction via a pedagogical voice agent, and eases use through a block-like graphical interface. In a between-subjects evaluation comparing Visual StoryCoder to a leading block-based programming app for this age group (N = 24), we show that Visual StoryCoder is more understandable to independent learners, leads to higher-quality code after app familiarization, and encourages personally meaningful projects.",
    "author": [
      {
        "family": "Dietz",
        "given": "Griffin"
      },
      {
        "family": "Tamer",
        "given": "Nadin"
      },
      {
        "family": "Ly",
        "given": "Carina"
      },
      {
        "family": "Le",
        "given": "Jimmy K"
      },
      {
        "family": "Landay",
        "given": "James A."
      }
    ],
    "collection-title": "CHI ’23",
    "container-title": "Proceedings of the 2023 CHI conference on human factors in computing systems",
    "id": "10.1145/3544548.3580981",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "children, computational thinking, multimodal interface, storytelling",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Visual StoryCoder: A multimodal programming environment for children’s creation of stories",
    "title-short": "Visual StoryCoder",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3102113.3102144",
    "ISBN": "9781450350839",
    "URL": "https://doi.org/10.1145/3102113.3102144",
    "abstract": "Self-adaptive UIs (SAUIs) have been promoted as a solution for context variability due to their ability to automatically adapt to the context-of-use at runtime. The development of SAUIs is a complex task since self-adaptivity and context management aspects have to be incorporated in the UI development process. In this paper, we present an integrated development environment (IDE) for model-driven development of SAUIs. This IDE, named Adapt-UI, provides integrated views for UI, context and adaptation modeling. Based on the specified models, final UI code and context as well as adaptation services are generated and integrated in an overall UI framework. This allows runtime UI adaptation realized by an automatic reaction to context-of-use changes. The benefit of our approach is demonstrated by a case study, showing the development of self-adaptive UIs for a university library application, utilizing the Angular 2 JavaScript framework.",
    "author": [
      {
        "family": "Yigitbas",
        "given": "Enes"
      },
      {
        "family": "Sauer",
        "given": "Stefan"
      },
      {
        "family": "Engels",
        "given": "Gregor"
      }
    ],
    "collection-title": "EICS ’17",
    "container-title": "Proceedings of the ACM SIGCHI symposium on engineering interactive computing systems",
    "id": "10.1145/3102113.3102144",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "self-adaptive UIs, model-driven UI development, context-management, UI adaptation",
    "page": "99-104",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Adapt-UI: An IDE supporting model-driven development of self-adaptive UIs",
    "title-short": "Adapt-UI",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2532748.2532761",
    "ISBN": "9781450324557",
    "URL": "https://doi.org/10.1145/2532748.2532761",
    "abstract": "Computer programming has become an important skill and it can be taught from early school years. Previous research has developed and evaluated several visual programming tools that are suitable for computer education in schools. However, little is known about how pedagogic styles affect student attitudes towards learning computer programming. This paper reports on a preliminary study on the influence of alternative teaching styles on student’s enjoyment and attitude towards computing. Two groups of twelve students each were asked to revise a computer game. The traditional instruction group was provided with detailed information, while the encouragement group was asked to help the teacher to change the variables of the game. The results indicate that an encouraging pedagogic style promotes more positive attitudes towards computer programming and more self-confidence than traditional instruction. Further research should repeat the experiment across several weeks for more programming concepts and should also assess the cognitive benefits.",
    "author": [
      {
        "family": "Makris",
        "given": "Dimosthenis"
      },
      {
        "family": "Euaggelopoulos",
        "given": "Kleomenis"
      },
      {
        "family": "Chorianopoulos",
        "given": "Konstantinos"
      },
      {
        "family": "Giannakos",
        "given": "Michail N."
      }
    ],
    "collection-title": "WiPSE ’13",
    "container-title": "Proceedings of the 8th workshop in primary and secondary computing education",
    "id": "10.1145/2532748.2532761",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "keyword": "secondary education, scratch, programming, encouragement, confidence, computer education, computational thinking",
    "page": "79-82",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Could you help me to change the variables? Comparing instruction to encouragement for teaching programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "9783540899617",
    "URL": "https://doi.org/10.1007/978-3-540-89962-4_5",
    "abstract": "Developments in computer networking and the Internet in the last decade have provided new possibilities and new challenges for designing web-based learning environment for embedded applications. The design elements should facilitate instruction delivery, interaction, quality of learning and support for learner. This paper presents a technology, which supports remote experimentation on an embedded system. The ability to combine practical applications with visualization of real hardware using powerful and efficient virtual instrumentation and multimedia tool is the advantage of technology-based education. The paper describes the hardware and software structure of such a system and the interface between various data processing units. The design is based on interfacing a graphical programming tool such as LabVIEW with an embedded development board. It describes the ongoing research in this area exploiting current telematics techniques, which supports remote experimentation with real hardware via the Internet.",
    "author": [
      {
        "family": "Chandra A. P.",
        "given": "Jagadeesh"
      },
      {
        "family": "Samuel",
        "given": "R. D."
      }
    ],
    "container-title": "Advances in blended learning: Second workshop on blended learning, WBL 2008, jinhua, china, augustl 20-22, 2008. Revised selected papers",
    "id": "10.1007/978-3-540-89962-4_5",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "page": "46-54",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Design of a real-time on-line web-based collaborative learning environment for embedded applications",
    "type": "chapter"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "This tutorial will introduce Alice 2.0, an interactive programming course developed at Carnegie Mellon University. This program is an ideal introductory high school or college one-semester Computer Science course. This program is especially useful for recruiting female students into the work of Computer Science. Alice is an innovative 3D programming environment that makes it easy to create an animation for telling a story, playing an interactive game, or a video to share on the web. Alice is a freely available teaching tool designed to be a student’s first exposure to object-oriented programming. In Alice’s interactive interface, students drag and drop graphic tiles to create a program, where the instructions correspond to standard statements in a production oriented programming language, such as Java. By manipulating the objects in their virtual world, students gain experience with all the programming constructs typically taught in an introductory programming course. Attendees will gain knowledge on how to incorporate Alice 2.0 into their introductory curriculum.",
    "author": [
      {
        "family": "Amerikaner",
        "given": "Erik W."
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1734797.1734824",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2010,
          4
        ]
      ]
    },
    "page": "141",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Introduction to computer science using alice 2.0: Tutorial presentation",
    "title-short": "Introduction to computer science using alice 2.0",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "DOI": "10.1145/3408877.3432534",
    "ISBN": "9781450380621",
    "URL": "https://doi.org/10.1145/3408877.3432534",
    "abstract": "The process of writing code and use of features in an integrated development environment (IDE) is a fruitful source of data in computing education research. Existing studies use records of students’ actions in the IDE, consecutive code snapshots, compilation events, and others, to gain deep insight into the process of student programming.In this paper, we present a set of tools for collecting and processing data of student activity during problem-solving. The first tool is a plugin for IntelliJ-based IDEs (PyCharm, IntelliJ IDEA, CLion). By capturing snapshots of code and IDE interaction data, it allows to analyze the process of writing code in different languages — Python, Java, Kotlin, and C++. The second tool is designed for the post-processing of data collected by the plugin and is capable of basic analysis and visualization. To validate and showcase the toolkit, we present a dataset collected by our tools. It consists of records of activity and IDE interaction events during solution of programming tasks by 148 participants of different ages and levels of programming experience. We propose several directions for further exploration of the dataset.",
    "author": [
      {
        "family": "Lyulina",
        "given": "Elena"
      },
      {
        "family": "Birillo",
        "given": "Anastasiia"
      },
      {
        "family": "Kovalenko",
        "given": "Vladimir"
      },
      {
        "family": "Bryksin",
        "given": "Timofey"
      }
    ],
    "collection-title": "SIGCSE ’21",
    "container-title": "Proceedings of the 52nd ACM technical symposium on computer science education",
    "id": "10.1145/3408877.3432534",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "programming education, ide instrumentation, code tracking, activity tracking",
    "page": "495-501",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TaskTracker-tool: A toolkit for tracking of code snapshots and activity data during solution of programming tasks",
    "title-short": "TaskTracker-tool",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3364510.3364522",
    "ISBN": "9781450377157",
    "URL": "https://doi.org/10.1145/3364510.3364522",
    "abstract": "Courses in C programming at two Finnish universities were assessed with electronic exams. In the study setting, two types of electronic exams were used: lecture hall exams and exam studio exams. Student experiences were collected with surveys and interviews, and system data was used for exam statistics. The results were compared between exam types and between universities. The results show that electronic exams are perceived by the students as more realistic and natural in programming exams than traditional pen and paper exams. Thus, electronic exams support the development of working life skills above pen and paper exams. Students in the lecture hall exam described challenges not relevant in the exam studio exam, and on the other hand, students in the exam studio exam described benefits not available in the lecture hall exam. Based on the study, electronic exams are strongly recommended for programming courses using exams for summative assessment. In addition, programming environments are recommended for added authenticity in reflection to working-life skills, and exam studios are recommended because of the added values they provide compared to lecture hall exams.",
    "author": [
      {
        "family": "Rytkönen",
        "given": "Anni"
      },
      {
        "family": "Virtakoivu",
        "given": "Venla"
      }
    ],
    "collection-title": "Koli calling ’19",
    "container-title": "Proceedings of the 19th koli calling international conference on computing education research",
    "id": "10.1145/3364510.3364522",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "student assessment, programming in C, programming course, lecture hall exam, exam studio exam, electronic examining, C programming",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Comparative student experiences on electronic examining in a programming course - case c",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1504/ijlt.2018.098500",
    "ISSN": "1477-8386",
    "URL": "https://doi.org/10.1504/ijlt.2018.098500",
    "abstract": "The fast development of several programming tools has enabled researchers to explore interactive technology targeting various areas of human knowledge. Despite the several studies about the benefits of using the interactive technologies in the educational field, it is necessary to generalise these affirmations through of field studies that determine how those devices facilitate and improve teaching and learning. This research aims to apply an MS-Kinect-based learning system in a real pre-school environment and based on the results of this experiment, to answer some questions related to the motivational impact, effectiveness and acceptance of the teacher in teaching and learning process. This research uses a MS-Kinect-based learning system and several children’s educational games in an initial stage of studies; the developed learning system has been tested in two preschool education centres and was evaluated positively. In the field test, the learning system evaluation was determined to have a mean 95.5",
    "author": [
      {
        "family": "Lozada",
        "given": "Raul Marcelo"
      },
      {
        "family": "Escriba",
        "given": "Luis Rivera"
      },
      {
        "family": "Granja",
        "given": "Fernando T. Molina"
      }
    ],
    "container-title": "Int. J. Learn. Technol.",
    "id": "10.1504/ijlt.2018.098500",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2018,
          1
        ]
      ]
    },
    "keyword": "learning game, HCI, human-computer interaction, Kinect, preschoolers education",
    "page": "277-305",
    "publisher": "Inderscience Publishers",
    "publisher-place": "Geneva 15, CHE",
    "title": "MS-kinect in the development of educational games for preschoolers",
    "type": "article-journal",
    "volume": "13"
  },
  {
    "DOI": "10.1007/978-3-540-31958-0_21",
    "ISBN": "354025336X",
    "URL": "https://doi.org/10.1007/978-3-540-31958-0_21",
    "abstract": "Traditionally programming is considered to be a core content of informatics education. Just as traditional is the discussion of how to teach programming at school. One major aspect seems to be the choice of a suitable software tool allowing to focus on the basic concepts and avoiding tool-specific overhead at the same time. Therefore, special learning environments (so called microworlds) have been developed, designed to reduce the complexity learners are confronted with. But – in most cases – these microworlds are a sort of iso lated solution and call for a shift to “real” programming environments later on. The contrary approach is to downsize professional programming or (to be more general) software environments to the needs of the learner, which appears to be almost impossible due to the complexity of current software. This paper discusses how this might be achieved though by concentrating on programmable spread-sheet software. It points at possible didactic and methodical benefits by teaching programming this way and presents a list of criteria that can be helpful in deciding the relevance of software-tools for informatics classes.",
    "author": [
      {
        "family": "Antonitsch",
        "given": "Peter K."
      }
    ],
    "collection-title": "ISSEP’05",
    "container-title": "Proceedings of the 2005 informatics in secondary schools - evolution and perspectives international conference on from computer literacy to informatics fundamentals",
    "id": "10.1007/978-3-540-31958-0_21",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "189-197",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Standard software as microworld?",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/CERMA.2010.98",
    "ISBN": "9780769542041",
    "URL": "https://doi.org/10.1109/CERMA.2010.98",
    "abstract": "Teaching robotics is often a theoretical task, since many universities may have one or none robots for practical courses, specially in underdeveloped countries that suffer the lack of technology facilities. Many robot simulators exist, all of them allow the user to modify the joint values or to solve inverse kinematics. Nevertheless, a low cost, immersive virtual reality system, to manipulate and program a robot is not yet developed. This paper proposes a novel virtual reality system to train on robotics systems. The main contribution of this paper is a system the lets the user immerse in a virtual reality simulation of a real robot programming environment, enhancing the experience by means of tactile (haptic) and 3D visual feedback. Additionally, forward and inverse kinematics for a CRS robot is presented to clarify some of our system advantages, ease of configuration and extendability. Our system is open source under the GNU/GPL license.",
    "author": [
      {
        "family": "Hurtado",
        "given": "Carlos Vazquez"
      },
      {
        "family": "Valerio",
        "given": "Alejandro Rojo"
      },
      {
        "family": "Sanchez",
        "given": "Luis Ruvalcaba"
      }
    ],
    "collection-title": "CERMA ’10",
    "container-title": "Proceedings of the 2010 IEEE electronics, robotics and automotive mechanics conference",
    "id": "10.1109/CERMA.2010.98",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "haptic aided robot programming, Virtual robotics training",
    "page": "162-167",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Virtual reality robotics system for education and training",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.chb.2017.04.058",
    "ISSN": "0747-5632",
    "URL": "https://doi.org/10.1016/j.chb.2017.04.058",
    "abstract": "This article describes the implementation of various core elements of Computational Thinking (CT) in the classrooms of schools of Latin America and USA in two specific courses: PC-01 and ECE130. These courses were designed for students of primary and secondary education, as well as for students of high school as part of a dual enrollment program with a local university. Both courses introduce the core concepts and processes of CT aided by the visual programming environments Scratch and Alice. The courses are facilitated by the classroom teacher with the support of a learning platform. This platform is configured to provide innovative pedagogical strategies based on emerging educational technologies. This article describes the concepts integrated under the term CT, and discusses the benefits of learning environments used to incorporate CT in the classroom. It describes as well the syllabi and assessments of both courses, and analyzes their impact of these courses on the educational institutions, the teachers and the students. Computational Thinking trough object-based programming.Human Cognitive Primitives: in search of new computational tools.Blended Learning: added value for teachers and students.Student Peer Review: new roles and responsibilities for students.Mastery Learning through student portfolios and peer review.",
    "author": [
      {
        "family": "Basogain",
        "given": "Xabier"
      },
      {
        "dropping-particle": "ngel",
        "family": "Olabe",
        "given": "Miguel"
      },
      {
        "family": "Olabe",
        "given": "Juan Carlos"
      },
      {
        "family": "Rico",
        "given": "Mauricio Javier"
      }
    ],
    "container-title": "Comput. Hum. Behav.",
    "id": "10.1016/j.chb.2017.04.058",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2018,
          3
        ]
      ]
    },
    "keyword": "Scratch, Learning technologies, Educational technology, Computational Thinking, Cognitive science, Alice",
    "page": "412-419",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Computational thinking in pre-university blended learning classrooms",
    "type": "article-journal",
    "volume": "80"
  },
  {
    "DOI": "10.1145/2839509.2850492",
    "ISBN": "9781450336857",
    "URL": "https://doi.org/10.1145/2839509.2850492",
    "abstract": "Computing educators have become increasingly interested in learning analytics, which involves collecting and analyzing data on students’ learning processes and outcomes for the purpose of improving learning and instructional practices. A variety of computer programming environments enable the automated collection of log data on students’ programming processes. In addition, log data on students’ online social behavior can be easily collected. All of these data can be analyzed alongside data on students’ learning outcomes in order to identify correlations between learning processes and outcomes, and ultimately to better tailor instruction to students’ needs. This BOF will provide a platform for discussing the emerging field of learning analytics within the context of computing education. The following questions will serve as a starting point for our discussions: (1) What types of data should we be collecting on computing students’ (2) How can we best analyze these data in order to gain meaningful insights into students’ learning processes? (3) How can we design effective instructional interventions based on the data we collect and analyze?",
    "author": [
      {
        "family": "Hundhausen",
        "given": "Christopher D."
      },
      {
        "family": "Carter",
        "given": "Adam S."
      }
    ],
    "collection-title": "SIGCSE ’16",
    "container-title": "Proceedings of the 47th ACM technical symposium on computing science education",
    "id": "10.1145/2839509.2850492",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "learning management systems, learning analytics, computer science education",
    "page": "707",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring learning analytics for computing education (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3159450.3162177",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3162177",
    "abstract": "CS Education makes heavy use of online educational tools like IDEs, Learning Management Systems, eTextbooks, interactive programming environments, and other smart content. Instructors and students would benefit from greater interoperability between tools. CS Ed researchers increasingly make use of the large collections of data generated by click streams coming from them. However, we all face barriers that slow progress: (1) Educational tools do not integrate well. (2) Information about CS learning process and outcome data generated by one system is not compatible with that from other systems. (3) CS problem solving and learning (e.g., coding solutions) is different from the type of data (discrete answers to questions or verbal responses) that current educational data mining focuses on. This BOF will discuss ways that we might support and better coordinate efforts to build community and capacity among CS Ed researchers, data scientists, and learning scientists toward reducing these barriers. CS Ed infrastructure should support broader re-use of innovative learning content that is instrumented for rich data collection, formats and tools for analysis of learner data, and best practices to make large collections of learner data available to researchers. Achieving these goals requires engaging a large community of researchers to define, develop, and use critical elements of this infrastructure to address specific data-intensive research questions.",
    "author": [
      {
        "family": "Shaffer",
        "given": "Clifford A."
      },
      {
        "family": "Brusilovsky",
        "given": "Peter"
      },
      {
        "family": "Koedinger",
        "given": "Kenneth R."
      },
      {
        "family": "Edwards",
        "given": "Stephen H."
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3162177",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "student analytics, smart content, interoperability, infrastructure, computer science education research, LTI",
    "page": "1063",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CS education infrastructure for all: Interoperability for tools and data analytics (abstract only)",
    "title-short": "CS education infrastructure for all",
    "type": "paper-conference"
  },
  {
    "ISBN": "3319367587",
    "abstract": "This unique text/reference describes an exciting and novel approach to supercomputing in the DataFlow paradigm. The major advantages and applications of this approach are clearly described, and a detailed explanation of the programming model is provided using simple yet effective examples. The work is developed from a series of lecture courses taught by the authors in more than 40 universities across more than 20 countries, and from research carried out by Maxeler Technologies, Inc. Topics and features: presents a thorough introduction to DataFlow supercomputing for big data problems; reviews the latest research on the DataFlow architecture and its applications; introduces a new method for the rapid handling of real-world challenges involving large datasets; provides a case study on the use of the new approach to accelerate the Cooley-Tukey algorithm on a DataFlow machine; includes a step-by-step guide to the web-based integrated development environment WebIDE.",
    "author": [
      {
        "family": "Milutinovi",
        "given": "Veljko"
      },
      {
        "family": "Salom",
        "given": "Jakob"
      },
      {
        "family": "Trifunovic",
        "given": "Nemanja"
      },
      {
        "family": "Giorgi",
        "given": "Roberto"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3122732",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "Guide to DataFlow supercomputing: Basic concepts, case studies, and a detailed example",
    "title-short": "Guide to DataFlow supercomputing",
    "type": "book"
  },
  {
    "DOI": "10.1109/ICComm.2018.8430148",
    "URL": "https://doi.org/10.1109/ICComm.2018.8430148",
    "abstract": "An optimized implementation for a parameter-less radial-basis neural paradigm called super fast vector support classifier (SFSVC) is presented. Training resides only in a process of selecting centers and consequently it is a very fast process, linear in the number of hidden neurons. Several improvements make the resulting implementation a highly effective, high speed., machine learning engine convenient for various applications on a large variety of platforms. It is shown that among various programming environments., Python with optimized math library support represents the best choice for its implementation. An important (up to 40 times) speed-up for the testing time is achieved by implementing the distance calculations as matrix multiplications., thus accelerating RBF computations on platforms with optimized math and linear algebra libraries such as Intel’s MKL. Another important aspect of SFSVC., making it suitable for various embedded platforms (e.g. micro controllers., FPGA., etc.) is the lack of any tunable parameter except a unique radius., leading to a very convenient structure. The overall test plus training speed is better than for support vector machines while SFSVC has the important advantage of accepting arbitrary RBF kernels.",
    "author": [
      {
        "family": "Dogaru",
        "given": "Radu"
      },
      {
        "family": "Dogaru",
        "given": "Ioana"
      }
    ],
    "container-title": "2018 international conference on communications (COMM)",
    "id": "10.1109/ICComm.2018.8430148",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "page": "193-196",
    "publisher": "IEEE Press",
    "publisher-place": "Bucharest",
    "title": "Optimized super fast support vector classifiers using python and acceleration of RBF computations",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s11227-016-1633-y",
    "ISSN": "0920-8542",
    "URL": "https://doi.org/10.1007/s11227-016-1633-y",
    "abstract": "In this paper, we show that the GPU (graphics processing unit) can be used not only for processing graphics, but also for high speed computing. We provide a comparison between the times taken on the CPU and GPU to perform the training and testing of a back-propagation artificial neural network. We implemented two neural networks for recognizing handwritten digits; one consists of serial code executed on the CPU, while the other is a GPU-based version of the same system which executes in parallel. As an experiment for performance evaluation, a system for neural network training on the GPU is developed to reduce training time. The programming environment that the system is based on is CUDA which stands for compute unified device architecture, which allows a programmer to write code that will run on an NVIDIA GPU card. Our results over an experiment of digital image recognition using neural network confirm the speed-up advantages by tapping on the resources of GPU. Our proposed model has an advantage of simplicity, while it shows on par performance with the state-of-the-arts algorithms.",
    "author": [
      {
        "family": "Brito",
        "given": "Ricardo"
      },
      {
        "family": "Fong",
        "given": "Simon"
      },
      {
        "family": "Cho",
        "given": "Kyungeun"
      },
      {
        "family": "Song",
        "given": "Wei"
      },
      {
        "family": "Wong",
        "given": "Raymond"
      },
      {
        "family": "Mohammed",
        "given": "Sabah"
      },
      {
        "family": "Fiaidhi",
        "given": "Jinan"
      }
    ],
    "container-title": "J. Supercomput.",
    "id": "10.1007/s11227-016-1633-y",
    "issue": "10",
    "issued": {
      "date-parts": [
        [
          2016,
          10
        ]
      ]
    },
    "keyword": "Parallel execution, NVIDIA, CUDA, Artificial neural networks",
    "page": "3868-3886",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "GPU-enabled back-propagation artificial neural network for digit recognition in parallel",
    "type": "article-journal",
    "volume": "72"
  },
  {
    "ISBN": "9780889867062",
    "abstract": "Data mining applications have facilitated knowledge discovery in a multitude of areas including marketing, biological and geological sciences, and image processing. Through well established mathematical algorithms related to pattern recognition, predictive modeling, and anomaly detection, warehouses of data have been explored and interpreted with the purposes of helping researchers unveil and understand complex patterns. In this paper, we present the development of a web-based Data Mining Utility, created with the ultimate goal of allowing medical researchers to detect new artifacts that have been previously obscured through conventional signal processing techniques in neurological datasets. This web tool is powered by Data to Knowledge, which was created by the Automated Learning Group of the National Center for Supercomputing Applications at the University of Illinois, by integrating a vast library of customizable data mining techniques into a unified programming environment. Using this framework, along with the D2K Web Service, this Data Mining Utility will enhance an established Multi-Site Pediatric Network for fMRI in Childhood Epilepsy, as a means for researchers to gain further insight on medical case studies.",
    "author": [
      {
        "family": "Sanchez",
        "given": "Daniel"
      },
      {
        "family": "Shirk",
        "given": "Andrew"
      },
      {
        "family": "Sanchez",
        "given": "Danmary"
      },
      {
        "family": "Marrero",
        "given": "Adrian"
      }
    ],
    "collection-title": "SEA ’07",
    "container-title": "Proceedings of the 11th IASTED international conference on software engineering and applications",
    "id": "10.5555/1647636.1647741",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "web services, distributed computing, data mining",
    "page": "603-608",
    "publisher": "ACTA Press",
    "publisher-place": "USA",
    "title": "Introducing the data mining utility: A web-based application for data mining experimentation on neurological datasets",
    "title-short": "Introducing the data mining utility",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130829293",
    "author": [
      {
        "family": "Deitel",
        "given": "Harvey M."
      },
      {
        "family": "Deitel",
        "given": "Paul J."
      },
      {
        "family": "Nieto",
        "given": "T. R."
      }
    ],
    "id": "10.5555/552832",
    "issued": {
      "date-parts": [
        [
          1998
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "The complete visual basic 6 training course",
    "type": "book"
  },
  {
    "DOI": "10.1145/3017680.3017749",
    "ISBN": "9781450346986",
    "URL": "https://doi.org/10.1145/3017680.3017749",
    "abstract": "The recent introduction of computer science (CS) education into schools in many countries has led to a surge in interest in programming tools and approaches which make CS concepts and tasks engaging, motivating and accessible to all. There is renewed interest in supporting learning through physical computing, which has been shown to be motivational whilst offering opportunities for collaboration and creativity. Within this context the BBC recently led a collaborative venture in the UK to develop a portable and low-cost programmable device. The consortium funded and produced one million devices, enough for every 11-12 year-old in the UK. In this paper, we report on what we believe to be the first study to investigate the usability and affordances of the BBC micro:bit. We interviewed 15 teachers and 54 pupils in schools in England about their experiences with the device who were, in general, enthusiastic about the potential of the BBC micro:bit. We describe pupils’ experiences in terms of usability, creativity, the tangibility of the device and their learning of programming, and analyse their experiences in the context of previously reported benefits of physical computing.",
    "author": [
      {
        "family": "Sentance",
        "given": "Sue"
      },
      {
        "family": "Waite",
        "given": "Jane"
      },
      {
        "family": "Hodges",
        "given": "Steve"
      },
      {
        "family": "MacLeod",
        "given": "Emily"
      },
      {
        "family": "Yeomans",
        "given": "Lucy"
      }
    ],
    "collection-title": "SIGCSE ’17",
    "container-title": "Proceedings of the 2017 ACM SIGCSE technical symposium on computer science education",
    "id": "10.1145/3017680.3017749",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "tangibility, physical computing, creativity, K-12 computer science, BBC micro:bit",
    "page": "531-536",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\"Creating cool stuff\": Pupils’ experience of the BBC micro:bit",
    "title-short": "\"Creating cool stuff\"",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2818314.2818342",
    "ISBN": "9781450337533",
    "URL": "https://doi.org/10.1145/2818314.2818342",
    "abstract": "Learning to program in computer code has been considered one of the pillars of contemporary education with benefits that reach well beyond the skills required by the computing industry, into creativity and self-expression. Nevertheless, the execution of computer programs usually takes place on a traditional desktop computer, which has a limited repertoire of input and output interfaces to engage with the user. On the other hand, pedagogy has emphasized that physical representations and tangible interactive objects benefit learning especially for young students. In this work, we explore the benefits of learning to code for ubiquitous computers, such as robots and wearable computers, in comparison to programming for the desktop computer. For this purpose, thirty-six students participated in a within groups study that involved three types of tangibility at the target computer platform: 1) desktop with Scratch, 2) wearable with Arduino LilyPad, and 3) robotic with Lego Mindstorms. Regardless of the target platform, we employed the same desktop visual programming environment (MIT Scratch, Modkit and Enchanting) and we measured emotional engagement and assessed students’ programming skills. We found that students expressed more positive emotions while programming with the robotic rather than the desktop computer. Furthermore, tangible computing platforms didn’t affect dramatically students’ performance in computational thinking.",
    "author": [
      {
        "family": "Merkouris",
        "given": "Alexandros"
      },
      {
        "family": "Chorianopoulos",
        "given": "Konstantinos"
      }
    ],
    "collection-title": "WiPSCE ’15",
    "container-title": "Proceedings of the workshop in primary and secondary computing education",
    "id": "10.1145/2818314.2818342",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "wearable, robot, learning, experiment, embodiment, children, Ubiquitous computing",
    "page": "69-72",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Introducing computer programming to children through robotic and wearable devices",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3078072.3079740",
    "ISBN": "9781450349215",
    "URL": "https://doi.org/10.1145/3078072.3079740",
    "abstract": "Computational thinking and coding is gradually becoming an important part of K-12 education. Most parents, policy makers, teachers, and industrial stakeholders want their children to attain computational thinking and coding competences, since learning how to code is emerging as an important skill for the 21st century. Currently, educators are leveraging a variety of technological tools and programming environments, which can provide challenging and dynamic coding experiences. Despite the growing research on the design of coding experiences for children, it is still difficult to say how children of different ages learn to code, and to cite differences in their task-based behaviour. This study uses eye-tracking data from 44 children (here divided into \"kids\" [age 8-12] and \"teens\" [age 13-17]) to understand the learning process of coding in a deeper way, and the role of gaze in the learning gain and the different age groups. The results show that kids are more interested in the appearance of the characters, while teens exhibit more hypothesis-testing behaviour in relation to the code. In terms of collaboration, teens spent more time overall performing the task than did kids (higher similarity gaze). Our results suggest that eye-tracking data can successfully reveal how children of different ages learn to code.",
    "author": [
      {
        "family": "Papavlasopoulou",
        "given": "Sofia"
      },
      {
        "family": "Sharma",
        "given": "Kshitij"
      },
      {
        "family": "Giannakos",
        "given": "Michail"
      },
      {
        "family": "Jaccheri",
        "given": "Letizia"
      }
    ],
    "collection-title": "IDC ’17",
    "container-title": "Proceedings of the 2017 conference on interaction design and children",
    "id": "10.1145/3078072.3079740",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "teens, maker movement, kids, eye-tracking, coding",
    "page": "171-181",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using eye-tracking to unveil differences between kids and teens in coding activities",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICPC.2019.00028",
    "URL": "https://doi.org/10.1109/ICPC.2019.00028",
    "abstract": "As deep learning (DL) opens the way to many technological innovations in a wild range of fields, more and more researchers and developers from diverse domains start to take advantage of DLs. In many circumstances, a developer leverages a DL framework and programs the training software in the form of source code (e.g., Python, Java). However, not all of the developers across domains are skilled at programming. It is highly desirable to provide a way so that a developer could focus on how to design and optimize their DL systems instead of spending too much time on programming. To simplify the programming process towards saving time and effort especially for beginners, we propose and implement DeepVisual, a visual programming tool for the design and development of DL systems. DeepVisual represents each layer of a neural network as a component. A user can drag-and-drop components to design and build a DL model, after which the training code is automatically generated. Moreover, DeepVisual supports to extract the neural network architecture on the given source code as input. We implement DeepVisual as a PyCharm plugin and demonstrate its usefulness on two typical use cases.",
    "author": [
      {
        "family": "Xie",
        "given": "Chao"
      },
      {
        "family": "Qi",
        "given": "Hua"
      },
      {
        "family": "Ma",
        "given": "Lei"
      },
      {
        "family": "Zhao",
        "given": "Jianjun"
      }
    ],
    "collection-title": "ICPC ’19",
    "container-title": "Proceedings of the 27th international conference on program comprehension",
    "id": "10.1109/ICPC.2019.00028",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "visualization, visual programming, deep neural networks, deep learning",
    "page": "130-134",
    "publisher": "IEEE Press",
    "publisher-place": "Montreal, Quebec, Canada",
    "title": "DeepVisual: A visual programming tool for deep learning systems",
    "title-short": "DeepVisual",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3484272.3484970",
    "ISBN": "9781450390897",
    "URL": "https://doi.org/10.1145/3484272.3484970",
    "abstract": "In teaching and learning programming at first-year-university level, simple languages with small feature sets are preferable over industry-strength languages with extensive feature sets, to reduce the learners’ cognitive load. At the same time, there is increasing pressure to familiarise students with mainstream languages early in their learning journey, and these languages accumulate features as years go by. In response to these competing requirements, we developed Source, a collection of JavaScript sublanguages with feature sets just expressive enough to introduce first-year computer science students to the elements of computation. These languages are supported by a web-based programming environment custom-built for learning at beginner’s level, which provides transpiler, interpreter, virtual machine, and algebraic-stepper-based implementations of the languages, and includes tracing, debugging, visualization, type-inference, and smart-editor features. This paper motivates the choice of JavaScript as starting point and describes the syntax and semantics of the Source languages compared to their parent language, and their implementations in the system. We report our experiences in developing and improving the languages and implementations over a period of three years, teaching a total of 1561 computer science first-year students at a university.",
    "author": [
      {
        "family": "Anderson",
        "given": "Boyd"
      },
      {
        "family": "Henz",
        "given": "Martin"
      },
      {
        "family": "Low",
        "given": "Kok-Lim"
      },
      {
        "family": "Tan",
        "given": "Daryl"
      }
    ],
    "collection-title": "SPLASH-e 2021",
    "container-title": "Proceedings of the 2021 ACM SIGPLAN international symposium on SPLASH-e",
    "id": "10.1145/3484272.3484970",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "teaching programming, learning tools, learning environments, JavaScript",
    "page": "87-96",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Shrinking JavaScript for CS1",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2538862.2539024",
    "ISBN": "9781450326056",
    "URL": "https://doi.org/10.1145/2538862.2539024",
    "abstract": "This workshop will conduct an exploration of the newly released Lego Mindstorms EV3 robot platform and its applicability to the college computer science curriculum. Participants will learn about the EV3 through handouts and hands-on programming exercises. The first part of the workshop will focus on demonstrating EV3 robots as well as the STEM concepts and computing concepts they illustrate. The second part of the workshop will focus in on the new capabilities of the EV3. This workshop will be more detailed than the vendor led workshop. It will be of benefit to participants new to Mindstorms robotics as well as those with NXT/RCX experience who want to see the evolution of the platform and new components featured in the EV3. These include a revision of the controller brick hardware and software, new color and gyroscopic sensors, and increased processing and memory capabilities. The organizers have a combined 20 years of experience using Mindstorms in CS courses (including courses in introductory programming, systems, and artificial intelligence) with Lego and third party programming environments. Participants must bring a Bluetooth-capable laptop (Mac or Windows), and will have a robot, software, and kit to use for the workshop. Participants will receive a promotion code to purchase a 10",
    "author": [
      {
        "family": "Klassner",
        "given": "Frank"
      },
      {
        "family": "Schafer",
        "given": "Benjamin"
      }
    ],
    "collection-title": "SIGCSE ’14",
    "container-title": "Proceedings of the 45th ACM technical symposium on computer science education",
    "id": "10.1145/2538862.2539024",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "mindstorms, lego, educational robotics, EV3",
    "page": "745-746",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using the new lego MindStorms EV3 robotics platform in CS courses (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3341525.3387428",
    "ISBN": "9781450368742",
    "URL": "https://doi.org/10.1145/3341525.3387428",
    "abstract": "This paper reports on an intervention in introductory Computer Graphics courses, where practical coursework is transitioned from standard OpenGL Graphics APIs to the Unity Game Development Engine. Game Development Engines (GDEs) provide powerful programming tools and computing components. Software development in GDEs is facilitated by full-fledged IDEs. Complex scene modeling and image rendering are managed through a rich catalogue of rendering assets. Graphics APIs are evolving towards a lower level of hardware abstraction, reduced overhead, and multithreading capabilities. Such changes in APIs benefit software developers who build graphics engines; how much they benefit Computer Graphics education is yet to be determined. New graphics APIs represent a shift in graphics programming practices, nearly as big as programmable GPUs and shader-based APIs over a decade ago. As then, Computer Graphics instructors have to decide: either use outdated models, or again change how Computer Graphics is taught. This paper describes an educational approach that acknowledges the increasing divide between the ease of use and development speed of GDEs, and the complexity and vastness of new graphics APIs. We show the use of a GDE as software development framework, to support programming assignments covering core Computer Graphics concepts. Relying on a GDE, such graphics assignments don’t have to shy away from shader-based graphics programming, while non-graphics low-level tasks are managed by the engine itself. With our approach, we hope to contribute to the discussion about evolving best practices in teaching Computer Graphics.",
    "author": [
      {
        "family": "Hmeljak",
        "given": "Dimitrij (Mitja)"
      },
      {
        "family": "Zhang",
        "given": "Holly"
      }
    ],
    "collection-title": "ITiCSE ’20",
    "container-title": "Proceedings of the 2020 ACM conference on innovation and technology in computer science education",
    "id": "10.1145/3341525.3387428",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "game development engine, educational technology, computer-aided learning, computer graphics",
    "page": "75-81",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Developing a computer graphics course with a game development engine",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3093338.3093346",
    "ISBN": "9781450352727",
    "URL": "https://doi.org/10.1145/3093338.3093346",
    "abstract": "We present performance results obtained with a new single-node performance benchmark of the R programming environment on the many-core Xeon Phi Knights Landing and standard Xeon-based compute nodes of the Stampede supercomputer cluster at the Texas Advanced Computing Center. The benchmark consists of microbenchmarks of linear algebra kernels and machine learning functionality that includes clustering and neural network training from the R distribution. The standard Xeon-based nodes outperformed their Xeon Phi counterparts for matrices of small to medium dimensions, performing approximately twice as fast for most of the linear algebra microbenchmarks. For matrices of medium to large dimensions, the Knights Landing nodes were competitive with or outperformed the standard Xeon-based nodes with most of the linear algebra microbenchmarks, executing as much as five times faster than the standard Xeon-based nodes. For the clustering and neural network training microbenchmarks, the standard Xeon-based nodes performed up to four times faster than their Xeon Phi counterparts for many large data sets, indicating that commonly used R packages may need to be reengineered to take advantage of existing optimized, scalable kernels.",
    "author": [
      {
        "family": "McCombs",
        "given": "James R."
      },
      {
        "family": "Michael",
        "given": "Scott"
      }
    ],
    "collection-title": "PEARC ’17",
    "container-title": "Proceedings of the practice and experience in advanced research computing 2017 on sustainability, success and impact",
    "id": "10.1145/3093338.3093346",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "scalability, many-core, benchmarking, Xeon Phi, XSEDE, R",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Performance benchmarking of the r programming environment on the stampede 1.5 supercomputer",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3368308.3415397",
    "ISBN": "9781450370455",
    "URL": "https://doi.org/10.1145/3368308.3415397",
    "abstract": "Jupyter notebooks are widely used in industry and in academic research, but have only begun to make inroads into the classroom. The design of the Jupyter notebook is in many ways well suited for teaching subjects in information technology and computer science, but it is a tool that departs significantly from a standard text editor or integrated development environment, and thus carries with it several unique advantages as well as several surprising potential pitfalls. As use of Jupyter notebooks has grown, so has criticism of the notebook, for varied reasons: notebooks can behave in unexpected ways, they can be difficult to reproduce, they open up potential security issues, and they may encourage poor coding practices. A set of best practices to guide instructors and help addressing these concerns when using Jupyter notebooks in the classroom is currently lacking. This paper addresses the strengths and weaknesses of the Jupyter notebook for education, drawing on existing literature as well as the author’s experience teaching a range of courses with Jupyter notebooks for over five years, and recommends a set of best practices for teaching with the Jupyter notebook.",
    "author": [
      {
        "family": "Johnson",
        "given": "Jeremiah W."
      }
    ],
    "collection-title": "SIGITE ’20",
    "container-title": "Proceedings of the 21st annual conference on information technology education",
    "id": "10.1145/3368308.3415397",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "literate programming, jupyter notebooks, ipython",
    "page": "32-37",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Benefits and pitfalls of jupyter notebooks in the classroom",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800227.806922",
    "ISBN": "0897910311",
    "URL": "https://doi.org/10.1145/800227.806922",
    "abstract": "The long-term goal of the User Software Engineering (USE) project at the University of California, San Francisco, is to provide an integrated homogeneous programming environment for the design and development of interactive information systems. Realization of this goal involves the development of new software tools, their integration with existing tools, and the creation of an information system development methodology in which these tools are systematically used [1,2].The successful construction of interactive information systems requires the utilization of principles of user-centered design [3,4,5], combined with features traditionally associated with the separate areas of programming languages, operating systems, and data base management [6]. It has become increasingly clear that the key to being able to provide such a unified view lies in providing a unified view of data [7]. The potential benefits of such a unification are considerable, including:1) conceptual simplification of the system structure permitting, for example, joint design of data structures and data bases2) the elimination of duplication or inconsistencies among diverse software components3) the ability to achieve greater reliability in systems because of reduced dependence upon multiple software systems",
    "author": [
      {
        "family": "Wasserman",
        "given": "Anthony I."
      }
    ],
    "container-title": "Proceedings of the 1980 workshop on data abstraction, databases and conceptual modeling",
    "id": "10.1145/800227.806922",
    "issued": {
      "date-parts": [
        [
          1980
        ]
      ]
    },
    "page": "198-200",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The extension of data abstraction to database management",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1930464.1930474",
    "ISBN": "9781450305204",
    "URL": "https://doi.org/10.1145/1930464.1930474",
    "abstract": "Complexity being an essential part of our everyday and occupational life, the following question arises: Which fundamental skills do pupils need to develop, in order to be well prepared for handling future complex technological, and social, systems? We believe that general education should address this issue by cultivating computational—or rather \"informatical\"— thinking, i. e. an informatical view on the world.The educational programming environment Greenfoot consolidates the strengths of traditional microworlds with Java’s scalability [1], thus enabling the provision of rather complex systems, most notably simulations of material or traffic streams. In Greenfoot, these systems can be interactively explored and manipulated. Thus Greenfoot is not only an excellent learning environment for introductory programming courses but it is also particularly well suited to address more application-oriented issues in computer science.In a one week school project pupils in their eighth year were presented with a Greenfoot simulation of a highly simplified airport baggage handling system. Using the example of baggage handling, they got involved not only with programming but also with applied computing, namely with issues related to the field of Business Informatics (BI, German Wirtschaftsinformatik). Our aim in including applied computing issues in the school project was to present a broad image of computer science.",
    "author": [
      {
        "family": "Rick",
        "given": "Detlef"
      },
      {
        "family": "Ludwig",
        "given": "Julia"
      },
      {
        "family": "Meyer",
        "given": "Sebastian"
      },
      {
        "family": "Rehder",
        "given": "Carsten"
      },
      {
        "family": "Schirmer",
        "given": "Ingrid"
      }
    ],
    "collection-title": "Koli calling ’10",
    "container-title": "Proceedings of the 10th koli calling international conference on computing education research",
    "id": "10.1145/1930464.1930474",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "simulation, complex systems, business informatics and general education, applied computing, Greenfoot",
    "page": "68-69",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Introduction to business informatics with greenfoot using the example of airport baggage handling",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1080/13614568.2016.1152314",
    "ISSN": "1361-4568",
    "URL": "https://doi.org/10.1080/13614568.2016.1152314",
    "abstract": "Students in secondary education strive hard enough to understand basic programming concepts. With all that is known regarding the benefits of programming, little is the published evidence showing how high school students can learn basic programming concepts following innovative instructional formats correctly with the respect to gain/enhance their computational thinking skills. This distinction has caused lack of their motivation and interest in Computer Science courses. This case study presents the opinions of twenty-eight n = 28 high school students who participated voluntarily in a 3D-game-like environment created in Second Life. This environment was combined with the 2D programming environment of Scratch4SL for the implementation of programming concepts i.e. sequence and concurrent programming commands in a blended instructional format. An instructional framework based on Papert’s theory of Constructionism to assist students how to coordinate or manage better the learning material in collaborative practice-based learning activities is also proposed. By conducting a mixed-method research, before and after finishing several learning tasks, students’ participation in focus group qualitative data and their motivation based on their experiences quantitative data are measured. Findings indicated that an instructional design framework based on Constructionism for acquiring or empowering students’ social, cognitive, higher order and computational thinking skills is meaningful. Educational implications and recommendations for future research are also discussed.",
    "author": [
      {
        "family": "Pellas",
        "given": "Nikolaos"
      },
      {
        "family": "Peroutseas",
        "given": "Efstratios"
      }
    ],
    "container-title": "New Rev. Hypermedia Multimedia",
    "id": "10.1080/13614568.2016.1152314",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2017,
          1
        ]
      ]
    },
    "page": "51-79",
    "publisher": "Taylor &amp; Francis, Inc.",
    "publisher-place": "USA",
    "title": "Leveraging Scratch4SL and second life to motivate high school students’ participation in introductory programming courses: Findings from a case study",
    "title-short": "Leveraging Scratch4SL and second life to motivate high school students’ participation in introductory programming courses",
    "type": "article-journal",
    "volume": "23"
  },
  {
    "DOI": "10.1145/3408877.3439661",
    "ISBN": "9781450380621",
    "URL": "https://doi.org/10.1145/3408877.3439661",
    "abstract": "The growing interest in teaching Computer Science (CS) to K-12 students has led to the development of blocks-based programming languages (BBPLs) for young students where a program can be created by connecting blocks in a structured way. One of the benefits of a BBPL is removing the necessity to recall the syntax rules of a language. However, the visual nature of these languages makes learning and creating code difficult for children with visual impairments and blindness (VIB). Although a few BBPLs were designed for children with VIB, such environments are rarely used by sighted children. Therefore, to investigate the requirements for designing and implementing an accessible blocks-based programming environment that can be used by both students with and without VIB, we developed a BBPL environment for middle school children. The environment consists of a two-dimensional grid where a character can be moved by creating a simple blocks program. Our future plans include performing several empirical experiments to evaluate our BBPL, including the educational impact of the environment on all students and accessibility support for students with VIB. To perform the study, we also plan to prepare lessons for training the students. The results of the study will inform the design of future BBPL environments, as well as contribute toward broadening participation in computing by enabling children with visual impairments to participate fully in CS education opportunities.",
    "author": [
      {
        "family": "Tabassum",
        "given": "Moumita"
      },
      {
        "family": "Gray",
        "given": "Jeff"
      },
      {
        "family": "Smith",
        "given": "Derrick"
      }
    ],
    "collection-title": "SIGCSE ’21",
    "container-title": "Proceedings of the 52nd ACM technical symposium on computer science education",
    "id": "10.1145/3408877.3439661",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "visual impairment, blocks-based programming environment",
    "page": "1309",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing accessibility into blocks languages",
    "type": "paper-conference"
  },
  {
    "ISBN": "3832540172",
    "abstract": "Originally developed by James McCartney in 1996 and now an open source project, SuperCollider is a software package for the synthesis and control of audio in real time. Currently, it represents the state of the art in the field of audio programming: there is no other software available that is equally powerful, efficient or flexible. Yet, SuperCollider is often approached with suspicion or awe by novices, but why? One of the main reasons is the use of a textual user interface. Furthermore, like most software packages that deal with audio, SuperCollider prerequisites a series of skills, ranging from expertise in analog/digital signal processing, to musical composition, to computer science. However, as the beginner overcomes these initial obstacles and understands the powerful flexibility of SuperCollider, what once were seen as weaknesses become its strengths. SuperCollider’s features also mean versatility in advanced software applications, generality in terms of computer modelling, and expressivity in terms of symbolic representations. This book aims at providing a brief overview of, and an introduction to, the SuperCollider programming environment. It also intends to informally present, by employing SuperCollider, a series of key notions relevant to what is broadly referred to as computer music. Andrea Valle is a researcher/aggregate professor in film, photography and television at the University of Turin-DAMS, and is active as a musician and composer. He has been a SuperCollider user since 2005.",
    "author": [
      {
        "family": "Valle",
        "given": "Andrea"
      }
    ],
    "id": "10.5555/3055864",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Logos Verlag",
    "publisher-place": "DEU",
    "title": "Introduction to SuperCollider",
    "type": "book"
  },
  {
    "DOI": "10.1109/CGIV.2008.24",
    "ISBN": "9780769533599",
    "URL": "https://doi.org/10.1109/CGIV.2008.24",
    "abstract": "VRML is one of the most common and popular virtual reality development tools available in the market. This low end product is widely used in school or college. High end product such as Sense8, EON, Cartia and many others have been in the market for quite number of years. These applications have been popularly used in the big industries such as medical, automobile and infrastructure design. However, for our purpose of environment visualization and immersion, Virtools development kit was used. The main focus of this paper is to describe the approach used in producing an immersive and interactive 3D environment used to treat acrophobia. The 3D environment consists of a busy city surrounded by tall buildings. The advantages and benefit of using Virtools as virtual reality development tool is then explained.",
    "author": [
      {
        "family": "Balbed",
        "given": "Mustafa Agil Muhamad"
      },
      {
        "family": "Ibrahim",
        "given": "Nazrita"
      },
      {
        "family": "Yusof",
        "given": "Azmi Mohd"
      }
    ],
    "collection-title": "CGIV ’08",
    "container-title": "Proceedings of the 2008 fifth international conference on computer graphics, imaging and visualisation",
    "id": "10.1109/CGIV.2008.24",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "Virtual Reality, Virtools, 3D Virtual Environment",
    "page": "101-106",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Implementation of virtual environment using VIRTOOLS",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2839509.2850525",
    "ISBN": "9781450336857",
    "URL": "https://doi.org/10.1145/2839509.2850525",
    "abstract": "Block languages (e.g., Scratch, Snap!, Alice, App Inventor, Blockly) offer a gentle introduction to programming and have been adopted widely in both K-12 and CS0 courses. However, block languages often are dependent on the mouse/keyboard for input and typically are visual in their output and representation. Because of these dependencies, students with a disability (e.g., mobility limitations or vision impairment) generally are unable to use block languages, thereby reducing the opportunities for broader participation in computational learning activities. Given the increasing need to broaden the participation of computing to those with diverse skills and backgrounds, it is important that the tools used to initiate the earliest entre into computing do not erect immediate roadblocks that impede initial interest and opportunity. There are many variations of user interfaces and assistive technologies that benefit those who may have difficulties utilizing traditional Graphical User Interfaces (GUIs), but these tools often cannot be used universally across block languages. As more block languages are being developed and integrated into K12 and University curriculum, it is imperative that accessible solutions are discussed and implemented. These discussions require participation from the block language developer community, accessible computing community, and those educators who encounter accessibility needs among the students in their classrooms. The goal of this lightning talk is to call attention to the need for more accessible block-based programming environments and to spark conversation surrounding possible standard accessibility APIs that could possibly be supported by block language environment tool developers.",
    "author": [
      {
        "family": "Wagner",
        "given": "Amber"
      },
      {
        "family": "Gray",
        "given": "Jeff"
      },
      {
        "family": "Marghitu",
        "given": "Daniela"
      },
      {
        "family": "Stefik",
        "given": "Andreas"
      }
    ],
    "collection-title": "SIGCSE ’16",
    "container-title": "Proceedings of the 47th ACM technical symposium on computing science education",
    "id": "10.1145/2839509.2850525",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "broadening participation, block languages, accessibility",
    "page": "497",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Raising the awareness of accessibility needs in block languages (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3328778.3372680",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3372680",
    "abstract": "In the past several years, there has been an increase in web-based compilers that allow students to learn how to code using a browser. Many Universities use online code editors for their large Computer Science (CS) courses. For example, the CS200 course at UC Berkeley uses Jupyter Notebooks to teach Python for data science to 800+ students. All the students in the course must write and submit their code assignments in the web-browser. These online code editors for large CS courses presents several benefits. One benefit is that it becomes easier to monitor the steps that a student takes to solve a coding problem since keystrokes can be tracked using Javascript. Another benefit is that the code written by students can be stored in one central database, creating less barriers for code analysis. The CodeKey project aims to take advantage of analyzing code patterns of students in a CS course in order to find key insights. CodeKey aims to find these insights by monitoring the interactions (i.e. clicks and keystrokes) of students as each student attempts to solve a coding problem. The goal is to study the code patterns of students in a CS course in order to understand similarities and differences between students who perform well on a problem and students who do not. We also aim to study how revealing these coding patterns to a student can increase his understanding of how to solve a difficult coding problem by showing common mistakes, and by showing simple steps that lead to the correct solution.",
    "author": [
      {
        "family": "Williams",
        "given": "Renaldo"
      },
      {
        "family": "Garcia",
        "given": "Dan"
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3372680",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "web-compilers, intelligent tutor systems, computer science education",
    "page": "1357",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CodeKey - an online code editor to study code patterns and enhance student performance in CS courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3484272.3484959",
    "ISBN": "9781450390897",
    "URL": "https://doi.org/10.1145/3484272.3484959",
    "abstract": "As Scratch has become one of the most popular educational programming languages, understanding its common programming idioms can benefit both computing educators and learners. This understanding can fine-tune the curricular development to help learners master the fundamentals of writing idiomatic code in their programming pursuits. Unfortunately, the research community’s understanding of what constitutes idiomatic Scratch code has been limited. To help bridge this knowledge gap, we systematically identified idioms as based on canonical source code, presented in widely available educational materials. We implemented a tool that automatically detects these idioms to assess their prevalence within a large dataset of over 70K Scratch projects in different experience backgrounds and project categories. Since communal learning and the practice of remixing are one of the cornerstones of the Scratch programming community, we studied the relationship between common programming idioms and remixes. Having analyzed the original projects and their remixes, we observed that different idioms may associate with dissimilar types of code changes. Code changes in remixes are desirable, as they require a meaningful programming effort that spurs the learning process. The ability to substantially change a project in its remixes hinges on the project’s code being easy to understand and modify. Our findings suggest that the presence of certain common idioms can indeed positively impact the degree of code changes in remixes. Our findings can help form a foundation of what comprises common Scratch programming idioms, thus benefiting both introductory computing education and Scratch programming tools.",
    "author": [
      {
        "family": "Long",
        "given": "Xingyu"
      },
      {
        "family": "Techapalokul",
        "given": "Peeratham"
      },
      {
        "family": "Tilevich",
        "given": "Eli"
      }
    ],
    "collection-title": "SPLASH-e 2021",
    "container-title": "Proceedings of the 2021 ACM SIGPLAN international symposium on SPLASH-e",
    "id": "10.1145/3484272.3484959",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Scratch, Project remixing, Programming idioms, Novice programmers, Block-based programming",
    "page": "1-12",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The common coder’s scratch programming idioms and their impact on project remixing",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.chb.2019.03.003",
    "ISSN": "0747-5632",
    "URL": "https://doi.org/10.1016/j.chb.2019.03.003",
    "author": [
      {
        "family": "Papavlasopoulou",
        "given": "Sofia"
      },
      {
        "family": "Sharma",
        "given": "Kshitij"
      },
      {
        "family": "Giannakos",
        "given": "Michail N."
      }
    ],
    "container-title": "Comput. Hum. Behav.",
    "id": "10.1016/j.chb.2019.03.003",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2020,
          4
        ]
      ]
    },
    "keyword": "Learning strategies, Gender differences, Eye-tracking, Computational thinking, Coding",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Coding activities for children: Coupling eye-tracking with qualitative data to investigate gender differences",
    "title-short": "Coding activities for children",
    "type": "article-journal",
    "volume": "105"
  },
  {
    "DOI": "10.1109/FIE49875.2021.9637261",
    "URL": "https://doi.org/10.1109/FIE49875.2021.9637261",
    "abstract": "This Innovative Practice Full Paper presents BlocklyPar, a set of three tutorial games to move from sequential to parallel programming using a block-based visual language. Block-based tutorial games are attractive tools for introducing programming to novices. A few of existing tools can express multiple tasks running at the same time, but none of them address parallel programming concepts and terms used in the field of parallel computing. Our tutorial games are targeted for first-year Computer Science students, as a resource to anticipate parallel computing using a self-taught approach with engaging challenges. The challenges involve university students’ day-to-day tasks to make the games more meaningful for the audience, thus collaborating with the idea that everyday tasks can benefit from parallel approaches. The first game introduces the programming environment and the sequential blocks; the second introduces the concepts of tasks, resources allocation, and parallel task execution; and the third presents the concepts of computational load distribution and performance metrics for evaluating improvements in a parallel solution. The concepts are expressed through animation components and three new programming blocks. We have conducted preliminary tests with Computer Science students for evaluating the platform usage and parallel programming concepts assessed. The results suggest that the games contribute to the student’s learning on parallelism as an extension of practicing sequential programming. It can also motivate students to design parallel solutions to explore today’s multi-core and multiprocessor computers.",
    "author": [
      {
        "family": "Solórzano",
        "given": "Ana Luisa Veroneze"
      },
      {
        "family": "Charão",
        "given": "Andrea Schwertner"
      }
    ],
    "container-title": "2021 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE49875.2021.9637261",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "1-8",
    "publisher": "IEEE Press",
    "publisher-place": "Lincoln, NE, USA",
    "title": "BlocklyPar: From sequential to parallel with block-based visual programming",
    "title-short": "BlocklyPar",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s10639-023-12325-z",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-023-12325-z",
    "abstract": "While numerous studies have highlighted the potential benefits of programming environment (PE) use for children’s learning, the boundary conditions of children’s PE acceptance within the programming education context are less clear. This study fills this gap in the literature by investigating the critical determinants of children’s PE use intention and extending the boundary conditions to programming competition, computational thinking, and programming modality. A total of 1527 primary students participated in this study. Using structural equation modelling (SEM) analyses, the measurement model was validated, and the configural, metric and scalar invariance of the measurement model was established. The structural model was also confirmed, with most of the hypothesized relationships were supported. Multigroup SEM analyses were conducted to compare structural path coefficient differences across different personal moderators (i.e., gender, grade, and experience), environmental moderators (i.e., both parents’ education level), and PE use-relevant moderators (i.e., programming competition, computational thinking, and programming modality). The results revealed significant path differences in six group comparisons, with most of the path differences associated with perceived self-efficacy and perceived ease of use. It should be noted that no significant path differences were identified for the gender and programming competition group comparisons. This work serves as a pioneer study of a comprehensive understanding of the determinants and moderators of children’s PE use intention. The findings offer important theoretical implications through accommodating essential constructs within a PE acceptance framework and recommending effective strategies to improve primary students’ PE acceptance for programming learning in primary education.",
    "author": [
      {
        "family": "Cheng",
        "given": "Miaoting"
      },
      {
        "family": "Lai",
        "given": "Xiaoyan"
      },
      {
        "family": "Tao",
        "given": "Da"
      },
      {
        "family": "Lai",
        "given": "Juntong"
      },
      {
        "family": "Yang",
        "given": "Jun"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-023-12325-z",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2023,
          11
        ]
      ]
    },
    "keyword": "Programming education, Programming environment, Technology acceptance, Primary students, Multigroup structural equation modeling",
    "page": "939-969",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Children’s programming environment acceptance: Extending the boundary conditions to programming competition, computational thinking, and programming modality",
    "title-short": "Children’s programming environment acceptance",
    "type": "article-journal",
    "volume": "29"
  },
  {
    "ISBN": "9798516902383",
    "abstract": "In recent years, we have witnessed a progressive increase in enrollment in computer science education programs; this has unfortunately been matched by a constantly low representation of students with visual impairments in the area of computer science. A possible explanation for this phenomenon is the environmental aspects of teaching programming to students with visual impairment, such as input (keyboard and mouse), output (display screen), and feedback (visual information). Although there exist different techniques (e.g., Block-based programming, program visualization, and tangible interfaces) which have proven to be effective for the development of creativity and computational thinking in students, learners with visual impairments face limitations that make difficult or impossible to use them due to the dependence on visual artifacts. Therefore, there is an urgent need for interfaces that allow novice students with visual impairments and low vision to develop computational thinking skills. We addressed the challenges of learning basic programming concepts by young learners with visual impairments and low vision through a literature review. The systematic review provides a guideline for an effective design of accessible programming learning environments for novice students with visual impairments and low vision. We obtained an in-depth knowledge of features needed to make Block-based environments accessible and feedback to improve our prototype through a preliminary user study performed with nine participants. Moreover, this dissertation presents the final version of the tangible music programming tool and findings of a qualitative study performed to validate the tool. The results show that the participants could gain a deep understanding of basic programming concepts using our system.",
    "author": [
      {
        "family": "Utreras-Mercado",
        "given": "Emmanuel"
      },
      {
        "family": "Huiping",
        "suffix": "Cao"
      },
      {
        "family": "Loana",
        "suffix": "Mason"
      },
      {
        "family": "O",
        "given": "Z.",
        "suffix": "Toups"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI28416713",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "note": "AAI28416713",
    "publisher": "New Mexico State University",
    "publisher-place": "USA",
    "title": "Tangible music programming tool for students with visual impairments and low vision",
    "type": "thesis"
  },
  {
    "ISBN": "012803761X",
    "abstract": "Shared Memory Application Programming presents the key concepts and applications of parallel programming, in an accessible and engaging style applicable to developers across many domains. Multithreaded programming is today a core technology, at the basis of all software development projects in any branch of applied computer science. This book guides readers to develop insights about threaded programming and introduces two popular platforms for multicore development: OpenMP and Intel Threading Building Blocks (TBB). Author Victor Alessandrini leverages his rich experience to explain each platforms design strategies, analyzing the focus and strengths underlying their often complementary capabilities, as well as their interoperability. The book is divided into two parts: the first develops the essential concepts of thread management and synchronization, discussing the way they are implemented in native multithreading libraries (Windows threads, Pthreads) as well as in the modern C++11 threads standard. The second provides an in-depth discussion of TBB and OpenMP including the latest features in OpenMP 4.0 extensions to ensure readers skills are fully up to date. Focus progressively shifts from traditional thread parallelism to modern task parallelism deployed by modern programming environments. Several chapter include examples drawn from a variety of disciplines, including molecular dynamics and image processing, with full source code and a software library incorporating a number of utilities that readers can adapt into their own projects.Designed to introduce threading and multicore programming to teach modern coding strategies for developers in applied computingLeverages author Victor Alessandrini’s rich experience to explain each platforms design strategies, analyzing the focus and strengths underlying their often complementary capabilities, as well as their interoperabilityIncludes complete, up-to-date discussions of OpenMP 4.0 and TBBBased on the authors training sessions, including information on source code and software libraries which can be repurposed",
    "author": [
      {
        "family": "Alessandrini",
        "given": "Victor"
      }
    ],
    "edition": "1st",
    "id": "10.5555/2911144",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "publisher": "Morgan Kaufmann Publishers Inc.",
    "publisher-place": "San Francisco, CA, USA",
    "title": "Shared memory application programming: Concepts and strategies in multicore application programming",
    "title-short": "Shared memory application programming",
    "type": "book"
  },
  {
    "DOI": "10.1145/3545947.3569611",
    "ISBN": "9781450394338",
    "URL": "https://doi.org/10.1145/3545947.3569611",
    "abstract": "For CS50 at Harvard, we have long provided students with a standardized programming environment, to avoid start-of-term technical difficulties that might otherwise arise if students had to install and configure compilers, interpreters, and debuggers on their own Macs and PCs. (For many students, \"hello, world\" is challenge enough on day 0, without also encountering \"command not found\" at the same time!) We originally provided students with shell accounts on a university-managed cluster of systems. We then transitioned to a cloud-based equivalent so as to manage the systems ourselves, root access and all. We transitioned thereafter to client-side virtual machines, to scale to more students and enable GUI-based assignments. We have since transitioned to web-based environments, complete with code tabs, terminal windows, and file explorers, initially implemented atop AWS Cloud9 and now, most recently, GitHub Codespaces, an implementation of Visual Studio (VS) Code in the cloud, free for teachers and students alike. In this workshop, we’ll discuss the pedagogical and technological advantages and disadvantages of every approach and focus most of our time, hands-on, on using and configuring GitHub Codespaces itself for teaching and learning. Along the way, attendees will learn how to create their own Docker images and \"devcontainers\" for their own classes and any languages they teach. Attendees will learn what is possible educationally by writing their own VS Code extensions as well. And how, at term’s end, to \"offboard\" students to VS Code itself on their own Macs and PCs, so as to continue programming independent of Codespaces.",
    "author": [
      {
        "family": "Malan",
        "given": "David J."
      },
      {
        "family": "Carter",
        "given": "Jonathan"
      },
      {
        "family": "Liu",
        "given": "Rongxin"
      },
      {
        "family": "Zenke",
        "given": "Carter"
      }
    ],
    "collection-title": "SIGCSE 2023",
    "container-title": "Proceedings of the 54th ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3545947.3569611",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "web application, web app, text editor, terminal window, programming, integrated development environment, ide, gui, graphical user interface, editor, docker, container, command-line interface, code editor, code, cli",
    "page": "1183",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Providing students with standardized, cloud-based programming environments at term’s start (for free)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3563296",
    "URL": "https://doi.org/10.1145/3563296",
    "abstract": "Block-based programming environments, already popular in computer science education, have been successfully used to make programming accessible to end-users in domains like robotics, mobile apps, and even DevOps. Most studies of these applications have examined small programs that fit within a single screen, yet real-world programs often grow large, and editing these large block-based programs quickly becomes unwieldy. Traditional programming language features, like functions, allow programmers to decompose their programs. Unfortunately, both previous work, and our own findings, suggest that end-users rarely use these features, resulting in large monolithic code blocks that are hard to understand. In this work, we introduce a block-based system that provides users with a hierarchical, domain-specific program structure and requires them to decompose their programs accordingly. Through a user study with 92 users, we compared this approach, which we call guided program decomposition, to a traditional system that supports functions, but does not require decomposition. We found that while almost all users could successfully complete smaller tasks, those who decomposed their programs were significantly more successful as the tasks grew larger. As expected, most users without guided decomposition did not decompose their programs, resulting in poor performance on larger problems. In comparison, users of guided decomposition performed significantly better on the same tasks. Though this study investigated only a limited selection of tasks in one specific domain, it suggests that guided decomposition can benefit end-user programmers. While no single decomposition strategy fits all domains, we believe that similar domain-specific sub-hierarchies could be found for other application areas, increasing the scale of code end-users can create and understand.",
    "author": [
      {
        "family": "Ritschel",
        "given": "Nico"
      },
      {
        "family": "Fronchetti",
        "given": "Felipe"
      },
      {
        "family": "Holmes",
        "given": "Reid"
      },
      {
        "family": "Garcia",
        "given": "Ronald"
      },
      {
        "family": "Shepherd",
        "given": "David C."
      }
    ],
    "container-title": "Proc. ACM Program. Lang.",
    "id": "10.1145/3563296",
    "issue": "OOPSLA2",
    "issued": {
      "date-parts": [
        [
          2022,
          10
        ]
      ]
    },
    "keyword": "program decomposition, mobile robots, block-based programming",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Can guided decomposition help end-users write larger block-based programs? A mobile robot experiment",
    "type": "article-journal",
    "volume": "6"
  },
  {
    "DOI": "10.1145/3427596",
    "URL": "https://doi.org/10.1145/3427596",
    "abstract": "As Information and Communication Technology (ICT) literacy education has recently shifted to fostering computing thinking ability as well as ICT use, many countries are conducting research on national curriculum and evaluation. In this study, we measured Korean students’ ICT literacy levels by using the national measurement tool that assesses abilities of the IT (Information Technology) area and the CT (Computational Thinking) area. A research team revised an existing ICT literacy assessment tool for the IT test and developed a new CT test environment in which students could perform actual coding through a web-based programming tool such as Scratch. Additionally, after assessing ICT literacy levels, differences in ICT literacy levels by gender and grade were analyzed to provide evidence for national education policies. Approximately 23,000 elementary and middle school students participated in the 2018 national assessment of ICT literacy, accounting for 1",
    "author": [
      {
        "family": "Kim",
        "given": "Han Sung"
      },
      {
        "family": "Kim",
        "given": "Soohwan"
      },
      {
        "family": "Na",
        "given": "Wooyoul"
      },
      {
        "family": "Lee",
        "given": "Woon Jee"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/3427596",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2021,
          1
        ]
      ]
    },
    "keyword": "secondary education, elementary education, computational thinking, ICT literacy, 21st century abilities",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Extending computational thinking into information and communication technology literacy measurement: Gender and grade issues",
    "title-short": "Extending computational thinking into information and communication technology literacy measurement",
    "type": "article-journal",
    "volume": "21"
  },
  {
    "ISBN": "9780542825583",
    "abstract": "The focus of this dissertation work is the formulation and improvement of anemia management process involving trial-and-error. A two-stage method is adopted toward this objective. Given a medical treatment process, a discrete Markov representation is first derived as a formal translation of the treatment process to a control problem under uncertainty. A simulative numerical solution of the control problem is then obtained on-the-fly in the form of a control law maximizing the long-term benefit at each decision stage. Approximate dynamic programming methods are employed in the proposed solution. The motivation underlying this choice is that, in reality, some patient characteristics, which are critical for the sake of treatment, cannot be determined through diagnosis and remain unknown until early stages of treatment, when the patient demonstrates them upon actions by the decision maker. A review of these simulative control tools, which are studied extensively in reinforcement learning theory, is presented. Two approximate dynamic programming tools, namely SARSA and Q -learning, are introduced. Their performance in discovering the optimal individualized drug dosing policy is illustrated on hypothetical patients made up as fuzzy models for simulations. As an addition to these generic reinforcement learning methods, a state abstraction scheme for the considered application domain is also proposed. The control methods of this study, capturing the essentials of a drug delivery problem, constitutes a novel computational framework for model-free medical treatment. Experimental evaluation of the dosing strategies produced by the proposed methods against the standard policy, which is being followed actually by human experts in Kidney Diseases Program, University of Louisville, shows the advantages for use of reinforcement learning in the drug dosing problem in particular and in medical decision making in general.",
    "author": [
      {
        "family": "Muezzinoglu",
        "given": "Mehmet K."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1236791",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "note": "AAI3228046",
    "publisher": "University of Louisville",
    "publisher-place": "USA",
    "title": "Approximate dynamic programming for anemia management",
    "type": "thesis"
  },
  {
    "DOI": "10.1109/ITNG.2015.47",
    "ISBN": "9781479988280",
    "URL": "https://doi.org/10.1109/ITNG.2015.47",
    "abstract": "Several virtual communities have spread during the last decade where hundreds of people interact and socialize. Users use these communities in many fields including education, health, business, and entertainment. They use them to communicate, share information, and collaborate to achieve common goals and finish their tasks. To our knowledge, no existing literature or research studies show the benefit of using virtual world in 1) improving software engineering education, 2) enhancing the collaboration in distributed software development environment, and 3) increasing their effectiveness in the distributed developers’ progress. For this purpose we conducted a case study to test effect of integrating a virtual environment called CVE in software development environments. This study presents both qualitative and quantitative analysis of the data collected from the case study surveys and log files. It conducted a survey on the users’ preferences a. Also, it collected data about the developer’s interactions with the 3D objects, and analyzed the collected results.",
    "author": [
      {
        "family": "Bani-Salameh",
        "given": "Hani"
      },
      {
        "family": "Jeffery",
        "given": "Clinton"
      }
    ],
    "collection-title": "ITNG ’15",
    "container-title": "Proceedings of the 2015 12th international conference on information technology - new generations",
    "id": "10.1109/ITNG.2015.47",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "Virtual Environments, Social Networking, Social Interaction, IDE (Integrated Development Environment), CVEs, 3D World",
    "page": "255-260",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Evaluating the effect of 3D world integration within a social software environment",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/268084.268090",
    "ISBN": "0897918894",
    "URL": "https://doi.org/10.1145/268084.268090",
    "abstract": "Although a computer science curriculum may use a single language as its \"core\" language, many curricula require students to learn and use multiple languages for course or practicum work. Students benefit from the exposure to other languages and other language models. However, a problem arising from the multi-lingual nature of a curriculum is the necessity to learn and use different development environments and language front-ends. GRASP (Graphical Representations of Algorithms, Structures, and Processes) is a software engineering tool currently being successfully utilized as a common development environment for the multi-lingual computer science curriculum at Auburn University. Besides providing a common front-end for different languages, GRASP also provides automated visualization of source code in the form of the control structure diagram and the complexity profile graph. This paper describes GRASP and its current use in the computer science curriculum. GRASP is freely available via the Internet at the following URL: http://www.eng.auburn.edu/grasp",
    "author": [
      {
        "family": "Hendrix",
        "given": "T. Dean"
      },
      {
        "family": "Barowski",
        "given": "Larry A."
      },
      {
        "family": "Cross",
        "given": "James H."
      }
    ],
    "collection-title": "SIGCSE ’97",
    "container-title": "Proceedings of the twenty-eighth SIGCSE technical symposium on computer science education",
    "id": "10.1145/268084.268090",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "page": "20-24",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A visual development environment for multi-lingual curricula",
    "type": "paper-conference"
  },
  {
    "ISBN": "0387898816",
    "abstract": "Ecology is more quantitative and theory-driven than ever before, and A Primer of Ecology with R combines an introduction to the major theoretical concepts in general ecology with a cutting edge open source tool, the R programming language. Starting with geometric growth and proceeding through stability of multispecies interactions and species-abundance distributions, this book demystifies and explains fundamental ideas in population and community ecology. Graduate students in ecology, along with upper division undergraduates and faculty, will find this to be a useful overview of important topics. In addition to the most basic topics, this book includes construction and analysis of demographic matrix models, metapopulation and source-sink models, host-parasitoid and disease models, multiple basins of attraction, the storage effect, neutral theory, and diversity partitioning. Several sections include examples of confronting models with data. Chapter summaries and problem sets at the end of each chapter provide opportunities to evaluate and enrich one’s understanding of the ecological ideas that each chapter introduces. R is rapidly becoming the lingua franca of quantitative sciences, and this text provides a tractable introduction to using the R programming environment in ecology. An appendix provides a general introduction, and examples of code throughout each chapter give readers the option to hone their growing R skills. \"The distinctive strength of this book is that truths are mostly not revealed but discovered, in the way that R-savvy ecologistsempirical and theoreticalwork and think now. For readers still chained to spreadsheets, working through this book could be a revolution in their approach to doing science.\" (Stephen P. Ellner, Cornell University) \"One of the greatest strengthsis the integration of ecological theory with examples ... pulled straight from the literature.\" (James R. Vonesh, Virginia Commonwealth University)",
    "author": [
      {
        "family": "Henry",
        "given": "M."
      },
      {
        "family": "Stevens",
        "given": "H."
      }
    ],
    "edition": "1st",
    "id": "10.5555/1717944",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "A primer of ecology with r",
    "type": "book"
  },
  {
    "DOI": "10.1145/1273039.1273042",
    "ISSN": "0362-1340",
    "URL": "https://doi.org/10.1145/1273039.1273042",
    "abstract": "The article describes an IDE for functional programming, called WinHIPE. It provides an interactive and flexible tracer, as well as a powerful visualization and animation system. The former tool is based on the rewriting model of evaluation, and the latter provides automatic generation of visualizations and animations, friendly support for customization, maintenance and exportation of animations to the Web, and facilities to cope with large scale. Its main advantage over other visualization systems is an effortless approach to animation creation and maintenance, based on generating visualizations and animations automatically, as a side effect of program execution. Finally, we briefly describe our experience using the system during several years in educational settings.",
    "author": [
      {
        "family": "Pareja-Flores",
        "given": "Cristóbal"
      },
      {
        "family": "Urquiza-Fuentes",
        "given": "Jamie"
      },
      {
        "family": "Velázquez-Iturbide",
        "given": "J. Ángel"
      }
    ],
    "container-title": "SIGPLAN Not.",
    "id": "10.1145/1273039.1273042",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2007,
          3
        ]
      ]
    },
    "keyword": "tracing, term rewriting, programming environments, program visualization, program animation, functional programming, expression evaluation",
    "page": "14-23",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "WinHIPE: An IDE for functional programming based on rewriting and visualization",
    "title-short": "WinHIPE",
    "type": "article-journal",
    "volume": "42"
  },
  {
    "DOI": "10.1016/j.chb.2018.11.043",
    "ISSN": "0747-5632",
    "URL": "https://doi.org/10.1016/j.chb.2018.11.043",
    "author": [
      {
        "family": "Cheng",
        "given": "Gary"
      }
    ],
    "container-title": "Comput. Hum. Behav.",
    "id": "10.1016/j.chb.2018.11.043",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          3
        ]
      ]
    },
    "page": "361-372",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Exploring factors influencing the acceptance of visual programming environment among boys and girls in primary schools",
    "type": "article-journal",
    "volume": "92"
  },
  {
    "ISBN": "0131478230",
    "abstract": "Praise for Mark Sobell’s Books “I keep searching for books that collect everything you want to know about a subject in one place, and keep getting disappointed. Usually the books leave out some important topic, while others go too deep in some areas and must skim lightly over the others. A Practical Guide to Red Hat® Linux® is one of those rare books that actually pulls it off. Mark G. Sobell has created a single reference for Red Hat Linux that cannot be beat! This marvelous text (with a 4-CD set of Linux Fedora Core 2 included) is well worth the price. This is as close to an ’everything you ever needed to know’ book that I’ve seen. It’s just that good and rates 5 out of 5.” -Ray Lodato, Slashdot contributor “Mark Sobell has written a book as approachable as it is authoritative.” -Jeffrey Bianchine, Advocate, Author, Journalist “Excellent reference book, well suited for the sysadmin of a linux cluster, or the owner of a PC contemplating installing a recent stable linux. Don’t be put off by the daunting heft of the book. Sobell has striven to be as inclusive as possible, in trying to anticipate your system administration needs.” -Wes Boudville, Inventor “A Practical Guide to Red Hat® Linux® is a brilliant book. Thank you Mark Sobell.” -C. Pozrikidis, University of California at San Diego “This book presents the best overview of the Linux operating system that I have found. . . . It should be very helpful and understandable no matter what the reader’s background is: traditional UNIX user, new Linux devotee, or even Windows user. Each topic is presented in a clear, complete fashion and very few assumptions are made about what the reader knows. . . . The book is extremely useful as a reference, as it contains a 70-page glossary of terms and is very well indexed. It is organized in such a way that the reader can focus on simple tasks without having to wade through more advanced topics until they are ready.” -Cam Marshall, Marshall Information Service LLC, Member of Front Range UNIX Users Group FRUUG, Boulder, Colorado “Conclusively, this is THE book to get if you are a new Linux user and you just got into RH/Fedora world. There’s no other book that discusses so many different topics and in such depth.” -Eugenia Loli-Queru, Editor in Chief, OSNews.comThe Most Useful Linux Tutorial and Reference Ever, with Hundreds of High-Quality Examples Covering Every Linux Distribution!To be truly productive with Linux, you need to thoroughly master the shells and the command line. Until now, you had to buy two books to gain that mastery: a tutorial on fundamental Linux concepts and techniques, plus a separate reference. Worse, most Linux references offer little more than prettied-up man pages. Now, there’s a far better solution. Renowned Linux expert Mark Sobell has brought together comprehensive, insightful guidance on the tools system administrators, developers, and power users need most, and an outstanding day-to-day reference, both in the same book.This book is 100 percent distribution and release agnostic: You can use it on any Linux system, now and for years to come. What’s more, it’s packed with hundreds of high-quality examples: better examples than you’ll find in any other Linux guidebook. This is Linux from the ground up: the clearest explanations and most useful knowledge about everything from filesystems to shells, editors to utilities, and programming tools to regular expressions. And when you need instant answers, you’ll constantly turn to Sobell’s comprehensive command reference section-organized and tabbed for easy, fast access!Don’t settle for yesterday’s Linux guidebook. Get the one book that meets today’s challenges-and tomorrow’s!A Practical Guide to Linux® Commands, Editors, and Shell Programming is the most useful, most comprehensive Linux tutorial and reference you can find. It’s the only book to deliver Better, more realistic examples covering tasks you’ll actually need to perform Deeper insight, based on Sobell’s immense knowledge of every Linux nook and cranny More practical explanations of more than eighty core utilities, from aspell to xargs Techniques for implementing secure communications using ssh and scp-plus dozens of tips for making your system more secure A superior introduction to the Linux programming environment, including make, gcc, gdb, CVS, and much more Expert guidance on basic and advanced shell programming using bash and tcsh Tips and tricks for customizing the shell and using it interactively from the command line Thorough guides to vim and emacs, designed to help you get productive fast and maximize your editing efficiency Dozens of exercises to help you practice and gain confidence Instructions for using Apt, yum, and BitTorrent for keeping your system up to date automatically And much more, including coverage of gawk, sed, find, sort, bzip2, and regular expressions",
    "author": [
      {
        "family": "Sobell",
        "given": "Mark G."
      }
    ],
    "id": "10.5555/1051260",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "A practical guide to linux commands, editorsnd shell programming, a",
    "type": "book"
  },
  {
    "abstract": "Cultures deal with their environments by adapting to them and simultaneously changing them. This is particularly true for technological cultures, such as the dynamic culture of computer users. To date, the ability to change computing environments in non-trivial ways has been dependent upon the skill of programming. Because this skill has been hard to acquire, most computer users must adapt to computing environments created by a small number of programmers. In response to the scarcity of programming ability, the computer science community has concentrated on producing general-purpose tools that cover wide spectrums of applications. As a result, contemporary programming languages largely ignore the intricacies arising from complex interactions between different people solving concrete problems in specific domains.This dissertation describes Agentsheets, a substrate for building domain-oriented, visual, dynamic programming environments that do not require traditional programming skills. It discusses how Agentsheets supports the relationship among people, tools, and problems in the context of four central themes: (1) Agentsheets features a versatile construction paradigm to build dynamic, visual environments for a wide range of problem domains such as art, artificial life, distributed artificial intelligence, education, environmental design, and computer science theory. The construction paradigm consists of a large number of autonomous, communicating agents organized in a grid, called the agentsheet. Agents utilize different communication modalities such as animation, sound, and speech. (2) The construction paradigm supports the perception of programming as problem solving by incorporating mechanisms to incrementally create and modify spatial and temporal representations. (3) To interact with a large number of autonomous entities Agentsheets postulates participatory theater, a human-computer interaction scheme combining the advantages of direct manipulation and delegation into a continuous spectrum of control and effort. (4) Metaphors serve as mediators between problem solving-oriented construction paradigms and domain-oriented applications. Metaphors are used to represent application semantics by helping people to conceptualize problems in terms of concrete notions. Furthermore, metaphors can simplify the implementation of applications. Application designers can explore and reuse existing applications that include similar metaphors.",
    "author": [
      {
        "family": "Repenning",
        "given": "Alexander"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/193426",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "note": "UMI Order No. GAX94-23532",
    "publisher": "University of Colorado at Boulder",
    "publisher-place": "USA",
    "title": "Agentsheets: A tool for building domain-oriented dynamic, visual environments",
    "title-short": "Agentsheets",
    "type": "thesis"
  },
  {
    "ISBN": "9798662455146",
    "abstract": "The goal of traditional optimizations is to map applications onto limited machine resources such that application performance is maximized while application semantics (program correctness), is preserved. Semantics is thought of as a unique mapping from inputs to outcomes. Relaxing application semantics through approximations has the potential of orders of magnitude performance improvements by trading off outcome quality for resource usage. Here, an execution outcome is not only based on its inputs but also resource availability and user quality expectations.Emerging approximation techniques provides various ways to trade-off output quality for lower resource consumption. However, as a developer, the guidance and support on how to utilize the power of approximation in everyday applications are limited and rarely discussed in recent works. The offline training overhead to support approximation is usually huge, but often be treated as \"free.\" Besides, it is surprising that end-users involvement is always overlooked when determining the quality notion, which should be highly subjective. Finally, supporting approximation in a multi-programming environment is crucial to let approximation be widely accepted as a general technique.In this dissertation, I introduce Rapids, Reconfiguration, Approximation, Preferences, Implementation, Dependencies, and Structure, a framework for developing and executing applications suitable for dynamic configuration management for approximate computing. The main contribution of Rapids is its design to address the above concerns through exploiting the different expertise/strengths of the three actors (developers, users, applications) involved. I conduct comprehensive experiments and show that Rapids is adaptive and extendable by providing customizable configuration spaces for developers and the support for customizable quality for end-users. It has low overheads and small cross-platform porting costs. I also introduce an extension of Rapids, Rapids-M (Rapids for Multiprogramming), which is the first system that discusses cross-application approximation management. The target is to understand and overcome the challenges in approximation management fundamentally, then let both developers and end-users benefit from approximation with little extra efforts so that a wider audience can accept the technique.",
    "author": [
      {
        "family": "Liu",
        "given": "Liu"
      },
      {
        "family": "Isaacman",
        "given": "Sibren"
      },
      {
        "family": "Zhang",
        "given": "Desheng"
      },
      {
        "family": "Martin",
        "given": "Richard"
      },
      {
        "family": "Yu",
        "given": "Linbin"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI27735970",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "note": "AAI27735970",
    "publisher": "Rutgers The State University of New Jersey, School of Graduate Studies",
    "title": "Trading quality for resource consumption through approximation management",
    "type": "thesis"
  },
  {
    "ISBN": "9781450377980",
    "abstract": "This foreword sketches the history of the Eclipse project. It then presents the context of the present workshop, the eclipse Technology Exchange (eTX), which was held on October 24, 2004 at OOPSLA 2004, Vancouver, British Columbia, Canada.&lt;b&gt;The Eclipse Project&lt;/b&gt;The Eclipse Project began in April 1999 at IBM’s OTI laboratory. It was initially conceived as a successor product for the VisualAge family of software development tools. VisualAge was a commercially successful IDE, but it was also a closed environment built on proprietary APIs. It did not integrate well with other vendors’ tools, and only the IBM/OTI team could enhance or extend the product. Moreover, it was becoming apparent from customer experience that more was required than a simple re-write of VisualAge. In fact, there was growing demand for a tool integration platform — a programming environment that would provide kernel IDE functionality, but also allow developers, third party vendors and users to seamlessly add their own extensions, personalizations, and enhancements.The Eclipse team set out to identify the essential kernel concepts underlying the VisualAge product line (or any other IDE for that matter). In effect, they wanted to strip out all of the functionality within an IDE that was specific to a particular programming language, development task, or programming model. The hope was that there would be substantial residual function left behind, that could then be restructured to form a content-neutral, and programming language-neutral, foundation on which IDEs and similar products could be built from components. It was a bold venture, since there was no guarantee that anything practically useful would result.What they discovered was Eclipse: a tool integration platform together with a set of components (plugins, in the Eclipse vernacular) that could be seamlessly assembled into a wide variety of software development products. The Java Development Toolkit (JDT) — the Eclipse Java IDE — became their proof-point. It was built in parallel by a separate team, which operated independently from the Eclipse Platform project. The JDT team had no special privileges; they had to use the same APIs as any third party product and were allowed no \"back door\" access to Platform kernel functionality. The intent was that, despite these constraints, the finished JDT should be indistinguishable from a purpose-built, vertically integrated IDE product like VisualAge. This goal was realized, the Eclipse Project was a success, and the Eclipse Community was born.In the years since the Eclipse code base was released into open source by IBM, its growth has been nothing short of spectacular. Tens of thousands download the Eclipse SDK every week from over fifty mirror sites around the globe. Thousands of Eclipse plugins are now available from open source and commercial suppliers. Software vendors are now shipping several hundred commercial products based on Eclipse. Approximately 60 companies are members of the Eclipse Foundation, which hosts Eclipse open source development. The first Eclipse Developer Conference (EclipseCON 2004) was held in February 2004 in Anaheim, California. Over 220 companies and organizations from nearly 25 countries were represented.&lt;b&gt;ECLIPSE AND COMPUTER SCIENCE RESEARCH&lt;/b&gt;It has been particularly interesting to see the uptake of Eclipse within the research community. In retrospect one could perhaps have anticipated this. Computing is, after all, an empirical discipline — ideas must be implemented to be validated. For software researchers in particular, the computer becomes our laboratory. We necessarily build on the work of those who have gone before, and of course as time progresses our technology pyramids keep getting higher. Complexity is our bane: the low-hanging fruit were picked long ago, and most interesting problems are just not simple. Consequently, experimentation usually requires complex infrastructure, plumbing, as we often call it. Most researchers spend far too much time building (and rebuilding, and fixing) this plumbing, and far too little time actually developing new ideas. Given the nature of research, there are seldom any applicable standards for such infrastructure (these only come much later when the research has matured into products). Consequently researchers up to now have had to live and work in their own vertical towers, sharing their ideas but only infrequently sharing code. The only common programming platform among researchers was \"emacs\", and while this continues to be very flexible, it lags far behind industrial-scale IDEs in terms of functionality.But Eclipse changes this context. It provides a means to create and share that necessary common infrastructure, particularly for investigators in such areas as programming languages, tools, and environments. Researchers can focus more of their time on their real mission of innovation, and much less on the tedious plumbing tasks. Moreover, Eclipse-based implementations are built from commercial-quality components, resulting in robust demonstration systems that make it much easier for researchers to publicize and promote their work.What specifically does Eclipse offer researchers that makes it so attractive? First, it is an extensible platform for integrating components, which comes replete with a large number of commercial quality components out of the box. It runs on nearly all operating systems and GUI combinations, and is one of the few Java implementations that actually realizes that language’s \"write once run everywhere\" potential (rather than the typical \"write once test everywhere\" experience). Perhaps most importantly, it is available in open source with a generous non-viral license. Finally, it has tremendous visibility due to broad based industry support, which includes the backing of such powerhouse firms as IBM, HP, SAP, Intel, and many more.&lt;b&gt;ECLIPSE AND COMPUTER SCIENCE EDUCATION&lt;/b&gt;There are numerous challenges in education these days such as distance, limited resources and the recognized need to make learning a personalized and active experience. Many educators are consequently looking at how technology can address these challenges and enhance learning in the classroom and beyond. For computer science education, Eclipse has already been widely adopted as an IDE to support programming. The advantages for some are that it is free, platform independent and industrially relevant. But beyond these obvious advantages, other researchers have recognized that Eclipse provides an excellent infrastructure for developing learning tools. These tools can leverage the wealth of technology already present in the Eclipse community, as well as benefit from integration with other learning tools developed by other researchers and educators. The result of these multiple efforts is the emergence of Eclipse as an effective and powerful platform to support research in educational technologies and an improved learning experience in many settings.&lt;b&gt;THE ECLIPSE TECHNOLOGY EXCHANGE&lt;/b&gt;That idea that Eclipse would provide exactly the rich, open and robust platform that IT researchers needed was not initially an obvious one, and so it needed to be promoted within the academic community. IBM and eclipse.org set out to popularize these ideas by hosting a series of workshops and birds-of-a-feather events at various software research conferences. This ad hoc program gradually evolved into the eclipse Technology Exchange (eTX) workshops, the most recent of which was held at OOPSLA 2004 in Vancouver. These events provide a forum for researchers who are using Eclipse to network and share their experiences and their code.The foundation for a successful eTX is a set of high quality, refereed presentations, which serve to illustrate the breadth and vitality of the Eclipse research and teaching communities. The papers in this volume are exemplary in this regard. Several describe plugins that build on the Eclipse Platform to offer new programming tools, such as for aspect browsing; debugging distributed applications; profiling and monitoring program behaviour; visualization of complex data; and feature modeling, a technique used in product-line development to model similarities and differences of products. About half of the papers describe the use of Eclipse for teaching object-oriented programming and software engineering, in both classroom and distance settings. One such paper addresses distributed collaborative programming. Others describe Eclipse courseware plugins for code-based tutorials; visualization of computer organization concepts; and tracking student programming projects.Each paper illustrates the advantages that Eclipse offers researchers and teachers. They describe rich full-featured implementations, which can be used and modified by other researchers/teachers in their respective areas, at minimal cost in terms of incremental programming effort. This works because they all leverage the rich infrastructure and base of components provided by Eclipse. And of course by developing their own new components, each of these projects extends that base and enables others to build on their work — a virtuous cycle that is creating an eco-system around Eclipse and enriching the entire software research and teaching communities.",
    "id": "10.1145/1066129",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Eclipse ’04: Proceedings of the 2004 OOPSLA workshop on eclipse technology eXchange",
    "title-short": "Eclipse ’04",
    "type": "book"
  },
  {
    "abstract": "To date, reuse of software has not had its anticipated effect on improvements in software productivity. This is because we do not fully understand the concepts behind reusability and because there has been relatively little experimentation with reusability systems. In this research we attack these problems in three ways: (1) An investigation of the conceptual foundations of reuse for a parallel programming environment based on the Unified Computation Graph Model designed by Dr. James C. Browne at the University of Texas, Austin. (2) A realization of these concepts in a software base management system, ROPE, to support reuse in such an environment. (3) An experimental evaluation of the effectiveness of ROPE. The research addresses each of the fundamental steps of finding, understanding, modifying, and composing reusable components: (1) The problem of finding components is addressed by a new classification method, called the structured relational classification method. This method appears to be an effective technique for combining the strengths of relational methods in the maintenance and query areas with the strengths of more traditional methods in the browsing area. (2) For understanding components, we have introduced design analysis methods which basically flow from the UCGM model itself. (3) Modifying components is addressed in several ways. First through a suitable definition of generic designs and secondly through techniques for composing and decomposing graphs. (4) Composition of components is discussed in detail and a framework is laid for a calculus of composition of components. This required a formalization of some new aspects of the UCGM model and definitions and theorems about the structure of UCGM.The reusability system ROPE was built, tested and used by a variety of people. Each of the concepts discussed above was realized to some degree in the final system though the theory outstripped the implementation in several areas. This was a very substantial programming project.A fairly extensive evaluation of ROPE was done. The initial set of experiments has clearly established the effectiveness of CODE and ROPE in promoting component reuse in programs of modest size and complexity and in delivery of nearly error free programs with relatively little effort.",
    "author": [
      {
        "family": "Lee",
        "given": "Taejae"
      },
      {
        "family": "Browne",
        "given": "James C."
      },
      {
        "family": "Werth",
        "given": "John"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/915812",
    "issued": {
      "date-parts": [
        [
          1989
        ]
      ]
    },
    "note": "AAI9005613",
    "publisher": "The University of Texas at Austin",
    "title": "Software reuse in parallel programming environments",
    "type": "thesis"
  },
  {
    "ISBN": "0599358882",
    "abstract": "Over the past several years, systems are increasingly supporting a new class of multimedia applications that need to trade off Quality of Service with respect to resource constraints. In particular, soft-real time applications, such as continuous media ( CM ý) systems, have an important property, viz, they allow for graceful adaptation of the application Quality-of-Service (QoS), and therefore are able to have acceptable performance with reduced resource utilization. The use of graceful adaptation of the application for admission control leads to an integrated admission control and service negotiation protocol. This dissertation specifically deals with the policies the system adopts, which are referred to as the application admission and negotiation process. For this, we use the constructs of resource demand functions and benefit functions , which simplify the mechanisms for graceful adaptation of the applications. We adopt welfare economic theories into our system model and define a price-based framework for resource allocation and QoS support in distributed multimedia systems. By formulating a computational economy and finding its competitive equilibrium using market-based techniques that are widely used in economic theories, we can solve the distributed resource allocation problem. In the first part of the dissertation, we present a QoS-based resource management model for multimedia applications for both single resource allocation and multiple resource environments. The second part of the dissertation focuses on the problem of the Soft-QoS framework , including QoS-based admission control, negotiations, and scheduling for continuous media applications. In this dissertation, we develop novel admission control and QoS negotiation algorithms using benefit and resource demand functions. In the next chapter, our effort focuses on disk bandwidth-based admission control and scheduling in video servers. The fourth part of the dissertation involves actual system implementation and performance analysis; that is, QoS-based evaluation of the file system and distributed system services for continuous media provisioning. We designed and developed a QoS-based continuous media server system which was incorporated into the HDIMI ( Heterogeneous Distributed Multimedia Information Management for the Infosphere ) and Presto projects, which were Air Force-sponsored at the University of Minnesota. Our CM servers were implemented both on Socket programming environments and on CORBA. The comparison of performance between such various network protocols on the Internet was also done. (Abstract shortened by UMI.)",
    "author": [
      {
        "family": "Lee",
        "given": "Wonjun"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/929168",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "note": "AAI9934977",
    "publisher": "University of Minnesota",
    "publisher-place": "USA",
    "title": "Quality-of-service provisioning for multimedia applications",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3516529.3516580",
    "ISBN": "9781450384100",
    "URL": "https://doi.org/10.1145/3516529.3516580",
    "abstract": "my country’s colleges and universities have completed the transition from elite education to popular education. Under the globalized development environment, Subject Education, as an important feature and advantage of modern college education, is facing new tasks and challenges. The research on general education in my country is relatively in-depth at this stage, and the general education practice carried out by universities has also begun to bear fruit. This paper constructs the SECI model of the practical teaching of the Subject Educations of general education in colleges and universities, uses the analytic hierarchy process and the fuzzy comprehensive evaluation method to establish the evaluation system and weight indicators of the practical teaching of the Subject Educations in general education in the colleges and universities, and then proposes the practical teaching of the Subject Educations in general education in colleges and universities. Strategy.",
    "author": [
      {
        "family": "Lingyu",
        "given": "Li"
      },
      {
        "family": "Linlin",
        "given": "Jin"
      }
    ],
    "collection-title": "AICSconf ’21",
    "container-title": "2021 2nd artificial intelligence and complex systems conference",
    "id": "10.1145/3516529.3516580",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "subject educations, general education, evaluation system, SECI model",
    "page": "262-265",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Research on the practical teaching of subject educations of general education in colleges and universities based on the SECI model",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3159450.3159602",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3159602",
    "abstract": "The increasing number of students in computer science courses leads to high efforts in manual assessment of exercises. Existing assessment systems are not designed for exercises with immediate feedback in large classes. In this paper, we present an AuTomated assEssment Management System for interactive learning.ArTEMiS assesses solutions to programming exercises automatically and provides instant feedback so that students can iteratively solve the exercise. It is open source and highly scalable based on version control, regression testing and continuous integration. ArTEMiS offers an online code editor with interactive exercise instructions, is programming language independent and applicable to a variety of computer science courses. By using it, students gain experiences in version control, dependency management and continuous integration.We used ArTEMiS in 3 university and 1 online courses and report about our experiences. We figured out that ArTEMiS is suitable for beginners, helps students to realize their progress and to gradually improve their solutions. It reduces the effort of instructors and enhances the learning experience of students.",
    "author": [
      {
        "family": "Krusche",
        "given": "Stephan"
      },
      {
        "family": "Seitz",
        "given": "Andreas"
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3159602",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "version control, programming exercises, online editor, online courses, interactive exercise instructions, instant feedback, in-class exercises, continuous integration, automated assessment",
    "page": "284-289",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ArTEMiS: An automatic assessment management system for interactive learning",
    "title-short": "ArTEMiS",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/242604.242618",
    "ISSN": "0362-1340",
    "URL": "https://doi.org/10.1145/242604.242618",
    "abstract": "Object-orientation has a long tradition at the Computer Science Department, Aarhus University, starting with Simula in the early seventies. For more than 20 years there have been courses in object-oriented programming, including BETA, Smalltalk, Self and others. Recently object-orientation has started to be integrated in other parts of the curriculum such as in software engineering, distributed systems and databases. In this paper we report on this approach to teaching object-orientation. One of the advantages of object-orientation is that it provides an integrating perspective on the various areas to be taught. Besides providing a common conceptual framework, it also makes it possible to use common languages and tools that have a profound influence on the integration. Especially in the software engineering course, it has been possible to let the students experience an iterative software development method where they make a number of iterations through analysis, design and implementation. To do these iterations, it is necessary with good development tools like a CASE tool that supports code generation and reverse engineering. The Mjølner BETA System is used in the various courses as a common platform, but the students are also introduced to other object-oriented environments like Smalltalk, Self, Eiffel, and C++. The Mjølner BETA System that is a software development environment for object-oriented development based on the BETA programming language.",
    "author": [
      {
        "family": "Knudsen",
        "given": "Jørgen Lindskov"
      },
      {
        "family": "Madsen",
        "given": "Ole Lehrmann"
      }
    ],
    "container-title": "SIGPLAN Not.",
    "id": "10.1145/242604.242618",
    "issue": "12",
    "issued": {
      "date-parts": [
        [
          1996,
          12
        ]
      ]
    },
    "page": "52-62",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using object-orientation as a common basis for system development education",
    "type": "article-journal",
    "volume": "31"
  },
  {
    "ISBN": "9798209808770",
    "abstract": "In the last few years, ISEP in collaboration with FEUP and other universities, created a realistic driving simulator called DriS, which had the objective to help in researches of different areas, as civil engineer, computer graphics, psychology, education, etc.The result of this thesis pretends to help the professionals who analyse the data collected in each driving experience, in order to allow them the study of the driver’s reactions at different obstacles during a ride, at the same time.DriS simulator consists in one white screen where the driving simulators environments are projected, in one real car to make the driving experience and four cameras placed in the car. Of these four cameras, three are inside the car and one of them outside the car. Each camera is focused in one specific and critical part of the driving: the road, the driver, the pedals and the controls (gearshift, steering wheel, wiper controls, etc.).Each one of the camera records a video that is save in one computer placed in the control room, inside the Laboratório de Análise de Tráfego in FEUP. Also, a text file is saved in this computer. This text file contains some information about the driver’s experience, as it can be the car coordinates, the speed of the car, the time, etc.The work of this thesis arises in order to improve the way on how professionals analyse and perform data collected from a DriS driving experience. For that purpose, was created a video-­‐monitorization system, consists in a video application, that allows load and player four videos simultaneously as well as a text file which contains all the data collected from the experience. All of them will be time-coordinated and the user could move forward and backward through them using a slider. Also, as a basic video player, contains some buttons to control the status of the video (play, stop, pause) allowing the professionals analyse with detail the four videos and the data.Take advantage of the new progresses in software development, the application was made in C++ using the Qt library, and its integrated development environment the Qt Creator, which made easier the implementation.At the end of this report (Chapter 4) is attached a user manual in order to explain and help the professionals to use the application.",
    "author": [
      {
        "family": "Formoso",
        "given": "Laura Dapena"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI28991918",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "note": "AAI28991918",
    "publisher": "Instituto Politecnico do Porto (Portugal)",
    "title": "Video-monitorization system for a realistic driving simulator",
    "type": "thesis"
  },
  {
    "ISBN": "9781109750638",
    "abstract": "Data structures and algorithms are important foundation topics in computer science education. However, they are often complex and hard to understand. As a result, educational tools, such as algorithm visualization systems, are always needed to help students better learn and understand algorithms. The focus on graphics and sound instead of pedagogical aspects in the design of current algorithm visualization systems undermines effectiveness in teaching algorithms. In addition, most algorithm visualization systems lack features that encourage student engagement. This research addresses some required issues in creating algorithm visualization techniques by integrating learning theories and models in algorithm learning and by visualizing algorithms using computer games to fully engage students in the algorithm learning process. A new algorithm visualization and learning approach, namely Algorithm Visualization using Serious Games (AVuSG), has been introduced. It visualizes algorithms using educational or serious games to benefit from their popularity and engagement to motivate students who are learning algorithms. Moreover, it facilitates the students’ assessment using the winning-losing criteria of computer games without the need for external questions. The conceptual framework of AVuSG visualizes the algorithm to be learned using three forms of representations: Text, Flowchart, and Computer Game. Moreover, it defines three types of learning processes: Viewing,Playing, and Designing, which learners can use to engage with any of the three forms of the produced algorithm visualizations. Finally, AVuSG integrates learning theories with game design to introduce three learning models: Bloom Based, Gagne Based, and Constructivist Models, which can be adopted either by students to learn the algorithm or by the instructors to teach the algorithm depending on the learning objectives that they want to achieve. To demonstrate AVuSG framework, a software system called Serious Algorithm Game Visualizer (Serious-AV) has been developed to provide a viewer and a designer for each algorithm representation form (Text, Flowchart, and Computer Game). Serious-AV is used on two levels: by the user interacting with the visualizations and by the developer creating these visualizations. The user views the algorithm text and flowchart using the Algorithm Text Viewer and the Algorithm Flowchart Viewer, respectively, and plays its game using the Algorithm Game Viewer. On the other hand, the developer uses the three development tools: Algorithm Text Designer, Algorithm Flowchart Designer, and Algorithm Game Designer to create each of those three algorithm representation forms. The Algorithm Game Designer is an integrated development environment tailored to create computer science educational games, namely an Algorithm Game, for the Windows platform to teach about specific algorithms and data structures. To visualize an algorithm, an Algorithm Game must have a game-play that simulates the behavior of the visualized algorithm and graphics to depict the features of its data structure. Several components and editors have been added to the Algorithm Game Designer to automate and simplify the visual development of algorithm games using as little code as possible. First, it is built on top of a game engine called SAVGEngine, which contains several modules that provide the basic functionality to the newly created game in addition to a repository of ready-to-use algorithm game components that can be altered and plugged in to the new game. Moreover, the Algorithm Game Designer includes an Algorithm Game Template to be used as a blueprint in the creation of a new algorithm game by providing basic game classes that implement the algorithm game basic architecture. Furthermore, the Algorithm Game Designer contains five visual editors: Properties, Assets, Screens, Classes, and Graphic Items Editors for creating all game content visually with no code, using a flexible, user-friendly graphical user interface (GUI). Lastly, it takes advantage of current software tools and libraries, such as XNA-GS, and VS Shell-Isolated Mode to simplify game design. At last, several algorithm visualizations, including texts, flowcharts, and algorithm games prototypes, have been developed using the developed systems.",
    "author": [
      {
        "family": "Shabanah",
        "given": "Sahar Siraj"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1925240",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "note": "AAI3407063",
    "publisher": "George Mason University",
    "publisher-place": "USA",
    "title": "Simplifying algorithm learning using serious games",
    "type": "thesis"
  },
  {
    "ISBN": "032194786X",
    "abstract": "The Only Tutorial Covering BOTH iOS and Androidfor students and professionals alike! Now, one book can help you master mobile app development with both market-leading platforms: Apples iOS and Googles Android. Perfect for both students and professionals, Learning Mobile App Development is the only tutorial with complete parallel coverage of both iOS and Android. With this guide, you can master either platform, or bothand gain a deeper understanding of the issues associated with developing mobile apps. Youll develop an actual working app on both iOS and Android, mastering the entire mobile app development lifecycle, from planning through licensing and distribution. Each tutorial in this book has been carefully designed to support readers with widely varying backgrounds and has been extensively tested in live developer training courses. If youre new to iOS, youll also find an easy, practical introduction to Objective-C, Apples native language. All source code for this book, organized by chapter, is available at https://github.com/LearningMobile/BookApps Coverage includes Understanding the unique design challenges associated with mobile apps Setting up your Android and iOS development environments Mastering Eclipse development tools for Android and Xcode 5 tools for iOS Designing interfaces and navigation schemes that leverage each platforms power Reliably integrating persistent data into your apps Using lists (Android) or tables (iOS) to effectively present data to users Capturing device location, displaying it, and using it in your apps Accessing hardware devices and sensors Publishing custom apps internally within an organization Monetizing your apps on Apples AppStore or the Google Play marketplace, as well as other ways of profiting from app development, such as consulting and developer jobs",
    "author": [
      {
        "family": "Iversen",
        "given": "Jakob"
      },
      {
        "family": "Eierman",
        "given": "Michael"
      }
    ],
    "edition": "1st",
    "id": "10.5555/2613605",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Learning mobile app development: A hands-on guide to building apps with iOS and android",
    "title-short": "Learning mobile app development",
    "type": "book"
  },
  {
    "ISBN": "1782173331",
    "abstract": "Key FeaturesBuild an effective development environment in Azure using the right set of technologies. Architect a full-stack solution in the cloud to choose the best service setA comprehensive guide full of real-life examples to help you take your developer skills up a notchBook Description Microsoft Azure is a cloud computing platform that supports many different programming languages, tools, and frameworks, including both Microsoft-specific and third-party software and systems. This book starts by helping you set up a professional development environments in the cloud and integrating them with your local environment to achieve improved efficiency. You will move on to create front-end and back-end services, and then build cross-platform applications using Azure. Next you’ll get to grips with advanced techniques used to analyze usage data and automate billing operations. Following on from that, you will gain knowledge of how you can extend your on-premise solution to the cloud and move data in a pipeline. In a nutshell, this book will show you how to build high-quality, end-to-end services using Microsoft Azure. By the end of this book, you will have the skillset needed to successfully set up, develop, and manage a full-stack Azure infrastructure. What You Will LearnSet up a development environment with VMs, ARM, and Remote App Connect with VPNs to manage security and backups Establish a front-end architecture with App Service, storage, search, and caching Implement identity solutions, integrate applications, and use dataIntegrate cross-platform mobile applications with the cloud Consistently build and manage an API layer for millions of users Work with messages in the enterprise Deploy your services as an IT expert with ARM templates About the Author Roberto Freato has been an independent IT consultant since he started to work. Working for small software factories while he was studying, after his M.Sc. in Computer Science Engineering with his thesis on Consumer Cloud Computing, he got specialization in Cloud and Azure. Today, he works as a freelance consultant for major companies in Italy, helping clients design and kick off their distributed software solutions. He trains the developer community in his free time, speaking at many conferences. He has been a Microsoft MVP since 2010. Marco Parenzan is an experienced .NET developer, now also a Cloud Computing and Azure trainer. A Microsoft MVP on Azure since 2014, he is curious about the IoT business and architectures. He loves retrogaming, and he tries programming little games in his spare time. He is a community lead for 1nn0va, a local Microsoft community in Pordenone, Italy, and he likes training developers in companies and university.",
    "author": [
      {
        "family": "Freato",
        "given": "Roberto"
      },
      {
        "family": "Parenzan",
        "given": "Marco"
      }
    ],
    "id": "10.5555/3055808",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Mastering cloud development using microsoft azure",
    "type": "book"
  },
  {
    "DOI": "10.1145/3632530",
    "URL": "https://doi.org/10.1145/3632530",
    "abstract": "Background and Context: Understanding how a student programmer solves different task types in different programming languages is essential to understanding how we can further improve teaching tools to support students to be industry-ready when they graduate. It also provides insight into students’ thought processes in different task types and languages. Few (if any) studies investigate whether any differences exist between the reading and navigation behavior while completing different types of tasks in different programming languages.Objectives: We investigate whether the use of a certain programming language (C++ versus Python) and type of task (new feature versus bug fixing) has an impact on performance and eye movement behavior in students exposed to both languages and task types.Participants: Fourteen students were recruited from a Python course that taught Python as an introductory programming language.Study Method: An eye tracker was used to track how student programmers navigate and view source code in different programming languages for different types of tasks. The students worked in the Geany Integrated Development Environment (IDE, used also in their course) while eye-tracking data was collected behind the scenes making their working environment realistic compared to prior studies. Each task type had a Python and C++ version, albeit on different problems to avoid learning effects. Standard eye-tracking metrics of fixation count and fixation durations were calculated on various areas of the screen and on source code lines. Normalized versions of these metrics were used to compare across languages and tasks.Findings: We found that the participants had significantly longer average fixation duration and total fixation duration adjusted for source code length during bug fixing tasks than the feature addition tasks, indicating bug fixing is harder. Furthermore, participants looked at lines adjacent to the line containing the bug more often before looking at the buggy line itself. Participants who added a new feature correctly made their first edit earlier compared to those who failed to add the feature. Tasks in Python and C++ have similar overall fixation duration and counts when adjusted for character count. The participants spent more time fixating on the console output while doing Python tasks. Overall, task type has a bigger effect on the overall fixation duration and count compared to the programming language.Conclusions: CS educators can better support students in debugging their code if they know what they typically look at while bug fixing. For new feature tasks, training students not to fear edits to learn about the code could also be actively taught and encouraged in the classroom. CS education researchers can benefit by building better IDE plugins and tools based on eye movements that guide novices in recognizing bugs and aid in adding features. These results will lead to updating prior theories on mental models in program comprehension of how developers read and understand source code. They will eventually help in designing better programming languages and better methods of teaching programming based on evidence on how developers use them.",
    "author": [
      {
        "family": "Mansoor",
        "given": "Niloofar"
      },
      {
        "family": "Peterson",
        "given": "Cole S."
      },
      {
        "family": "Dodd",
        "given": "Michael D."
      },
      {
        "family": "Sharif",
        "given": "Bonita"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/3632530",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2024,
          1
        ]
      ]
    },
    "keyword": "eye-tracking study, learning behavior, programming education, new feature tasks, bug fixing, Python, C++, source code, Program comprehension",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Assessing the effect of programming language and task type on eye movements of computer science students",
    "type": "article-journal",
    "volume": "24"
  },
  {
    "DOI": "10.1109/FIE49875.2021.9637170",
    "URL": "https://doi.org/10.1109/FIE49875.2021.9637170",
    "abstract": "Full Paper Research-to-Practice The current COVID-19 crisis has created significant challenges for schools. The growing importance of “flipping the classroom” and the needful emphasizing of online-learning were owed to the situation. To meet these requirements, materials and tasks must be adapted. The Open Educational Resource (OER) textbook “Computational Thinking with the BBC micro:bit” was developed for the introduction of Computational Thinking (CT) for 10-14-year-old pupils in Austria’s secondary schools. Example tasks in the textbook are designed with an open end and present extensions with ideas for further development instead of ending abruptly. This article provides a guideline for a clear distinction in redesigning existing lessons following the Inverted Classroom Model (ICM) using videos for pre-class work and live task extensions for in-class work. Which parts in the learning design must remain as live lessons and which parts can be adapted for video lessons? The respective research shows that examples that have a makerspace activity as an extension are especially helpful for an efficient determination of the appropriate part in the learning design and particularly suitable for an adaptation with ICM. The central advantage of the ICM is that it responds flexibly to the individual learning needs of each student. It allows students to take their time reviewing the material at their own pace without getting left behind. The textbook used here encourages pupils to find their own solutions by explorative learning using the block-based programming environment MakeCode. Additional information to be uncovered by the learner is provided for every single step in the accompanying online wiki website. Results from observations showed that this uncover-function, being a central element of the online material, encouraged the learners to explore their own way in finding a solution with playful elements and increased motivation. The many haptic elements of a makerspace activity are in particular useful for consolidation of the learned and are predisposed for in-class work and deepening the understanding following the constructionism theory. A Design-Based Research (DBR) approach is used to create and evaluate the redesign of a proven example task in a pilot project. Teachers, who are already familiar with the BBC micro:bit and the OER textbook, were trained on how to use the “flip-version” of an example task in their lessons and asked to develop a lesson plan for implementation. The didactic approach to redesigning the material and teacher training was evaluated during the first cycle of DBR. Results from expert interviews showed that the redesigned material and training deliver a solid ground for rework and further research on a larger scale.",
    "author": [
      {
        "family": "Kastner-Hauler",
        "given": "Oliver"
      },
      {
        "family": "Tengler",
        "given": "Karin"
      },
      {
        "family": "Demarle-Meusel",
        "given": "Heike"
      },
      {
        "family": "Sabitzer",
        "given": "Barbara"
      }
    ],
    "container-title": "2021 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE49875.2021.9637170",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "1-8",
    "publisher": "IEEE Press",
    "publisher-place": "Lincoln, NE, USA",
    "title": "Adapting an OER textbook for the inverted classroom model — how to flip the classroom with BBC micro:bit example tasks",
    "title-short": "Adapting an OER textbook for the inverted classroom model — how to flip the classroom with BBC micro",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/330908.331912",
    "ISBN": "1581132131",
    "URL": "https://doi.org/10.1145/330908.331912",
    "abstract": "Object-oriented languages have been taught for some time at universities. The most common approach has been to teach those constructs required for imperative programming first and to introduce the notion of classes and objects somewhat later in the course. More recently, many educators have been promoting the notion of teaching about classes and objects first. This helps students to adopt the object-oriented paradigm at an early stage and encourages them to focus on the application structure before beginning coding. Most new textbooks have followed such an approach.While this method has clear advantages, it is not easy to realise in practice. This is partly a result of the languages used for teaching. However, we would argue that the major difficulty comes from the lack of program development environments and tools which themselves fully embrace the object-oriented paradigm.The use of Java as the language for teaching addresses some of the problems. Java with its clean support for the object-oriented paradigm is now widely regarded as a suitable choice for introductory teaching. The choice of environment, however, remains an issue.The view of the development environment as a major difficulty in Java courses is further supported by numerous reports of educators relating their experiences with teaching introductory Java courses. While Java was consistently described as an excellent language for teaching the object-oriented paradigm, the environments available are regularly identified as a significant source of problems. These may be divided into two areas: The environments are designed for professional programmers. They are too complex and have a steep learning curve. Thus valuable teaching time is spent teaching the students how to use the environment and this detracts from the principles of programming.Most of the existing environments fail to fully adopt the object-oriented paradigm. Users of the environment must deal with files, lines of code and directory hierarchies rather than classes, objects and relationships.In this seminar we will argue the case that the requirements for teaching the object-oriented paradigm and Java can only be satisfied by the provision of a program development environment specifically designed for teaching.We will introduce BlueJ, a relatively new development environment which addresses all of these issues. We will show how the unique features of this environment can be used to create an introductory Java course that fully embraces the “object first” approach and supports the presentation of a cleaner picture of the paradigm than previously possible.BlueJ is based heavily on earlier work by us on a language and environment called Blue. BlueJ is a complete Java development environment, written entirely in Java. It provides graphical support for object-oriented design, abstracts over files and the operating system and provides fully integrated support for a design, edit, compile and test cycle. In addition, BlueJ supports interactive creation of objects and interactive calling of methods of objects. This provides support for incremental development, one of the major advantages of object-orientation. It includes an easy-to-use debugger and support for applications and applets.One of the main differences between BlueJ and other environments is its distinct focus on a teaching context. It combines powerful tools with an easy-to-use interface, avoiding the complexity that creates so many problems when using existing environments in a classroom.BlueJ has been used very successfully for two semesters as Monash University.The presentation will provide the context in which the BlueJ project has been developed. We will discuss the design principles for BlueJ, the major aims of the project and our experiences with using it in class. A demonstration of the current version of BlueJ will be given. We will also demonstrate a set of examples and problems which can be used in a first Java course and show how the course structure can be improved and support teaching “objects first” with the availability of an environment that fully supports the paradigm.BlueJ is available free of charge and can be used by any interested institution. Details of how to obtain a copy of BlueJ will be provided at the seminar.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      },
      {
        "family": "Rosenberg",
        "given": "John"
      }
    ],
    "collection-title": "SIGCSE ’00",
    "container-title": "Proceedings of the thirty-first SIGCSE technical symposium on computer science education",
    "id": "10.1145/330908.331912",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "page": "429",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Objects first with java and BlueJ (seminar session)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1384271.1384395",
    "ISBN": "9781605580784",
    "URL": "https://doi.org/10.1145/1384271.1384395",
    "abstract": "Informatics education, not only in higher but also in secondary education, is often assisted by special learning software to teach the fundamental ideas of algorithms [2]. In this context pupils also learn the basics of programming using didactically reduced, textbased or visual programming languages. Therefore in Germany, in some federal countries (for example Bavaria), where the basics of algorithms are already taught in the 7th grade (age 12 to 13 years), age-based learning and programming environments, such as Karel, the robot and Kara, the programmable ladybug [1], are used. Although the design of these environments is age-based, working with them to solve algorithmic problems often causes problems in the classroom. These tools give feedback to the learners based on the analysis of a current solution attempt without taking the previous problem solving process into account. The system messages are often rather technical and therefore hardly helpful especially for weaker learners to enable them to correct arisen problems by themselves. In order to give optimal support to pupils in these situations and therefore improve the learning processes, the learner-system interaction of the used educational software environments should be enhanced and better be adapted to the learners? individual problem solving strategies.The main objective of this research project is to find out, to what extent the automated diagnosis of a problem solving strategy of a learner is possible, and to what extent this knowledge can be used to enhance the learner-system interaction. Starting from the advantages and disadvantages of standardized process observation methods, two software-based research instruments for the system supported diagnosis of the individual proceedings, using the learning environment Kara, were designed and implemented. With the first component learner-system interactions are recorded, the second one provides functions to analyse the collected data. Using test-cases gives a first idea of the quality of the solution attempts.The requirements for the software components resulted from several test scenarios with a small number of participants with different qualification in computer science (from novices to graduating computer science students). During these tests each individual was observed by a researcher and additionally interviewed afterwards. A first version of the implemented instruments was tested in case studies with more than 100 participants (12 to 13 years old) from Bavarian grammar schools to evaluate the suitability for daily use. During the studies the learners were asked to solve three given tasks in a session of 45 minutes, provided by the Kara system, individually (one pupil per computer), but communication between the test persons was allowed. The tasks required knowledge of the control structures (sequence, selection, iteration).The results of these studies indicate that it is possible to identify and to evaluate different problem solving patterns with the help of the developed instruments. To identify different types of learners? strategies it is necessary to combine the various kinds of visualizations of the collected data. To support automatic categorization pattern-recognition methods will be used. The collected ordinal (test-case results) and nominal data can be used for analyses of the correlation between different factors (for example number of error messages or program executions compared with the assessment of the solution attempt) with methods of descriptive statistics.",
    "author": [
      {
        "family": "Kiesmueller",
        "given": "Ulrich"
      },
      {
        "family": "Brinda",
        "given": "Torsten"
      }
    ],
    "collection-title": "ITiCSE ’08",
    "container-title": "Proceedings of the 13th annual conference on innovation and technology in computer science education",
    "id": "10.1145/1384271.1384395",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "tool-based analysis, secondary computer science education, problem solving process, kara, didactics of informatics, algorithms",
    "page": "353",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How do 7th graders solve algorithmic problems? A tool-based analysis",
    "type": "paper-conference"
  },
  {
    "ISBN": "0131367366",
    "abstract": "Praise for the First Edition of A Practical Guide to Linux Commands, Editors, and Shell Programming First Sobell taught people how to use Linuxnow he teaches you the power of Linux. A must-have book for anyone who wants to take Linux to the next level. Jon maddog Hall, Executive Director, Linux International This book is a very useful tool for anyone who wants to look under the hood so to speak, and really start putting the power of Linux to work. What I find particularly frustrating about man pages is that they never include examples. Sobell, on the other hand, outlines very clearly what the command does and then gives several common, easy-tounderstand examples that make it a breeze to start shell programming on ones own. As with Sobells other works, this is simple, straight-forward, and easy to read. Its a great book and will stay on the shelf at easy arms reach for a long time. Ray Bartlett, Travel Writer Overall I found this book to be quite excellent, and it has earned a spot on the very front of my bookshelf. It covers the real guts of Linuxthe command line and its utilitiesand does so very well. Its strongest points are the outstanding use of examples, and the Command Reference section. Highly recommended for Linux users of all skill levels. Well done to Mark Sobell and Prentice Hall for this outstanding book! Dan Clough, Electronics Engineer and Slackware Linux user Totally unlike most Linux books, this book avoids discussing everything via GUI and jumps right into making the power of the command line your friend. Bjorn Tipling, Software Engineer, ask.com This book is the best distro-agnostic, foundational Linux reference Ive ever seen, out of dozens of Linux-related books Ive read. Finding this book was a real stroke of luck. If you want to really understand how to get things done at the command line, where the power and flexibility of free UNIX-like OSes really live, this book is among the best tools youll find toward that end. Chad Perrin, Writer, TechRepublic Praise for Other Books by Mark G. Sobell I keep searching for books that collect everything you want to know about a subject in one place, and keep getting disappointed. Usually the books leave out some important topic, while others go too deep in some areas and must skim lightly over the others. A Practical Guide to Red Hat Linux is one of those rare books that actually pulls it off. Mark G. Sobell has created a single reference for Red Hat Linux that cant be beat! This marvelous text (with a 4-CD set of Linux Fedora Core 2 included) is well worth the price. This is as close to an everything you ever needed to know book that Ive seen. Its just that good and rates 5 out of 5. Ray Lodato, Slashdot contributor Mark Sobell has written a book as approachable as it is authoritative. Jeffrey Bianchine, Advocate, Author, Journalist Excellent reference book, well suited for the sysadmin of a Linux cluster, or the owner of a PC contemplating installing a recent stable Linux. Dont be put off by the daunting heft of the book. Sobell has strived to be as inclusive as possible, in trying to anticipate your system administration needs. Wes Boudville, Inventor A Practical Guide to Red Hat Linux is a brilliant book. Thank you Mark Sobell. C. Pozrikidis, University of California at San Diego This book presents the best overview of the Linux operating system that I have found. . . . [It] should be very helpful and understandable no matter what the readers background: traditional UNIX user, new Linux devotee, or even Windows user. Each topic is presented in a clear, complete fashion, and very few assumptions are made about what the reader knows. . . . The book is extremely useful as a reference, as it contains a 70-page glossary of terms and is very well indexed. It is organized in such a way that the reader can focus on simple tasks without having to wade through more advanced topics until they are ready. Cam Marshall, Marshall Information Service LLC, Member of Front Range UNIX Users Group [FRUUG], Boulder, Colorado Conclusively, this is THE book to get if you are a new Linux user and you just got into the RH/Fedora world. Theres no other book that discusses so many different topics and in such depth. Eugenia Loli-Queru, Editor in Chief, OSNews.com For use with all versions of Linux, including Ubuntu, Fedora, openSUSE, Red Hat, Debian, Mandriva, Mint, and now OS X, too! Get more done faster, and become a true Linux guru by mastering the command line! Learn from hundreds of realistic, high-quality examples NEW! Coverage of the Mac OS X command line and its unique tools NEW! Expert primer on automating tasks with Perl The Most Useful Linux Tutorial and Reference, with Hundreds of High-Quality Examples for Every DistributionNow Covers OS X and Perl, Too! To be truly productive with Linux, you need to thoroughly master shells and the command line. Until now, you had to buy two books to gain that mastery: a tutorial on fundamental Linux concepts and techniques, plus a separate reference. Now, theres a far better solution. Renowned Linux expert Mark Sobell has brought together comprehensive, insightful guidance on the tools system administrators, developers, and power users need most, and an outstanding day-to-day reference, both in the same book. This book is 100 percent distribution and release agnostic: You can use it with any Linux system, now and for years to come. Use Macs, too? This new edition adds comprehensive coverage of the Mac OS X command line, including essential OS X-only tools and utilities other Linux/UNIX books ignore. Packed with hundreds of high-quality, realistic examples, this book gives you Linux from the ground up: the clearest explanations and most useful knowledge about everything from filesystems to shells, editors to utilities, and programming tools to regular expressions. Sobell has also added an outstanding new primer on Perl, the most important programming tool for Linux admins seeking to automate complex, time-consuming tasks. A Practical Guide to Linux Commands, Editors, and Shell Programming, Second Edition, is the only book to deliver Better, more realistic examples covering tasks youll actually need to perform Deeper insight, based on Sobells immense knowledge of every Linux and OS X nook and cranny A start-to-finish primer on Perl for every system administrator In-depth coverage of basic and advanced Linux shell programming with bash and tcsh Practical explanations of 100 core utilities, from aspell to xargsincluding Mac OS X specific utilities from ditto to SetFile All-new coverage of automating remote backups with rsync Dozens of system security tips, including step-by-step walkthroughs of implementing secure communications using ssh and scp Tips and tricks for customizing the shell and using it interactively from the command line Complete guides to high-productivity editing with both vim and emacs A comprehensive, 286-page command reference sectionnow with revised and expanded indexes for faster access to the information you need Instructions for updating systems automatically with apt-get and yum Dozens of exercises to help you practice and gain confidence And much more, including coverage of BitTorrent, gawk, sed, find, sort, bzip2, and regular expressions",
    "author": [
      {
        "family": "Sobell",
        "given": "Mark G."
      }
    ],
    "edition": "2nd",
    "id": "10.5555/1667111",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Practical guide to linux commands, editors, and shell programming, a",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "This workshop and accompanying paper will discuss and demonstrate some of the strengths and weaknesses of the new VB.Net object-oriented programming language. It is appropriate for anyone who is contemplating a course in the new language or anyone who just wants to know more about VB.Net architecture. Database connectivity and web applications will be demonstrated in addition to some fundamental navigational and Interactive Development Environment (IDE) issues. Finally, the authors will share their experiences in developing and teaching VB.Net as a second or third language to junior and senior CS/IS majors and minors at Northwest Missouri State University.",
    "author": [
      {
        "family": "Ury",
        "given": "Gary"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/767598.767646",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2003,
          4
        ]
      ]
    },
    "page": "332-335",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Workshop on moving to visual basic.net",
    "type": "article-journal",
    "volume": "18"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Logicwriter Actual is a web app (https://www.cs.drexel.edu/ bchar/logicwriter/standardConfig/web/index.html) designed for freeform entry and linear display in Unicode of text combined with symbolic logic characters such as ≡, ∃, ∧, ⇒, λ, and Ω. It is designed for the writing done by students or instructors in foundational-level (second year) courses introducing mathematical reasoning: elementary formal or informal proofs often involving commonplace situations or computer science contexts such as program behavior. Rather than being a scaffolded practice harness [1], or an automated reasoning tool/proof checker [2, 5], the goal of Logicwriter Actual is just to make it easier for students to practice more mathematical writing. The WYSIWYG result can be copy/pasted into most document processors (for submitted or shared work), Discord or Slack channels (for chat conversations), email, code editors, etc. It is designed to be immediately usable by browser- and laptop-savvy students, so more convenient to use in a foundational course than available alternatives (word processors, LaTeX, LyX, keyboard entry of Unicode indices, Math Jax plugins, etc. [3, 4, 6]) It is designed to need minimal computer resources (runs in browser, can be delivered from any web page server), and instructor time (for student training, or tech support). Because it is just a writing tool, it is compatible with most instructional approaches that ask students to write their own proofs and explanations. Assessment is underway through student survey of usage experience and effects, and by instructor survey/interview.to see if there are perceived benefits to its approach to text entry and style of implementation as a web app.",
    "author": [
      {
        "family": "Char",
        "given": "Bruce"
      },
      {
        "family": "Earth",
        "given": "Steve"
      },
      {
        "family": "Johnson",
        "given": "Jeremy"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/3606402.3606429",
    "issue": "8",
    "issued": {
      "date-parts": [
        [
          2023,
          4
        ]
      ]
    },
    "page": "220-221",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "A web app for writing with mathematical logic",
    "type": "article-journal",
    "volume": "38"
  },
  {
    "ISBN": "1928994512",
    "abstract": "From the Publisher: All the essential information needed to take full advantage of Microsoft’s newest Web development platform. What is ASP.NET ASP.NET is a revolutionary new programming framework that enables the rapid development of powerful web applications and services. Part of the emerging Microsoft .NET Platform, it provides the easiest and most scalable way to build, deploy and run distributed web applications that can target any browser or device. ASP.NET (formerly referred to as ASP+) is more than the next version of Active Server Pages (ASP); it is a unified Web development platform that provides the services necessary for developers to build enterprise-class Web applications. ASP.NET Web Developer’s Guide will teach Web developers to quickly and easily build solutions for the Microsoft .NET platform. Programmers who are expert in asp and other languages will find this book invaluable. Features: This book will appeal to all web developers - regardless of what language they are using or what platform they will be using You can take it with you. The book comes packaged with Syngress’ revolutionary wallet-sized CD containing a printable HTML version of the book, all of the source code examples and demos of popular ASP.NET programming tools Comprehensive Coverage of the Entire .net Framework for B2B commerce About the Author Jeremy Faircloth (CCNA, MCSE, MCP+I, A+) is a Systems Analyst for Gateway, Inc. In this position, he develops and maintains enterprise-wide clientserver and Web-based technologies. As a Systems Analyst with over 10 years of real-world IT experience, he has become an expert in many areas of IT including Web development, database administration, enterprise security, network design, and project management. Mesbah Ahmed (PhD and MS, Industrial Engineering) is a Professor of Information Systems at the University of Toledo. In addition to teaching and research, he provides technical consulting and training for IT and manufacturing industries in Ohio and Michigan. His consulting experience includes systems design and implementation projects with Ford Motors, Dana Corporation, Riverside Hospital, Sears, and others. Currently, he provides IT training in the areas of Java Server, XML, and .NET technologies. He teaches graduate level courses in Database Systems, Manufacturing Systems, and Application Development in Distributed and Web Environment. Recently, he received the University of Toledo Outstanding Teaching award, and the College of Business Graduate Teaching Excellence award. He has published many research articles in academic journals such as Decision Sciences, Information &amp; Management, Naval Research Logistic Quarterly, Journal of Operations Management, IIE Transaction, and International Journal of Production Research. Chris Garrett is the Technical Manager for a large European Web agency. He has been working with Internet technologies since 1994 and has provided technical and new media expertise for some of the world s biggest brands. Chris Payne, author of Teach Yourself ASP.NET in 21 Days, is the Co-Founder and CIO of Enfused Media, Inc., which designs and develops applications to automate and facilitate business processes. Chris has taught ASP and solution techniques through articles and tutorials. Jonothon Ortiz is Vice President of Xnext, Inc. in Winter Haven, FL. Xnext, Inc. is a small, privately owned company that develops Web sites and applications for prestigious companies such as the New York Times. Wei Meng Lee is Series Editor for Syngress Publishings .NET Developer Series. He is currently lecturing at The Center for Computer Studies, Ngee Ann Polytechnic, Singapore. Wei Meng is actively involved in Web development work and conducts training for Web developers and Visual Basic programmers. He has co-authored two books on WAP. He holds a bachelor s degree in Information Systems and Computer Science from the National University of Singapore. The first book in the .NET series, VB.NET Developers Guide (ISBN: 1-928994-48-2), is currently available from Syngress Publishing.",
    "author": [
      {
        "family": "Payne",
        "given": "Chris"
      },
      {
        "family": "Lee",
        "given": "Wei Meng"
      },
      {
        "family": "Garrett",
        "given": "Chris"
      },
      {
        "family": "Ahmed",
        "given": "Mesbah"
      },
      {
        "family": "Faircloth",
        "given": "Jeremy"
      },
      {
        "family": "Ortiz",
        "given": "Jonothon"
      },
      {
        "family": "Patton",
        "given": "Robert"
      }
    ],
    "id": "10.5555/559981",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Syngress Publishing",
    "title": "ASP.NET web developer’s guide",
    "type": "book"
  },
  {
    "DOI": "10.1145/199688.199713",
    "ISBN": "089791693X",
    "URL": "https://doi.org/10.1145/199688.199713",
    "abstract": "A student internship in a suitable business or organization can augment, reinforce, and embellish material learned in the classroom. Computer Science student interns can experience such things as real-world development environments, projects which greatly exceed the scale of typical programming assignments, the utter importance of (possibly lacking) documentation, as well as diverse languages, operating systems, and hardware. Opportunities for such internships occur rarely, however, for many rural two-year colleges, especially those geographically isolated from companies which could provide this experience.Despite such a situation at our college, we still provide students with an internship experience by creating an internal organization: the Software Development Internship (SDI) with the mission to develop custom software for other departments on campus. In this paper we describe the formation of the SDI, its activities, and some of the benefits and lessons learned to date.",
    "author": [
      {
        "family": "Cohen",
        "given": "Norman"
      },
      {
        "family": "Dann",
        "given": "Wanda"
      }
    ],
    "collection-title": "SIGCSE ’95",
    "container-title": "Proceedings of the twenty-sixth SIGCSE technical symposium on computer science education",
    "id": "10.1145/199688.199713",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "page": "44-47",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using an internal internship to enhance computer science education in a two-year college",
    "type": "paper-conference"
  },
  {
    "ISBN": "1787283690",
    "abstract": "Key Features Covers the latest and advanced concepts of Python such as parallel processing with Python 3.6 Explore the Python language from its basic installation and setup to concepts such as reactive programming and microservices Get introduced to the mechanism for rewriting code in a compiled language along with ctypes and Cython tools Book Description Daniel Arbuckle’s Mastering Python covers the basics of operating in a Python development environment, before moving on to more advanced topics. Daniel presents you with real-world solutions to Python 3.6 and advanced-level concepts, such as reactive programming, microservices, ctypes, and Cython tools. You don’t need to be familiar with the Python language to use this book, as Daniel starts with a Python primer. Throughout, Daniel highlights the major aspects of managing your Python development environment, shows you how to handle parallel computation, and helps you to master asynchronous I/O with Python 3.6 to improve performance. Finally, Daniel will teach you the secrets of metaprogramming and unit testing in Python, helping you acquire the perfect skillset to be a Python expert. Daniel will get you up to speed on everything from basic programming practices to high-end tools and techniques, things that will help set you apart as a successful Python programmer. What you will learnGet to grips with the basics of operating in a Python development environment Build Python packages to efficiently create reusable code Become proficient at creating tools and utility programs in Python Use the Git version control system to protect your development environment from unwanted changes Harness the power of Python to automate other software Distribute computational tasks across multiple processors Handle high I/O loads with asynchronous I/O to get a smoother performance Take advantage of Python’s metaprogramming and programmable syntax featuresGet acquainted with the concepts behind reactive programming and RxPyAbout the Author Daniel Arbuckle gained his PhD in Computer Science from the University of Southern California. He has published numerous papers along with several books and video courses, and he is both a teacher of computer science and a professional programmer.",
    "author": [
      {
        "family": "Arbuckle",
        "given": "Daniel"
      }
    ],
    "id": "10.5555/3161092",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Daniel arbuckle’s mastering python",
    "type": "book"
  },
  {
    "ISBN": "1595933425",
    "abstract": "eTX and The Eclipse PhenomenonThe following sketches the history of the Eclipse project and the eTX events.The Eclipse ProjectThe Eclipse Project began in April 1999 at IBM’s OTI laboratory. It was initially conceived as a successor product for the VisualAge family of software development tools. VisualAge was a commercially successful IDE, but it was also a closed environment built on proprietary APIs. It did not integrate well with other vendors’ tools, and only the IBM/OTI team could enhance or extend the product. Moreover, it was becoming apparent from customer experience that more was required than a simple re-write of VisualAge. In fact, there was growing demand for a tool integration platform — a programming environment that would provide kernel IDE functionality, but also allow developers, third party vendors and users to seamlessly add their own extensions, personalizations, and enhancements.The Eclipse team set out to identify the essential kernel concepts underlying the VisualAge product line (or any other IDE for that matter). In effect, they wanted to strip out all of the functionality within an IDE that was specific to a particular programming language, development task, or programming model. The hope was that there would be substantial residual function left behind, that could then be restructured to form a content-neutral, and programming language-neutral, foundation on which IDEs and similar products could be built from components. It was a bold venture, since there was no guarantee that anything practically useful would result.What they discovered was Eclipse: a tool integration platform together with a set of components (plugins, in the Eclipse vernacular) that could be seamlessly assembled into a wide variety of software development products. The Java Development Toolkit (JDT) — the Eclipse Java IDE — became their proof-point. It was built in parallel by a separate team, which operated independently from the Eclipse Platform project. The JDT team had no special privileges; they had to use the same APIs as any third party product and were allowed no \"back door\" access to Platform kernel functionality. The intent was that, despite these constraints, the finished JDT should be indistinguishable from a purpose-built, vertically integrated IDE product like VisualAge. This goal was realized, the Eclipse Project was a success, and the Eclipse Community was born.In the years since the Eclipse code base was released into open source by IBM, its growth has been nothing short of spectacular. Tens of thousands download the Eclipse SDK every week from over fifty mirror sites around the globe. Thousands of Eclipse plugins are now available from open source and commercial suppliers. Software vendors are now shipping several hundred commercial products based on Eclipse. Over 60 companies are members of the Eclipse Foundation, which hosts Eclipse open source development. The first Eclipse Developer Conference (EclipseCON 2004) was held in February 2004 in Anaheim, California. Over 220 companies and organizations from nearly 25 countries were represented. EclipseCON 2005, another success, was held in February 2005 in Burlingame, California.Eclipse and Computer Science ResearchIt has been particularly interesting to see the uptake of Eclipse within the research community. In retrospect one could perhaps have anticipated this. Computing is, after all, an empirical discipline — ideas must be implemented to be validated. For software researchers in particular, the computer becomes our laboratory. We necessarily build on the work of those who have gone before, and of course as time progresses our technology pyramids keep getting higher. Complexity is our bane: the low-hanging fruit were picked long ago, and most interesting problems are just not simple. Consequently, experimentation usually requires complex infrastructure, plumbing, as we often call it. Most researchers spend far too much time building (and rebuilding, and fixing) this plumbing, and far too little time actually developing new ideas. Given the nature of research, there are seldom any applicable standards for such infrastructure (these only come much later when the research has matured into products). Consequently researchers up to now have had to live and work in their own vertical towers, sharing their ideas but only infrequently sharing code. The only common programming platform among researchers was \"emacs\", and while this continues to be very flexible, it lags far behind industrial-scale IDEs in terms of functionality.But Eclipse changes this context. It provides a means to create and share that necessary common infrastructure, particularly for investigators in such areas as programming languages, tools, and environments. Researchers can focus more of their time on their real mission of innovation, and much less on the tedious plumbing tasks. Moreover, Eclipse-based implementations are built from commercial-quality components, resulting in robust demonstration systems that make it much easier for researchers to publicize and promote their work.What specifically does Eclipse offer researchers that makes it so attractive? First, it is an extensible platform for integrating components, which comes replete with a large number of commercial quality components out of the box. It runs on nearly all operating systems and GUI combinations, and is one of the few Java implementations that actually realizes that language’s \"write once run everywhere\" potential (rather than the typical \"write once test everywhere\" experience). Perhaps most importantly, it is available in open source with a generous non-viral license. Finally, it has tremendous visibility due to broad based industry support, which includes the backing of such powerhouse firms as IBM, HP, SAP, Intel, and many more.Eclipse and Computer Science EducationThere are numerous challenges in education these days such as distance, limited resources and the recognized need to make learning a personalized and active experience. Many educators are consequently looking at how technology can address these challenges and enhance learning in the classroom and beyond. For computer science education, Eclipse has already been widely adopted as an IDE to support programming. The advantages for some are that it is free, platform independent and industrially relevant. But beyond these obvious advantages, other researchers have recognized that Eclipse provides an excellent infrastructure for developing learning tools. These tools can leverage the wealth of technology already present in the Eclipse community, as well as benefit from integration with other learning tools developed by other researchers and educators. The result of these multiple efforts is the emergence of Eclipse as an effective and powerful platform to support research in educational technologies and an improved learning experience in many settings.The eclipse Technology eXchangeThat idea that Eclipse would provide exactly the rich, open and robust platform that IT researchers needed was not initially an obvious one, and so it needed to be promoted within the academic community. IBM and eclipse.org set out to popularize these ideas by hosting a series of workshops and birds-of-a-feather events at various software research conferences. This ad hoc program gradually evolved into the eclipse Technology eXchange (eTX) workshops held in 2003, 2004 and 2005, the most recent of which being held at OOPSLA 2005 in San Diego. These events provide a forum for researchers who are using Eclipse to network and share their experiences and their code. The foundation for a successful eTX is a set of high quality, refereed presentations, which serve to illustrate the breadth and vitality of the Eclipse research and teaching communities. The paper presentations are combined with lively discussions which will help set the stage for future research and development using Eclipse.",
    "id": "10.1145/1117696",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Eclipse ’05: Proceedings of the 2005 OOPSLA workshop on eclipse technology eXchange",
    "title-short": "Eclipse ’05",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "The GitKit facilitates teaching Git and GitHub workflow in the context of an authentic Free and Open Source Software (FOSS) project. It is appropriate for use in software development courses ranging from high school through college. The GitKit is a snapshot of a FOSS project’s artifacts (codebase(s), issues, etc.) packaged with student learning activities, an instructor guide, and a containerized development environment. The GitKit can be used to provide a light introduction in a few class sessions, or a more comprehensive experience over 4-6 sessions. Participants will gain hands-on experience with the GitKit from both the student and instructor perspectives.",
    "author": [
      {
        "family": "Braught",
        "given": "Grant"
      },
      {
        "family": "Jackson",
        "given": "Stoney"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/3636988.3636991",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2023,
          10
        ]
      ]
    },
    "page": "21",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "GitKit: Teaching git and GitHub/GitLab workflow in an authentic context",
    "title-short": "GitKit",
    "type": "article-journal",
    "volume": "39"
  },
  {
    "DOI": "10.1016/j.future.2018.02.004",
    "ISSN": "0167-739X",
    "URL": "https://doi.org/10.1016/j.future.2018.02.004",
    "author": [
      {
        "family": "Sperhac",
        "given": "Jeanette M."
      },
      {
        "family": "Gallo",
        "given": "Steven M."
      }
    ],
    "container-title": "Future Gener. Comput. Syst.",
    "id": "10.1016/j.future.2018.02.004",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          5
        ]
      ]
    },
    "keyword": "Undergraduate education, Data analytics, Science gateway",
    "page": "833-840",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "VIDIA: A HUBzero gateway for data analytics education",
    "title-short": "VIDIA",
    "type": "article-journal",
    "volume": "94"
  },
  {
    "ISBN": "9780769531007",
    "abstract": "A range of technologies and teaching strategies may be used to improve the quality of teaching object-oriented (OO) concepts where there is a close relationship between OO analysis and design (OOAD) combined with OO programming (OOP). This study investigates the application of a number of these technologies and teaching strategies across university courses in OOAD and OOP, using an empirical approach based upon attitudinal and student performance data. The systems used include: development environments that provide two-way linkage between UML diagrams and OO program code; interactive whiteboards to allow educational demonstrations that more closely represent actual practice; and an online delivery tool for course content, messages and discussions. Close integration between the processes of OOAD and OOP courses is also investigated. The approaches significantly improved student grades, perceived levels of understanding and productivity. The integration of course concepts and assignments, and the electronic discussion boards, are key benefit drivers.",
    "author": [
      {
        "family": "Debuse",
        "given": "Justin C. W."
      },
      {
        "family": "Stiller",
        "given": "Tony"
      }
    ],
    "collection-title": "ASWEC ’08",
    "container-title": "Proceedings of the 19th australian conference on software engineering",
    "id": "10.5555/1395083.1395659",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "page": "97-103",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Technologies and strategies for integrating object-oriented analysis and design education with programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1384271.1384315",
    "ISBN": "9781605580784",
    "URL": "https://doi.org/10.1145/1384271.1384315",
    "abstract": "While collaborative approaches in the classroom have been shown to be highly beneficial for students of computer science, obstacles inherent in today’s academic environment often prevent collocated collaborative approaches from being implemented. One solution to the collocation problem may lie with tools that facilitate distributed collaboration. This paper presents RIPPLE (Remote Interactive Pair Programming and Learning Environment), a development environment for distributed synchronous collaborative programming. RIPPLE is an open source software tool. Initial user tests demonstrate positive responses from students, and the potential for long term learning, motivation, and retention benefits is significant. In addition to its benefits for students, RIPPLE is a tool for computing education researchers who wish to collect data on collaborative programming.",
    "author": [
      {
        "family": "Boyer",
        "given": "Kristy Elizabeth"
      },
      {
        "family": "Dwight",
        "given": "August A."
      },
      {
        "family": "Fondren",
        "given": "R. Taylor"
      },
      {
        "family": "Vouk",
        "given": "Mladen A."
      },
      {
        "family": "Lester",
        "given": "James C."
      }
    ],
    "collection-title": "ITiCSE ’08",
    "container-title": "Proceedings of the 13th annual conference on innovation and technology in computer science education",
    "id": "10.1145/1384271.1384315",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "programming environments, laboratory/active learning, distributed tutoring, distributed pair programming, distributed collaboration, distance learning",
    "page": "158-162",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A development environment for distributed synchronous collaborative programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3478431.3499422",
    "ISBN": "9781450390705",
    "URL": "https://doi.org/10.1145/3478431.3499422",
    "abstract": "One notable part of the academia-industry gap is the deficiency in computing ecosystem literacy, which may result in college graduates exhibiting little technical knowledge of software development tools and practices commonly used in industry. This paper presents our experience developing and teaching \"The Missing CS Class,\" the student-led 1-unit course that we created at our university to address computing ecosystem literacy. This course primarily targets lower-division students and, based on our observations as peer tutors, covers four common but crucial gaps in technical knowledge: (1) Unix-like command-line environments and tools, (2) Software testing and debugging, (3) Scripting, and (4) Version control. Based on the collected feedback from two consecutive offerings of this course during the winter and spring quarters of 2021, most surveyed students reported having increased their self-efficacy on all course topics and incorporated them into their software development workflow.To benefit the community at large, we have published all the lecture materials online at &lt;a href=\"https://missing.cs.ucdavis.edu\"&gt;https://missing.cs.ucdavis.edu&lt;/a&gt;.",
    "author": [
      {
        "family": "Gilson",
        "given": "Grant"
      },
      {
        "family": "Ott",
        "given": "Stephen"
      },
      {
        "family": "Rose Ledesma",
        "given": "Noah"
      },
      {
        "family": "Prabhu",
        "given": "Aakash"
      },
      {
        "family": "Porquet-Lupine",
        "given": "Joël"
      }
    ],
    "collection-title": "SIGCSE 2022",
    "container-title": "Proceedings of the 53rd ACM technical symposium on computer science education - volume 1",
    "id": "10.1145/3478431.3499422",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "student-led undergraduate course, computing ecosystem literacy, computer science education, academia-industry gap",
    "page": "467-473",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design and evaluation of \"the missing CS class,\" a student-led undergraduate course to reduce the academia-industry gap",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ASE.2011.6100095",
    "ISBN": "9781457716386",
    "URL": "https://doi.org/10.1109/ASE.2011.6100095",
    "abstract": "For decades now, mainstream development environments provide the same basic automations for navigating source code: mainly searching and the tree exploration of files and folders. This may imply that other automations have little additional value or too steep a learning curve for mainstream adoption. This paper investigates whether source code navigation enriched with traceability benefit basic maintenance tasks such as changing features and fixing bugs in code. To test this, we conducted a controlled experiment with 52 subjects performing real maintenance tasks on two third-party development projects: all with the same navigation tool but half of the tasks with and the other half without traceability navigation. We found that the existence of traceability profoundly affected the quality of the change tasks and fundamentally changed how software engineers navigated through source code. We show that software engineers benefit instantly from traceability, without training, which is to show that the current automations available to software engineers are by no means sufficient or the only easy ones to use.",
    "author": [
      {
        "family": "Mader",
        "given": "Patrick"
      },
      {
        "family": "Egyed",
        "given": "Alexander"
      }
    ],
    "collection-title": "ASE ’11",
    "container-title": "Proceedings of the 26th IEEE/ACM international conference on automated software engineering",
    "id": "10.1109/ASE.2011.6100095",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "page": "444-447",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Do software engineers benefit from source code navigation with traceability? – an experiment in software change management",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3291280.3291787",
    "ISBN": "9781450365680",
    "URL": "https://doi.org/10.1145/3291280.3291787",
    "abstract": "Scratch is a visual, block-based programming language, adopted as a computational thinking development tool in elementary education among many countries. Thailand has also recently included Scratch as part of the computing science course in its basic education. However, Thailand is facing a shortage of ICT teachers who are skillful in Scratch programming, especially in small provincial schools. This research aims to overcome the shortage by developing ScratchThAI, a Scratch tutorial chatbot. It is designed to assist young learners directly through a messaging platform. By giving supports through a textual conversation, more relevant advice, knowledge, and resources could be provided precisely. Different levels of each computational thinking concept are extracted and evaluated by the designed assessment algorithm. Extra predefined exercises are assigned based on the analyzed learner’s strengths and weaknesses in order to actively improving the learner’s understanding. Moreover, gamification is incorporated to engage and motivate young learners in computational thinking development.",
    "author": [
      {
        "family": "Katchapakirin",
        "given": "Kantinee"
      },
      {
        "family": "Anutariya",
        "given": "Chutiporn"
      }
    ],
    "collection-title": "IAIT ’18",
    "container-title": "Proceedings of the 10th international conference on advances in information technology",
    "id": "10.1145/3291280.3291787",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "Virtual Teaching Assistant, Virtual Scratcher, Scratch Tutoring Chatbot, Personalized Learning, Game-Based Learning, Educational Technology, Computational thinking development, AI in Education",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An architectural design of ScratchThAI: A conversational agent for computational thinking development using scratch",
    "title-short": "An architectural design of ScratchThAI",
    "type": "paper-conference"
  },
  {
    "ISBN": "0789724731",
    "abstract": "From the Publisher: Platinum Edition XHTML, XML and Java 2 is separated into several sections, each of which focuses on a specific technology, including XHTML, XML, JavaScript, Dynamic HTML, CGI programming with Perl, Server-side Programming with ASP, ColdFusion and PHP, and Java 2. Throughout the book, the authors focus on the features and benefits of each technology, giving readers a well-rounded education in current web development tools and techniques. In addition, the authors demonstrate the value of combining various technologies (such as Java and XML) for more powerful web solutions. All the code and working applications developed in the book will be available for download from Que’s web site at www.mcp.com/que Completely updated and revised with the latest information about the newest web technologies including XHTML, Java 2 and XML.",
    "author": [
      {
        "family": "Ladd",
        "given": "Eric"
      },
      {
        "family": "Watt",
        "given": "Andrew H."
      },
      {
        "family": "Morgan",
        "given": "Mike"
      }
    ],
    "id": "10.5555/557698",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "Que Corp.",
    "publisher-place": "USA",
    "title": "Platinum edition using XHTML, XML, and java 2",
    "type": "book"
  },
  {
    "ISBN": "178646795X",
    "abstract": "Key Features Configure, build, and run Android projects with Android Studio 2Test your apps using the Android emulator and learn how to manage virtual devices Explore how Android Studio 2 can be made a part of your workflow to reduce the overall development time Book Description Android Studio 2, the official IDE for Android application development, dramatically improves your workflow by letting you quickly see changes running on your device or emulator. It gives developers a unique platform by making app builds and deployment faster. This book will get you up and running with all the essential features of Android Studio 2 to optimize your development workflow. Starting off with the basic installation and configuration of Android Studio 2, this book will help you build a new project by showing you how to create a custom launcher icon and guiding you to choose your project. You will then gain an insight into the additional tools provided in Android Studio, namely the Software Development Kit (SDK) Manager, Android Virtual Device (AVD) Manager, and Javadoc. You’ll also see how to integrate Google Play Services in an Android project. Finally, you’ll become familiar with the Help section in Android Studio, which will enable you to search for support you might require in different scenarios. What you will learn Install Android Studio on your system and configure the Android Software Development KitCreate your first project and explore its structure Manage a project in Android Studio 2 with Gradle Improve your productivity while programming by getting the best of the code editor Design the user interface using layouts and see how to handle various user events Integrate Google Play services into your project efficiently Monitor your app while it’s running and constantly improve its performance About the Author Belen Cruz Zapata received her engineer’s degree in computer science from the University of Murcia in Spain, specializing in software technologies, and intelligent and knowledge technologies. She earned an MSc in computer science and is now working on her PhD in the Software Engineering Research Group from the University of Murcia. During the 2013/2014 academic year, Belen collaborated with the Universite Mohammed V-Soussi, in Rabat, Morocco. Her research is focused on usability applied to mobile health (mHealth) applications. Belen is currently working as a mobile developer for Android and iOS in the San Francisco Bay area. She is also the author of the book: Testing and Securing Android Studio Applications, Packt Publishing. To follow her projects, you can visit her personal webpage at http://www.belencruz.com and you can follow her on Twitter: @belen_cz.",
    "author": [
      {
        "family": "Zapata",
        "given": "Belen Cruz"
      }
    ],
    "edition": "2nd",
    "id": "10.5555/3055949",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Android studio 2 essentials",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Group projects are widely used in software engineering courses. With group projects come issues of group management and individual student assessment. At the University of Mary Washington, a different approach to group composition and management was used in a semester-long undergraduate software engineering course. In this approach, the student composition of each group changes at each phase of the software lifecycle. This approach offered several advantages including increased fairness in group composition, more honest peer assessments, and lower risk of group failure. In addition, this approach modeled the software development environment seen in the real-world. The details of the software engineering course and dynamic group element are described in this paper along with reactions from students and the instructor.",
    "author": [
      {
        "family": "Anewalt",
        "given": "Karen"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1629036.1629060",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2009,
          12
        ]
      ]
    },
    "page": "146-151",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Dynamic group management in a software projects course",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "ISBN": "0970284624",
    "abstract": "From the Publisher:Helping developers harness the power of Intel s new line of very long instruction word (VLIW) processors, this guide provides insight into the effective use of Itanium software development tools. Beginning with code optimization advice, including low-level explanation of the process of code compilation, this resource then gives an explanation of ways programmers can take advantage of the EPIC architecture’s parallelism. A thorough treatment of porting applications to the Itanium environment is provided along with unique insights into optimization and tuning of Itanium applications. Included are numerous examples and an extensive case history. Walter Triebel is the author of Itanium Architecture for Software Developers and is currently an adjunct professor at Fairleigh Dickinson University. He lives in Wayne, New Jersey. Joe Bissell teaches computer architecture, assembly language and embedded systems at the University of Delaware. He lives in Media, Pennsylvania. Rick Booth manages digital video production and delivery at Visible World and is the author of Inner Loops. He lives in Bensalem, Pennsylvania.",
    "author": [
      {
        "family": "Triebel",
        "given": "Walter"
      },
      {
        "family": "Booth",
        "given": "Rick"
      },
      {
        "family": "Bissell",
        "given": "Joe"
      }
    ],
    "id": "10.5555/581807",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Intel Press",
    "title": "Programming itanium-based systems",
    "type": "book"
  },
  {
    "DOI": "10.1145/3484272.3484969",
    "ISBN": "9781450390897",
    "URL": "https://doi.org/10.1145/3484272.3484969",
    "abstract": "First-year students benefit from robotics-based programming exercises by learning how to use sensors to gain information on the (changing) world surrounding the robot, how to model this information using data structures, and how to design algorithms for performing meaningful activities. Robotics-based exercises are naturally experiential and team-based and provide among the most memorable teachable moments of first-year programming courses. We summarize the pedagogical challenges that robotics-based exercises face, even under ideal circumstances, and how a university responded to these challenges. We report on the additional challenges faced in late 2020 at the same university as a result of the COVID pandemic, and how the course staff addressed these challenges using programming language implementation and network tools. The crucial components were (1) a custom-built web-based development environment with collaborative features including a built-in compiler, (2) a portable virtual machine, (3) collaborative editing, (4) open source protocols, and (5) peer-to-peer teleconferencing software. We report on the lessons learnt and how to further improve the resilience of robotics-based programming exercises.",
    "author": [
      {
        "family": "Anderson",
        "given": "Boyd"
      },
      {
        "family": "Henz",
        "given": "Martin"
      },
      {
        "family": "Tee",
        "given": "Hao-Wei"
      }
    ],
    "collection-title": "SPLASH-e 2021",
    "container-title": "Proceedings of the 2021 ACM SIGPLAN international symposium on SPLASH-e",
    "id": "10.1145/3484272.3484969",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "teaching CS1 using robotics, online robotics, learning tools, educational robotics",
    "page": "82-86",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Ruggedizing CS1 robotics: Tools and approaches for online teaching",
    "title-short": "Ruggedizing CS1 robotics",
    "type": "paper-conference"
  },
  {
    "ISBN": "0818679964",
    "abstract": "Cache memory design in embedded systems can take advantage from the analysis of the software that runs on that system, which usually remains the same for its whole life. Programs can be characterized, in respect of the memory hierarchy, using locality analysis. We propose an environment which permits to analyze the locality of a program and the effects on the target system performance. The student can thus figure out the best tradeoff between costs and performance for cache, memory and timings exploring different system configurations. A fully graphical interface permits to observe the program behavior from many points of view: locality surface, working set evolution, performance metrics. The tool is currently used as a teaching tool at our University and it is distributed as part of a commercial development environment for embedded systems.",
    "author": [
      {
        "family": "Giorgi",
        "given": "Roberto"
      },
      {
        "family": "Prete",
        "given": "Cosimo Antonio"
      },
      {
        "family": "Prina",
        "given": "Gianpaolo"
      }
    ],
    "collection-title": "MSE ’97",
    "container-title": "Proceedings of the 1997 international conference on microelectronics systems education (MSE ’97)",
    "id": "10.5555/523205.882907",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "keyword": "Program Locality, Performance Evaluation, Embedded System, Didactic Tool, Cache",
    "page": "16",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Cache memory design for embedded systems based on program locality analysis",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321286081",
    "abstract": "\"Over the years I have seen the software development pendulum swing from one extreme to the other, as deficiencies in ’best practices’ at one end of the spectrum spawned a new set of ’best practices’ at the opposite end. Kevin Tate’s book has finally brought the pendulum to a screeching halt, right about dead center. This book provides a balanced and practical guide to what’s important if your goal is to develop software that lasts.\"-Mary Poppendieck, Poppendieck.LLC. Author of \"Lean Software Development\"\"1) In this very practical and accessible book interspersed with real-world examples and personal opinions, Kevin has distilled his years of developing quality software into a set of principles and practices that have been proven to work. If you are thinking of introducing an agile development environment (ADE) into your organization or of improving the one you already have, this book will help you clearly understand the benefits of a sustainable ADE, establish the practices to make it happen and coach you through the follow-up required to change the culture of your organization to make sure the changes take hold.I am currently faced with exactly this challenge and this book has already given me several ideas I am looking forward to trying out.2) In an industry plagued with missed deadlines despite long overtime hours, this book offers a refreshing alternative: a set of guiding principles and simple practices to follow that allow you to get the job done by working smarter, not harder. Drawing on the author’s extensive experience developing quality software, the book clearly explains the principles behind a sustainable agile development environment, why it works, the practices to make it happen and the follow through required to turn these practices into habits.\"-Peter Schoeler, Technical Director, Artificial Mind &amp; Movement\"It’s a familiar scene-the schedule’s tight, people are putting in heroic efforts to get everything done, then at the last minute a change request comes in that wipes out the gains you had finally managed to make in meeting your ship date. Looks like it’s pizza at your desk for the weekend again! An unfortunate situation to be in but a pattern that repeats itself all too often. \"Sustainable Software Development\" offers hope to break this cycle. It shows how a change in mindset can free you from the tyranny of unrealistic expectations and brings development realities out onto the table for everyone to see. By following these techniques you will be able to define and manage a software development environment that will work for the long haul.\"-Kevin PicottSoftware development for immediate success and long-term sustainabilitySustainable Software Development brings together principles and practices for building software that is technically superior, delivers exceptional business value, and can evolve rapidly to reflect any change to your business or technical environment.Kevin Tate shows how to eliminate practices that make development unsustainable and replaces these practices with a sustainable approach that draws on the best ideas from both agile and conventional development. Tate demonstrates how to balance rapid releases and long-term sustainability, achieving both rich functionality and superior quality. You’ll learn how to build a development organization that is more productive and can continually improve its capability to handle complexity and change.Writing for developers, architects, project leaders, and other software team members, Tate shows how to: Take control of your development environment, so you can outship your competitors, leveraging new technologies and responding to new business opportunities Maintain a consistent pace that optimally balances short- versus long-term requirements Keep your code base in a \"near-shippable\" state between releases Prevent defects, rather than just recognizing and fixing them Invest continually and cost-effectively in software design improvements Leverage the fundamentals of the craft of software development Integrate sustainable processes with Agile and traditional methodologies© Copyright Pearson Education. All rights reserved.",
    "author": [
      {
        "family": "Tate",
        "given": "Kevin"
      }
    ],
    "id": "10.5555/1076970",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Sustainable software development: An agile perspective",
    "title-short": "Sustainable software development",
    "type": "book"
  },
  {
    "DOI": "10.1145/1953163.1953165",
    "ISBN": "9781450305006",
    "URL": "https://doi.org/10.1145/1953163.1953165",
    "abstract": "In 1995, my research team and I decided to create TeachScheme!, an educational outreach project, with the hope that our work on programming languages could effect a dramatic change in K-12 computer science. Specifically, we envisioned a virtuous cycle of two mutually reinforcing ideas. On the one hand, we would create a design-oriented curriculum path from middle school through college. On the other hand, our approach would help kids with learning school mathematics. Hence a course on programming would benefit every student, not just those who end up choosing computer science as a college major. At this point, we have a new design-oriented curriculum; a pedagogic program development environment to make it fun; and a series of matching programming languages. After focusing at the overlap between high schools and colleges at first, we now use after-school programs to move upstream, and we are working on two major downstream courses for the second semester in college: one on object-oriented design and another on logic in program design.My talk will focus on just one aspect of the project: the design-oriented curriculum and its smooth path from middle school to college. I will first demonstrate how to teach an intellectually interesting and fun course on programming with something that looks like plain school mathematics. For the rest of the talk, I will sketch the path from there through college.",
    "author": [
      {
        "family": "Felleisen",
        "given": "Matthias"
      }
    ],
    "collection-title": "SIGCSE ’11",
    "container-title": "Proceedings of the 42nd ACM technical symposium on computer science education",
    "id": "10.1145/1953163.1953165",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "keyword": "scheme, design-oriented curriculum",
    "page": "1-2",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TeachScheme!",
    "type": "paper-conference"
  },
  {
    "abstract": "Multimedia systems integrate text, audio, video, graphics, and other media and allow them to be utilized in a combined and interactive manner. Using this exciting and rapidly developing technology, multimedia applications can provide extensive benefits in a variety of arenas, including research, education, medicine, and commerce. While there are many commercial multimedia development packages, the easy and fast creation of a useful, full-featured multimedia document is not yet a straightforward task. This paper addresses issues in the development of multimedia documents, ranging from user-interface tools that manipulate multimedia documents to multimedia communication technologies such as compression, digital video editing and information retrieval. It outlines the basic steps in the multimedia authoring process and some of the requirements that need to be met by multimedia development environments. It also presents the role of video, an essential component of multimedia systems and the role of programming in digital video editing. A model is described for remote access of distributed video. The paper concludes with a discussion of future research directions and new uses of multimedia documents.",
    "author": [
      {
        "family": "Makedon",
        "given": "Fillia"
      },
      {
        "family": "Matthews",
        "given": "James"
      },
      {
        "family": "Owen",
        "given": "Charles B."
      },
      {
        "family": "Rebelsky",
        "given": "Samuel A."
      }
    ],
    "id": "10.5555/867967",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Dartmouth College",
    "publisher-place": "USA",
    "title": "Multimedia authoring, development environments, and digital video editing.",
    "type": "report"
  },
  {
    "DOI": "10.1155/2020/8868793",
    "ISSN": "1076-2787",
    "URL": "https://doi.org/10.1155/2020/8868793",
    "abstract": "In this paper, the forest algorithm and the decision tree algorithm are mainly used to analyze students’ physical education information, course exam results, and student learning data and relevant feature attributes from the online teaching platform. We aim to generate decision trees using the decision tree algorithm for the purpose of generating classification rules, based on which we can find factors that are important to students’ physical education performance and form data basis for improving teaching quality to help teaching management and teachers improve teaching methods and adjust teaching strategies. We specifically achieved this objective by constructing a model for assessing the effectiveness of student teaching, the steps of which include data collection and preparation, data preprocessing (data cleaning, conversion, integration), model construction (algorithm training), and algorithm optimization, as well as realizing the simulation results of the model. At the same time, the importance of the relevant attributes of the model is analyzed, and some measures are proposed to improve the universities: the standard of physical education teaching and the corresponding strategies for improving teaching methods. The mainstream development environment is chosen to ensure the complete operation of the project system that integrates learning, operation, and evaluation. The sports virtual simulation experimental teaching system realized in this paper has good functionality, stability, and application benefits in operation and use.",
    "author": [
      {
        "family": "Zhang",
        "given": "Zhifei"
      },
      {
        "family": "Zhao",
        "given": "Zijian"
      },
      {
        "family": "Yeom",
        "given": "Doo-Seoung"
      },
      {
        "family": "Lv",
        "given": "Zhihan"
      }
    ],
    "container-title": "Complex.",
    "id": "10.1155/2020/8868793",
    "issued": {
      "date-parts": [
        [
          2020,
          1
        ]
      ]
    },
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "Decision tree algorithm-based model and computer simulation for evaluating the effectiveness of physical education in universities",
    "type": "article-journal",
    "volume": "2020"
  },
  {
    "DOI": "10.1145/971300.971323",
    "ISBN": "1581137982",
    "URL": "https://doi.org/10.1145/971300.971323",
    "abstract": "Computer science instructors frequently teach using slides displayed with a computer and a data projector. This has many advantages, e.g., ability to present prepared materials and ease of switching the display to a development environment during mid-presentation. However, existing computer-based presentation systems severely limit flexibility in delivery, hindering instructors’ extemporaneous adaptation of their presentations to match their audiences. One major limitation of computer-based systems is lack of support for high-quality handwriting over slides, as with overhead projectors and other manual presentation systems. We developed and deployed Classroom Presenter, a Tablet PC-based presentation system that (1) combines the advantages of existing computer-based and manual presentation systems and (2) builds on these systems, introducing novel affordances. Classroom Presenter has been used in 25 Computer Science courses at three universities. In this paper we describe the system, summarize results from its deployment, and detail several novel uses of the system by instructors in computer science courses.",
    "author": [
      {
        "family": "Anderson",
        "given": "Richard"
      },
      {
        "family": "Anderson",
        "given": "Ruth"
      },
      {
        "family": "Simon",
        "given": "Beth"
      },
      {
        "family": "Wolfman",
        "given": "Steven A."
      },
      {
        "family": "VanDeGrift",
        "given": "Tammy"
      },
      {
        "family": "Yasuhara",
        "given": "Ken"
      }
    ],
    "collection-title": "SIGCSE ’04",
    "container-title": "Proceedings of the 35th SIGCSE technical symposium on computer science education",
    "id": "10.1145/971300.971323",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "keyword": "tablet PC, digital ink, classroom presentation",
    "page": "56-60",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Experiences with a tablet PC based lecture presentation system in computer science courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.advengsoft.2009.01.019",
    "ISSN": "0965-9978",
    "URL": "https://doi.org/10.1016/j.advengsoft.2009.01.019",
    "abstract": "With the evolution of technology, and especially of the Internet, a growing interest has appeared for on-line education. The many advantages of e-Learning have made this teaching philosophy an ideal partner for teachers, either as a complement to regular education or as a substitute for traditional education. The development of an e-Learning system poses extra challenges for software developers, since there are other facets, such as contents and user tracking, not usually considered in software development methodologies. In this paper eLearniXML approach to the development of e-Learning systems is presented. This approach enriches the development of e-Learning systems method proposed in ADDIE with the model-based development of user interfaces and software quality consideration. By doing so, we aim at the development of, what we have named, a Model-Based Instructional Development Environment (MB-ISDE), to include e-Learning development in the current trends of model-based software development.",
    "author": [
      {
        "family": "Fardoun",
        "given": "Habib"
      },
      {
        "family": "Montero",
        "given": "Francisco"
      },
      {
        "family": "López Jaquero",
        "given": "Vı́ctor"
      }
    ],
    "container-title": "Adv. Eng. Softw.",
    "id": "10.1016/j.advengsoft.2009.01.019",
    "issue": "12",
    "issued": {
      "date-parts": [
        [
          2009,
          12
        ]
      ]
    },
    "keyword": "e-Learning, Model-based design of user interfaces, MB-ISDE",
    "page": "1297-1305",
    "publisher": "Elsevier Science Ltd.",
    "publisher-place": "GBR",
    "title": "eLearniXML: Towards a model-based approach for the development of e-learning systems considering quality",
    "title-short": "eLearniXML",
    "type": "article-journal",
    "volume": "40"
  },
  {
    "DOI": "10.4018/jvple.2012040103",
    "ISSN": "1947-8518",
    "URL": "https://doi.org/10.4018/jvple.2012040103",
    "abstract": "Task-based language learning using the benefits of online computer-assisted language learning CALL can be effective for rapid vocabulary expansion, especially when target vocabulary has been pre-arranged into bilingual categories under simpler, common Semantic Field Keywords. Results and satisfaction levels for both Chinese English majors and Japanese Engineering majors were high in this qualitative comparative study, indicating its potential for helping many students from various language backgrounds to rapidly expand their target language vocabulary, especially when blended with other real language negotiation tasks, preferably for an authentic audience. Print versus online reading and vocabulary development methods are compared, as well as surveys of both Chinese and Japanese college students, after they were engaged in a \"Collaborative Writing Exchange Project\" using similar online vocabulary development tools. All target terms were pre-organized and made available under common Semantic Field Keywords online in both Japanese and Chinese, but students had freedom to choose within sets of most relevant words from five academic disciplines. Writing themes were suggested to learners in both countries to keep their email exchanges consistent.",
    "author": [
      {
        "family": "Loucky",
        "given": "John Paul"
      }
    ],
    "container-title": "Int. J. Virtual Pers. Learn. Environ.",
    "id": "10.4018/jvple.2012040103",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2012,
          4
        ]
      ]
    },
    "keyword": "Second Language Vocabulary Acquisition SLVA, Immediate-Access Automatic Glossing, Enhancing Online Reading, Digital Vocabulary Learning, Density and Placement of Word Glosses in Reading Texts, Computer-Assisted Language Learning CALL, Clickable Glossing",
    "page": "35-58",
    "publisher": "IGI Global",
    "publisher-place": "USA",
    "title": "Designing distance learning tasks to help maximize vocabulary development",
    "type": "article-journal",
    "volume": "3"
  },
  {
    "ISBN": "0542155397",
    "abstract": "Scope of study. This dissertation investigated differences in students’ perceptions of the relative perceived complexity of traditionally developed software programs versus object-oriented developed software programs. Previous research and students at two different academic institutions were surveyed to gain insights for developing a framework by which different programming paradigms may be compared for complexity. Findings and conclusions. This dissertation discovered that the surveyed students’ perceptions of programs’ relative complexity increase when object-oriented technologies are used to solve a given business problem instead of traditional programming technologies. It will be of interest to faculty and administrators at technical institutes who want to have a greater understanding of student perceptions of complexity in different programming paradigms. It identified critical success factors, such as formatting and input/output commands, that can impact perceived program complexity. The findings also indicated a need for more efficient development tools, better training for existing tools, and more consistent design approaches.",
    "author": [
      {
        "family": "Dyck",
        "given": "Randall"
      },
      {
        "family": "Neiman",
        "given": "Amiram"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1104364",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "note": "AAI3176270",
    "publisher": "Northcentral University",
    "title": "A comparison of student perceptions of complexity for traditional and object-oriented programs",
    "type": "thesis"
  },
  {
    "DOI": "10.1109/ICGSE.2007.44",
    "ISBN": "0769529208",
    "URL": "https://doi.org/10.1109/ICGSE.2007.44",
    "abstract": "Siemens Austria’s Program and System Engineering Division SIS PSE has moved away from the classic approach of offering training via an inhouse Training Center towards a new approach called \"Learning Network\". This Learning Network is part of PSE wide international knowledge networking, and consists of about 100 internal trainers, who perform their training activities beside their main job as engineers, project managers, quality managers, or the like. Given the organization’s set-up in a global software development environment, this has particular advantages in terms of international standardization of content (where needed), provision of local content, cost, and pedagogical efficiency. This paper briefly outlines the challenges PSE is faced with, introduces the approach adopted by PSE in detail, gives three examples of training for skills development specifically needed in global software development, highlights the critical success factors of such an approach, and provides a résumé.",
    "author": [
      {
        "family": "Lutz",
        "given": "Benedikt"
      }
    ],
    "collection-title": "ICGSE ’07",
    "container-title": "Proceedings of the international conference on global software engineering",
    "id": "10.1109/ICGSE.2007.44",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "page": "140-150",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Training for global software development in an international \"learning network\"",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3524383.3533247",
    "ISBN": "9781450395793",
    "URL": "https://doi.org/10.1145/3524383.3533247",
    "abstract": "By exploring the characteristic of interaction of network teaching, we proposed to develop an English teaching interaction system based on artificial intelligence, which can solve the problems in current English teaching class. We analyzed the functional requirements of the system corresponding to different user. By buiding Ubuntu operating system as the computing platform and exploring the object-oriented dynamic teaching environment provided by artificial intelligence platform, we build the LAMP development environment with MySQL database and PHP script language. We constructed a three-tier separated architecture system by using B/S mode, and refined the design and implementation of each module function through the secondary development of platform module plug-ins. To exhibit the advantages of the artificial intelligence system, we take college English teaching as an example to illustrate its functions. The functions of curriculum creation, teaching resources and activity design can be realized in the system, which verifies the effectiveness of the artificial intelligence system in interactive teaching and learning.",
    "author": [
      {
        "family": "Zhao",
        "given": "Huimin"
      }
    ],
    "collection-title": "ICBDE ’22",
    "container-title": "Proceedings of the 5th international conference on big data and education",
    "id": "10.1145/3524383.3533247",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "LAMP development environment, English teaching, B/S architecture, Artificial intelligence",
    "page": "451-454",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design of english teaching interactive system based on artificial intelligence",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2676723.2677275",
    "ISBN": "9781450329668",
    "URL": "https://doi.org/10.1145/2676723.2677275",
    "abstract": "The recent renaissance in early computer science education has provided K-12 teachers with multiple options for introducing children to computer science. However, tools for teaching programming for children with wide-scale adoption have been targeted mostly at pre-readers or middle school and higher grade-levels. This leaves a gap for 4th – 6th grade students, who differ developmentally from older and younger students.In this paper, we investigate block-based programming languages targeted at elementary and middle school students and demonstrate a gap in existing programming languages appropriate for 4th – 6th grade classrooms. We analyze the benefits of Scratch, ScratchJr, and Blockly for students and curriculum developers. We describe the design principles we created based on our experiences using block-based programming in 4th – 6th grade classrooms, and introduce LaPlaya, a language and development environment designed specifically for children in the gap between grades K-3 and middle school students.",
    "author": [
      {
        "family": "Hill",
        "given": "Charlotte"
      },
      {
        "family": "Dwyer",
        "given": "Hilary A."
      },
      {
        "family": "Martinez",
        "given": "Tim"
      },
      {
        "family": "Harlow",
        "given": "Danielle"
      },
      {
        "family": "Franklin",
        "given": "Diana"
      }
    ],
    "collection-title": "SIGCSE ’15",
    "container-title": "Proceedings of the 46th ACM technical symposium on computer science education",
    "id": "10.1145/2676723.2677275",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "novice programming environments, middle school, graphical programming, elementary school, computer science education",
    "page": "546-551",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Floors and flexibility: Designing a programming environment for 4th-6th grade classrooms",
    "title-short": "Floors and flexibility",
    "type": "paper-conference"
  },
  {
    "abstract": "This study examines the organizational and technological factors that contribute to the successful implementation of CASE (computer-aided software engineering) technology. A questionnaire was developed to determine a profile of CASE users. This profile was used to determine with whom interviews would be conducted. Data were collected through personal interviews with integrated CASE tool users. These interviews were analyzed using a grounded theory approach. A theory of CASE implementation was developed based on this analysis. This study found that CASE implementation success relies on the interaction between management’s understanding of information technology, the information systems development environment, and the complexity of application systems that are developed in an organization. Some of the factors underlying these core themes were suggested by the literature, but most emerged from the analysis of the data.The core theme of organizational understanding of information systems technology is described by: the presence of a champion; the factors that were considered in the decision; the commitment of management; the expected benefits of CASE technology; and the role of an information systems development methodology in the organization. The core theme of information systems development environment is described by: the skill set of the information systems professionals that the organization employs; the way the CASE tool is used; the implementation strategy chosen; and the role of an information systems development methodology in the organization. Finally, the core theme of information systems development complexity is described by: the training approach followed; the expected benefits of CASE technology; the implementation strategy used; and the role of an information systems development methodology in the organization. This study found that adherence to a systems development methodology is of particular importance when integrated CASE technology is being implemented.This research adds to the body or knowledge that explores the relationship between factors in an organization and CASE adoption success. This work also extends the stream of information systems research which utilizes qualitative techniques.",
    "author": [
      {
        "family": "Knapp",
        "given": "Constance Anne"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/220790",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "note": "UMI Order No. GAX95-30890",
    "publisher": "City University of New York",
    "publisher-place": "USA",
    "title": "An investigation into the organizational and technological factors that contribute to the successful implementation of CASE technology",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3568739.3568802",
    "ISBN": "9781450398091",
    "URL": "https://doi.org/10.1145/3568739.3568802",
    "abstract": "With the continuous promotion of the digitalization of Library and document resources, there are more and more types and scales of outsourced and self built databases in University Libraries and information units at home and abroad. In order to obtain complete digital resources, it needs to spend a lot of time searching in various types of resource systems. Therefore, at present, digital library is a user-oriented service resource system based on digital resources, which can integrate information resources, information services and information activities as a dynamic mechanism. Based on Visual Studio c# and SQL Server development environment, the Russian digital characteristic resource construction platform expounds the process of Russian database construction and Russian document resource construction from the system design and platform implementation according to the development process of software engineering. This platform has the advantages of convenient operation, fast pre search, effective management of Russian literature and strong support for the use of literature.",
    "author": [
      {
        "family": "Zhang",
        "given": "Shang"
      }
    ],
    "collection-title": "ICDTE ’22",
    "container-title": "Proceedings of the 6th international conference on digital technology in education",
    "id": "10.1145/3568739.3568802",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "database, Russian, Resource integration, Relying on color resources",
    "page": "375-380",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design of russian digital resource construction platform",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1275604.1275610",
    "ISBN": "9781450347341",
    "URL": "https://doi.org/10.1145/1275604.1275610",
    "abstract": "In the course of a major curriculum change at California Polytechnic State University, the embedded processing course was redesigned. During this process, the course had the opportunity to purchase new hardware. Analog Device’s Black-fin processor was chosen based mostly on cost, but also on performance, development environment, and documentation.We first present our goals in the class. We then give an overview of the Blackfin architecture and how the Blackfin fits in with many of our goals. We then present the implementation of an expansion board developed to interface with Blackfin’s EZ-KIT Lite board.We present our experiences with this setup in the hopes that others who might be thinking of a similar curricular change can learn from our successes and failures. We outline the strengths and weaknesses of the Blackfin architecture as an educational platform, followed by a discussion of our experiences and a presentation of the support materials we developed to accompany the course, including lecture material and laboratories. Finally, we discuss our future directions for our uses with the board.",
    "author": [
      {
        "family": "Franklin",
        "given": "Diana"
      },
      {
        "family": "Seng",
        "given": "John"
      }
    ],
    "collection-title": "WCAE ’05",
    "container-title": "Proceedings of the 2005 workshop on computer architecture education: Held in conjunction with the 32nd international symposium on computer architecture",
    "id": "10.1145/1275604.1275610",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "3-es",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Experiences with the blackfin architecture for embedded systems education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3573051.3596180",
    "ISBN": "9798400700255",
    "URL": "https://doi.org/10.1145/3573051.3596180",
    "abstract": "The popularity of Massive Open Online Courses (MOOCs) as a means of delivering education to large numbers of students has been growing steadily over the last decade. As technology improves, more educational content is becoming readily available to the public. JupyterLab, an open-source web-based interactive development environment (IDE), is also becoming increasingly popular in education, however, it is so far primarily used in small classroom settings. JupyterLab can provide a more interactive, hands-on, and collaborative learning experience for students in MOOCs, and it is highly customizable and can be accessed from anywhere. To capitalize on these benefits, we have developed OpenJupyter, which integrates JupyterLab at scale with MOOCs, enhancing the student learning experience and providing hands-on exercises for data science courses, making them more interactive and engaging. While MOOCs provide access to education for a large number of students, one of the significant challenges is providing effective and timely feedback to learners.&nbsp;OpenJupyter includes an auto-assessment capability that addresses this problem in MOOCs by automating the evaluation process and providing feedback to learners in a timely manner. In this paper, we provide an overview of the architecture of OpenJupyter, its scalability in the context of MOOCs, and its effectiveness in addressing the auto-assessment challenge. We also discuss the Advantages and limitations associated with using OpenJupyter in a MOOC context and provide a reference for educators and researchers who wish to implement similar tools. Our efforts aim to foster an open educational environment in the field of programming by providing learners with an interactive learning tool and a streamlined technical setup, allowing them to acquire and test their knowledge at their own pace.",
    "author": [
      {
        "family": "Elhayany",
        "given": "Mohamed"
      },
      {
        "family": "Meinel",
        "given": "Christoph"
      }
    ],
    "collection-title": "L@s ’23",
    "container-title": "Proceedings of the tenth ACM conference on learning @ scale",
    "id": "10.1145/3573051.3596180",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "programming, openjupyter, auto-assessment, MOOC, JupyterLab",
    "page": "321-325",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards automated code assessment with OpenJupyter in MOOCs",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/11499053_40",
    "ISBN": "3540262776",
    "URL": "https://doi.org/10.1007/11499053_40",
    "abstract": "Genesys Solutions is a bespoke IT company, first of its kind, run by MSc and fourth year students of Department of Computer Science, University of Sheffield under the supervision of Prof. Mike Holcombe and Dr. Marian Gheorghe. Genesys follows the eXtreme Programming (XP) methodology for software development based on client requirements. The commitment towards XP and its ‘good software practices’ can be considered as the greatest strength of Genesys.Agile Development Environment for Programming and Testing (ADEPT) is our contribution towards supporting the XP methodology by adopting the Eclipse platform along with its associated tools and frameworks within Genesys Solutions. It aimed to teach good software practices in Genesys to support XP by providing a software development life cycle management tool that will encompass the best practices of XP. It comprises of tools based on the principles of XP such as story cards, system metaphor, estimations, testing and quality assurance. ADEPT was the result of the IBM Eclipse Innovation 2004 awarded to the University of Sheffield. Also, based on the previous year’s performance and more innovative ideas to implement more principles of XP we have been awarded another grant under the IBM Eclipse Innovation 2005 programme.",
    "author": [
      {
        "family": "Holcombe",
        "given": "Mike"
      },
      {
        "family": "Kalra",
        "given": "Bhavnidhi"
      }
    ],
    "collection-title": "XP’05",
    "container-title": "Proceedings of the 6th international conference on extreme programming and agile processes in software engineering",
    "id": "10.1007/11499053_40",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "keyword": "software life cycle, project management, extreme programming, eclipse",
    "page": "255-258",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Agile development environment for programming and testing (ADEPT) – eclipse makes project management extreme",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.cageo.2010.10.017",
    "ISSN": "0098-3004",
    "URL": "https://doi.org/10.1016/j.cageo.2010.10.017",
    "abstract": "LavaNet is a series of scripts written in Perl that gives access to a neural network simulation environment inside a general mine planning package. A well known and a very popular neural network development environment, the Stuttgart Neural Network Simulator, is used as the base for the development of neural networks. LavaNet runs inside VULCAN(TM)-a complete mine planning package with advanced database, modelling and visualisation capabilities. LavaNet is taking advantage of VULCAN’s Perl based scripting environment, Lava, to bring all the benefits of neural network development and application to geologists, mining engineers and other users of the specific mine planning package. LavaNet enables easy development of neural network training data sets using information from any of the data and model structures available, such as block models and drillhole databases. Neural networks can be trained inside VULCAN(TM) and the results be used to generate new models that can be visualised in 3D. Direct comparison of developed neural network models with conventional and geostatistical techniques is now possible within the same mine planning software package. LavaNet supports Radial Basis Function networks, Multi-Layer Perceptrons and Self-Organised Maps.",
    "author": [
      {
        "family": "Kapageridis",
        "given": "Ioannis Konstantinou"
      },
      {
        "family": "Triantafyllou",
        "given": "A. G."
      }
    ],
    "container-title": "Comput. Geosci.",
    "id": "10.1016/j.cageo.2010.10.017",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2011,
          4
        ]
      ]
    },
    "keyword": "VULCAN, SNNS, Perl, Neural networks, Mine planning, Estimation",
    "page": "634-644",
    "publisher": "Pergamon Press, Inc.",
    "publisher-place": "USA",
    "title": "LavaNet-neural network development environment in a general mine planning package",
    "type": "article-journal",
    "volume": "37"
  },
  {
    "ISBN": "1931836590",
    "abstract": "From the Publisher:Ok. You bought the kit for yourself or one of your kids. You used the instructions in the box to build a robot or two. Now what__ __ You may not be ready to design and build your own robots, but you don’t want to build the same robot over again. This book is the perfect way to build additional projects from the same kit, and then to improvise and design your own. Ten Cool Projects. One hour each. Perfect. Robots Included: Ludic Ordinance Units, (LOUs), are usually put together to create entertainment for the troops, but they usually end up serving as moving targets for Imperial Stormtroopers. Scorpion Assassin Droid a silent and deadly hunter. Tracking its intended target with a variety of sensors, it moves stealthily to within striking distance. Draigons swoop from the sky to attack their prey, carrying off to their lairs to be devoured those creatures unfortunate enough to become their victims. Droid Transporters can carry up to a dozen Droids over rough terrain and deliver them where they are needed. X-Stormer is a prototype of what would eventually become the AT-AT. Imperial engineers worked for many years to create the X-Stormers. Super Battle Droid is a biped that walks on two legs by shifting its weight from side to side and moving its legs forwards and backwards. Go-Rillas are fast biped robots often used by the smugglers and bounty hunters of the galaxy to defend their hideouts. What they lack in intelligence they more than make up for in speed and brute strength. Imperial All-Terrain Scout Transport, better known as the AT-ST, is a small, agile, armored biped that can carry two Imperial Stormtroopers. Orbital Defense Cannons, guided by their large targeting radar dish, can shoot down even the largest Imperial Star Destroyers and Corellian Cruisers. Imperial Hounds serve as both companions for the troops and as powerful tools of war on the battlefields of the Empire. Author Biographies: Hideaki Yabuki works as a Media Activist promoting new technologies to the next generation. To him, robotics is the most important of these technologies. He was first introduced to LEGO robots in 1985 by a friend of his who had recently returned from the MIT Media Lab with some LEGO Dacta products. His robot in this book, the Scorpion, is the result of much trial and error on his part. Kevin Clague graduated in 1983 from Iowa State University with a bachelor’s of Science degree in Computer Engineering. For the past 18 years, Kevin has worked as a Diagnostic Engineer at the Amdahl Corporation. For the last two years, he has also acted as a Senior Staff Engineer doing verification work at Sun Microsystems on their Ultra-Sparc V RISC processor. Kevin has two major hobbies: theatrical lighting and LEGO Mindstorms. Kevin has been playing with the RIS 1.5 for several years now and is currently working on LPub, an application to revolutionize the world of creating online LEGO building instructions. Miguel Agullo was born in Spain but has lived abroad for long periods of time, from the Far East to South America, from central Europe to the U.S. His wide range of interests is responsible for his work in such diverse industries as finance, media, aeronautics, and antique trading. Trained as a journalist and impressed with the candor and resourcefulness of the online LEGO community, Miguel tries to give something back by regularly updating his Web site with instructions for new models, new Ldraw pieces, and anything he thinks is worth sharing with other LEGO aficionados. His building interests revolve around robotics, and specifically biomechanics: creating mechanisms that mimic the behavior of natural devices such as legs or arms. His creations include biped walkers, robots that jump, and a fully functional (including a brake!) LEGO motorcycle. Søren Rolighed is a data warehouse consultant, working on building and maintaining databases for telco-data in the largest data warehouse in Denmark. Like almost all Danish kids, he started playing with LEGO at an early age. As an adult he has continued with his passion for LEGOs, and the introduction of the LEGO Technics and LEGO Mindstorms kits opened up a whole new world of possibilities! J.P. Brown is a Consultant Environmental Conservator who has worked on such historical sites as Independence Hall, Philadelphia, PA and George Washington’s mansion, Mount Vernon, VA. He first became interested in LEGO Mindstorms in July 1999, but his interest did not really take off until he discovered Dave Baum’s Not Quite C (NQC) programming environment for the RCX brick later that year. He quickly became involved as a moderator for LEGO Mindstorms forums on the Web, and was later selected by LEGO as a preview builder for the Mindstorms Vision Command. His robot, Biped II, won the February 2001 Mindstorms Hall of Fame, Special Competition, but he is perhaps best known for his Rubik’s Cube solving robot, CubeSolver, which was featured in the New York Times in October 2001 and other papers around the world.",
    "author": [
      {
        "family": "Clague",
        "given": "Kevin"
      },
      {
        "family": "Rolighed",
        "given": "Soren"
      },
      {
        "family": "Brown",
        "given": "J. P."
      },
      {
        "family": "Agullo",
        "given": "Miguel"
      },
      {
        "family": "Yabuki",
        "given": "Hideaki"
      },
      {
        "family": "Ferrari",
        "given": "Giulio"
      }
    ],
    "id": "10.5555/579602",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Syngress Publishing",
    "title": "10 cool LEGO mindstorms: Dark side robots, transports, and creatures – amazing projects you can build in under an hour",
    "title-short": "10 cool LEGO mindstorms",
    "type": "book"
  },
  {
    "DOI": "10.1109/13.804563",
    "ISSN": "0018-9359",
    "URL": "https://doi.org/10.1109/13.804563",
    "abstract": "Multi-disciplinary product design teams are now an accepted project development tool in industry. Many advantages cited are: rapid prototyping, cost reduction and the design of a more marketable product. While multi-disciplinary teams are common in such environments, it is more problematical to offer students in higher education experience of working in such a team. A variety of difficulties are encountered by educators wishing to provide such an experience for their students, ranging from cultural through logistical to the level of intellectual rigour required and the assessment methodologies used. This paper describes the research methodologies and results of an investigation into the operation of a large multi-disciplinary team project conducted by the authors over a period of two years to two sets of undergraduates, each consisting of over one hundred and eighty full-time students drawn from a number of engineering, design and design management disciplines. An action research programme to investigate the group experience and attitudes was undertaken and the principal findings are presented and briefly debated. The findings support the view that the exercise provided a wide range of tangible and intangible benefits. This enables the authors to propose a conceptual model of large multi-disciplinary team working which may be used by other educators as a basis for developing future project modules within their host institution’s environment. Finally, the benefits gained, as shown by previous research, for students and staff from such projects are summarised",
    "author": [
      {
        "family": "Ivins",
        "given": "J. R."
      },
      {
        "family": "Holland",
        "given": "R."
      }
    ],
    "container-title": "IEEE Trans. on Educ.",
    "id": "10.1109/13.804563",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1999,
          11
        ]
      ]
    },
    "page": "9 pp.",
    "publisher": "IEEE Press",
    "title": "Reflections on the operation of large multidisciplinary projects in engineering, design and design management",
    "type": "article-journal",
    "volume": "42"
  },
  {
    "DOI": "10.1007/s11042-020-09772-y",
    "ISSN": "1380-7501",
    "URL": "https://doi.org/10.1007/s11042-020-09772-y",
    "abstract": "The main element of extended reality (XR) environments is behavior-rich 3D content consisting of objects that act and interact with one another as well as with users. Such actions and interactions constitute the evolution of the content over time. Multiple application domains of XR, e.g., education, training, marketing, merchandising, and design, could benefit from the analysis of 3D content changes based on general or domain knowledge comprehensible to average users or domain experts. Such analysis can be intended, in particular, to monitor, comprehend, examine, and control XR environments as well as users’ skills, experience, interests and preferences, and XR objects’ features. However, it is difficult to achieve as long as XR environments are developed with methods and tools that focus on programming and 3D modeling rather than expressing domain knowledge accompanying content users and objects, and their behavior. The main contribution of this paper is an approach to creating explorable knowledge-based XR environments with semantic annotations. The approach combines description logics with aspect-oriented programming, which enables knowledge representation in an arbitrary domain as well as transformation of available environments with minimal users’ effort. We have implemented the approach using well-established development tools and exemplify it with an explorable immersive car showroom. The approach enables efficient creation of explorable XR environments and knowledge acquisition from XR.",
    "author": [
      {
        "family": "Flotyński",
        "given": "Jakub"
      }
    ],
    "container-title": "Multimedia Tools Appl.",
    "id": "10.1007/s11042-020-09772-y",
    "issue": "5",
    "issued": {
      "date-parts": [
        [
          2021,
          2
        ]
      ]
    },
    "keyword": "Annotations, Ontologies, Semantic web, Queries, Reasoning, Exploration, 3D Web, Extended reality",
    "page": "6959-6989",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Creating explorable extended reality environments with semantic annotations",
    "type": "article-journal",
    "volume": "80"
  },
  {
    "ISBN": "1576102610",
    "abstract": "From the Publisher:Helps programming professionals gain knowledge that directly applies to the Sun Microsystems exam for Java. Covers all the curriculum objectives established by Sun Education that are needed to successfully pass the Java exam. Serves as an essential resource to the programmer who wants to learn Java quickly; it builds on the reader’s knowledge of C++ by spending less time on programming fundamentals and more time on topics that are unique or difficult in Java. Gartner Research estimates that there will be market demand for over 1 million Java programmers by the year 2000. Covers two development environments, Sun’s JavaWorkShop and IBM’s VisualAge and relates objectives in the chapter material to required topics on the certification exam. Includes all topics required for successful completion of the Java Programmer Certification Exam, as well as covering additional topics essential to using Java in business situations. Written by Sun-certified programmers who use Java in a professional setting. Features a unique exam simulation program designed especially for Certification Insider Press that includes two complete interactive practice tests, allowing readers to measure their skills and build confidence before taking the actual certifcation exam. Although the questions are formatted like those encountered on the actual exam, they are based on the book’s content to reinforce critical concepts and their practical applications.",
    "author": [
      {
        "family": "Brogden",
        "given": "William B."
      },
      {
        "family": "Brogden",
        "given": "Bill"
      }
    ],
    "id": "10.5555/553951",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "publisher": "Coriolis Group Books",
    "publisher-place": "USA",
    "title": "Java 2 exam prep: Exam: 310-025 with cdrom",
    "title-short": "Java 2 exam prep",
    "type": "book"
  },
  {
    "ISBN": "1555442455",
    "abstract": "From the Publisher:Written for designers, programmers, and users of SAS applications, this book shows how to build client/server database applications through table-driven technology. Each chapter addresses these three different audiences, detailing ways to construct high-quality, reliable applications that are easy to maintain. The \"code-free\" approach offers you flexibility in design, reduces development time, and provides the advantages of integrated data dictionaries, user-defined integrity rules, and trigger-message mechanisms that implement and manage data processing. With the many realistic examples included here, experienced users who build or regularly use SAS applications can master techniques of application development and data analysis that are straightforward and powerful. Supports releases 6.09 and higher of SAS software.Author Biography: Tanya Kolosova Tanya Kolosova is an independent consultant with expertise in time series and forecasting, operations research, and statistical training. With Berestizhevsky, she is the coauthor of TARGET, a fully integrated applications development tool based on SAS software. Also published in scientific journals, she has extensive experience working with the SAS System. Samuel Berestizhevsky Samuel Berestizhevsky is an independent consultant specializing in statistical data analysis, the design of experiments, quality control and assurance, system analysis, and training. Published in several scientific magazines, he has an impressive amount of experience working with the SAS System.",
    "author": [
      {
        "family": "Kolosova",
        "given": "Tanya"
      },
      {
        "family": "Berestizhevsky",
        "given": "Samuel"
      }
    ],
    "edition": "1st",
    "id": "10.5555/546215",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "publisher": "SAS Publishing",
    "title": "Table-driven strategies for rapid SAS applications development",
    "type": "book"
  },
  {
    "DOI": "10.1145/3419635.3419727",
    "ISBN": "9781450387729",
    "URL": "https://doi.org/10.1145/3419635.3419727",
    "abstract": "In the current situation of the development of science and technology, virtual technology arises at the historic moment. As a kind of computer simulation technology, it has the simulation ahead of the real world. Because of its many advantages, virtual technology is already being used in fields such as education and medicine. However, there are still some shortcomings in the current virtual technology. Although the development tools are equipped, there are still some disadvantages in the process of using them, which hinders the developers to improve their work efficiency significantly. Among the prospects, this technology is the most widely used in education, and this paper aims to develop a virtual reality application engine that is convenient for party school teaching. In the education and learning of the party school, the design and r&amp;d of VR products should be completed under the support of the model and theory of education, and should respond to the characteristics of the discipline. This paper expounds a series of processes from design to r&amp;d of VR products. At the beginning, I analyses the subject and investigated the market prospect of VR education, so as to get a product with the same learning efficiency and teaching efficiency. Secondly, the depth plane analysis is carried out on the mathematical knowledge needed in the construction of 3d model, and the emphasis is put on the introduction of quaternions, transformation matrix, homogeneous coordinates and the functions of these knowledge in 3d application.",
    "author": [
      {
        "family": "Yuan",
        "given": "Menghui"
      }
    ],
    "collection-title": "CIPAE 2020",
    "container-title": "Proceedings of the 2020 international conference on computers, information processing and advanced education",
    "id": "10.1145/3419635.3419727",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "Virtual reality technology, VR education, Party school teaching",
    "page": "472-475",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Research on the construction of virtual reality engine for party school teaching application",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/HICSS.2012.198",
    "ISBN": "9780769545257",
    "URL": "https://doi.org/10.1109/HICSS.2012.198",
    "abstract": "End-user training is complicated to implement in global corporations whose activities are typically scattered across multiple sites in different countries and leverage information systems in various ways. This is especially true in global software development where the sites may leverage a development tool for totally different purposes. Web-based Virtual Meeting Tools (VMT) enable synchronous communication globally through interactive audio, online chats, video, and the sharing of presentations. They provide potentially a cost effective way to train even complex topics to large numbers of people in global settings. Few industrial experiences from the design and use of VMT-based training innovations have been reported. This paper draws upon a case study in a global corporation to describe the design, implementation, and evaluation of a training innovation, consisting of a set of courses delivered by means of a VMT and conference calls, to support the global deployment of a Unified Modeling Language (UML) modeling tool and to develop UML modeling skills. Evaluation is based on interviews to verify 1) the impacts of the innovation on skills, knowledge and motivation, 2) perceived learner satisfaction with respect to the innovation. The innovation proved successful in improving skills, knowledge, and motivation in the case organization and learners were satisfied with it. Other organizations may benefit from using VMT to train people to use similar complex information systems for supporting global software development.",
    "author": [
      {
        "family": "Koivulahti-Ojala",
        "given": "Mervi"
      },
      {
        "family": "Kakola",
        "given": "Timo"
      }
    ],
    "collection-title": "HICSS ’12",
    "container-title": "Proceedings of the 2012 45th hawaii international conference on system sciences",
    "id": "10.1109/HICSS.2012.198",
    "issued": {
      "date-parts": [
        [
          2012
        ]
      ]
    },
    "keyword": "web-based learning, learning, global software development, UML",
    "page": "3980-3989",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Design, implementation, and evaluation of a virtual meeting tool-based innovation for UML technology training in global organizations",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3508352.3549478",
    "ISBN": "9781450392174",
    "URL": "https://doi.org/10.1145/3508352.3549478",
    "abstract": "Multiplication is arguably the most cost-dominant operation in modern deep neural networks (DNNs), limiting their achievable efficiency and thus more extensive deployment in resource-constrained applications. To tackle this limitation, pioneering works have developed handcrafted multiplication-free DNNs, which require expert knowledge and time-consuming manual iteration, calling for fast development tools. To this end, we propose a Neural Architecture Search and Acceleration framework dubbed NASA, which enables automated multiplication-reduced DNN development and integrates a dedicated multiplication-reduced accelerator for boosting DNNs’ achievable efficiency. Specifically, NASA adopts neural architecture search (NAS) spaces that augment the state-of-the-art one with hardware inspired multiplication-free operators, such as shift and adder, armed with a novel progressive pretrain strategy (PGP) together with customized training recipes to automatically search for optimal multiplication-reduced DNNs; On top of that, NASA further develops a dedicated accelerator, which advocates a chunk-based template and auto-mapper dedicated for NASA-NAS resulting DNNs to better leverage their algorithmic properties for boosting hardware efficiency. Experimental results and ablation studies consistently validate the advantages of NASA’s algorithm-hardware co-design framework in terms of achievable accuracy and efficiency tradeoffs. Codes are available at https://github.com/shihuihong214/NASA.",
    "author": [
      {
        "family": "Shi",
        "given": "Huihong"
      },
      {
        "family": "You",
        "given": "Haoran"
      },
      {
        "family": "Zhao",
        "given": "Yang"
      },
      {
        "family": "Wang",
        "given": "Zhongfeng"
      },
      {
        "family": "Lin",
        "given": "Yingyan"
      }
    ],
    "collection-title": "ICCAD ’22",
    "container-title": "Proceedings of the 41st IEEE/ACM international conference on computer-aided design",
    "id": "10.1145/3508352.3549478",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "NASA: Neural architecture search and acceleration for hardware inspired hybrid networks",
    "title-short": "NASA",
    "type": "paper-conference"
  },
  {
    "ISBN": "3030336239",
    "abstract": "This book focuses on the development and implementation of cloud-based, complex software that allows parallelism, fast processing, and real-time connectivity. Software engineering (SE) is the design, development, testing, and implementation of software applications, and this discipline is as well developed as the practice is well established whereas the Cloud Software Engineering (CSE) is the design, development, testing, and continuous delivery of service-oriented software systems and applications (Software as a Service Paradigm). However, with the emergence of the highly attractive cloud computing (CC) paradigm, the tools and techniques for SE are changing. CC provides the latest software development environments and the necessary platforms relatively easily and inexpensively. It also allows the provision of software applications equally easily and on a pay-as-you-go basis. Business requirements for the use of software are also changing and there is a need for applications in big data analytics, parallel computing, AI, natural language processing, and biometrics, etc. These require huge amounts of computing power and sophisticated data management mechanisms, as well as device connectivity for Internet of Things (IoT) environments. In terms of hardware, software, communication, and storage, CC is highly attractive for developing complex software that is rapidly becoming essential for all sectors of life, including commerce, health, education, and transportation. The book fills a gap in the SE literature by providing scientific contributions from researchers and practitioners, focusing on frameworks, methodologies, applications, benefits and inherent challenges/barriers to engineering software using the CC paradigm.",
    "author": [
      {
        "family": "Ramachandran",
        "given": "Muthu"
      },
      {
        "family": "Mahmood",
        "given": "Zaigham"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3385370",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "Software engineering in the era of cloud computing",
    "type": "book"
  },
  {
    "ISBN": "0131863339",
    "abstract": "Praise for Mark Sobell’s Books \"If you want to become a real Linux guru, this is one of the better books available. Readable, straightforward, educational, it is a superb reference that blends the educational aspect of a typical book on learning Linux with a typical book of command line references. I highly recommend A Practical Guide to Linux® Commands, Editors, and Shell Programming.\" Harold D. McFarland, Editor, Readers Preference Reviews \"I keep searching for books that collect everything you want to know about a subject in one place, and keep getting disappointed. Usually the books leave out some important topic, while others go too deep in some areas and must skim lightly over the others. A Practical Guide to Red Hat® Linux® is one of those rare books that actually pulls it off. Mark G. Sobell has created a single reference for Red Hat Linux that cannot be beat! This marvelous text (with a 4-CD set of Linux Fedora Core 2 included) is well worth the price. This is as close to an ’everything you ever needed to know’ book that I’ve seen. It’s just that good and rates 5 out of 5.\" Ray Lodato, Slashdot contributor \"Mark Sobell has written a book as approachable as it is authoritative.\" Jeffrey Bianchine, Advocate, Author, Journalist \"Excellent reference book, well suited for the sysadmin of a Linux cluster, or the owner of a PC contemplating installing a recent stable Linux. Don’t be put off by the daunting heft of the book. Sobell has striven to be as inclusive as possible, in trying to anticipate your system administration needs.\" Wes Boudville, Inventor \"A Practical Guide to Red Hat® Linux® is a brilliant book. Thank you Mark Sobell.\" C. Pozrikidis, University of California at San Diego \"This book presents the best overview of the Linux operating system that I have found. . . . [It] should be very helpful and understandable no matter what the reader’s background is: traditional UNIX user, new Linux devotee, or even Windows user. Each topic is presented in a clear, complete fashion and very few assumptions are made about what the reader knows. . . . The book is extremely useful as a reference, as it contains a 70-page glossary of terms and is very well indexed. It is organized in such a way that the reader can focus on simple tasks without having to wade through more advanced topics until they are ready.\" Cam Marshall, Marshall Information Service LLC, Member of Front Range UNIX Users Group [FRUUG], Boulder, Colorado \"Conclusively, this is THE book to get if you are a new Linux user and you just got into the RH/Fedora world. There’s no other book that discusses so many different topics and in such depth.\" Eugenia Loli-Queru, Editor in Chief, OSNews.comThe Most Useful UNIX Guide for Mac OS X Users Ever, with Hundreds of High-Quality Examples!Beneath Mac OS® X’s stunning graphical user interface (GUI) is the most powerful operating system ever created: UNIX®. With unmatched clarity and insight, this book explains UNIX for the Mac OS X user giving you total control over your system, so you can get more done, faster. Building on Mark Sobell’s highly praised A Practical Guide to the UNIX System, it delivers comprehensive guidance on the UNIX command line tools every user, administrator, and developer needs to master together with the world’s best day-to-day UNIX reference.This book is packed with hundreds of high-quality examples. From networking and system utilities to shells and programming, this is UNIX from the ground up both the \"whys\" and the \"hows\" for every Mac user. You’ll understand the relationships between GUI tools and their command line counterparts. Need instant answers? Don’t bother with confusing online \"manual pages\": rely on this book’s example-rich, quick-access, 236-page command reference!Don’t settle for just any UNIX guidebook. Get one focused on your specific needs as a Mac user!A Practical Guide to UNIX® for Mac OS® X Users is the most useful, comprehensive UNIX tutorial and reference for Mac OS X and is the only book that delivers Better, more realistic examples covering tasks you’ll actually need to perform Deeper insight, based on the authors’ immense knowledge of every UNIX and OS X nook and cranny Practical guidance for experienced UNIX users moving to Mac OS X Exclusive discussions of Mac-only utilities, including plutil, ditto, nidump, otool, launchctl, diskutil, GetFileInfo, and SetFile Techniques for implementing secure communications with ssh and scp plus dozens of tips for making your OS X system more secure Expert guidance on basic and advanced shell programming with bash and tcsh Tips and tricks for using the shell interactively from the command line Thorough guides to vi and emacs designed to help you get productive fast, and maximize your editing efficiency In-depth coverage of the Mac OS X filesystem and access permissions, including extended attributes and Access Control Lists (ACLs) A comprehensive UNIX glossary Dozens of exercises to help you practice and gain confidence And much more, including a superior introduction to UNIX programming tools such as awk, sed, otool, make, gcc, gdb, and CVS",
    "author": [
      {
        "family": "Seebach",
        "given": "Peter"
      },
      {
        "family": "Sobell",
        "given": "Mark G."
      }
    ],
    "id": "10.5555/1051099",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "A practical guide to unix for mac OS x users",
    "type": "book"
  },
  {
    "DOI": "10.1145/2538862.2538928",
    "ISBN": "9781450326056",
    "URL": "https://doi.org/10.1145/2538862.2538928",
    "abstract": "Higher education is facing a paradigm shift in the ownership and use of computer hardware. The school computer lab is no longer the primary place of student computer use. Instead, students increasingly expect to use their own hardware to complete their school assignments. This creates a challenge for computer science educators: we must now support a wide range of heterogeneous hardware without the benefits of tight control over its use. To address this “Bring-Your-Own-Device” (BYOD) challenge, we leverage virtualization and software packaging systems to gracefully deploy and support a standardized development environment for all core CS courses across a range of both school-owned and student-owned computing devices. We have deployed and evaluated our system for the previous two years at scale and continue to actively use and develop it. It has effectively helped us support multiple classes comprising hundreds of students with very limited IT staffing. We describe the design and management of our system, present our experience using our system, and discuss the lessons we’ve learned. We also provide data reflecting current student user experience with our system. Our system has proven very effective in addressing the student BYOD challenge in a manageable, cost-efficient, and easy-to-use manner.",
    "author": [
      {
        "family": "Sayler",
        "given": "Andy"
      },
      {
        "family": "Grunwald",
        "given": "Dirk"
      },
      {
        "family": "Black",
        "given": "John"
      },
      {
        "family": "White",
        "given": "Elizabeth"
      },
      {
        "family": "Monaco",
        "given": "Matthew"
      }
    ],
    "collection-title": "SIGCSE ’14",
    "container-title": "Proceedings of the 45th ACM technical symposium on computer science education",
    "id": "10.1145/2538862.2538928",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "virtual machines, tools, package management, education, development environment, bring your own device, best practices, BYOD",
    "page": "313-318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting CS education via virtualization and packages: Tools for successfully accommodating \"bring-your-own-device\" at scale",
    "title-short": "Supporting CS education via virtualization and packages",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3606150.3606158",
    "ISBN": "9798400707353",
    "URL": "https://doi.org/10.1145/3606150.3606158",
    "abstract": "Secondary school physical education (PE) teachers are continuously challenged to find ways to support students learning and motivate them for an active and healthy lifestyle. To address this complexity, continuing teacher professional development (TPD) is key. Technological tools can facilitate the effective delivery of TPD in this context. Successful implementation of this technology, however, is not self-evident. Based on the general aim of effectively integrating technologies in the educational process and focusing on the needs of educators, this study examines how the evidence-based theoretical TARGET framework for creating a motivating PE learning climate might be embedded into a digital professional development tool for PE teachers, useful in everyday practice. It presents a case study in which a multidisciplinary team of researchers, designers, and end-users iteratively went through several phases of need identification, idea generation, designing, development, and testing. By using a participatory approach, we were able to collect contextualized data and gain insights into users’ preferences, requirements, and ideas for designing and engaging with the tool. Based on these insights the TPD TARGET-tool for PE teachers was ultimately developed. The most prominent characteristics of this tool are (1) the combination of an evaluative function with teaching strategy support, (2) the strong emphasis on ease of use due to the complex PE teaching context, (3) the avoidance of social comparison, and suggestions of normative judgment, and (4) the allowance for a high level of customization and teacher autonomy.",
    "author": [
      {
        "family": "Weeldenburg",
        "given": "Gwen"
      },
      {
        "family": "Kromkamp",
        "given": "Len"
      },
      {
        "family": "Borghouts",
        "given": "Lars"
      },
      {
        "family": "Verburg",
        "given": "Pepijn"
      },
      {
        "family": "Hansen",
        "given": "Nicolai Brodersen"
      },
      {
        "family": "Vos",
        "given": "Steven"
      }
    ],
    "collection-title": "ICFET ’23",
    "container-title": "Proceedings of the 2023 9th international conference on frontiers of educational technologies",
    "id": "10.1145/3606150.3606158",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "Teacher Professional Development, Physical Education, Participatory Design, Human-computer Interaction, Educational Technology",
    "page": "40-51",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TARGET-tool: Participatory design of an interactive professional development tool for secondary school physical education teachers",
    "title-short": "TARGET-tool",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321375777",
    "abstract": "How to Design for Software Reliability, Security, and MaintainabilityMany enterprises unfortunately depend on software that is insecure, unreliable, and fragile. They compensate by investing heavily in workarounds and maintenance, and by employing hordes of \"gurus\" to manage their systems’ flaws. This must change. And it can. In this book, respected software architect Clifford J. Berg shows how to design high-assurance applications-applications with proven, built-in reliability, security, manageability, and maintainability.High-Assurance Design presents basic design principles and patterns that can be used in any contemporary development environment and satisfy the business demand for agility, responsiveness, and low cost. Berg draws on real-world experience, focusing heavily on the activities and relationships associated with building superior software in a mainstream business environment. Practicing architects, lead designers, and technical managers will benefit from the coverage of the entire software lifecycle, showing how to: Understand and avoid the problems that lead to unreliable, insecure software Refocus design and development resources to improve software Identify project risks and plan for assurable designs Obtain the requirements needed to deliver high assurance Design application systems that meet the identified requirements Verify that the design satisfies these requirements Plan and design tests for reliability and security Integrate security design, reliability design, and application design into one coherent set of processes Incorporate these concerns into any software development methodology© Copyright Pearson Education. All rights reserved.",
    "author": [
      {
        "family": "Berg",
        "given": "Clifford"
      }
    ],
    "id": "10.5555/1076985",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "High-assurance design: Architecting secure and reliable enterprise applications",
    "title-short": "High-assurance design",
    "type": "book"
  },
  {
    "ISSN": "1092-0617",
    "abstract": "Present computer-aided design (CAD) systems, intentionally developed as detail oriented designing tools, do not fully support the activities at the early stage of product development. CAD systems, which require a detailed level of design, prohibit the creative and free expression of a design idea. The solution to the limitations of present CAD systems is to fully utilize the graphical ability of current computer systems to represent a design with an easily understood design description in the conceptual design stage. We have developed a computerized product development tool to support designing activities in the conceptual design phase. The attribute-based design description system (ADDS) is a feature-based system that incorporates life-cycle engineering analysis and solid modeling to form an integrated CAD system. It provides a simple design representation interface and assembly modeling, evaluates the design for life-cycle engineering issues, and exports the design to AutoCAD as a solid model with flexible information input requirements. The research thus provides a starting point to the development of CAD systems that support productivity in the conceptual design stage. ADDS has been validated by describing three different design examples of power transmission systems in ADDS and exporting them to AutoCAD. This paper examines the benefits of applying a specification driven approach and presents a framework for environments that can support the related design activities. The Design Analysis and Simulation Environment (DASE) based upon this framework has been successfully implemented through a joint initiative between Bell Canada and McGill University.",
    "author": [
      {
        "family": "Paluri",
        "given": "Srinivas"
      },
      {
        "family": "Gershenson",
        "given": "John K."
      }
    ],
    "container-title": "J. Integr. Des. Process Sci.",
    "id": "10.5555/1241721.1241728",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2001,
          4
        ]
      ]
    },
    "page": "83-94",
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Attribute-based design description system in design for manufacturability and assembly",
    "type": "article-journal",
    "volume": "5"
  },
  {
    "ISBN": "1488523347",
    "abstract": "There has never been a Application Development Guide like this. Application Development 62 Success Secrets is not about the ins and outs of Application Development. Instead, it answers the top 62 questions that we are asked and those we come across in our forums, consultancy and education programs. It tells you exactly how to deal with those questions, with tips that have never before been offered in print. Get the information you need–fast! This comprehensive guide offers a thorough view of key knowledge and detailed insight. This Guide introduces everything you want to know to be successful with Application Development. A quick look inside of the subjects covered: IT disciplines impacted by a security program - Certified Information Security Manager, DSDM , Deployment , Supporting PaaS and SaaS , Configuration Management ITIL, The Service Level Agreement of Data Base Administration, Application Management Lifecycle , Supporting the Customer, Enterprise s Software &amp; Platforms , The Importance Of Configuration Management Tutorial, Internet Companies , Open Source Software and security - CISSP - Certified Information Systems Security Professional, The Future of Cloud Computing , Cloud Application Development Tools, Summarizing Project Management, PMBOK and ITIL, Accelerator , The 13 Levels of MCP CCNA, Planning , Adaptive Software Development , There are six distinct levels of MDM maturity. , What is the reason to perform Qualitative Risk Assessments? - Certified Information Systems Auditor, Benefits of MDM , Agile Development Methods and ITIL, Introducing Applications on the Web , System Development and Maintenance , Speed , History, , Zoho Office Suite , The Different MCTS Certifications, MDM Component Layer Model , Microsoft Office Access, Application Management , Service Catalog, The Importance of Software Functional Testing, Origins , Architecture , Application Management, Typical Architecture of Data Warehouse , This is especially true fo...etc...",
    "author": [
      {
        "family": "Gamble",
        "given": "Willie"
      }
    ],
    "id": "10.5555/2559530",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "Emereo Publishing",
    "publisher-place": "Newstead, Queensland, AUS",
    "title": "Application development 62 success secrets: 62 most asked questions on application development - what you need to know",
    "title-short": "Application development 62 success secrets",
    "type": "book"
  },
  {
    "ISBN": "9781109465778",
    "abstract": "Training and development are necessary components to insure the success of small businesses in the changing global economy. Previous small- and medium-size enterprise (SME) research has shown that the owners and employees of small businesses receive less formal education than employees at larger firms due to high costs, inconvenient locations, inflexible schedules, lack of human resources, and owner attitudes. Technology and the advancement of internet-based learning may be a solution to many of these potential barriers. This descriptive study examines the current adoption and attitudes towards the Internet as a formal and informal training and development tool by small tourism and hospitality businesses (STHB) in Northern Norway. The study provides an introduction to SMEs and the attitudes and barriers they face in pursuing training, the advantages and disadvantages of internet-based training and a discussion of formal versus informal training methods followed by a description of the methodology and results. For this study a web-based survey link was e-mailed to 615 STHBs in Northern Norway in June and July 2008. The findings of this research have significance in the context of STHBs in Northern Norway, but given the low response rate of 24.2",
    "author": [
      {
        "family": "Fyllingness",
        "given": "Jennifer Lynne"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1834920",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "note": "AAI3383804",
    "publisher": "Seattle University",
    "title": "Internet as a training tool in small tourism and hospitality businesses in norway",
    "type": "thesis"
  },
  {
    "ISBN": "1861000375",
    "author": [
      {
        "family": "Li",
        "given": "Sing"
      },
      {
        "family": "Economopoulos",
        "given": "Panos"
      }
    ],
    "id": "10.5555/548919",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "publisher": "Wrox Press Ltd.",
    "publisher-place": "GBR",
    "title": "Professional visual c++ activex intranet programming",
    "type": "book"
  },
  {
    "ISBN": "9781595939951",
    "abstract": "Welcome to SIGSOFT 2008 and the Sixteenth ACM SIGSOFT International Symposium on the Foundations of Software Engineering (FSE-16).SIGSOFT 2008 provides many different opportunities for software engineering researchers and practitioners to interact. Four workshops, ranging in topics from specification and verification to collaborative development tools, provide an opportunity for in-depth discussion of particular areas. A doctoral symposium and a student research forum allow for lively exchange between experienced researchers and student participants. A symposium for new faculty and new researchers allows for sharing of experiences and the opportunity for those new to the field to gain advice from more experienced researchers. A symposium dedicated to software engineering educators aims to improve the recruitment, education and retention of students in software engineering. Also co-located with SIGOSFT 2008 is the 8th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering (PASTE), which provides an opportunity to explore how program analysis can help improve and extend the software tools available to developers.The main event at SIGSOFT 2008 is FSE, a leading conference for research in software engineering theory and practice. This year, FSE received 152 submissions from the global software engineering community. Each paper was reviewed by at least three members of the high-qualified technical program committee. The program committee met for one-and-a-half days to discuss the submissions in detail. Based on this discussion, the program committee selected 31 papers for presentation at the conference and publication in the conference proceedings. In addition to these papers, the conference proceedings contains abstracts from the keynote speakers and the SIGSOFT award winners that we are thrilled to have as part of the FSE-16 program.",
    "id": "10.1145/1453101",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SIGSOFT ’08/FSE-16: Proceedings of the 16th ACM SIGSOFT international symposium on foundations of software engineering",
    "title-short": "SIGSOFT ’08/FSE-16",
    "type": "book"
  },
  {
    "ISBN": "0136449336",
    "abstract": "Creative professionals seeking the fastest, easiest, most comprehensive way to learn Adobe Animate choose Adobe Animate Classroom in a Book (2020 release) from Adobe Press. The 11 project-based step-by-step lessons in this book show users the key techniques for working in Animate. Adobe Animate provides more expressive tools, powerful controls for animation, and robust support for playback across a wide variety of platforms. Create interactive virtual reality immersive environments with VR 360 and VR Panorama documents. Gain advanced control over character animations with layer parenting and AI-driven lip syncing. Learn to create dynamic strokes with the new fluid brush, and work smarter with the revamped Timeline, Tools palette and Properties inspector. Support for SVG, WebGL, HTML5, animated GIFs, and HD video, and seamless collaboration with other designers and with other Adobe applications through Creative Cloud libraries make Adobe Animate the ideal development environment for creative animation and multimedia. Classroom in a Book is the best-selling series of hands-on software training books designed to help you learn the features of Adobe software quickly and easily. Developed by the training experts at Adobe Systems, these books offer complete, self-paced lessons designed to fit your busy schedule and help you learn the features of Adobe software quickly and easily. The online companion files include all the necessary assets for students to complete the projects featured in each chapter as well as eBook updates when Adobe releases new features for Creative Cloud customers. And all buyers of the book get full access to the Web Edition: a Web-based version of the complete eBook enhanced with video and interactive multiple-choice quizzes.",
    "author": [
      {
        "family": "Chun",
        "given": "Russell"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3387334",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "publisher": "Adobe Press",
    "title": "Adobe animate: 2020 release",
    "title-short": "Adobe animate",
    "type": "book"
  },
  {
    "ISBN": "9789606766428",
    "abstract": "In the recent years, software development has become larger in scale and more complicated. Furthermore, development with faster delivery and lower cost is required, thus the software development environment is becoming more and more complex. Accordingly, companies seek high potential students in universities who have a practical sense. The information engineering department of Shibaura Institute of Technology provides classes that adopt a more practical approach to software development so that students can obtain knowledge and skills necessary for software development. However, as class hours assigned for learning software engineering are not sufficient, a support system that enables students to practice outside the classroom or school is required. This support system should have work such that it enables each member belonging to the same group to collectively perform tasks just like in the classroom. In order to solve this problem, the authors developed EtUDE [1][2], the group exercise support environment for software development. Although group exercise helps to reduce the burden of instructing compared to individual exercise, it is difficult to offer instructions that meet the individual’s needs. However, it is the goal of the exercise-based classes to accomplish the obtainment of knowledge and skills for software development according to each student’s level. Therefore, the authors developed the group exercise support environment for software development, EtUDE which features various functions necessary for group exercise support as well as the function that detects learners who do not benefit from the group exercise and need individual instruction. With this, the software development exercise in more practical form will be available, and at the same time, it is made possible to acquire the knowledge and skills necessary for software development according to each student’s level. This essay presents the overview of EtUDE system and the outcome of the application of the system.",
    "author": [
      {
        "family": "Hashiura",
        "given": "Hiroaki"
      },
      {
        "family": "Yamashita",
        "given": "Kotaro"
      },
      {
        "family": "Ishikawa",
        "given": "Tatsuya"
      },
      {
        "family": "Isozaki",
        "given": "Yuka"
      },
      {
        "family": "Komiya",
        "given": "Seiichi"
      }
    ],
    "collection-title": "SEPADS’08",
    "container-title": "Proceedings of the 7th WSEAS international conference on software engineering, parallel and distributed systems",
    "id": "10.5555/1416502.1416527",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "software development group exercises, software development environment",
    "page": "124-131",
    "publisher": "World Scientific; Engineering Academy; Society (WSEAS)",
    "publisher-place": "Stevens Point, Wisconsin, USA",
    "title": "A software development group exercise support environment, EtUDE: The system overview and the system evaluation through applying to classes",
    "title-short": "A software development group exercise support environment, EtUDE",
    "type": "paper-conference"
  },
  {
    "abstract": "A critiquing expert system was developed to assist in operating San Francisco’s water supply network. The critiquing system goes beyond a traditional expert system by refining (rather than supplying) the user’s proposed operating plan through a critique. A traditional expert system requests problem-specific data, then provides the operator with a plan. In the critiquing approach, the operator submits not only relevant information to the system, but also a proposed plan. The system evaluates the plan and provides feedback, which includes suggestions for improvement, warnings, and alternatives. The SFWD was motivated to have the critiquing system developed because of the perceived benefits in formalizing operating expertise in a critiquing system. Operating decisions are based on heuristic knowledge, not mathematical models. When personnel leave, the SFWD loses key information about how to operate the water supply network. A critiquing system can improve operators’ decisions by providing expert feedback on their proposed plans, and can aid in training novice operators.Building the critiquing expert system provided several technical challenges. A new paradigm was designed to implement critiquing in an expert system development tool. Also, developing a critiquing system is more complex than developing a traditional expert system. The critiquing paradigm and system development techniques designed for this research can be used to build critiquing systems in a variety of domains.The research included experiments to test the postulated advantages of the critiquing approach over the traditional approach to expert systems. The results were unambiguous; the critiquing system was preferred to the traditional expert system for each of several measures of system performance and acceptability.The research makes three main contributions. First, the research establishes the feasibility of implementing a critiquing system for decision support in a civil engineering problem domain. Second, the research demonstrates, both theoretically and empirically, the substantial benefits of the critiquing approach to expert systems. Third, the research reveals ways the organization influences the system’s development, and how system development profoundly influences the organization. Not only the system itself, but also the development process that creates the system, fosters organizational acceptance and use of the system.",
    "author": [
      {
        "family": "Steinemann",
        "given": "Anne Carol"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/193660",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "note": "UMI Order No. GAX94-04052",
    "publisher": "Stanford University",
    "publisher-place": "Stanford, CA, USA",
    "title": "A critiquing expert system to assist in operations of the san francisco water supply system",
    "type": "thesis"
  },
  {
    "ISBN": "0130331155",
    "abstract": "From the Publisher: Dont wait another day to get started with tomorrows most important enterprise development technology! Master .NET hands-on with this start-to-finish multimedia training course. Based on Bertrand Meyers amazing in person .NET seminar, this course delivers all the guidance and code you need to get results with .NET — now! Youll start with the big picture then gain insiders insights into .NETs advantages, architecture, runtime, object model, deployment, and migration. Discover practical techniques for working with every key .NET technology, from C# to ASP+, SOAP to .NET frameworks, and beyond. Its all the .NET you need, in one box! Video lectures from one of the worlds top .NET experts! 6+ hours of comprehensive digital seminars on every aspect of the .NET platform — planning through coding! Covers every key .NET technology! C#, ASP+, ADO+, SOAP, and more Real-world insights into .NET deployment, migration, handling legacy code, and more Workbook includes all lecture slides, background material, and .NET glossary All the .NET skills you need, in one box! .NET in 15 minutes: an insiders overview .NET and Internet-centered mission-critical applications Beyond the limits of yesterdays components .NET architecture: runtime, framework, platform, and web services .NET runtime vs. Java Virtual Machine The MSIL intermediate language: security, variability, and more Managed code C++ under .NET: Managed and unmanaged versions Assemblies &amp; metadata: Organizing and extending your componentscomponents with contracts. .NET object model and type system Classes, methods, fields, properties and events .NET types: reference and value types, array types, arrays Inheritance concepts: multiple interface inheritance, novariance Encapsulating behavior: delegates Understanding C#: Microsofts new .NET programming language Language interoperability: Java, C++, VB, and more Cross-language inheritance and debugging The Common Language System Visual Studio.NET: a common multi-language development environment Frameworks and applications Web and Win Forms Remoting and threading ASP+: advanced e-commerce &amp; Web solutions Web services, SOAP, and Building Block Services Database access and manipulation: ADO The significance and future of .NET Corporate strategies: Getting ready for .NET",
    "author": [
      {
        "family": "Meyer",
        "given": "Bertrand"
      }
    ],
    "id": "10.5555/516473",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": ".NET training course by bertrand meyer",
    "type": "book"
  },
  {
    "abstract": "Context: Software defects occurring in code bases lead to an increased cost for software production and maintenance. To err is human nature and the process of software development is human centric. My analysis of the literature shows that the use of human error theory is emerging as an important tool for software development. Aim: The aim of my thesis is to present a training tool aimed at reducing the number of human errors developers make while working within the development phase of the Software Development Life cycle (SDLC) by improving developer situation awareness. Methods: My first study uses semi structured interviews to gain insight into what Skill-based (SB) errors developers make and how they mitigate these errors. My second study employs an experimental setup where developers log all human errors they make during developmental tasks across two weeks. At the beginning of week two the developers are asked to complete an online training package which I have developed on situation awareness. Results: The first study shows that the complexity of the development environment is one of the most frequently reported reasons for errors. I found that software developers struggle with effective mitigation strategies for their errors, reporting strategies largely based on improving their own willpower to concentrate better on development tasks. The results from the second study show that training software developers in situation awareness does lead to a decrease in the number of human errors made by those software developers. Conclusion: My doctoral research shows that human errors are a problem for software developers and loss of situation awareness is key for many of these developers. My preliminary results show that training tools which address situation awareness can aid developers in reducing the number of human errors that they make. Further work is required to investigate other means of improving developer situation awareness and determine whether my findings are generalisable.",
    "author": [
      {
        "family": "Nagaria",
        "given": "Bhaveet"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI29351245",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "note": "AAI29351245",
    "publisher": "Brunel University (United Kingdom)",
    "title": "An investigation of human error in software development",
    "type": "thesis"
  },
  {
    "ISBN": "0321934113",
    "abstract": "Few books in computing have had as profound an influence on software management as Peopleware . The unique insight of this longtime best seller is that the major issues of software development are human, not technical. Theyre not easy issues; but solve them, and youll maximize your chances of success. Peopleware has long been one of my two favorite books on software engineering. Its underlying strength is its base of immense real experience, much of it quantified. Many, many varied projects have been reflected on and distilled; but what we are given is not just lifeless distillate, but vivid examples from which we share the authors inductions. Their premise is right: most software project problems are sociological, not technological. The insights on team jelling and work environment have changed my thinking and teaching. The third edition adds strength to strength. Frederick P. Brooks, Jr., Kenan Professor of Computer Science, University of North Carolina at Chapel Hill, Author of The Mythical Man-Month and The Design of Design Peopleware is the one book that everyone who runs a software team needs to read and reread once a year. In the quarter century since the first edition appeared, it has become more important, not less, to think about the social and human issues in software development. This is the only way were going to make more humane, productive workplaces. Buy it, read it, and keep a stock on hand in the office supply closet. Joel Spolsky, Co-founder, Stack Overflow When a book about a field as volatile as software design and use extends to a third edition, you can be sure that the authors write of deep principle, of the fundamental causes for what we readers experience, and not of the surface that everyone recognizes. And to bring people, actual human beings, into the mix! How excellent. How rare. The authors have made this third edition, with its additions, entirely terrific. Lee Devin and Rob Austin, Co-authors of The Soul of Design and Artful Making For this third edition, the authors have added six new chapters and updated the text throughout, bringing it in line with todays development environments and challenges. For example, the book now discusses pathologies of leadership that hadnt previously been judged to be pathological; an evolving culture of meetings; hybrid teams made up of people from seemingly incompatible generations; and a growing awareness that some of our most common tools are more like anchors than propellers. Anyone who needs to manage a software project or software organization will find invaluable advice throughout the book.",
    "author": [
      {
        "family": "DeMarco",
        "given": "Tom"
      },
      {
        "family": "Lister",
        "given": "Tim"
      }
    ],
    "edition": "3rd",
    "id": "10.5555/2505459",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Peopleware: Productive projects and teams (3rd edition)",
    "title-short": "Peopleware",
    "type": "book"
  },
  {
    "DOI": "10.1016/j.cageo.2019.02.009",
    "ISSN": "0098-3004",
    "URL": "https://doi.org/10.1016/j.cageo.2019.02.009",
    "author": [
      {
        "family": "Pu",
        "given": "Yingxia"
      },
      {
        "family": "Zhao",
        "given": "Xinyi"
      },
      {
        "family": "Chi",
        "given": "Guangqing"
      },
      {
        "family": "Zhao",
        "given": "Shuhe"
      },
      {
        "family": "Wang",
        "given": "Jiechen"
      },
      {
        "family": "Jin",
        "given": "Zhibin"
      },
      {
        "family": "Yin",
        "given": "Junjun"
      }
    ],
    "container-title": "Comput. Geosci.",
    "id": "10.1016/j.cageo.2019.02.009",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          6
        ]
      ]
    },
    "keyword": "Parallel gwk-NN classifier, Geostatistical models, Parallel computing, Remotely sensed image classification",
    "page": "111-122",
    "publisher": "Pergamon Press, Inc.",
    "publisher-place": "USA",
    "title": "Design and implementation of a parallel geographically weighted k-nearest neighbor classifier",
    "type": "article-journal",
    "volume": "127"
  },
  {
    "ISBN": "0805370838",
    "abstract": "From the Book: Preface: Motivation After teaching file processing courses for years using COBOL as the vehicle language, I concluded that the students do learn to use COBOL for a variety of file organizations (sequential, indexed sequential, and relative) but do not gain an understanding of the data structures involved in implementing the more complex file structures such as direct files and indexed sequential files. A programming language with less support for file organizations than COBOL allows the students to gain greater in-depth knowledge about the implementation of routines that access data structures on external files. Pascal, with its support for relative files, fills this need. Goal This textbook meets the requirements for The Association for Computing Machinery (ACM) course CS5 as defined in the ACM curriculum guidelines. The goal of the book is to study the external data structures necessary for implementing different file organizations. Most texts currently available present file processing by using languages such as COBOL or PL/1, which have built-in support for direct access and indexed sequential access. Pascal does not have this built-in support. Instead, this language can be used in a more practical, prdagogical way by allowing students to gain more in-depth file implementation experience as they analyze data structures for efficiency and write their own access routines. The algorithms in this book are presented in a Pascal-like pseudocode, which provides students with a familiar environment in which to study the key concepts and structures necessary to implement a variety of file organizations.Datastructures such as trees, linked lists, stacks and queues are studied and analyzed for efficient use in the implementation of various file organizations. By using a superior pedagogical language such as Pascal and analyzing key data structures, students will gain a better understanding of design analysis and the implementation of file organization. Level/Audience/Prerequisites The prerequisites for the course addressed by this book, CS5, are two semesters of Pascal; in other words students should already have taken ACM CS1 and CS2 courses. Third-semester Computer Science majors constitute the primary audience for this book. Organization and Coverage Chapter 1 presents a conceptual overview of the file-processing environment, including discussions of common file organizations, file types and characteristics, and different ways of manipulating files as factors that affect file design. Several of the examples of file applications in this chapter are referenced in later chapters. Chapter 2 reviews the syntax for declaring and using records and for declaring and accessing files in Pascal. This chapter may be omitted for those students with a good understanding of Pascal records and files. Chapter 3 deals with the topics of blocking and buffering of records in a file. The central theme of the chapter is the fewer I/O operations required for a program that accesses a blocked file and the reduction of the time that the CPU waits for an I/O operation to be completed when using a buffered file. Interfacing algorithms for record blocking and deblocking are also presented. Quantitative measures of the effects of blocking and buffering effects are given solely in terms of the number of I/O accesses. Chapter 4 describes external storage devices as a background for understanding the impact of storage devices on file design and manipulation. Quantitative measures of the effects of blocking and buffering (similar to those in Chapter 3) are repeated in terms of physical access time of the devices using various blocking factors and different numbers of buffers. Chapter 5 deals with the design and maintenance of sequential files on both sequential and random-access storage devices. Algorithms for maintenance of sequential files stored on sequential devices are contrasted with algorithms for maintenance of sequential files stored on random-access devices. Sample data for a car-rental agency are used for implementating a sequential file. Quantitative measures of access times are given. Chapter 6 describes external sort/merge techniques, which are necessary for sorting very large sequential files. Sorting is a common file-processing task, especially for manipulating sequential files. Sorting methods discussed at length are the two-way merge, the balanced k-way merge, and the polyphase merge. These methods are compared in terms of the number of merge cycles and external storage devices needed for several example data sets. Chapter 7 begins with a discussion of the basic structures of direct files. A variety of techniques are presented for obtaining random access to data files, including the use of hashing. Examples are used to illustrate several methods for handling hashing collisions. Also included are some algorithms for creating and maintaining random-access files in versions of Pascal with the random-access files extension. In order to compare random and sequential access, the car-rental agency data used in Chapter 5 are stored in a random-access file and quantitative measures of access times are computed. Chapter 8 describes several types of tree structures that are useed to accessing random-access files sequentially. The most important tree structure is the B-Tree, and ways of representing and manipulating the B-tree are discussed along with accompanying algorithms. The chapter also discusses the application of trees that allow sequential and random access to the car-rental agency data file created in Chapter 7. Chapter 9 describes common implementations of indexed sequential organization, including implementations that use a tree structure, such as a B+-Tree, for the indexes. The chapter studies Scope Indexed Sequential files used on CDC computers, cylinder-and-surface-indexed sequential files (ISAM) used on IBM computers, and VSAM file organization used on IBM computers. Also included are algorithms for implementing indexed sequential files using a variety of data structures. Applications include the car- rental agency data, and access times for sequential, random, and indexed sequential files are compared. Chapter 10 investigates other types of file organization that use linked lists or tree structures to provide multiple-key access to random-access data files. Included in this chapter is a discussion of inverted files and multilist files along with creation and manipulation algorithms. The car-rental agency data are implemented as an inverted file and multilist files to provide access by several keys. Quantitative measures of access times are given by comparing these file organizations with others discussed previously. Outstanding Features Pedagogy Case Studies: Chapter 5 introduces a case study based on an actual car-rental agency, and this case study is used throughout the book as an on-going example illustrating practical file concepts and issues. Additional practical, real-world case studies are presented in Chapter 2. They include discussions of an inventory of products, student class schedules, and the assignment of course grades for a class. Examples/Illustrations: Throughout the book algorithms are presented in Pascal-like pseudocode. Students learn best by working with files of varying organizations rather than just reading about them. A variety of exercises and programming projects have been provided that illustrate the creation and manipulation of files for each type of organization. Students can implement the algorithms from the book in a hands-on, file organization programming environment, thus gaining experience and greater knowledge of all key concepts. The program solutions for these exercises are available from the author. Solutions to odd- numbered exercises are provided at the back of the book while the solutions to even-numbered exercises are provided in the Instructor’s Guide. Glossary/Key Terms: Key terms are highlighted and defined as they occur in the test, and are also included in the glossary in the end of the book. Class Tested: This book was thoroughly class tested for six semesters in a sophomore-level file structures course. The readability of the book was greatly enhanced because of student and reviewer feedback over the course of several drafts. The Use of Pascal Chapter 2 reviews the Pascal syntax for declaring, using, and accessing Pascal records and files. This chapter can be omitted for those students with a good understanding of Pascal. The Pascal syntax for records, linked lists and trees is included in corresponding sections. The first two sections of the book (I and II) reference the ISO standard Pascal, while sections III and IV require random-access files, which are not included in the ISO standard. Most versions of Pascal have been extended to allow random access (OMSI Pascal, TURBO Pascal, UCSD P-System Pascal, and VAX-11 Pascal, to name a few). Appendix A includes a sequential simulation of random access using arrays in internal memory as an easy alternative to those versions of Pascal without random access. The syntax for random access for various versions of Pascal is included in Appendix B. Instructor’s Guide The accompanying Instructor’s Guide includes: guidelines for presenting the material in each chapter additional examples for classroom use, including points to be emphasized solutions to all even-numbered exercises transparency masters of various illustrations and tables from the book quizzes for each chapter Software: A disk of solutions to all programming problems is available from the author for a nomimal fee to all instructors. Acknowledgements I am grateful to the numerous individuals that have helped me in preparing this book. I am indebted to the faculty of the Computer Science Department of Mississippi State University for providing equipment and an environment conducive to writing a book. My thanks also go to the reviewers: James D. Schoeffler, Cleveland State University; Rayno D. Niemi, Rochester Institute of Technology; James Blahnik, St. Norbert’s College; Medhi Owrand, University of Oklahoma; Robert Uzgalis, University of California at Los Angeles; Walter Scacchi, University of Southern California. Special thanks to the students in my classes who corrected typing errors in earlier versions of the book. I express my appreciation to my Editor Alan Apt and all those individuals at Benjamin/Cummings who have organized the reviewing and production of this book. Finally, I thank my husband for his continued support, encouragement, and understanding. Nancy E. Miller",
    "author": [
      {
        "family": "Miller",
        "given": "Nancy E."
      }
    ],
    "id": "10.5555/535835",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "publisher": "Benjamin-Cummings Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "File structures using pascal",
    "type": "book"
  },
  {
    "ISBN": "0072123869",
    "abstract": "From the Publisher: Windows 2000 advantage includes decreased cost of ownership through improved directory services,increased security,better integration with database and development tools,and vastly expanded network and /Internet/Web capabilities. Explains how to optimize and maintain the Active Directory,plan the active directory namespace,develop the organization and implementation of a domain,and manage Active Directory replication. Visually maps complicated processes wth frequent screen shots to help build familiarity with the new functions. CD-RO contains more than 300 practice questions on TEST YOURSELF Personal Testing Center software along with lings to the chapter in the book for review. The Only Classroom-Based Training and Self-Assessment System 100",
    "author": [
      {
        "family": "Shinder",
        "given": "Thomas W."
      },
      {
        "family": "Shinder",
        "given": "Debra Littlejohn"
      }
    ],
    "id": "10.5555/557256",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "McGraw-Hill Professional",
    "title": "MCSE windows 2000 server study guide (exam 70-215) (book/CD-ROM)",
    "type": "book"
  },
  {
    "DOI": "10.1145/100348.100412",
    "ISBN": "0897913485",
    "URL": "https://doi.org/10.1145/100348.100412",
    "abstract": "Software reusability has been proclaimed as the common sense solution to many software development problems. The concept of reusability promotes productivity because it avoids “reinventing the wheel.” Using existing components which are similar to the current needs can be much faster than creating components from scratch. Reusability can also be viewed as promoting reliability since reused components have the benefit of both experimental and field testing.However, reusability has not fulfilled its potential for revolutionizing the software development industry. Identifying the factors which cause current reuse efforts to fail is essential to its later success. Likewise, identifying the factors that seem to promote successful reusability is equally important. Furthermore, practical ways to eliminate the detrimental factors must be developed.An experiment designed to ferret out the causes of software reuse success and failure must consider several important issues: (1) The experiment must consist of actual development and reuse. Questionnaires and subjective measurements about whether to reuse, etc. are necessary but not sufficient. (2) The experiment must be greatly controlled to avoid extraneous factors from skewing the results. Factors which might influence the outcome must be deliberately tested for, or controlled such that they do not bias the experimental data. (3) The components to be reused must be determined. Reusing requirements and designs has been suggested, but with little success. On the other hand, reusing test cases has been greatly successful. In between is code. Current experiments should still concentrate on the ability to reuse source code. You must walk before you run. (4) Finally, the factors being tested must be established and they must consider two main tangents. First, specific factors concerning the code characteristics, the organization of components, and the development environment must be considered. Other concerns deal with the human factors. Predisposition, ego, training and skill must be taken into account for an accurate study of reusability.A current reusability experiment concentrates on the use of an object-oriented organization scheme, reusable code characteristics, and several human factors. The experimental subjects actually design and implement code under varying conditions. Subjects are divided into groups that must reuse whenever possible, may reuse if desired, and cannot reuse at all. Comparing the results of the various groups will lead to a better understanding of the problems faced in software reusability.",
    "author": [
      {
        "family": "Lewis",
        "given": "John A."
      }
    ],
    "collection-title": "CSC ’90",
    "container-title": "Proceedings of the 1990 ACM annual conference on cooperation",
    "id": "10.1145/100348.100412",
    "issued": {
      "date-parts": [
        [
          1990
        ]
      ]
    },
    "page": "405",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An experiment to determine software reusability factors (abstract)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1155/2021/7106104",
    "ISSN": "1530-8669",
    "URL": "https://doi.org/10.1155/2021/7106104",
    "abstract": "With the rapid development of the economy, the integration of corporate strategic management and human resource management has become an issue of concern. This research mainly discusses the role of intelligent communication management terminal in the construction of human resource management mode. In this research, the system development process of this research mainly uses the class library in the software architecture layer to support the software development process. The main development language of Android, JAVA, is to install the Android Develop Tools plug-in on eclipse and install the Android SDK in the computer operating system to build the Android development environment. The development and application of the system not only make the enterprise managers more convenient and efficient in the process of managing the enterprise but also smooth the operation of the enterprise while reducing the human resource investment and also gives the employees more right to know and the right to participate in the enterprise construction. By creating more value while reducing human resource input, enterprises will enable it to obtain more benefits, and thus enter a cycle of good development and contribute to society. The system has the functions of personnel management, recruitment management, attendance management, training management, work management, and salary management. The recruitment management function of the system is mainly composed of recruitment plan management, recruitment information management, and talent pool. In the system’s recruitment plan management function, important information such as the recruitment part, the number of recruits, personnel requirements, and the specific arrival time of the personnel must be clarified. The personnel in charge of the enterprise personnel department shall conduct corresponding regulations according to the specific needs of the enterprise and shall be experienced by the personnel department. The review is carried out, and all parts of the enterprise are coordinated and completed at the same time. In the platform performance test, when the number of concurrent users reaches 50000, the request time is about 6 seconds, which meets the requirement that the response time of 10000 people per second is less than 10 seconds. This research puts forward suggestions and countermeasures for the optimization of human resource management, which can not only improve the efficiency of Y company’s human resource management but also provide useful reference and reference for other enterprises facing the same problem.",
    "author": [
      {
        "family": "Wu",
        "given": "Shumei"
      },
      {
        "family": "Lv",
        "given": "Zhihan"
      }
    ],
    "container-title": "Wirel. Commun. Mob. Comput.",
    "id": "10.1155/2021/7106104",
    "issued": {
      "date-parts": [
        [
          2021,
          1
        ]
      ]
    },
    "publisher": "John Wiley; Sons Ltd.",
    "publisher-place": "GBR",
    "title": "Intelligent communication management terminal in the construction of human resource management mode",
    "type": "article-journal",
    "volume": "2021"
  },
  {
    "DOI": "10.1145/3626252.3630816",
    "ISBN": "9798400704239",
    "URL": "https://doi.org/10.1145/3626252.3630816",
    "abstract": "Many CS1 teachers focus on specific content approaches in CS1. Some want objects early, some functions early, some decisions/loops first. Some put emphasis on language details, some on language-neutral problem solving. Some demand real-world IDEs, code versioning tools, industry-quality comments, specifications, documentation, or test coverage. While the focus shows teachers care and may indeed provide benefits, those specific focuses can also prevent increased cooperation among universities in defining a more \"common\" CS1 curricula. With a more common curriculum, better content and tool support is enabled due to economies of scale. Such cooperation could yield a more powerful approach to teaching CS1, elevating the role of CS1 instructors. CS1 instructors, by being more flexible in their content approaches, may help show the college education community the great benefits of increased cooperation among universities, especially in the design and delivery of introductory gateway courses taken by large numbers of students. We describe results of discussions with over 100 instructors at over 50 universities during the past decade, highlighting frequently-stated content approaches that have little or no evidence supporting the approach and that may hamper cooperation, and we end by encouraging flexibility in content approaches to enable the community and publishers to provide better CS1 support.",
    "author": [
      {
        "family": "Vahid",
        "given": "Frank"
      }
    ],
    "collection-title": "SIGCSE 2024",
    "container-title": "Proceedings of the 55th ACM technical symposium on computer science education v. 1",
    "id": "10.1145/3626252.3630816",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "common courses, cooperation, cs1, programming, teaching",
    "page": "1368-1373",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CS1 instructors: Flexibility in content approaches is justified, and can enable more cross-university cooperation",
    "title-short": "CS1 instructors",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321545494",
    "abstract": "Regardless of your perceptions of Agile, this is a must read! Douglasss book is a powerful and practical guide to a well-defined process that will enable engineers to confidently navigate the complexity, risk, and variability of real-time and embedded systemsincluding CMMI compliance. From requirements specification to product delivery, whatever your modeling and development environment, this is the instruction manual. Mark Scoville, software architect This book will provide you with the framework of agile development for real-time projects ranging from embedded systems to web-based, data collection applications. I wish I had this book three years ago when we began a real-time, embedded drilling control system project, but all my engineers will be getting copies now that it is available. And, for my academic colleagues, this is the perfect book for graduate seminars in applied software development techniques. Don Shafer, chief technology officer, Athens Group; adjunct professor, Cockrell School of Engineering, The University of Texas at Austin We have used Dr. Douglasss books on real-time (Doing Hard Time, Real-Time UML, and Real-Time Design Patterns) for years. His books are always informative, accessible, and entertaining. Real-Time Agility continues that tradition, and I cant wait to introduce it to my colleagues. Chris Talbott, principal software designer Until now, agile software development has been mostly applied within the IT domain. This book breaks new ground by showing how to successfully traverse the perceived chasm between agility and real-time development. Although embedded systems impose challenging constraints on development teams, you can always benefit from increasing your agility. Scott W. Ambler, chief methodologist/Agile, IBM Rational; author of Agile Modeling Real-time and embedded systems face the same development challenges as traditional software: shrinking budgets and shorter timeframes. However, these systems can be even more difficult to successfully develop due to additional requirements for timeliness, safety, reliability, minimal resource use, and, in some cases, the need to support rigorous industry standards. In Real-Time Agility, leading embedded-systems consultant Bruce Powel Douglass reveals how to leverage the best practices of agile development to address all these challenges. Bruce introduces the Harmony/ESW process: a proven, start-to-finish approach to software development that can reduce costs, save time, and eliminate potential defects. Replete with examples, this book provides an ideal tutorial in agile methods for real-time and embedded-systems developers. It also serves as an invaluable in the heat of battle reference guide for developers working to advance projects, both large and small. Coverage includes How Model-Driven Development (MDD) and agile methods work synergistically The Harmony/ESW process, including roles, workflows, tasks, and work products Phases in the Harmony/ESW microcycle and their implementation Initiating a real-time agile project, including the artifacts you may (or may not) need Agile analysis, including the iteration plan, clarifying requirements, and validation The three levels of agile design: architectural, mechanistic, and detailed Continuous integration strategies and end-of-the-microcycle validation testing How Harmony/ESWs agile process self-optimizes by identifying and managing issues related to schedule, architecture, risks, workflows, and the process itself",
    "author": [
      {
        "family": "Douglass",
        "given": "Bruce Powel"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1572526",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Real-time agility: The harmony/ESW method for real-time and embedded systems development",
    "title-short": "Real-time agility",
    "type": "book"
  },
  {
    "ISBN": "1861005040",
    "abstract": "From the Publisher: ASP.NET is the latest incarnation of Microsoft’s Active Server Pages (ASP) - a powerful server-based technology, designed to create dynamic and interactive HTML pages for your Web site, or corporate intranet. ASP.NET also constitutes a core element in Microsoft’s .NET vision, providing web-based access to an immensely powerful new development environment, .NET; in this respect alone, it’s a great leap ahead of all previous versions of ASP. This book will provide you with a step-by-step introduction to ASP.NET using VB.NET, with plenty of worked examples that will help you to gain a deep understanding of what ASP.NET is all about, and how you can harness it to build powerful web applications. This book covers: Creating basic ASP.NET pages Learning the basics of VB.NET Understanding the concepts of Object Oriented Programming Working with Data and XML The ASP.NET Server Controls Creating User Controls and Components Exploring the world of Web Services Configuring your ASP.NET Applications The future of VoiceXML technologies, including VoiceXML 2.0 This book is aimed at relatively inexperienced web builders who are looking to enrich their sites with dynamically-generated content, and want to learn how to start building web applications using ASP.NET. Developers who have a little experience with previous versions of ASP (and are looking to move over to ASP.NET), may also find this book helpful in getting a simple grasp on what ASP.NET is, what it does, and how it can be used. Experience of basic HTML is required, but previous experience of ASP or VBScript is not essential. We’ll be teaching the basics of VB.NET in this book, so prior experience of VB.NET is not required. This is one of two editions of Beginning ASP.NET. This version presents all code examples in Visual Basic .NET. The C# version of the same title (Beginning ASP.NET using C#, ISBN: 1-861006-15-2) will be available from November 2001. Author Biography: Chris Ullman is a Computer Science graduate who came to Wrox five years ago, when 14.4 modems were the hottest Internet technology and Netscape Navigator 2.0 was a groundbreaking innovation. Since then he’s applied his knowledge of HTML, server-side web technologies, Java and Visual Basic to developing, editing and authoring books. Ollie Cornes has been working with the Internet and the Microsoft platform since the early 90’s. In 1999 he co-founded a business-to-business Internet company and until recently was their Chief Technical Officer. Prior to that his various roles involved programming, technical authoring, network management, writing, leading development projects and consulting. He has worked with Demon Internet, Microsoft, Saab, Travelstore and Vodafone. Ollie holds a degree in computer science and is Microsoft certified. Juan T. Llibre is the Director of the Computer Sciences and Distance Education departments at Universidad Nacional Pedro Henrı́quez Ureña in Santo Domingo, Dominican Republic. He has been a consultant to the Caribbean Export Development Agency and the Dominican Republic’s Central Bank and is currently the Technical Architect for the Caribbean Virtual University. Juan has been an Active Server Pages Microsoft MVP for 4 years and can regularly be found in the newsgroups and mailing lists, offering advice on ASP and ASP.NET in English and Spanish. He co-authored Wrox’s \"Beginning ASP 2.0\" and \"Beginning ASP 3.0\", and has been a Technical Reviewer for over a dozen books on ASP and its related technologies. Chris Goode is a Technical Architect in the .NET team at Wrox, currently specializing in ASP.NET. She has a degree in Mechanical Engineering, but decided that the engineering world wasn’t for her. She’s now back firmly in the world of computers, finding that life at Wrox combines the fun stuff with the work stuff pretty well.",
    "author": [
      {
        "family": "Team",
        "given": "Wrox Author"
      },
      {
        "family": "Llibre",
        "given": "Juan T."
      },
      {
        "family": "Goode",
        "given": "Chris"
      }
    ],
    "edition": "1st",
    "id": "10.5555/559366",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Wrox Press Ltd.",
    "publisher-place": "GBR",
    "title": "Beginning ASP.NET using VB.NET",
    "type": "book"
  },
  {
    "ISBN": "0201185377",
    "abstract": "From the Book: PREFACE: Why Another Book on Microsoft Foundation Classes Programming To answer this question, let us look at a typical MFC programming scenario. First, you attend an MFC training session or read some introductory books on MFC programming. You quickly become able to write and customize small tutorial applications. AppWizard and ClassWizard allow you reach an unprecedented level of productivity. Your applications support the multiple document interface (MDI) and have a professional-looking user interface with a floating toolbar, a status bar, printing and print preview, and so on. You then go back to work and start using MFC to produce great-looking applications. Code flows freely from your keyboard, the wizards work hard at your side, and life looks great under the MFC sun. One day, you start wondering about how to implement new features that were not explicitly covered in the training session. For example: Make your application remember the last active document and automatically reopen it. Support multiple kinds of views on the same document and allow the user to explicitly open any kind of view. Add ToolTips to the controls in a form view. Dynamically switch the view displayed in a window to replace it with another kind of view. Implement an expanding dialog box. Embed a property sheet (tabbed dialog box) inside another window, such as a form view, a dialog box, or a mini frame window. Display a progress indicator in a status bar pane. Have a menu pop up when the user clicks a button on a toolbar or in a dialog box. Support headers and footers in your print and print preview. Displaya custom Printing . . . dialog box with a progress indicator. You feel that implementing these features cannot be that difficult: after all, you have already seen them in other Windows applications. But where do you start looking for an answer The solution may be as easy as knowing the specific MFC virtual functions that you must override to produce the desired effect or knowing the Windows messages you should trap and handle appropriately. For some features, however, more involved techniques may be neededeven to the point of tracing into MFC’s source code to understand just where and how you can act to modify your application’s default behavior. One infuriating fact of life is that the answer to your particular question may be lying around somewhere: buried in some MFC programming book or magazine article, on the Microsoft Developer’s Network CD-ROM, in the Microsoft Knowledge Base, in the various threads and mailing lists maintained on the Internet, or even in the online books or samples contained on the Visual C++ CD-ROM. The problem is this: How are you going to locate the most relevant and reliable source of information among all these resources How are you going to find the solution you need right now Introducing The MFC Answer Book This book is intended to provide ready-to-use techniques that answer the most common real-world questions that typically confront MFC developers. The structure of this book is specifically designed to help you quickly locate the answers youire looking for and integrate the relevant solutions into your own programs. The FAQ format of this book makes it ideally suited to the needs of the developer looking for a quick answer to a pressing question. At the same time, you will find that many techniques will give you a better understanding of the inner workings of MFC applications and more generally help you improve your MFC programming skills. In particular, the Explanations and Additional Comments sections often delve into the MFC source code or undocumented functions to explain how the techniques discussed work and how they differ from or integrate with MFC’s default behavior. Key Features of This Book Although most books about Visual C++ and MFC programming answer valid questions about MFC programming and provide useful tips if you read them from cover to cover, most of them are not structured in a way that allows you to quickly find an answer to a given problem. Moreover, even if you find the answer, it is likely to be buried inside a larger discussion and not readily available as a step-by-step technique that you can simply incorporate into your current project to add a required feature. In contrast, The MFC Answer Book is specifically designed to help MFC developers solve their programming problems in the most efficient way: This book is organized so that the table of contents will help you to quickly zoom in on the FAQs that answer your questions. I have made every effort to build a convenient and comprehensive index that will direct you to all the pages relating to any keyword or function referenced in this book. Each FAQ is written in a concise way that first gives you the step-by-step answer you need. Explanations and additional comments are deferred to later sections so that they do not get in the way of the solution but are readily available for those who want to go further than the cookbook recipe and wish to understand what goes on under the hood. Each explanation comes with tested and reusable sample code that you can plug into your MFC application in a few minutes to integrate the required functionality immediately. To summarize: The goal of this book is to offer you the shortest way from a problem to the corresponding step-by-step solution that you can integrate immediately into your current project. Who Should Read This Book This book is written for all MFC developers who wish to solve their MFC-related problems and at the same time learn advanced MFC techniques that will allow them to add a range of sophisticated features to their applications. This book assumes a basic proficiency both in the C++ language and in MFC programming as well as a knowledge of how to use the Visual C++ integrated development environment and tools such as AppWizard and ClassWizard. The Visual C++ wizards are discussed only when used in nonstandard ways to achieve a specific result. To benefit fully from this book, you should already understand the basic MFC concepts presented in the Scribble tutorial described in the Visual C++ documentation: the document/view architecture, message maps, the UPDATE_COMMAND_UI mechanism, dialog data exchange (DDX), and so on. Typically, you will either have followed the Scribble tutorial, attended a training session in MFC programming, or read one of the many introductory books on this topic. Of course, having a more extensive background in MFC programming will not hurt! Quite to the contrary. Based on feedback from reviewers and colleagues, I know that this book will also appeal to experienced MFC developers, who will find many useful techniques to add to their bag of MFC programming tricks. Finally, reading this book will allow all MFC developers to improve their understanding of fundamental MFC concepts and sharpen their MFC programming skills. How To Use This Book This book focuses on the 32-bit MFC version 4.x for Windows 95 and Windows NT. However, most techniques and concepts discussed here also apply to older versions of MFC. They should also remain valid for future MFC versions, because they rely on core MFC classes and behaviors that are not likely to evolve in a way that breaks existing code. I tried to write this book so that it will become a flexible tool that you can use as you want to. This means that you can either read this book from cover to coverI would certainly appreciate it if you door use it as a reference to look up only the specific topics that interest you. Most FAQs are cross-referenced to help you locate all the relevant information you might need even if you jump into the middle of the book. However, before you start hunting for answers to your MFC questions, I suggest that you take a few minutes to read Chapter 0 (Terminology and Conventions) and Chapter 1 (Document/View Architecture Backgrounder) to make sure that we start on the same ground with respect to fundamental document/view architecture concepts. What Is on the CD-ROM The companion CD-ROM contains source code and executables for all of the book’s sample programs. The folder hierarchy is organized first by chapter number and then by project name. Thus, the AutoSaveDoc project for Chapter 2 is located in the d:Chap02AutoSaveDoc folder, where \"d:\" is your CD-ROM drive’s letter. All the executables are located under their respective chapter folders. For example, all the executable sample programs for Chapter 2 are located in the d:Chap02 folder. The EkUtil.h and EkUtil.cpp files located at the root of the hierarchy contain the various helper Ek . . . . . . functions and classes that are presented throughout the book. You can choose to copy the whole folder hierarchy from the CD-ROM to your hard disk, copy only the examples that are of interest to you, or access the files directly from the CD-ROM. If you copy files from the CD-ROM to your hard disk, remember to remove the read-only attribute from the files on your hard disk. All sample programs have been compiled and tested under both Visual C++ 5.0 and Visual C++ 6.0. They will also work properly with Visual C++ 4.x, but you will have to manually create the appropriate .mdp project file. Note, however, that the .dsp project files on the CD-ROM have the Visual C++ 5.0 format: if you open them with Visual C++ 6.0, simply answer Yes to the dialog box asking whether you want to convert these files to the new format. Your Feedback Is Welcome I have done my best to accurately present topics that I feel should be of interest to most MFC developers. However, if you think that a topic should be covered differently or should use another technique, don’t hesitate to send me e-mail at ekain@awl.com. Also, e-mail me if you want to submit a topic idea or a technique of your own that solves a problem you have encountered, if you find an error or have any problem with this book, or if you have suggestions or want to discuss anything with me. I can promise that I will read all e-mail messages, take them into account, and try to respond to each of them as soon as possible. Note, however, that I may not have the time to answer specific MFC programming questions. You can also visit my Web site at ...",
    "author": [
      {
        "family": "Kain",
        "given": "Eugene"
      },
      {
        "family": "Wingo",
        "given": "Scot"
      }
    ],
    "id": "10.5555/552037",
    "issued": {
      "date-parts": [
        [
          1998
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "The MFC answer book: Solutions for effective visual c++ applications",
    "title-short": "The MFC answer book",
    "type": "book"
  },
  {
    "ISBN": "9781605580777",
    "abstract": "We are pleased to introduce the technical program of the 2008 ACM Conference on Computing Frontiers, the fifth in the series. The conference was established as a forum to present and discuss explorations of territory at the edge of computing, perhaps risky, but intellectually challenging and with the potential to substantially improve the state of the art. In this context, papers have been solicited and submitted on theory, methods, technologies, and implementations concerned with innovations in computing paradigms, computational models, architectural paradigms, computer architectures, development environments, compilers, and operating environments.This year’s program includes 30 technical papers selected out of 110 submissions (a 27",
    "id": "10.1145/1366230",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CF ’08: Proceedings of the 5th conference on computing frontiers",
    "title-short": "CF ’08",
    "type": "book"
  },
  {
    "ISBN": "0769500013",
    "abstract": "The choice of techniques to support system design is important in order to achieve a satisfactory result with regards to the quality of the future system. In the IDEnet development project we chose to work with techniques used within, or inspired by, three different research areas, Sociology, Participatory Design and Hu-man Computer Interaction. The paper discusses the use of one technique from each of these research areas, ranging from ’scratch to sketch’ in the development of an Intranet (IDEnet) at the Department of Computer Science and Business Administration (IDE), University College of Karlskrona/Ronneby in Sweden. The advantages and disadvantages for the use of each technique for system design are also discussed.",
    "author": [
      {
        "family": "Berndtsson",
        "given": "Johan"
      }
    ],
    "collection-title": "HICSS ’99",
    "container-title": "Proceedings of the thirty-second annual hawaii international conference on system sciences-volume 2 - volume 2",
    "id": "10.5555/874069.875990",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "keyword": "Techniques, Intranet, Information Systems Design, Informal interviewing, Future Workshop with Democratic Dialogue, Card Sorting",
    "page": "2019",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Designing an intranet from scratch to sketch: Experiences from techniques used in the IDEnet project",
    "title-short": "Designing an intranet from scratch to sketch",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321685865",
    "abstract": "Successfully Implement High-Value Configuration Management Processes in Any Development Environment As IT systems have grown increasingly complex and mission-critical, effective configuration management (CM) has become critical to an organizations success. Using CM best practices, IT professionals can systematically manage change, avoiding unexpected problems introduced by changes to hardware, software, or networks. Now, todays best CM practices have been gathered in one indispensable resource showing you how to implement them throughout any agile or traditional development organization. Configuration Management Best Practices is practical, easy to understand and apply, and fully reflects the day-to-day realities faced by practitioners. Bob Aiello and Leslie Sachs thoroughly address all six pillars of CM: source code management, build engineering, environment configuration, change control, release engineering, and deployment. They demonstrate how to implement CM in ways that support software and systems development, meet compliance rules such as SOX and SAS-70, anticipate emerging standards such as IEEE/ISO 12207, and integrate with modern frameworks such as ITIL, COBIT, and CMMI. Coverage includes Using CM to meet business objectives, contractual requirements, and compliance rules Enhancing quality and productivity through lean processes and just-in-time process improvement Getting off to a good start in organizations without effective CM Implementing a Core CM Best Practices Framework that supports the entire development lifecycle Mastering the people side of CM: rightsizing processes, overcoming resistance, and understanding workplace psychology Architecting applications to take full advantage of CM best practices Establishing effective IT controls and compliance Managing tradeoffs and costs and avoiding expensive pitfalls Configuration Management Best Practices is the essential resource for everyone concerned with CM: from CTOs and CIOs to development, QA, and project managers and software engineers to analysts, testers, and compliance professionals. Praise for Configuration Management Best Practices Understanding change is critical to any attempt to manage change. Bob Aiello and Leslie Sachss Configuration Management Best Practices presents fundamental definitions and explanations to help practitioners understand change and its potential impact. Mary Lou A. Hines Fritts, CIO and Vice Provost Academic Programs, University of Missouri-Kansas City Few books on software configuration management emphasize the role of people and organizational context in defining and executing an effective SCM process. Bob Aiello and Leslie Sachss book will give you the information you need not only to manage change effectively but also to manage the transition to a better SCM process. Steve Berczuk, Agile Software Developer, and author of Software Configuration Management Patterns: Effective Teamwork, Practical Integration Bob Aiello and Leslie Sachs succeed handsomely in producing an important book, at a practical and balanced level of detail, for this topic that often goes without saying (and hence gets many projects into deep trouble). Their passion for the topic shows as they cover a wonderful range of topicseven culture, personality, and dealing with resistance to changein an accessible form that can be applied to any project. The software industry has needed a book like this for a long time! Jim Brosseau, Clarrus Consulting Group, and author of Software Teamwork: Taking Ownership for Success A must read for anyone developing or managing software or hardware projects. Bob Aiello and Leslie Sachs are able to bridge the language gap between the myriad of communities involved with successful Configuration Management implementations. They describe practical, real world practices that can be implemented by developers, managers, standard makers, and even Classical CM Folk. Bob Ventimiglia, Bobev Consulting A fresh and smart review of todays key concepts of SCM, build management, and related key practices on day-to-day software engineering. From the voice of an expert, Bob Aiello and Leslie Sachs offer an invaluable resource to success in SCM. Pablo Santos Luaces, CEO of Codice Software Bob Aiello and Leslie Sachs have a gift for stimulating the types of conversation and thought that necessarily precede needed organizational change. What they have to say is always interesting and often important. Marianne Bays, Business Consultant, Manager and Educator",
    "author": [
      {
        "family": "Aiello",
        "given": "Robert"
      },
      {
        "family": "Sachs",
        "given": "Leslie"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1869711",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Configuration management best practices: Practical methods that work in the real world",
    "title-short": "Configuration management best practices",
    "type": "book"
  },
  {
    "DOI": "10.1145/1937117.1937126",
    "ISBN": "9781450305471",
    "URL": "https://doi.org/10.1145/1937117.1937126",
    "abstract": "In this paper, we compare the usability of a library approach with a language approach to task parallelism. There are many practical advantages and disadvantages to both approaches. A key advantage of a library-based approach is that it can be deployed without requiring any change in the tool chain, including compilers and IDEs. However, the use of library APIs to express all aspects of task parallelism can lead to code that is hard to understand and modify. A key advantage of a language-based approach is that the intent of the programmer is easier to express and understand, both by other programmers and by program analysis tools. However, a language-based approach usually requires the standardization of new constructs and (possibly) of new keywords. In this paper, we compare the java.util.concurrent (j.u.c) library [14] from Java 7 and the Habanero-Java (HJ) [16] language, supported by our experiences in teaching both models at Rice University.",
    "author": [
      {
        "family": "Cavé",
        "given": "Vincent"
      },
      {
        "family": "Budimlić",
        "given": "Zoran"
      },
      {
        "family": "Sarkar",
        "given": "Vivek"
      }
    ],
    "collection-title": "PLATEAU ’10",
    "container-title": "Evaluation and usability of programming languages and tools",
    "id": "10.1145/1937117.1937126",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Comparing the usability of library vs. Language approaches to task parallelism",
    "type": "paper-conference"
  },
  {
    "abstract": "The explosive growth of cameras, image sensors, and computer vision as a discipline of Artificial Intelligence (AI) has garnered strong interest from researchers, developers, businesses and consumers. Image classification refers to a process to classify an image according to a model and match it to a set of classes or categories. Object detection is similar to image classification, which is a process to classify, locate and count multiple objects in an image and their respective locations within the image. Object tracking involves using object detection in each frame of a video to track the desired object through a series of image frames or video [1]. There are a number of use cases for computer vision including face recognition for application or device security, automatically counting and classifying items on a production line, and monitoring and responding to traffic conditions on busy road sections.Computer vision seeks to understand information in digital images through processing and analyzing digital images. This understanding is achieved through extracting high dimension data from images and processing them to produce usable information. Practical applications of computer vision in the context of machine learning include classification, segmentation, and tracking [2].IBM Watson Studio (https://www.ibm.com/watson) is IBM’s suite of enterprise-ready AI services, applications and tooling. As a service on IBM Cloud, IBM Watson Visual Recognition uses deep learning algorithms to analyze images for scenes, faces, and objects. This service provides built-in models and can also be used to create and train custom models for specific needs. Watson Studio provides a collaborative platform on top of IBM Cloud’s cloud computing capabilities to use existing models or train and deploy new models with minimal coding. Watson Studio has the added capability of setting up custom environments and Notebooks, allowing quick, cloud-enabled development machines that can scale as your projects scale.IBM PowerAI Vision (https://www.ibm.com/caen/marketplace/ibm-powerai-vision) is a Graphics Processing Unit (GPU) accelerated visual recognition solution running on IBM Power Systems. PowerAI Vision (https://www.ibm.com/caen/marketplace/ibm-powerai-vision) puts data science in the hands of subject matter experts. This tool simplifies building machine learning models with IBM Power Systems. As a result, users can build models and deploy them to the web without coding. The models can be accessed through an Application Program Interface (API). On the other hand, users can call the API from their own applications with a few lines of code.IBM provides developers free, open source, state-of-the-art assets for deep learning through the Model Asset Exchange (MAX) (https://developer.ibm.com/exchanges/models/) on IBM Developer. In the repository developers can find both assets for training deep learning models and pre-trained models to use in their projects.The first half of this workshop will focus on exploring the Watson Visual Recognition and Watson Machine Learning Services in IBM Cloud. We will begin by building and deploying a model on Watson Visual Recognition. We will focus on the key benefits of the service, including the ability of anyone with minimal coding experience to be able to train and deploy a computer vision model to the cloud. We will then demonstrate how easy it can be to integrate the model in any web-enabled application through a demo web application. Once this has been completed, we will give a soft introduction to Watson Machine Learning, including how to choose development environments, setting up a Jupyter notebook (https://jupyter.org/), and go over some prepared code snippets to train and analyze a model fully on the cloud. [We will then demonstrate how we can export the model and use it in our applications.In the second half of the workshop, we will demonstrate detecting and labeling objects within an image using PowerAI Vision object detection (https://github.com/IBM/powerai-vision-object-detection), based on customized training. Instead of writing code to train, deploy, and test the new model, we will only need to upload the images, and label the objects in the provided application. Once the model is deployed, we will use the PowerAI Vision user interface (UI) to test it. We will also use our application as a Representational State Transfer (REST) client to locate and count objects in an image using the provided REST API endpoint. At the end of the workshop we will briefly introduce Model Asset Exchange, we will demonstrate how to find a visual recognition model on MAX, deploy it as a microservice and test it.In summary, we will introduce some visual recognition services provided by IBM in this workshop. We together will develop an image classification model using Watson Visual Recognition service with Watson Studio. We also consume a visual recognition service from a client side. Then we discuss the features of PowerAI Vision and demonstrate object detection in PowerAI Vision. Finally, we introduce Model Asset Exchange.",
    "author": [
      {
        "family": "Ahmed",
        "given": "Imtihan"
      },
      {
        "family": "House",
        "given": "Rachael"
      },
      {
        "family": "Deilma",
        "given": "Neil"
      },
      {
        "family": "Luo",
        "given": "Li"
      }
    ],
    "collection-title": "CASCON ’19",
    "container-title": "Proceedings of the 29th annual international conference on computer science and software engineering",
    "id": "10.5555/3370272.3370324",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "watson studio, visual recognition, powerai vision, model asset exchange, machine learning, deep learning, artificial intelligence, IBM cloud, IBM Watson visual recognition",
    "page": "376-377",
    "publisher": "IBM Corp.",
    "publisher-place": "USA",
    "title": "Custom visual recognition model with watson studio",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321116208",
    "abstract": "From the Book: As a fairly public figure in the Windows developer community, I often get asked if I think that .NET is going to take off. I always answer the same thing; its not a matter of if, its a matter of when. Microsofts .NET Framework has so many benefits that even as a grizzled old C++Win32 guy, I wasnt able to resist the siren song of a managed development environment. Its ironic that the temporary dip in the economy has caused folks to avoid anything new just when .NET comes along to deliver significant reductions in time to market and cost while simultaneously increasing code quality. The organizations that have already adopted .NET know that its going to have a long and happy life, especially as it gets pushed further and further into Microsofts own plans for the future of the Windows platform, both on the server and on the client. The primary server-side technology in .NET is ASP.NET, which provides the infrastructure needed to build web sites and web services. ASP.NET provides the reach to deploy web sites to anyone by aiming at the baseline of features provided by the middle generation web browsers. To provide the highest level of functionality possible, ASP.NET does most of the work on the server-side, leaving the client-side HTML as a thin wrapper to trigger server-side requests for new pages of data. The server-side handles practically everything, from data manipulation to user preferences to the rendering of simple things like menus and toolbars. This model provides the greatest availability across operating systems and browsers. If, on the other hand, your targeted customers are Windows users, an HTML-based experience limits the users to alowest-common denominator approach that is unnecessary. In fact, in an attempt to provide a richer client-side experience, many organizations that know theyre targeting Windows users require specific versions of Microsofts Internet Explorer (IE) web browser. However, as soon as that happens, IE becomes less of a browser and more of an HTML-based application runtime. And for that purpose, the HTML object model is fairly primitive, often requiring a lot of work to do things that are normally simple (like keeping track of a users session state). If youre going to be targeting Windows users, the .NET Framework provides a much richer set of objects for building interactive user interfaces. This brings me to the subject of this book: Windows Forms (WinForms). WinForms is the face of .NET on the client, providing a forms-based development environment meant to provide the best of the UI object models that have come before it. In addition, it provides one feature that no Windows-based development framework has provided to date - the deployment features of HTML-based web applications. The ability to combine the richness of Windows applications with the deployment of web applications signals a completely new world for Windows developers; one that makes me more than happy to give up the mess of unmanaged code. Audience When writing this book, I had two target audiences in mind. I wanted to provide real-world WinForms coverage for both the programmer that had already programmed in .NET as well as for the programmer that hadnt. Towards that end, I do briefly introduce core .NET topics as they come up. However, the .NET Framework itself is a large area that this book doesnt pretend to cover completely. Instead, when I think more information would be useful to the reader, I reference another work that provides the full details. In particular, I find that Ive referenced Essential .NET, by Don Box, with Chris Sells, a great deal, making it a good companion to this book. In this same category, I can also recommend Pragmatic ADO.NET, by Shawn Wildermuth, Advanced .NET Remoting, by Ingo Rammer, .NET Web Services, by Keith Ballinger and Applied Microsoft .NET Framework Programming, by Jeffrey Richter. Two core .NET topics are of special importance to WinForms programmers and I cover them in more detail in Appendix B: Delegates &amp; Events and Appendix C: Serialization Basics. The coverage of delegates and events is particularly important if youre new to .NET, although I dont recommend diving into that topic until youve got a WinForms-specific frame of reference (which is provided about 13rd of the way through Chapter 1: Hello, Windows Forms). Id like to provide one other note for potential readers. Many years ago, I wrote my first five-day training course. The topic was Windows 95 and included a few hours of coverage on the new controls; what they looked like, what their properties, methods and events were and how to program against them. Those hours seemed to take days for both me and for the students. The details of a particular control are only interesting when youre putting that control to use and when that time comes, the control-specific documentation and IntelliSense do a marvelous job of giving you the information you need. Towards that end, this book covers none of the standard controls completely. Instead, as each control is interesting the context of the current topic, like the DataGrid control in Chapter 13: Data Binding &amp; Data Grids, that control is covered appropriately. Also, Chapter 8: Controls and Chapter 9: Design-Time Integration introduces the broad range of categories of controls that WinForms provides, including the category of non-visual controls called components in .NET. Finally, to give you a visual to go with all of the controls and components and to introduce you to the major functionality of each of them, Appendix D: Standard WinForms Components &amp; Controls provides a list of the standard controls and components. I wouldnt think to waste your time by attempting to be more thorough that that reference documentation that comes with the .NET Framework SDK and Visual Studio .NET. Instead, this book focuses on the real-world scenarios that arent already covered in detail elsewhere. Conventions For those of you that have decided to take the plunge with this book, Id like to thank you for your faith and express my hope that I live up to in. To aid you in reading the following text, I want to let you in on some conventions I use in my writing. First and foremost, the wonderful thing about WinForms is how visual it is, which is why I use a lot of figures to illustrate its features. Some of those pictures really need to be color to make the point, so be sure to check the color pages at the center of this book for those figures. As useful as figures are, I think primarily in code. Code will be shown in mono-faced type: System.Console.WriteLine(Hello, WinForms.); Console application activation will also be shown in mono-faced type: C:&gt; csc.exe hello.cs When a part of a code snippet or a command line activation is of particular interest, I mark it in bold and often provide a comment: Notice the use of the .NET System namespaceSystem.Console.WriteLine(Hello, WinForms.); When I want to direct your attention to a piece of code even more fully, Ill replace superfluous code with ellipses: class MyForm : System.Windows.Forms.Form  ... fields private void MyForm_Load(object sender, System.ComponentModel.EventArgs e)  MessageBox.Show(Hello from MyForm);  Further, to make the printed code more readable, Ill often drop namespaces and protection keywords when they dont provide additional information: Shortened System.Windows.Forms.Form base class class MyForm : Form  ... fields Removed private specifier and System.ComponentModel namespace void MyForm_Load(object sender, EventArgs e)  MessageBox.Show(Hello from MyForm);  When showing .NET attributes, I use their full name: SerializableAttributeclass MyCustomType ... Some languages, like C#, allow the Attribute suffix to be dropped for convenience, but that makes it hard to find the details of the attribute class in the online documentation. Also, I sometimes take error checking out of the printed code for clarity, but try to leave it in the sample code that comes with this book.In the prose itself, I often put a word or phrase in italics to indicate a new term that Im about to define. As an example of this kind of term and its definition, hegemony is preponderant influence or authority, as well as a useful business practice. Finally, I often mention keyboard shortcuts because I find them convenient. The ones I mention are the default Visual Studio Developer key bindings. If youre not using those key bindings, youll need to map the keyboard shortcuts to your own settings.",
    "author": [
      {
        "family": "Sells"
      }
    ],
    "id": "10.5555/861497",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Windows forms programming in c#",
    "type": "book"
  },
  {
    "DOI": "10.1145/3545947.3573288",
    "ISBN": "9781450394338",
    "URL": "https://doi.org/10.1145/3545947.3573288",
    "abstract": "Quantum Machine Learning (QML) is an emerging field that involves training a parameterized quantum circuit in order to analyze quantum or classical datasets. QML has generated great excitement in recent years with the aim to develop Machine Learning (ML) models specifically designed for quantum computers that would allow exponential advantage in making accurate predictions on quantum data. Cybersecurity threats are evolving with the advancement of computing technology concurrently. Utilizing the concept of proactive prevention and early detection of security vulnerabilities may provide advantages to mitigate cybersecurity risk. In this paper, we adopt the Quantum Neural Network (QNN), a subset of QML for malware classification and detection. We use Google Collab as IDE and utilize an open-source ClaMP Dataset from Kaggle. We demonstrate our repository to classify and detect malware using a quantum neural network (QNN) and the result indicates that we achieved an accuracy of 94",
    "author": [
      {
        "family": "Hossain Faruk",
        "given": "Md Jobair"
      }
    ],
    "collection-title": "SIGCSE 2023",
    "container-title": "Proceedings of the 54th ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3545947.3573288",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "quantum neural network, quantum machine learning, quantum computing, malware classification and detection, cybersecurity",
    "page": "1235",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Malware classification and detection using quantum neural network (QNN)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3626252.3630913",
    "ISBN": "9798400704239",
    "URL": "https://doi.org/10.1145/3626252.3630913",
    "abstract": "In this paper, we present an education-focused Python IDE and runtime library which can run entirely in desktop, laptop, tablet, and mobile device web browsers. Our solution provides features useful for an engaging CS1 course, and eliminates the need for a server-based runtime. We describe a new, open source, methodology for running interactive Python entirely in the browser by solving the \"WebAssembly blocking problem,\" a core technical challenge to a web-based Python solution.Because our method enables Python entirely in the browser, it unlocks many new features. For example, students can share their code with others, without incurring extra costs to the instructors or institutions. Other features include line by line code highlighting as a program executes, highly intuitive interactive graphics, mouse and touch integration, and use of a wide selection of Python modules such as Numpy and Pandas. Currently, our IDE has been used in 5 classes, covering more than 10,000 students and teachers, with over 350,000 projects created. We found that students and instructors appreciated the variety of tools and abilities the IDE made possible. We benchmark the performance of running code with our method against other online Python solutions and we discuss the benefits and additional possibilities that our method allows, such as mobile device and/or offline code execution. We provide full free public access to our IDE and open source the core libraries which enable the conversion of student written Python to WebAssembly.",
    "author": [
      {
        "family": "Jefferson",
        "given": "Thomas"
      },
      {
        "family": "Gregg",
        "given": "Chris"
      },
      {
        "family": "Piech",
        "given": "Chris"
      }
    ],
    "collection-title": "SIGCSE 2024",
    "container-title": "Proceedings of the 55th ACM technical symposium on computer science education v. 1",
    "id": "10.1145/3626252.3630913",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "cs1, ide, integrated development environment, mobile, python, web browser, webassembly",
    "page": "583-589",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PyodideU: Unlocking python entirely in a browser for CS1",
    "title-short": "PyodideU",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130418048",
    "abstract": "From the Book: Preface Microsofts .NET is a revolutionary advance in programming technology that greatly simplifies application development. In addition to providing support for traditional desktop Windows applications, it provides tremendous support for Web-based services. Microsofts popular Visual Basic programming language has been upgraded to take advantage of the new .NET features. Visual Basic.NET, or simply VB.NET, has become a full object-oriented programming language with capabilities comparable to C++, Java, and Microsofts new language C# (pronounced C sharp). This book is a practical introduction to programming in VB.NET and using services provided by .NET. It emphasizes the VB.NET language and is part of The Integrated .NET Series from Object Innovations and Prentice Hall PTR. An important thrust of this book is to teach VB.NET programming from an object-oriented perspective. This book introduces object-oriented concepts early and includes a case study on object-oriented programming. The book is intended to be fully accessible to programmers who do not already have a background in object-oriented programming. Previous knowledge of Visual Basic is not essential. The book may also be read by more experienced programmers who desire a simple introduction to VB.NET with many example programs. Although designed for working professionals, the book includes enough detail, careful explanations, and sample programs so that it can be useful as a college textbook. VB.NET is now a fully object-oriented language. It supports classes, interfaces, interface and implementation inheritance, and polymorphism. It is also highly integrated with the .NETFramework. These features make VB.NET a compelling language for developing object-oriented and component-based systems. This book provides thorough coverage of all these features. One of the strengths of Visual Basic, and the reason it has enjoyed such widespread use, is the ease with which Windows application can be developed. Microsoft has revamped the way that Windows applications are built under .NET. Windows Forms, used by .NET languages, represents a class library that brings uniformity to the components of a Windows application. The book includes substantial coverage of using Windows Forms in VB.NET. VB.NET, as a language, is elegant and powerful. However, to fully utilize its capabilities, you must have a good understanding of how it works with the .NET Framework. The book examines several important interactions between VB.NET and the .NET Framework, and includes an introduction to major .NET classes for collections, files, databases, and threads. Organization of This Book This book is organized into five major parts and is structured to make it easy for you to isolate what you most need to know. Part 1, which everyone should read, begins with an introduction to the .NET Framework. The second chapter provides a short introduction to hands-on programming using VB.NET, so that you can start writing code on .NET right away. The third chapter introduces Visual Studio.NET. It is the latest version of Microsofts popular Visual Studio development environment and has many features that make application development easier and more pleasant. These chapters will equip you to use Visual Studio throughout the rest of the book. Part 2 covers the core features of VB.NET. If you know Visual Basic, you will have a definite leg up in learning VB.NET, and you can quickly skim this section, paying attention to the information in the sidebars. Sidebars alert you to either (1) the first time a concept new to VB.NET is introduced, or (2) a significant change to the VB.NET language that experienced VB programmers should note. If you are not familiar with Visual Basic, this section is for you. It will quickly bring you up to speed on the core topics of data types, operators, and control structures. Part 3 examines the object-oriented features of VB.NET. This language is now fully object-oriented, which is one of the most significant improvements in VB.NET. In this part, we begin by examine how classes are built. Subsequent chapters discuss implementation and interface inheritance. These topics are covered gradually and thoroughly, making this part of the book accessible to readers without previous object-oriented experience. Part 4 covers Windows programming in VB.NET. Microsoft has adopted a new approach to developing Windows applications that will be readily apparent to previous VB programmers. Systematic coverage is presented on the core topics in Windows Forms, including form design, controls, events, menus, toolbars, and dialogs. The rich variety of useful controls provided by Windows Forms is covered in detail. Part 5 explores the relationships between VB.NET and the .NET Framework. .NET collection classes are introduced. We also examine the .NET interfaces that classes must implement for fundamental operations such as copying and comparing objects. Delegates, a .NET callback mechanism, are discussed. We also introduce both VB.NET file IO and database programming using ADO.NET. We look at multiple thread programming and attributes. Attributes are powerful in .NET, enabling the programmer to accomplish tasks declaratively, even while writing very little code. You can implement custom attributes in VB.NET. You can read information about custom attributes, or any other metadata, by a mechanism known as reflection. The book concludes with an introduction to components and assemblies. Sample Programs The only way to really learn a programming language is to read and write many, many programs. This book provides many programs that illustrate features of VB.NET. The programs are clearly labeled in the text, and they can all be found in the software distribution that accompanies this book, available through our associated Web site. Also, a case study illustrates many features of VB.NET working together in combination, as they would in a practical application. We make a special point of demonstrating the object-oriented features of VB.NET. If you are new to OO, reading the case study is a must! The sample programs are provided in a self-extracting file. When expanded, a directory structure is created, rooted in C:OIIntroVb. The sample programs are in directories Chap01, Chap02, and so on. All the samples for a given chapter are in individual folders within the chapter directories. The names of the folders are clearly identified in the text. An icon in the margin alerts you to a code example. The case study is in a directory called CaseStudy, at the same level as the chapter directories. This book is part of The Integrated .NET Series. The sample programs for other books in the series are located in their own directories beneath OI, so all the .NET examples from all books in the series will be located in a common area as you install them. Web SiteHeres the Web site for the book series: A link is provided at that Web site for downloading the sample programs for this book. &lt;",
    "author": [
      {
        "family": "Wyatt",
        "given": "Dana L."
      },
      {
        "family": "Oberg",
        "given": "Robert J."
      }
    ],
    "id": "10.5555/579999",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Prentice Hall Professional Technical Reference",
    "title": "Introduction to programming visual basic using .net",
    "type": "book"
  },
  {
    "DOI": "10.1109/ICRA48506.2021.9561366",
    "URL": "https://doi.org/10.1109/ICRA48506.2021.9561366",
    "abstract": "For 25 years the Robotics Toolbox for MATLAB&lt;sup&gt;®&lt;/sup&gt; has been used for teaching and research worldwide. This paper describes its successor – the Robotics Toolbox for Python. More than just a port, it takes advantage of popular open-source packages and resources to provide platform portability, fast browser-based 3D graphics, quality documentation, fast numerical and symbolic operations, powerful IDEs, shareable and web-browseable notebooks all powered by GitHub and the open-source community. The new Toolbox provides well-known functionality for spatial mathematics (homogeneous transformations, quaternions, triple angles and twists), trajectories, kinematics (zeroth to second order), dynamics and a rich assortment of robot models. In addition, we’ve taken the opportunity to add new capabilities such as branched mechanisms, collision checking, URDF import, and interfaces to ROS. With familiar, simple yet powerful functions; the clarity of Python syntax; but without the complexity of ROS; users from beginner to advanced will find this a powerful open-source toolset for ongoing robotics education and research.",
    "author": [
      {
        "family": "Corke",
        "given": "Peter"
      },
      {
        "family": "Haviland",
        "given": "Jesse"
      }
    ],
    "container-title": "2021 IEEE international conference on robotics and automation (ICRA)",
    "id": "10.1109/ICRA48506.2021.9561366",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "11357-11363",
    "publisher": "IEEE Press",
    "publisher-place": "Xi’an, China",
    "title": "Not your grandmother’s toolbox – the robotics toolbox reinvented for python",
    "type": "paper-conference"
  },
  {
    "ISBN": "9783981080131",
    "abstract": "Welcome to the DATE 08 Conference Proceedings. DATE combines the world’s favourite electronic systems design conference and Europe’s leading international exhibition for electronic design, automation and test, from system level hardware and software implementation right down to integrated circuit design.The DATE 08 event features a technical program with 77 sessions covering the latest developments in system design and embedded software, IC design/test methodologies and EDA tools, together with an exhibition with the leading EDA, silicon and IP providers showing their new products and services. Challenges that you all face or soon will face in your daily practice are the increasing design complexity of highly integrated systems, the introduction of reconfigurability and embedded software, and the control of power and variability in nanometer IC designs. All these issues will be addressed in this year’s DATE event.For the 11th successive year DATE has prepared an exciting technical programme, with the help of the more than 400 members of the Technical Programme Committee, who dedicated their time to thoroughly review the 839 submissions in 37 topics, ranging from system level down to circuit design and covering all the most relevant application domains. The submissions are organised in 4 major areas:D — Design Methods, Tools, Algorithms and LanguagesA — Application DesignT — Test Methods, Tools and Innovative ExperiencesE — Embedded SoftwareAfter a thorough review and selection process (with an average of 5 reviews per paper), finally 198 regular papers were selected for presentation at the conference. Additionally, there are 46 Interactive Presentations that are organised in 5 IP sessions. Together with the invited special sessions (panels, embedded tutorials and hot topic sessions), this has resulted in a high-quality technical program. The technical program provides a wide but high-quality coverage of design, design automation and test topics, from the system level to the integrated circuit level. Compared with previous years, submissions in the Embedded Software track has increased by 50",
    "id": "10.1145/1403375",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "DATE ’08: Proceedings of the conference on design, automation and test in europe",
    "title-short": "DATE ’08",
    "type": "book"
  },
  {
    "ISBN": "0201703599",
    "abstract": "From the Book: XML: Its a cheese spread. No, its a floor wax. No, its two—two—two products in one! Or maybe its everything but the kitchen sink Say, did you hear the one about the XML Kitchen Sink Language (see http:blogspace.comxkitchensink) XML: What Its All About It has been said that XML, the Extensible Markup Language, will become the ASCII of the twenty-first century because it is rapidly becoming ubiquitous. XML is expected to have an impact on both the Web and application development comparable to that of Java and JavaScript because it has opened up a wide variety of new capabilities and has been embraced by so many sectors of human endeavor. XML is a metalanguage—a syntax for describing other languages. These languages span diverse vertical industries including accounting, advertising, aerospace, agriculture, astronomy, automotive products, biology, chemistry, database management, e-commerceEDI, education, financial institutions, health care, human resources, mathematics, publishing, real estate, software programs, supply chain management, and many more (for the many more, see http: ). In one sense, XML is really a very trivial thing—just a markup syntax for describing structured text using angle brackets. But in another sense, XML is a basic building block—an enabling technology that makes it possible to develop more complex, more interesting, and more powerful tools. In the Web arena, XML is facilitating exciting improvements such as user-controllable views and filtering of information, creation oftruly device-independent content that can be re-purposed for vastly different devices, highly focused searching based on element hierarchies, and more sophisticated and flexible linking mechanisms. In the business and application arena, XML makes it easier to deliver filtered content from databases, to more readily share data between applications and between companies, and to exchange EDI messages that describe complex transactions. In the scientific arena, XML is a natural fit for describing complex datasets, models, control of instruments, images, chemical compounds, and much more. Just as Java made data processing platform-independent, XML has done the same for data, making the exchange of information much easier than ever before. But, no, XML is not the kitchen sink; it is not the solution to all of the worlds problems in one tidy package; nor is it the solution to all your computer needs either, at least not alone. Rather, XML is a tool, or more accurately, a set of tools from the same toolbox. That toolbox is the XML family of specifications. This book will help you see what XML can and cannot do by describing how to use each tool. Although XML shares a number of concepts with its ancestor, SGML (Standard Generalized Markup Language), XML is said to yield 80 percent of the benefits of SGML, but with only 20 percent of the complexity. It is precisely this 8020 rule that has excited countless companies and developers, encouraging them to support the efforts of the World Wide Web Consortium (W3C) in the development of XML. A few of the more than 500 companies and organizations that actively support XML development as members of the W3C include IBM, Sun, Microsoft, Oracle, Commerce One, and NASA. Audience: Who Should Read This Book The book is intended for Web developers, which includes programmers, content writers, and designers. Depending on your background and interests, some chapters may be more relevant to you than others. Its intended for those who may be familiar with particular aspects of XML but who have not been formally exposed to all of the major W3C specifications, as well as those who have never dealt with XML before. Later in this preface, I provide a roadmap to help orient you. Ive assumed that most readers are familiar with HTML elements and syntax, although the XML and DTD syntax discussions in Chapters 3 and 4 pretty much cover the concepts of elements, attributes, types, entities, and content that carry over from HTML to XML. In other words, you can get by without knowing HTML, except the XHTML chapter, which will make much more sense to you if you do. For those who would like to brush up on HTML, see For Further Exploration: HTML and Java at the end of this preface. Some examples require programming knowledge, but for most examples, anyone with general Web development skills will find them beneficial. Generally, scope and breadth of treatment is favored over depth. On the other hand, some readers will find that the depth is more than they expected, but they should still be able to tread the water. My intent in writing this book was to cover a number of XML-related technologies in varying degrees of detail. Id like to make it clear that although there are three chapters containing Java examples, this is not a book about Java and XML. You dont need a Java background for the vast majority of whats in this book. Although I do assume the Windows operating system, this is not a statement of preference. My formative years were spent on UNIX (I still use UNIX utilities to maintain a ski club site) at the office and a Mac at home. Rather, since Windows tends to be somewhat ubiquitous, it seems appropriate to show Windows command lines and mention some Windows-only tools. UNIX and Mac users are encouraged to share their experiences with fellow readers via the books Web site. Personally, I have found cygwin—a UNIX environment for Windows developed by Red Hat—to be very handy (see http:cygwin.com). Whats Special About This Book There are several features that contribute to making this book an invaluable resource for anyone beginning to plunge into the somewhat turbulent seas of XML. XML Family of Specifications Big Picture —Since early 1998, Ive periodically updated a diagram I call The Big Picture of the XML Family of Specifications. This unique diagram (front inside cover) depicts virtually all of the key W3C efforts related to XML, with colors to indicate each specifications status (maturity); it includes related non-W3C efforts as well. Physical positioning denotes a relationship among neighboring specifications, as explained in Chapter 2. Best of all, the Big Picture diagram appears as an imagemap on the CD-ROM and on this books Web site, possibly as a more up-to-date version. The Big Picture imagemap on the Web site expands acronyms as your mouse hovers over a term. Clicking on the acronym or name connects you instantly to the actual specification or, in some cases, a collection of documents relating to that specification. History Timeline —A detailed History of the Web and XML in timeline form—the product of a considerable amount of research—is broken down into three time periods in Chapter 1, which should be interesting to many readers. Historical perspectives are also presented for particular specifications in their own chapters. A rather unique pullout at the back of the book shows, in bar chart format, the gestation periods of all of the XML specifications in this book, giving you a visual picture of what developments occurred in sequence andor in tandem. Coverage —Ive selected what are generally considered to be the most significant XML-related specifications from the W3C: XMLDTDs, XML Namespaces, XML Schema, the DOM, CSS, XSLT, XPath, XSLFO, XLink, XPointer, XHTML, and RDF. Several of the less frequently discussed specifications, such as XML Infoset, Canonical XML, XML Base, and XML Inclusions, are also covered. In addition, Ive included four topics that are not under the purview of the W3C: RDDL, SAX, JDOM, and JAXP. The focus is on breadth rather than depth of coverage because if you have a general understanding of a lot of XML topics, you can better appreciate which are most relevant to your needs and you can drill down to the details by following the links I provide. The hope is that as you become more familiar with each of the topics I present, youll know which areas youll want to explore by buying more specialized Addison-Wesley or Prentice Hall books (e.g., about XSLT, XML with Java, or XHTML). Ive tried hard to make the information current and have spent a good bit of time in the final months polishing and updating details here and there. All topics are as up-to-date as possible, except where noted otherwise. For Further Exploration —Each chapter ends with a section called For Further Exploration, which presents quite a few links that serve not only as my bibliography, but also points to resources that contain more details than what can be provided here without killing way more than my fair share of trees. Links are provided to the specifications themselves, to articles that explain the specs in more everyday language than the precision required for formal specifications, and to articles describing subtleties or nuances of the specs. Links to tutorials, books, software, special references, and so on are also supplied. My intention is that readers will use the links, so they all appear in HTML form on the books CD. Professors may wish to consider some of these links for students research assignments. Tables —Im a big fan of the use of tables. When I read a technical book, I seldom read it word for word, cover to cover. Often I want to locate some particular detail pretty quickly, so I look it up in the table of contents or index—I dont want to have to skim through paragraph after paragraph to find the little tidbit I need. Therefore, I feel that tables will help you do the same thing, maximizing the use of your time. The List of Tables is something with which you might want to familiarize yourself—let a table be your friend. CD-ROM —The CD that accompanies the book contains all the sample code presented in the text, as well as most of the software I used while writing this book, including the following: - Code Examples—every example that appears as a code listing plus a number of variations - XML Environment—batch files to simplify using XML with Java on Windows operation systems - For Further Exploration—all links from the end of each chapter - Big Picture of XML Family of Specifications Imagemap—links to more than 60 specifications, including many not covered in this book (see Chapter 2) - W3C XML Specifications in PDF Form—every W3C specification discussed in this book is available (unedited) for offline reading(hours and hours of fun for the whole family) - Glossary of terms - Chapter 12, Practical Formatting Using XSLFO by G. Ken Holman, in HTML format with two useful appendices which arent included in the printed book - Freeware and evaluation copies of commercial software (XMLDTDXML Schema editors, validators, parsers, XSLT processors, and more) Web Site —The books main Web site is hosted by Web Developers Virtual Library, an Internet.com site. I maintain the extensive XML section of WDVL.com. The books URL there is http:WDVL.Internet.comAuthoringLanguagesXMLXML-Family . There youll find all the links from the For Further Exploration sections organized by chapter, as well as the online version of the Big Picture imagemap, and of course the inevitable corrections to the text. While this material appears on the CD-ROM, the Web site versions may be more up-to-date. The Web site will be updated periodically; you can register to receive e-mail when the site is updated, if you wish. Organization and Roadmap: How You Should Read This BookThis book is divided into five conceptual parts. With the exception of a few chapters in Part I, it is not absolutely necessary to read this book chapter by chapter (and Ill tell you right up front: the butler did it). Chapter 1, History of the Web and XML, provides an interesting historical perspective of the development of XML, but some readers may prefer to skip it entirely, or at least defer reading it until theyve completed other chapters or find themselves on a long, boring plane flight with neither good movies nor readable magazines. Readers without a Java background may wish to gloss over the three chapters that contain Java examples, instead focusing on the concepts that are discussed in these chapters. The following describes the books organization and suggested reading emphasis. Introduction: History of the Web and XML —As mentioned, Chapter 1 provides an historical perspective. Its divided into three eras: Ancient History (1945 to 1984), Medieval History (1986 to 1994), and Modern History: From HTML to XML (1994 to 2001). Part I: Fundamental XML Concepts and Syntax —This part introduces XML Syntax, DTD Syntax, the XML Infoset abstraction, Canonical XML, Namespaces, RDDL (Resource Directory Description Language), and XML Schema, corresponding to Chapters 2 through 6, intended to be read in sequence. All readers should read these chapters, although if you wont be developing your own vocabularies, you might be able to skim the DTD and XML Schema chapters (4 and 6, respectively). Although XML Schema is expected to replace the use of DTDs in many applications, your own project needs may dictate sticking with DTDs, in which case you could skip the XML Schema chapter, although I still recommend that you read the sections in Chapters 4 and 6 that highlight DTD limitations and XML Schema advantages. If you are tempted to skip the chapter on Infoset, Canonical XML, Namespaces and RDDL (Chapter 5), be sure to at least read the Namespaces section because this concept is central to many XML specifications. All chapters following 5 assume you are familiar with XML Namespaces. Although RDDL is a recent grassroots effort as I write this, its bound to have gathered a lot of momentum by the time you read this. Part II: Parsing and Programming APIs —This part presents SAX (Simple API for XML), DOM (Document Object Model), JAXP (Java API for XML Processing) and JDOM—Chapters 7 through 9. All of these are application programming interfaces (APIs) to parsing and manipulating XML documents. This is the part of the book with the most Java examples. While all readers are encouraged to read the initial sections of the SAX and DOM chapters, non-Java developers can completely skip Chapter 9, which covers JAXP and JDOM, as well as the code examples in the SAX and DOM chapters. However, be sure to read the explanation of parsing at the beginning of Chapter 7 and study the comparison, SAX vs. DOM vs. JDOM vs. JAXP—Who Wins at the end of Chapter 9. Part III: Displaying and Transforming XML —This part covers CSS (Cascading Style Sheets), XSLT (Extensible Stylesheet Language Transformations), XPath (XML Path Language), XSLFO (Extensible Stylesheet Language Formatting Objects), presented in Chapters 10 to 12. Of these, the lengthy Chapter 11 on XSLT and XPath is essential reading for anyone who wishes to display or transform XML into other formats (including HTML, XHTML, text, or other kinds of XML, particularly in e-commerce applications). Chapter 10 on CSS is more important if your XML display needs are more modest and your transformation needs are nil. The chapter can be skimmed for XML hooks if you are already familiar with CSS. Chapter 12 concerns XSL Formatting Objects, sort of the next generation CSS for desktop publishing quality layout, PDF, and targeting your output for different devices. The XSLFO chapter was contributed by noted XSL expert and instructor, G. Ken Holman, chair of the OASIS XSLTXPath Conformance Technical Committee (see his home page at http: ). Part IV: Related Core XML Specifications —This part focuses on XLink (XML Link Language) and XPointer (XML Pointer Language)—Chapters 13 and 14. Most developers will benefit from reading about XLink and XPointer because they greatly extend the notion of linking and fragment access beyond what is possible in HTML 4.01, including one-to-many links, multidirectional links, links stored external to the documents, and linking to specific elements without hooks being provided by the original author. Part V: Specialized XML Vocabularies —This part presents two unrelated XML-based languages: XHTML (Extensible HyperText Markup Language) in Chapter 15 and RDF (Resource Description Framework) in Chapter 16. Please consider Chapter 15 on XHTML as essential reading for all developers. As youll see, XHTML is its own nuclear family of specifications that is currently replacing HTML, especially in the increasingly popular world of handheld devices, voice browsers, and other alternative Web interfaces. RDF should be of particular interest to developers and scientists with an interest in metadata (data about data), site descriptions, catalogs, intelligent software agents, and so on. RDF attempts to add semantics to the Web; related concepts are the recent XML Topic Maps (XTM) effort and the older Dublin Core work. The RDF chapter was contributed by Ora Lassila, co-author of the Resource Description Framework Model and Syntax Specification for the W3C and contributor to the RDF Core Working Group and Web-Ontology (WebOnt) Working Group (see his home page at http: ). This book does not cover XQuery, an XML Query language, nor Scalable Vector Graphics (SVG), except in passing. XQuery was still very much in flux at the time of this writing. As for SVG, with a more than 500-page specification, I felt I could not do the topic justice in the time I had left after writing the rest of this book. Well, theres always the Second Edition, I guess. What You Need to Get the Most Out of This Book All code examples have been developed on a Dell Dimension XPS R450 PC (a paltry 450 MHz) running Windows 98. DOS .bat files are provided to help you configure your environment so that you can run the examples on your own. UNIX developers should be able to study the .bat files and set environment variables accordingly, such as CLASSPATH for Java and variables that point to the location of XML parsers and XSLT processors. Im afraid I cant say much to Mac developers at this point (sadly, my own ancient PowerMac 710080 hasnt been used for the better part of three years), but if you contact me via the Web site and want me to share your experiences with others, I will gladly do so. Ill give you credit and a free copy of this book—it makes a great gift and keeps its flavor longer than fruitcake. XML and DTD examples are plain text, so they are viewable in their raw form on all platforms using any text editor. To process XML in a browser, however, youll need the most current generation of browsers, such as Netscape 6.x, Internet Explorer 5.5 or 6.x, Amaya 5.x, or Opera 5.x or higher. If youre not the type of reader who has to try out every example in his or her own browser, then perhaps the many screenshots in this book will be sufficient. Evaluation copies of commercial XML, DTD and XML Schema editors appear on the CD that accompanies this book; XML parsers and XSLT processors also appear there. The CD also contains a page of links to the current versions of all provided software, as well as links to software that couldnt be included on the CD for a variety of reasons. The Java code examples should compile and run fine with either JDK 1.2.x or 1.3.x, also known by other confusing names and numbers such as Java 2 SDK, J2EE, and J2SE—or their equivalent as provided with your favorite Java IDE (Integrated Development Environment). This book does not attempt to teach Java; on the other hand, you really dont need to know Java to follow most of the discussions. Interested readers who desire a better Java background should refer to the key Java resources listed in For Further Exploration: HTML and Java that follows. I truly hope you enjoy this book and find the XML family of specifications as fascinating as I do. Conventions Used in This Book The typographic conventions used in this book are as follows: Glosssary terms look like this where they are defined: node-set Code excerpts, code listings, command lines, filenames, element names, and attribute names look like this: &lt;xsl:template match=CD&gt; or collection8.xml. Quotations (material excerpted from another source) is indented both left and right and is set in a smaller type size. Notes, important information or things to watch out for, are set off by an arrow in the margin and rules above and below their text. For Further Exploration: HTML and JavaDave Raggetts Getting Started with HTML http: Web Design Groups HTML 4.0 Reference http: Googles HTML Tutorials category http:directory.google.comTopComputersData_FormatsMarkup_LanguagesHTMLTutorials Java Technology Products and APIs http:java.sun.comproducts The Java Tutorial http:java.sun.comdocsbookstutorial Google Web Directory: Java includes a Books category http:directory.google.comTopComputersProgrammingLanguagesJava Google Web Directory: Java IDEs http:directory.google.comTopComputersProgrammingLanguagesJavaDevelopment_ToolsIntegrated_Development_Environments Cafe au Lait Java FAQs, News, and Resources http:",
    "author": [
      {
        "family": "Sall",
        "given": "Kenneth B."
      }
    ],
    "id": "10.5555/515385",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Xml family of specifications",
    "type": "book"
  },
  {
    "ISBN": "0130911119",
    "abstract": "From the Book: Introducing BEA WebLogic Application Servers J2EE Applications and BEA WebLogic Server addresses the need for a practical, state-of-the art book on developing enterprise applications with the market-leading BEA WebLogic Java application servers. The BEA WebLogic family of application servers includes BEA WebLogic Server, BEA WebLogic Enterprise, BEA WebLogic Commerce Server, and BEA WebLogic Personalization Server. This book focuses on BEA WebLogic Server. BEA WebLogic Server (WebLogic Server) is a widely used Java application server for constructing multi-tier, secure, large-scale, distributed Web applications for e-commerce and other high-volume applications. Distributed applications require sophisticated, fast, fault-tolerant networked communication among application tiers and components. In a client-server application, client programs send requests and receive responses from a server system. With the advent of middleware and the Web revolution, many enterprise sites have moved from client-server application environments to n-tierusually, 3- or 4-tierarchitectures. In multi-level architectures, efficient network connectivity is paramount. In a multi-tier application, WebLogic Server provides the framework for developing and deploying server-side business logic, and supports a distributed programming model that hides the complexity of distributed programming from the application writer. The programming model provided by J2EE and the WebLogic Server extensions provides some level of transparency, so that writing a distributed application is similar to writing a local application. Although the programmer must still be concerned about error handling and efficiency, WebLogic Server’s implementation of the J2EE services provides an excellent development and execution environment for an enterprise-level distributed application. An application server such as BEA WebLogic Server handles server-side business logic and the administration of a multi-client, distributed application that uses a variety of clients and servers. Giving the responsibility for business logic and traffic control to an application server has the following benefits: Efficiency: Web browser and application clients can share the same business logic, rather than having to deploy business rules with each instance of a client. Performance: Locating server-side business logic with or near resource-intensive modules such as data stores can improve performance. Manageability: System administration and security issues are easier to address when business logic is centralized in an application server. History of BEA’s WebLogic Server Division WebLogic, Inc. was founded in 1995–when Java, still a \"think tank\" project of Sun Microsystems, was code-named \"Oak.\" In 1998, WebLogic merged with BEA Systems, Inc., a major vendor of transaction monitors and other tools for creating and managing enterprise-scale distributed systems. The BEA WebLogic Server product is a part of the BEA E-Business Platform. From the beginning, the WebLogic Server developers determined to use only Java, and to focus on server-side technologies: server support and middleware management of multi-tier applications. Using off-the-shelf Java development tools (and general-purpose text-editing tools such as emacs), the WebLogic Server developers implemented APIs for each new Java standard feature that Sun specified. As a result, WebLogic Server has not only kept current with Java standards development but has also had the capability to influence emerging Java standards. BEA WebLogic Server was an early implementer of each emerging Java Enterprise standard, including Enterprise JavaBeans (EJB), Remote Method Invocation (RMI), servlets, the Java Naming and Directory Interface (JNDI), and Java Database Connectivity (JDBC) for Oracle, Informix, Sybase, and Microsoft SQL Server. Each of these technologies is explained and illustrated in the chapters that follow. In July 2000, the BEA Systems family of application servers successfully completed Sun Microsystems Java 2 Enterprise Edition (J2EE) certification, becoming the first independent company to achieve official J2EE certification. BEA WebLogic Server has won several industry awards, including: Best Java Application Server ( JavaPro , June 2000) Product Excellence and Productivity Award ( Software Development Magazine , March 2000) Java World Reader’s Choice Award for best e-commerce application server, 1999 Infoworld ’s Product of the Year, 1999 Java Developers Journal Editor’s Choice Award in 1998 and 1999 Why We Wrote This Book BEA WebLogic Server has a growing installed base that has been supported by training classes and extensive documentation, but there has been no comprehensive, practical coverage of full-scale application development on the WebLogic Server platform. This step-by-step book explains where to start, and how to put all the pieces together. Planning for deployment and selecting the technologies that you’ll use for each tier of the application is as important as laying down code. Target Audience J2EE Applications and BEA WebLogic Server is targeted at intermediate to professional-level Java programmers developing applications for the BEA WebLogic Server platform, the market leader among application servers. This book focuses on best practices for developing enterprise applications using the WebLogic Server APIs. The WebAuction application, a complete sample e-commerce application, is explained and developed as an example in Chapter 14. An accompanying CD-ROM includes all software and code needed to implement the sample application in your own environment. After reading this book, Java developers will possess the skills and knowledge required to develop scalable and robust applications on the WebLogic platform. This book is targeted at programmers who know basic Java on at least an intermediate level and would like to learn WebLogic Server. We assume that readers know about standard Java programming concepts such as exceptions and threads. However, we do not assume that readers know much about J2EE or application servers. Brief Overview of the Book J2EE Applications and BEA WebLogic Server contains both a descriptive narrative and examples for each major J2EE API, and a sample application that concludes the book. Using a step-by-step approach, the book introduces each major J2EE API and uses it to build a component of the WebAuction application, which supports an online auction site. Building the WebAuction application gives users the opportunity to explore significant areas of building a distributed Enterprise Java application, including: Overview of J2EE technologies (Chapter 2) Building presentation logic with servlets or Java Server Pages (JSPs); (Chapters 3 and 4) Establishing database connectivity and using transactions (Chapter 5) Using Remote Method Invocation, and the Naming and Directory Interface (Chapter 6) Using a message-oriented middleware layer to coordinate all the components and operations in your multi-tier, distributed WebAuction application (Chapter 7) Creating Enterprise Java Beans (Chapters 8-10) Integrating Internet mail (Chapter 11) Adding security (Chapter 12) Designing a distributed deployment (Chapter 13) Building and deploying the completed application (Chapter 14) Performing a capacity-planning exercise to assess the performance of the deployed application (Chapter 15) Chapter 1 presents a detailed overview of the book, with a roadmap and chapter summaries. Chapter 1 also lists system requirements and conventions. Chapter 2 surveys the J2EE technologies that are described in depth, with examples, in Chapters 3-12. About the Authors Michael Girdley is the Senior Product Manager for the BEA WebLogic Server, a role in which he acts as marketing liaison to over 200 engineers. An experienced application developer in Java, HTML, C, and C++, Michael is a co-author of Web Programming with Java (Sams-net Publishing, 1996) and Java Unleashed, Second Edition (Sams-net Publishing, 1997). Michael holds a bachelor’s degree in computer science with honors from Lafayette College. Rob Woollen is a Senior Software Engineer at BEA Systems. He is currently the lead developer for the WebLogic Server EJB Container. Before joining BEA, Rob worked on UNIX kernel networking for Hewlett-Packard. Rob holds a bachelor’s degree in computer science from Princeton University. Sandra L. Emerson is a technical writer and consultant with 20 years’ experience in the software industry. She is a co-author of four computer trade books: The Business Guide to the UNIX System (Addison-Wesley); Database for the IBM PC (Addison-Wesley); Troff Typesetting for UNIX Systems (Prentice Hall PTR); and The Practical SQL Handbook (Addison-Wesley, Fourth Edition, 2001).",
    "author": [
      {
        "family": "Girdley",
        "given": "Michael"
      },
      {
        "family": "Emerson",
        "given": "Sandra L."
      },
      {
        "family": "Woollen",
        "given": "Rob"
      }
    ],
    "id": "10.5555/559265",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "J2EE applications and BEA WebLogic servers",
    "type": "book"
  },
  {
    "DOI": "10.1145/3510454.3516832",
    "ISBN": "9781450392235",
    "URL": "https://doi.org/10.1145/3510454.3516832",
    "abstract": "Natural Language (NL) programming, the concept of synthesizing code from natural language inputs, has garnered growing interest among the software community in recent years. Unfortunately, current solutions in the space all suffer from the same problem, they require many labeled training examples due to their data-driven nature. To address this issue, this paper proposes an NLU-driven approach that forgoes the need for large numbers of labeled training examples. Inspired by how humans learn programming, this solution centers around Natural Language Understanding and draws on a novel graph-based mapping algorithm. The resulting NL programming framework, HISyn, uses no training examples, but gives synthesis accuracies comparable to data-driven methods trained on hundreds of samples. HISyn meanwhile demonstrates advantages in terms of interpretability, error diagnosis support, and cross-domain extensibility. To encourage adoption of HISyn among developers, the tool is made available as an extension for the Visual Studio Code IDE, thereby allowing users to easily submit inputs to HISyn and insert the generated code expressions into their active programs. A demo of the HISyn Extension can be found at https://youtu.be/KKOqJS24FNo.",
    "author": [
      {
        "family": "Young",
        "given": "Mitchell"
      },
      {
        "family": "Nan",
        "given": "Zifan"
      },
      {
        "family": "Shen",
        "given": "Xipeng"
      }
    ],
    "collection-title": "ICSE ’22",
    "container-title": "Proceedings of the ACM/IEEE 44th international conference on software engineering: Companion proceedings",
    "id": "10.1145/3510454.3516832",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "program synthesis, natural language programming, code editor",
    "page": "110-114",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "IDE augmented with human-learning inspired natural language programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130091189",
    "abstract": "From the Book: This book is a practical guide to optimizing performance of computationally intensive applications on Sun UltraSPARC platforms. It offers techniques for improving performance of applications that are predominantly compute-intensive or CPU-bound. We wrote this book with a general enough scope so that it would be useful to as many developers of technical applications on Sun platforms as possible. Also, we made the material practical by showing developers how to use each optimization method. For information on related topics such as system configuration and tuning, or improving the IO and network performance, we refer readers to other resources. This book differs from other books and technical documents written aboutperformance optimization of high performance computing (HPC) applications. In many cases, other resources either give a detailed description of a product or provide general recommendations that are sometimes difficult to apply to practical tasks. In addition, some older resources are not as useful because of changes in technology. Though many of the techniques we offer apply to other platforms, we limited the scope of this guide to Sun compilers and UltraSPARC-based Solaris systems. We address new features in Sun compilers and in the Solaris Operating Environment, and we show readers how to use these products to get maximum performance on Sun hardware. Who Should Read This Book This guide is primarily for developers of technical or HPC applications for Solaris. This audience includes both independent software vendor (ISV) developers and non-commercial developers. Developers creating or optimizing applications in the following fields may benefit from reading this book: Mechanical computer-aided engineering (MCAE) Electronic design automation (EDA) Computational chemistry Bioinformatics Operations research Financial modeling Reservoir simulation and seismic modeling Mechanical computer-aided design (MCAD) modeling Graphics rendering and imaging Climate and weather modeling This book may also be helpful to technical application end-users in understanding the principles of HPC and how an application utilizes system resources. We assume the reader has: familiarity with development basics in UNIX environments a working knowledge of programming in C and Fortran languages familiarity with computer architecture experience in parallel programming a basic knowledge of SPARC assembly (desirable) Unless otherwise noted, topics in this book are not limited to a programming language, parallelization method, or software version. However, emphasis is on techniques relevant to applications written in Fortran 77, Fortran 90, and C, because these languages are most commonly used in HPC and technical applications. Most topics can be applied to C++ programs; however, we do not address performance optimization issues for object oriented programming. We refer readers to other resources. How This Book Is Organized This book presents information so that it follows logical stages of the process for application development and optimization. We pay special attention to issues related to parallel applications and to using appropriate performance monitoring tools. Wherever applicable, sections are illustrated with code examples that show benefits of methods described. Part I - Getting Started Chapter 1 Introduction, introduces optimization for HPC applications. We describe the basics of the optimization process and illustrate it with flow charts for serial and parallel optimization. Chapter 2 Overview of Sun UltraSPARC Solaris Platforms, describes the available tools of trade for HPC developers using Solaris platforms. It gives an overview of Sun hardware and software products for technical computing. Also, the chapter introduces software development tools. Chapter 3 Application Development on Solaris, considers development and porting issues on Sun platforms. It includes sections on binary compatibility between platforms, standards conformance, code verification tools, language interoperability, and 64-bit porting issues. Part II - Optimizing Serial Applications Chapter 4 Measuring Program Performance, focuses on tools that measure application performance. Accurate measurement of performance is crucial in tuning. We describe accurate timers available on Solaris, profiling tools, Forte Developer 6 Performance Analyzer, hardware performance counter access tools on UltraSPARC processors, and other system monitoring tools. Chapter 5 Basic Compiler Optimizations, introduces basic compiler optimizations and how to use compiler flags correctly. Options covered in this chapter are safe and generally can be applied without knowledge of any specifics of the application. The impact of using these flags is illustrated with examples, and analysis of the generated code with and without the options is presented. Chapter 6 Advanced Compiler Optimizations, extends Chapter 5 and gives an overview of techniques that enable aggressive compiler optimizations. These often result in additional performance gains but may also lead to incorrect answers or spurious side-effects. Also, we cover performance related compiler pragmas and directives, which can be inserted in a program. Information about a program can be passed to the compiler, allowing additional optimizations. Chapter 7 Linker and Libraries in Performance Optimization, highlights optimized libraries and features of the Solaris linker that can be used for application optimization. We describe the platform-specific optimized math libraries whose use can result in significant performance gains. We show linker techniques that allow linking of these platform-specific libraries in a portable fashion. Chapter 8 Source Code Optimization, provides an overview of tuning techniques at the source code level. The techniques were selected from the point of view of better utilizing the underlying architectural features of UltraSPARC systems. We pay special attention to memory hierarchy utilization such as cache blocking and reducing the translation lookaside buffer (TLB) misses. We present ways of simplifying the code to allow better compiler optimizations, such as alias disambiguation in C programs, to take place. Chapter 9 Loop Optimization, focuses on optimizing loops, one of the most commonly used constructs in scientific and HPC programs. We discuss ways in which developers can help the compiler control loop fusion and fission, as well as perform loop peeling. We show examples of register-tiling and consider loops with branches. Part III - Optimizing Parallel Applications Chapter 10 Parallel Processing Models on Solaris, introduces concepts of parallel programming and different parallelization models available on SolarisSPARC systems: automatic compiler parallelization, directives-based parallelism, explicit multithreading, UNIX forkexec, message passing model, and hybrid programming (combined directives and message-passing). Chapter 11 Parallel Performance Measurement Tools, details the tools for performance measurement and monitoring of parallel programs. Similar to Chapter 4, we focus on accurate timers for timing parallel programs, tools for measuring synchronization and communication overheads, tools for measuring hardware counters, and tools for multiprocessor system monitoring. Chapter 12 Optimization of Explicitly Threaded Programs, provides an overview of explicit multithreading of programs using P-threads and Solaris threads. An overview of thread scheduling models in Solaris and their relevance to HPC programs is given and techniques for decreasing synchronization overheads are described. Chapter 13 Optimization of Programs Using Compiler Parallelization, covers support and optimization techniques for automatic and directive-based parallelization in Sun compilers. Special emphasis is given to tuning OpenMP programs using the Fortran 95 compiler. OpenMP programming styles and data-scoping issues are illustrated with examples. Comparisons between OpenMP and P-threads approaches are presented. Chapter 14 Optimization of Message-Passing Programs, describes message-passing models and how to tune MPI programs. We present an overview of message-passing programming models, compiling and linking programs using Sun MPI, and using Sun MPI environment variables. This chapter describes approaches for optimizing point-to-point and global communication with Sun MPI, using the S3L scientific library and using a hybrid OpenMPMPI model. Part IV - Appendices Appendix A Commands That Identify System Configuration Parameters, lists useful Solaris commands that identify system configuration parameters. Appendix B Architecture of UltraSPARC Microprocessor Family, gives an overview of architectural features of the UltraSPARC microprocessor family. Appendix C Architecture of UltraSPARC Interconnect Family, describes the architecture of interconnect technologies for UltraSPARC systems. Appendix D Hardware Counter Performance Metrics, shares some useful performance metrics that can be derived from hardware counters on UltraSPARC systems. Appendix E Interval Arithmetic Support in Forte Developer 6 Fortran 95 Compiler, gives an overview of interval arithmetic support in the Forte Developer 6 Fortran 95 compiler. Appendix F Differences in IO Performance, considers the performance of different IO techniques. Additional Resources To keep the scope of this book manageable, we intentionally omitted many subjects related to performance optimization. Our criteria was to omit subjects that were not applicable to a wide range of applications. Many of these subjects are presented in other documentation for Sun products. The following is a list of publications you may find useful for more narrowly focused subjects: Numerical Computation Guide Fortran Programming Guide Fortran User’s Guide Analyzing Program Performance with Sun Workshop C User’s Guide Forte 6 update 1 C User’s Guide Supplement Linker and Libraries Guide Sun Performance Library Reference Multithreaded Programming Guide Programming Utilities Guide 64-bit Developer’s Guide Solaris Tunable Parameters Reference Manual Sun HPC ClusterTools 3.1 Performance Guide Sun MPI 4.1 Programming and Reference Guide Prism 6.1 User’s Guide Sun HPC ClusterTools 3.1 Installation Guide All these publications are available online at http:docs.sun.com. We strongly recommend that developers visit this site, because nearly all published Sun documentation is available there. Printed versions are available from Sun Documentation Center at Fatbrain: http: The following publications are related to UltraSPARC microprocessors: UltraSPARC I and II User’s Manual UltraSPARC IIi User’s Manual These publications are available at: http: Other sites of great use for developers are http: and http:soldc.sun.com, which contains current information for the Sun developer community. A description of Sun product lines is available at http: and http: . Sun products and solutions for the HPC are listed at http: . For specialized books and additional theoretical information on application optimization, we refer readers to other sources. There are many excellent books on topics such as optimizing compilers, software tuning techniques, and efficient parallelization. The following are some helpful resources: J. Hennessy, D. Patterson - Computer Architecture: A Quantitative Approach , Second Edition; Morgan Kaufmann Publishing, 1996 K. Dowd, Ch. Severance - High Performance Computing , Second Edition; O’Reilly &amp; Associates, 1998 D. E. Culler, J. P. Singh, A. Gupta - Parallel Computer Architecture: A Hardware Software Approach , Morgan Kaufmann Publishing, 1999 S. S. Muchnick - Advanced Compiler Design and Implementation ; Morgan Kaufmann Publishing, 1997. S. Kleinman, D. Shah, B. Smaalders - Programming with Threads ; SunSoft Press, A Prentice Hall Title, 1996. W. Gropp, E. Lusk, A. Skjellum - Using MPI: Portable Parallel Programming with Message-Passing Interface (Scientific and Engineering Computation Series); Second Edition, MIT Press, 1999. R. Chandra, L. Dagum, D. Kohr, D. Maydan, J. McDonald, R. Menon - Parallel Programming in OpenMP ; Morgan Kaufmann Publishing, 2000. More resources are listed in the References section at the end of this book. Readers interested in hands on training should check with the Sun Educational Services to determine if a class is scheduled and enrollment is open. Code Examples Many sections in this book are illustrated with code examples that show benefits of optimization techniques and coding practices. The code examples can be downloaded from the Sun BluePrints site: http: A makefile is provided for each chapter so that the examples can be run with a single make command. Unless otherwise noted, all examples and results presented in this book use Forte Developer 6 compilers and the HPC 3.1 ClusterTools release. The results for serial runs were obtained on Sun Ultra 60, Sun Ultra 80, and Sun Blade 1000 systems. The results for parallel runs were performed on Sun Enterprise 4500, Sun Enterprise 10000 servers, and a Sun technical compute farm. The system parameters are listed in TABLE P-1 and TABLE P-2, respectively. More information about Sun platforms is in Chapter 2.",
    "author": [
      {
        "family": "Garg",
        "given": "Rajat P."
      },
      {
        "family": "Sharapov",
        "given": "Ilya"
      }
    ],
    "id": "10.5555/572441",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Prentice Hall Professional Technical Reference",
    "title": "Techniques for optimizing applications: High performance computing",
    "title-short": "Techniques for optimizing applications",
    "type": "book"
  },
  {
    "ISBN": "0201702525",
    "abstract": "From the Book: PREFACE: This book focuses on the most powerful approach available today to model and build industrial-strength Java applications: the Unified Modeling Language (UML) adopted in 1997 by the Object Management Group (OMG). A project lifecycle and software process model are demonstrated (Rational’s Unified Process) using a sample application from requirements gathering, using Use Cases, through implementation via the creation Java code from Class and Sequence diagrams. This sample application uses the latest Java technology frameworks such as Java Server Pages (JSP), Servlets, and most importantly, the Enterprise Java Bean 2.0 (EJB) server-side enabling technology for the implementation of the business rules. Products to implement these server-side solutions range from the Apache Tomcat server to commercial applications servers such as BEA’s Weblogic server. Reason for the Book It took me many years to understand that writing a program was nothing more than a learned tactical skill. To program in a language like Java is to be a journeyman. But to somehow capture someone’s requirements in an intelligent fashion and organize the necessary resources and resulting software into a cohesive deliverable, is the sign of a strategic craftsman. To me, the majority of Java books never consider Java in \"the large.\" They focus on the small view, covering single Java enabled extensions such as JavaBeans, Servlets and Java Server Pages. Although these views, too, are necessary, unfortunately no one seems to touch on project planning, software process, and the methodology for building enterprise-status Java applications. This is a difficult topic to explore andpresent as the whole subject of process stirs many heartfelt debates and opinions. At the urging of many of my colleagues and supportive readers of my first book, Developing Applications with Visual Basic and UML, I have undertaken a similar project for Java. Who Should Read This Book This book is for anyone who wants to successfully build Java applications that can stand up over time. It provides an accurate road map for anyone to achieve the following goals. Review two processes, one commercially available through Rational Software called the Unified Process (UP) and one from the author’s experiences called Synergy. The greatest emphasis will be placed on the Unified Process. Establish a sound project plan (presented in-depth in Appendix E). Estimate projects with confidence, rather than a rule-of-thumb approach. Understand and describe the requirements of the application using UML Use Cases. Create a sound design based UML Class and Sequence diagrams. Use a visual modeling tool such as, Rose, by Rational Software not only to create and track UML artifacts but also to generate skeletons for the component code. Although this author firmly believes that an automated code-generation process is a big factor contributing to successful projects, it by far is not mandatory. Use Java to build server-side Java functionality employing frameworks such as Java Server Pages (JSP), Servlets, and Enterprise JavaBeans 2.0 (EJB). Produce the code for the project using an evolutionary approach showing various technology options: 1). Servlets, JSP, and JavaBeans 2). Servlets, JSP, and Bean-Managed Persistence (BMP) 3). Servlets, JSP, and Container-Managed Persistence (CMP). Investigate the benefit of deploying Java applications on both open-source products like the Apache Tomcat server as well as using commercial Application Server products such as BEA’s Weblogic application server. Anyone building Java applications today needs this book. What You Need to Know to Use This Book Maybe it’s best to start out with what you don’t need to know to benefit from this book. First, you don’t need to know anything about the UML. I present the essential aspects of the UML and, more important, how they relate to Java deliverables. Although the UML is expressed with nine separate diagrams, you will benefit the most from a core set. Second, you don’t need a formal background in object-oriented concepts (but it certainly wouldn’t hurt). I discuss standard object constructs in the text in Chapter 2. Third, you should have some conversational understanding of what Enterprise JavaBeans are. For a really thorough treatment of Enterprise JavaBeans (EJB), you should focus on one of the many texts that cover them in more detail. A favorite book of mine is by Richard Monson-Haefel entitled Enterprise JavaBeans (O’Reilly). The reader would also benefit by having some exposure to Java Server Pages (JSP). A favorite book of mine is by Hans Bergsten entitled Java Server Pages (O’Reilly). This book does assume that you have a working knowledge of Java. Both the new Java programmer and the experienced Java programmer will benefit. However, I don’t cover the basics of simple Java constructs, assuming that you already know these. I do briefly review the tenets of Java’s support for object-oriented principals in Chapter 2, but only as a baseline for other topics related to the UML. If you have had no exposure to Java, buy this book anyway and open it after you have had some initial training in that programming language. This book places an emphasis on the most mainstream Java techniques and products that are used to build production applications. When I began this book I planned to cover all kinds of java technologies (i.e., applets, java applications talking to Servlets or JSPs). However, it quickly became apparent to me that the majority of my clients and my associate’s clients were all pretty much cut from the same mold when you looked at their architecture. They consist of a light client browser on the front-end (with minimal JavaScript for syntax editing) a web server intercepting those browser requests with either Servlets and/or Java Server Pages acting as a broker within some container product which houses the business rules. These business rules are either implemented as JavaBeans or Enterprise JavaBeans. The container products range from open-source solutions like Apache Tomcat to commercial products. The two biggest of the commercial application server players I run across are BEA with their Weblogic product and IBM with their Websphere product. This doesn’t mean there aren’t more good commercial container products but these two vendors have the lion’s share of the market. This book will utilize a light client-side technology (no applets or java applications), web server running Servlets and Java Server Pages who in turn message to either JavaBeans (Tomcat) or Enterprise JavaBeans (session and entity beans) residing in a commercial application server. In the case of the later, I have chosen to use BEA’s Weblogic as my application server. Don’t get discouraged if you are using another vendor’s application server product because this book’s coverage of EJB is based on the 2.0 specification. This release of EJB resolved many of the ambiguities that disallowed beans to be truly transportable across vendor implementations. So, regardless of your EJB vendor, you will be able to use the code built in this book. It would be unfair to say you will know, for instance, everything about EJBs after reading this book. If you already know about EJBs then this book will better help you put them into a sound design architecture. The emphasis is placed on the notation, UML, and the process, Unified Process and Synergy, in beginning, developing, and implementing, a software project using the Java language. The benefit of seeing an application from requirements gathering to implementation is the key to goal of this book. This is where I shall place my emphasis. Structure of the Book Following is a summary of the book’s chapters and contents. Chapter 1: The Project DilemmaThis chapter reviews the current state of software development and my reasoning regarding why it’s in the shape that it is today. It also reviews the concept of iterative and incremental software development and provides an overview of both the Unified Process from Rational Software and my Synergy methodology. It also touches on the primary components of the UML that will be covered in more depth later in the book. Chapter 2: Java, Object-Oriented, and the UMLThis chapter covers some of the benefits that result from the adoption of Java as a development environment. It presents these in the context of Java’s implementation of encapsulation, inheritance, and polymorphism. It then maps the UML to various Java deliverables. Highlights include mapping the UML class to Java classes and Java interfaces; mapping use case pathways to Java entity, interface, and controller types of classes; and mapping component diagrams to Java classes and Java packages. Chapter 3: Getting the Project StartedThis chapter explores the case study used in the book, Remulak Productions. This fictional company sells musical equipment and needs a new order entry system. It introduces a project charter, along with a tool, called the event table, to help quickly solidify the application’s features. Further, the chapter maps events to the first UML model, the use case. Chapter 4: Use CasesThis chapter reviews the use case, one of the central UML diagrams. Included is a template to document the use case. Actors and their roles in the use cases are defined. The chapter reviews the concept of use case pathways, as well as the project’s preliminary implementation architecture. Also reviewed is an approach to estimating projects that are built by using the use case approach. Chapter 5: ClassesThis chapter explores the class diagram, the king of UML diagrams. It offers tips on identifying good class selections and defines the various types of associations. It also covers business rule categorization and how these rules can be translated into both operations and attributes of the class. Finally, it discusses the utilization of a visual modeling tool as a means to better manage all UML artifacts. Chapter 6: Building a User Interface PrototypeThis chapter reviews unique user interface requirements of each use case. It develops an early U/I prototype flow and an eventual graphical prototype. Finally, it maps what was learned during the prototype to the UML artifacts. Chapter 7: The Dynamic Elements of the ApplicationThis chapter discusses the dynamic models supported by the UML, exploring in depth the two key diagrams, often referred to as the interaction diagrams, sequence and collaboration. These are then directly tied back to the pathways found in the use cases. Other dynamic diagrams discussed include the state and activity diagrams. Chapter 8: The Technology LandscapeThis chapter covers the importance of separating logical services that are compliant with a model that separates services. It explores technology solutions specific to the Remulak Productions case study, including distributed solutions and the Internet using HTML forms, JSP and Servlets. Both JavaBeans and Enterprise JavaBeans as a solution for housing the business rules are also be explored. Chapter 9: Data Persistence: Storing the ObjectsThis chapter explores the steps necessary to translate the class diagram into a relational design to be supported by both Microsoft SQL Server and Oracle databases. It offers rules-of-thumb regarding how to handle class inheritance and the resulting possible design alternatives when translating to an RDMBS. This book will deliver solutions that range from roll-your-own persistence using JavaBeans and JDBC, all the way to Container Managed Persistence (CMP) features of the EJB 2.0 specification. The later removes all the requirements of the application to write SQL or control transactions. This chapter introduces the concept of Value objects to reduce network traffic as well as Data Access Objects that encapsulate SQL calls. Chapter 10: Applying the InfrastructureThis chapter finalizes the design necessary to implement the various layers of the application. It also presents the communication mechanism utilized between the layers and possible alternatives. Each class is delegated to one of three types: entity, boundary, or control. These are used as the basis for the design implementation and as the solution to providing alternative deployment strategies. Chapter 11: Constructing a Solution: Servlets, JSP, and JavaBeansThis chapter builds the first Architectural Prototype for Remulak and does not rely on Enterprise JavaBeans. Using the Maintain Relationships use case as the base, the various components are constructed. The primary goal of the Architectural prototype is to reduce risk early by eliminating any unknowns with the architecture. This chapter uses the Apache Tomcat server and introduces the concepts of user interface and use case controller classes. Chapter 12: Constructing a Solution: Servlets, JSP, and Enterprise JavaBeansThis chapter initially uses Rational Rose to generate EJB components. A primer on EJB is offered along with a thorough discussion of the transaction management options in the EJB environment. Session beans are utilized as the use case controller. Both a Container Managed Persistence (CMP) and Bean Managed Persistence (BMP) are presented. Leveraging the Data Access Objects created in the previous chapter is paramount to the success of a BMP implementation. Updates and Information I have the good fortune to work with top companies and organizations not only in the United States, but also in Europe, Asia, and South America. In my many travels, I am always coming across inventive ideas regarding how to use and apply the UML to build more-resilient applications that use not only Java but also C, C# and Visual Basic. Please visit my Web site at www.jacksonreed.com, where you can get the latest on the training and consulting services that I offer, as well as all of the source code presented in this book. I welcome your input and encourage you to contact me at prreed@jacksonreed.com.",
    "author": [
      {
        "family": "Reed",
        "given": "Paul R."
      }
    ],
    "id": "10.5555/515925",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Developing applications with java and uml",
    "type": "book"
  },
  {
    "DOI": "10.1145/3159450.3162351",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3162351",
    "abstract": "CS instructors are sometimes tasked with modifying CS1 courses to teach introductory programming for the Digital Humanities. Training computer science students in DH programming methods may also have some additional benefits, such as bringing more women into computing, and helping in the recruitment and retention of CS students overall. DH projects may also provide Service-Learning opportunities that will give students experiential learning opportunities not provided in industry. The presenters have developed six assignments in Python that are oriented towards DH topics while still providing CS students solid experiences in core programming concepts. This workshop introduces the participants to five of the assignments and gives them immersive abbreviated experiences in each. The topics include Computing Change over Time (calculating burials in a historic cemetery), Visualization of Change over Time (visualizing the burials in the historic cemetery), Textual Analysis (finding word frequencies and \"stop words\" in public domain texts), Stylometrics (comparing measured features of graphic images), and Social Network Analysis (analyzing extended relationships in historic social circles). A balance of direct coding experience and discussion of gotchas and best practices in classroom management will give workshop participants confidence in offering and managing these assignments in their own classrooms. Participants should bring a laptop/keying-friendly mobile device that has a Python 3.x IDE already installed, and some familiarity with the Python language.",
    "author": [
      {
        "family": "Kokensparger",
        "given": "Brian"
      },
      {
        "family": "Peyou",
        "given": "Wade"
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3162351",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "python programming, humanities programming, digital humanities, CS1",
    "page": "1050",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Programming for the humanities: A whirlwind tour of assignments (abstract only)",
    "title-short": "Programming for the humanities",
    "type": "paper-conference"
  },
  {
    "ISBN": "0782128734",
    "abstract": "From the Publisher: Master the RAD Tool Designed Especially for Linux Development Kylix 2 promises great things for the world of Linux application development. Mastering Kylix 2 is the best possible way for you to take advantage of everything this powerful RAD tool has to offer. Co-written by internationally acclaimed Delphi expert Marco Cantù, this book provides authoritative, tutorial-style instruction along with tips and tricks available nowhere else. Begin with Kylix basics and advance confidently, developing the skills needed to use Kylix to meet real challenges-from sockets programming to XML processing to web services development. Coverage includes: Getting acquainted with the Kylix IDE Using Kylix’s object-oriented facilities Implementing Linux file management Working with the BaseCLX library Developing GUIs Using advanced components and controls Creating forms Building graphics features Writing Kylix components Using the ClientDataSet component and MyBase Handling interprocess communication Creating web programs with WebBroker and WebSnap Processing XML Developing SOAP-based web services Featured on the CD On the CD, you get complete and ready-to-use source code for the hundreds of examples presented in the book. You also get an electronic copy of Essential Pascal, Marco Cantù’s acclaimed introduction to the Pascal programming language, written from a Kylix perspective. Finally, you get the open source version of Kylix, FreeCLX, Interbase 6 Open Source Edition, and the Indy open-source web component suite. About the Authors Marco Cantù is the author of sixeditions of the best-selling Mastering Delphi 6. Beside writing and speaking at conferences, he teaches technical classes on both Delphi and XML technologies. Marco lives in Italy. Uberto Barbini is a teacher and consultant for the Italian university Politecnico di Milano. He has published a book on Delphi in Italy and is the developer of the open source program Fractal Forge.",
    "author": [
      {
        "family": "Cantu",
        "given": "Marco"
      },
      {
        "family": "Barbini",
        "given": "Uberto"
      }
    ],
    "edition": "1st",
    "id": "10.5555/582764",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "SYBEX Inc.",
    "publisher-place": "USA",
    "title": "Mastering kylix 2",
    "type": "book"
  },
  {
    "ISBN": "0130660612",
    "abstract": "From the Book: Preface Core ColdFusion 5 is the book I wish I’d had when I began writing applications. One way of teaching programming is for the author to entice you, gentle reader, into the Technicolor landscape of the programming language at handthe author is your friendly guide, pointing out the dazzling array of colors and scents, while you, the Maui-shirted, floppy-hatted tourist, peer dimly into your map as you stand gawking dead center at the intersection of 42nd and Broadway. You get your required caramel milkshake at Ellen’s Stardust Diner and move on to stand in line for Cats tickets. Or something like that. This is a different kind of book. I learned ColdFusion on the flydevouring websites and books devoted to the topic, nosing about in newsgroups and loitering on lists while I tried to get my first applications up and running. I learned by reading, by asking endless questions, by trying things over and over until something clicked. I learned from the generosity of hundreds of programmers it has been my pleasure to work with. I don’t view it as an academic subject. This learning process was all very glamorous, but I think I wasted a lot of time that I didn’t need to waste. The approach is this: programmers are, above all, problem solvers. That’s what they get paid to do. Therefore, the language is presented as a set of tools that are available to you to solve business problems. The code you will work with will consist of numerous non-trivial, practical examples that you can build on and incorporate into your own websites. My belief is that you can learn best how it all fits together by seeing it in action, working together. Forinstance, it’s fun to learn about cookies, and it’s great to know that by using the CFLOCATION tag in your templates you can quickly jump to another URL. This is the sort of thing one learns as a programming tourist. Only when discussing a real-world application where all the parts have to fit together do you discover that, because of HTTP headers, you can’t effectively set a cookie in the same template that you use CFLOCATION to get out of. But that’s exactly the sort of thing you need to know when you sit down to write ColdFusion. You are a person in the world where people live. This indicates a certain relationship with space and time. This book was designed with these key factors in mind. There is only so much space in a book, so what you’ve got in your hands is the set of tools with which to continue on your own: There’s the complete tag and function reference. There are lists of dozens of websites where you can get ColdFusion code, find more information on related topics, discover hundreds of places where you can host your ColdFusion website, and more. You get a list of the common ColdFusion errors you’ll run into when debugging your applications, what they mean, and how to fix them. You put together a ColdFusion application for Web-enabled cell phones and a working e-commerce site, complete with rotating banner ads. The idea is to save your walls from the repeated impact of your head. This book will give you everything you need to get up and running quickly, effectively, and with an understanding of the real-world implications of developing with ColdFusion. The remainder of this preface briefly illuminates key things you will need to start using this book, and ColdFusion, quickly. Who You Are This book was written for anybody who wants practical knowledge of how to make Web applications on an easy, scalable, powerful platform. You know HTML already. You do not need to know another application programming language. You do not need knowledge of Web servers or data servers. Maybe you know ASP or JSP and want to learn another language. This book is perfect for you. Maybe you just took an IT job at Symantec or Doctor Solomon’s or Bank of America or the University of Utah or the Recording Industry of America. Or maybe you were just elected Senator of your fine state, and, while browsing at http://www.Senate.gov noticed the little \".cfm\" extension on your website and wondered what it was. All of the above organizations entrust their Web transactions to ColdFusion. And with good reason. This book was also written for Web developers and for people who have done a static website or two and want to make their next one dynamic. The ability to create an online store, to interact with data warehouses via enterprise-level features such as stored procedures and data probing, lets you get really serious. The ability to personalize your website, catering its content to each individual visitor, will allow you to create truly compelling relationships with your users. The ability to search and share documents in just about any format will allow your organization to stay ahead of the information cycle. Project managers and sales engineers will benefit from this book’s discussions of planning an enterprise-level website and making all of the components come together. Despite a seemingly universal predilection toward Mountain Dew, Web programmers are a diverse species. Whether you are a pleasantly dressed co-ed working in a college computer lab with well-modulated air, or if you’re grinding out 18-hour days in a high-tech job shop and have recently started looking like the long-lost fourth member of ZZ Top, or whether you’re all by yourself in your basement playing gladiator with IIS and scramming the cat from chewing your cables, this is the right book for you. What You Need You will need several things to work successfully through the exercises in this book. You will need a computer with a text editor. You will need access to ColdFusion Server 5 software, a Web server, and an Internet connection. A 30-day evaluation version of ColdFusion 5 comes on the CD-ROM with the book, Notepad or Pico comes with your OS, and Apache is free, so you’re in pretty good shape. What You Get This is a practical book. Its purpose is to answer the questions you need answered by showing you how everything works together (HTTP 1.1 headers, the Web server, your applications, conditional logic, and so forth). Some of this may be old hat to you. I have therefore tried to flag you about beginner material that you may want to skip. Here is what you get: A clear, detailed explanation of the ColdFusion language and how you can leverage it to build fantastic Web applications. Information, tips, and tricks about becoming a ColdFusion Certified Developer. Thousands of lines of complete, working code. On the CD-ROM, you get 30-day evaluation versions of Macromedia ColdFusion Enterprise Server 5.0 for Windows, HP-UX, Sun Solaris, and Linux; ColdFusion Studio 4.5.1 optional development environment for creating ColdFusion templates); HomeSite 4.5.1, Macromedia’s award-winning HTML editor; The Harpoon Flash Toolkit; ColdFusion Express, the nonexpiring, limited-functionality product for serving ColdFusion pages; JRun 3.0.1, the award-winning server for Java Server Pages, Servlets, and Enterprise Java Beans; Macromedia Spectra 1.5 for Windows and Sun Solaris, the packaged application solution for content management, e-commerce, and personalizationwritten in ColdFusion! A website companion to the book filled with even more ColdFusion resources. The website is located at http://www.CoreColdFusion.com. Check out http://www.conditionallogic.com as well. How This Book Is Organized This book begins where HTML left off. We start with an overview of how the Internet works and an overview of what ColdFusion does. We then move into a discussion of SQL (the Structured Query Language), the language used to create and manipulate databases and their data. If you have a solid understanding of relational databases and SQL, you can probably skim Chapters 9 and 10. Each chapter will have roughly the same structure. You will be introduced to the key concepts in a general way, and quickly move into details as they pertain to ColdFusion or application development. You’ll come out of most chapters with a working example that you can take with you. Because each chapter builds on the last, it is a good idea to read the book from beginning to end. If you’re used to programming in another Web application language such as PHP, you might want to at least skim the introductory chapters on the World Wide We HTTP, as well as the SQL chapters, just so I don’t make unfortunate assumptions. As the book continues, and you’ve got the key concepts and a number of tags and functions under your belt, we’ll start putting together bigger applications with a number of pieces that have to fit together. That is the only way you can learn how to work with ColdFusion in large-scale websites. Many of the examples in this book were created with the ColdFusion Application Server running on a Windows 2000 with IIS 5. The database used in most cases is Microsoft SQL Server 2000. Oracle 8i is used in some examples. Access has generally been eschewed because, while it is inexpensive and therefore easier to get hold of, it is desktop software and unsuited to a production environment. You can make most of the examples in this book work with Access or Paradox with little or no modification. You can even use Excel spreadsheets and plain text files with some modification. That’s a fabulous aspect of ColdFusion, and just one demonstration of its flexibility. However, I try to discourage the use of desktop database software with ColdFusion for applications that are likely to have more than a couple of concurrent connections or any frequency of use. About the Website If you point your browser to http://www.CoreColdFusion.com, you will discover the companion website to this book. It is meant to provide you with a resource for taking your applications to the next level and continuing your work. Some features of the website include: Databases, files, and code from the book Code for creating the website Enhancements and expansions to discussions i book Links to ColdFusion hosting providers Resource links for ColdFusion User Groups and the most useful ColdFusion sites on the Web Information about becoming a Macromedia ColdFusion Certified Developer A newsletter with product and informational updates on ColdFusion and Spectra A forum for reader feedbacktell me what you think! A schedule of ColdFusion and Spectra training seminars happening every month, all over the United States Fun things like the ColdFusion challengea compendium of tips and tricks Security bulletins If I’ve done my job, this book will teach you what you need to know about ColdFusion in order to go do it in the real world. Hopefully it will also prove useful long after you know what you’re doingit has been organized to serve also as a reference. It’s got the complete language in it, updated for ColdFusion 5. And it’s got working examples that represent the most commonly needed tasks in Web programming today. You can give me feedback at writer@CoreColdFusion.com. I welcome your comments and suggestions for future editions. Thank you for picking this up. I really hope you like it.",
    "author": [
      {
        "family": "Hewitt",
        "given": "Eben"
      }
    ],
    "id": "10.5555/516065",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Core coldfusion 5.0 with cdrom",
    "type": "book"
  },
  {
    "DOI": "10.1145/77556.77557",
    "ISSN": "0001-0782",
    "URL": "https://doi.org/10.1145/77556.77557",
    "author": [
      {
        "family": "Frenkel",
        "given": "Karen A."
      }
    ],
    "container-title": "Commun. ACM",
    "id": "10.1145/77556.77557",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1990,
          4
        ]
      ]
    },
    "keyword": "transborder data flow, statistics, standards, regulation",
    "page": "404-410",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The european community and information technology",
    "type": "article-journal",
    "volume": "33"
  },
  {
    "ISBN": "0201752948",
    "abstract": "From the Book: Oracle SQL and PL/SQL Handbook: A Guide for Data Administrators, Developers, and Business Analysts is a book whose purpose is to teach you techniques that you can use to extract information from complex modern Oracle relational databases. The business world has constructed numerous on-line transaction processing (OLTP) systems, databases, and data warehouses over the past twenty years. Information from these databases is very important to the successful operation of businesses. Corporations have also discovered that it is important to have personnel who can understand and efficiently extract information from these databases. This is why developers, data administrators, and business analysts who can get information from complex databases are so valuable to their companies. The Structured Query Language (SQL), which is an ANSI standard language for interacting with relational databases, is the main tool for extracting the information. SQL is somewhat standard across most relational database products, however this book only covers Oracle’s version. Oracle is the largest database manufacturer in the world and has the most product installations. So this is a good place to start your education. There are other tools you will need to know about in order to produce business information. This includes the ability to read and understand the database blue print. This blue print is the Entity Relationship Drawing (ERD) or my own favorite tool, the Table Relationship Drawing. You will also need to be aware of database objects such as views, synonyms, and indexes. After you learn how to extract the information, you will want to know how to extract the informationquickly. The book contains a chapter that has some common techniques that can be used to enhance the performance of your SQL. This book also covers PL/SQL. This is Oracle’s programming language. This is an extremely useful language for accessing object attributes and performing special calculations. This book contains numerous examples of various SQL techniques. It also has practice questions at the end of most chapters. The questions will allow you to practice the skills immediately after studying them. Appendix B contains answers to the practice questions and provides you with another set of examples to study, copy, and adapt to your work. The book is meant to be a basic reference book and a how-to manual that covers the most important and common Oracle database topics. It is not the ultimate reference book. It is very difficult to learn SQL from these types of books. This book can be used as a reference book, but is does not totally eliminate the need for true reference books that cover the mundane, once used in five-year topics. The purpose of this book is to help you get the skills to analyze, understand, and efficiently extract information from an Oracle database. Developers, database administrators (DBAs), data administrators (DAs) and business analysts normally have a score of books in their work area. No single book can contain everything about all topics. I want this book to be the first book you go to for answers about the Oracle database because it contains the most frequently used information. The book is based upon courses I have taught at Iowa Western Community College, the University of Nebraska at Omaha, and on-site seminars I teach at many major companies. During the past four years I have helped many students understand the basics of Oracle SQL and the techniques used to extract information. The techniques I cover are the result of fifteen years of experience producing business information from relational databases. Students say my books and seminar workbooks are very practical. I believe in studying and identifying good design, copying it, modifying it, and calling it my own. Much of this good design is included in this book. I truly hope and believe that you will find the information in this book practical, and I hope you steal it and call it your own. WHAT IS ORACLE Oracle is the largest database manufacturer and the second largest software manufacturer in the world. The company began as a relational database manufacturer. In the beginning Oracle touted their software as being able to run on any platform. This openness has been most attractive to companies and Oracle has tried to maintain its image as an open product. Oracle was at a good place when industry became extremely interested in moving away from network databases and the mainframe. By allowing companies to use the client/server paradigm, Oracle had a competitive advantage. It also identified the Internet as the future paradigm. Oracle remains the premier database manufacturer due to its foresight. Oracle continues to increase the power of its database. The current version is called Oracle9i. Oracle9i is an object-relational database, which has features that allow developers to model objects within the database. The i in the name means that Oracle intends that its database can also support the Internet. To this end, Java programming functions can be placed within the database. Oracle can understand applications using the Java functions. Oracle has recognized that Java is an open product and is one of the more important languages of the Web. Oracle also has several other database products. Personal Oracle is a smaller version of the Oracle Enterprise Edition. It resides on the client (your PC) and is designed primarily as a stand-alone database. Oracle also has a small database called Oracle Lite9i. This product is designed for use on mobile PC’s and hand held devices. Oracle has very powerful application development, report writing, and database analysis software. The application development package is currently called the Internet Developer Suite. It consists of a number of products. Developer 6i Form Builder and Report Builder are two of its products. Developer6i Form Builder is Oracle’s rapid application development (RAD) software. Report Builder is Oracle’s main report writing software. Designer 6i is Oracle’s computer aided software engineering (CASE) product. It is one of the best selling CASE products in the country. In addition to performing database documentation and object creation, it can be used to generate forms (screens). It is integrated with the other Developer6i products. Even though it will not be covered in this book, Designer is used in many shops as a repository of database information. It is an important tool that can be used to develop and obtain ERDs and other database documentation. The last remaining development software is JDeveloper. This is a Java based application development product somewhat similar to Developer 6i Form Builder. It can be used to create Java based applications, both client/server and Web based. Borland supplied the core technology for this product. It has a strong resemblance to Borland’s Jbuilder. Oracle hopes that JDeveloper will someday be the dominant Web development tool. Discoverer is Oracle’s database analysis product. It is an on-line analytical processing (OLAP) tool. It has a very easy user interface. It is an extremely powerful tool for developing and analyzing business information. The success of this product is due to the ease of creating business objects for analysis and the easy use of the product by end users. I have actually had novice students using the product with less than 2 hours of training. It is a great tool for empowering your users and reducing the report writing load of the programmers, DAs, and business analysts. Finally, Oracle has an array of packaged products for businesses. An example of this type product is Oracle Financials. This product is an entity resource planning (ERP) type application used by companies to document work requests, purchase the materials, maintain inventory levels. and manage their fixed assets, accounts payable, and other financial concerns. Oracle also has an array of other entity packages. As you can see, Oracle has a large number of tools and products. WHO SHOULD USE THIS BOOK At Iowa Western and my seminars, I allow anyone with Windows (or UNIX) experience to enroll in the courses. I would expect that this is the minimum technical criterion to properly use this book. This is an Intro book and will cover most of the commonly used areas of Oracle SQL and PL/SQL. It will also have some elementary coverage of relational and object database components and terminology. This book will be of interest for the following people: Mainframe programmers wanting to upgrade or develop SQL skills. Systems analysts, developers, or business personnel interested in Data Administration. Students desiring the skills to enter the Oracle market. Oracle developers looking new techniques. Developers interested in implementing business objects for analysis. Business analysts interested in gaining the skills to analyze corporate databases You would expect a book such as this to be of interest to readers that desire a technical career. Increasingly it is of importance for accountants, financial analysts, and other non-technical people to have SQL, database, and on-line-analytical-processing (OLAP) skills. A case in point is the job description for accountants at the company for which I am employed. Accountant job descriptions request Oracle knowledge as a needed skill. With the proliferation of ERP type databases such as Oracle Financials, SAP, or People Soft, non-technical personnel are having derive information from these databases. Knowledge of SQL, PL/SQL, and Discoverer will greatly aid these people. This knowledge will give these personnel an edge over other co-workers. The worker that can furnish information to management is always a valuable asset. The worker that cannot is not as valuable. Another class of developers that may reap benefits from this book are Microsoft Access developers. Access is a low level database product that is highly automated. I have had many comments over the years that my courses on SQL and database object creation help students understand what Access is actually doing. HOW IS THIS BOOK ORGANIZED This book contains sixteen chapters, a glossary appendix, and an answer appendix. The book begins with a discussion of the logical data model. This model is used to determine what the database represents, to identify data elements, and to identify the data linkages. This information is needed to effectively extract business information using SQL. The book then discusses the various Oracle database objects. It is important for you to understand these objects. Many of them will affect the SQL that is written. However, it may not be necessary for you to read the later portions of Chapter 2 until after the SQL chapters. Chapter 2 covers the use of the Data Definition Language (DDL). This language is used create and maintain database objects such as tables or views. The chapter also discusses how to log on to the Oracle database and enter commands. This section is important for the reader new to Oracle. I only place the DDL section at the beginning of the book for the readers that want to understand the database engine components before running the engine. Chapters 4-9 cover the Select command. This is the language used to extract information from the database. Chapter 10 discusses the use of views and sequences. Views are a really important tool for creating run time virtual records. Chapter 11 discusses commands contained within the database that can be used to change the presentation of your information. The Oracle database has limited report-writing tools. There are many more powerful tools available, including some fine Oracle tools. However, if your company does not have any of these tools, you will always have the tools discussed in Chapter 11 available. Chapter 12 discusses performance-tuning techniques. This chapter covers the more common and often used techniques. Chapter 13 discusses business objects. Business objects are database objects that can be used for analysis or to increase the performance of reports. The final three chapters will cover Oracle’s PL/SQL language. This language is a must for the data administrator. It can be used to create business objects and entity attributes of interest to the user. The language is also used in Oracle’s Report Builder and Form Builder products. Appendix 1 of the book is a glossary. This appendix has definitions of important database words. Appendix 2 contains the answers to exercises that reside at the end of many of the chapters. These questions will allow you to practice the discussed topics. I strongly encourage you to perform the practice questions, before checking the answers. CONVENTIONS There are two conventions that will be used throughout this book. These are: Bolded Text The first occurrence of a keyword that will be defined in the glossary. ItalicsIdentifies places in a command syntax template that will require a user defined value. OTHER SOURCES OF INFORMATION Despite the best attempts by the technical editors, copy editors, and myself, errors and misunderstandings will exist in this book. It is extremely humbling for an author/teacher to have his students/readers interpret his writing differently from what he expected. I have tried to be as skilled a technical writer as possible; however, I am sure that I fail occasionally. To remedy this, I intend to maintain a Web site that you can use to raise questions and view the answers to previous inquiries. The site will contain corrections, explanations, and clarifications. I believe this will be a valuable aid to you. The following is my home site: www.oracle-trainer.com Another valuable site is the Oracle Developer Tools User Group (ODTUG). This is an organization to which I have belonged for several years. They have an annual conference, a quarterly newsletter, and a special site where members can post enhancement requests to Oracle. Of special importance are the organization’s list servers. At the present time access to the list servers is free to everyone. The list servers allow you to post, answer, and receive advice about a variety of Oracle topics including SQL. I belong to the SQL, Java, Developer6i and Discoverer list servers. I monitor the questions and answers all day. There are also a number of other highly skilled professionals (and authors) who monitor the list servers during the day. It is an excellent place to get the latest Oracle information or help with technical issues. The ODTUG site is at www.odtug.com. If you are truly interested in Oracle, you must visit their Web site frequently. The home page (www.oracle.com) can be very complex and often appears to change daily. However, it is important that you visit the site since it is the source of new Oracle information. Below are some of the Oracle pages I recommend. Before trying to access the pages you should know that many of them are only available to members of the Oracle Technology Network. This is a free membership and you may join using Oracle’s Web site. You will be able to access a great deal of information using this membership. The Oracle Store page is the site for purchasing CD packs of Oracle databases (Personal Oracle, one of these databases, can be used on your PC for course work) and for the Internet Development Suite. These tools include Developer 6i, JDeveloper, Discoverer, and Designer. I strongly encourage you to purchase the database pack and install Personal Oracle (It only runs on Windows NT/2000 at the present time). You can practice all of the techniques discussed in this book. It is one thing to read about Oracle and another to actually employ the techniques. The current site for the CD packs is: https://oraclestore.oracle.com/OA_HTML/ibeCCtpSctDspRte.jsp section=11536&amp;jfn=CAB2E7AB8B81E955A27B05 The database package is called: Oracle(R) 9i Release 1 (9.0.1) CD Pack for Microsoft Windows.Oracle Certified Professional Programs. Oracle has a variety of certifications. Certifications are a series of tests about Oracle topics. Two of the more popular are the DBA and Developer certifications. The certifications consist of five tests. The initial test for the both the DBA and Developer certifications concerns SQL and PL/SQL. This book is an excellent primer for this exam. To learn more about Oracle certifications, visit: http://www.oracle.com/education/certification/ Oracle Certified Professional Assessment Test Download. It is possible to download sample certification exams. You may be interested in how you would perform on a certification exam before and after reading this book. Visit: http://www.oracle.com/education/certification/index.html sts.html to obtain the sample exams.",
    "author": [
      {
        "family": "Palinski",
        "given": "John Adolph"
      }
    ],
    "id": "10.5555/579616",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Oracle SQL and PL/SQL handbook: A guide for data administrators, developers, and business analysts",
    "title-short": "Oracle SQL and PL/SQL handbook",
    "type": "book"
  },
  {
    "ISBN": "1430218916",
    "abstract": "OpenSolaris is a rapidly evolving operating system with roots in Solaris 10, suitable for deployment on laptops, desktop workstations, storage appliances, and data center servers from the smallest singlepurpose systems to the largest enterpriseclass systems. The growing OpenSolaris community now has hundreds of thousands of participants and users in government agencies, commercial businesses, and universities, with more than 100 user groups around the world contributing to the use and advancement of OpenSolaris. New releases of OpenSolaris become available every six months, with contributions from both Sun engineers and OpenSolaris community members; this book covers the OpenSolaris 2008.11 release. Pro OpenSolaris was written to demonstrate that you can host your open source applications and solutions on OpenSolaris, taking advantage of its advanced features such as containers and other forms of virtualization, the ZFS file system, and DTrace. It’s assumed that you are already fairly knowledgeable about developing on Linux systems, so the authors give an overview of the similarities and differences between Linux and OpenSolaris, and then present details on how to use the Service Management Facility (SMF), ZFS, zones, and even a bit of DTrace. They also provide pointers to the many project communities associated with new OpenSolaris features. Special focus is given to web development using familiar applications such as Apache, Tomcat, and MySQL, along with the NetBeans IDE, and showing you how to exploit some of OpenSolaris’s unique technologies. What youll learn Discover the secrets of the ZFS, the most powerful file system ever conceived Explore OpenSolaris AMP (Apache, MySQL, PHP) and GlassFish in the context of Web 2.0 and Linux/Solaris, respectively Familiarize yourself with the new security administration features of OpenSolaris, including changes in DTrace Who is this book for? Linux system administrators and programmers who would like to know what they have missed since Solaris became an open source operating system. About the Apress Pro Series The Apress Pro series books are practical, professional tutorials to keep you on and moving up the professional ladder. You have gotten the job, now you need to hone your skills in these tough competitive times. The Apress Pro series expands your skills and expertise in exactly the areas you need. Master the content of a Pro book, and you will always be able to get the job done in a professional development project. Written by experts in their field, Pro series books from Apress give you the hardwon solutions to problems you will face in your professional programming career.",
    "author": [
      {
        "family": "Foxwell",
        "given": "Harry"
      },
      {
        "family": "Tran",
        "given": "Christine"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1540613",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Apress",
    "publisher-place": "USA",
    "title": "Pro OpenSolaris",
    "type": "book"
  },
  {
    "ISBN": "0130122475",
    "abstract": "From the Book: PREFACE: Introduction: How to Use This Book What Makes This Book Unique This book is intended to be a comprehensive reference to Informix products. It provides a substantial amount of detail as well as reference information. You can find much of this information in the many Informix manuals, but this book organizes it into one place and helps you find additional information. In addition, the book works in conjunction with its CD and Web site (www.informixhandbook.com) to provide a complete and long-term, ongoing reference. We want this to be one reference that can be on the shelf of any Informix developer or administrator. The information is organized into various functional groups, simplifying the process of finding what you need. My vision in designing this book is this: Create one reference that will help every level of Informix database administrator, application developer, system administrator, and end user. Organize the information in an easy-to-find fashion for all major Informix product lines. In conjunction with the book, its CD, and Web site, provide appropriate examples and detail, directing the readers to additional places to look for information. Supply a reasonable amount of \"behind-the-scenes\" information but focus on functionality. Use authors that specialize in particular Informix products and are well known in the Informix world. Make this the book to choose if you would like one reference on Informix. That’s a pretty tall order, isn’t it This book does not claim to be \"everything to everybody\" but it can help you on many different levels. If it can’t provide a specific answer, it will tell youwhereto find the answer. One of the major values with this book is that its Web site (www.informixhandbook.com) provides updated reference material for each chapter as well as numerous links that help you find more information. Many comprehensive Informix references in the world just don’t exist–at least not one-volume references–and I’m one Informix devotee who wants to fill that gap. The book also spans different versions of Informix. We provide plenty of information to get you up and running with older versions of the product, including INFORMIX-SE and OnLine Server (version 5.x). We offer more of a focus on the family of Informix Dynamic Server (IDS) products, including IDS versions 7.x, IDS.2000, Informix Internet Foundation.2000, and the data warehouse products. You may already know the names of many of the authors of this book. They were chosen from the local and international user groups as well as Internet newsgroups, ensuring that you will learn from some of the most knowledgeable Informix experts in the world. When choosing authors, I considered critical the fact that they had a special focus in the areas about which they wrote. In addition, all authors worked within the design and vision of this book, helping provide a consistent look and feel. To ensure overall consistency, I read and edited all of the chapters after they were submitted. We make this book more enjoyable by sprinkling it with amusing stories from Informix employees and others in the industry. These stories help add spice and make your learning experience much more enjoyable. All the way from this introduction to the CD-ROM to the Web site, we are crafting this book to meet the needs of Informix users worldwide. Please learn how to use it and have fun with it! The Web Site: An Ongoing Reference This book was designed by technologists who believe in using the best tools for the job (I guess that’s why we choose Informix products!). One of the major values that I think you can find with this book is that it has a very useful Web site. The site is designed to enhance and supplement the book on an ongoing basis. Using it in conjunction with this book, you will always be \"current\" on what is going on with Informix and the particular products. The site is found at www.informixhandbook.com and includes the following: Many informational Web site links about Informix and its products Enhanced and current information for each chapterfor example, if a product has changed or enhanced, we discuss it Further Web site links for each chapter Errata (error corrections, if any!) for each chapter Ability to use our monthly e-newsletter, which provides news and information about Informix and the book The latest Informix announcements and product information When the next edition of the book is released, most of the updates for each chapter will be included in the book. I truly intend the site to make this book a long-term, complete reference for your Informix needs. Please be sure to view the site and learn how to use it. If you want monthly news and updates about Informix, be sure to subscribe to our e-newsletter. As you read through each chapter, be sure to check the Web site for any new or updated information. I think that the site will prove to be a great value you are receiving by purchasing this book. Our Target Readers This book is designed to be an excellent tool for all levels of Informix users, including: Application developers Database administrators Informix server administrators End users The information is designed and organized in such a way that it should be easily accessible by all of these groups. As you’ll soon see, the book is divided into six major functional sections, placing related information together. In addition, each chapter has numerous cross-references that help you know where to find more information. The book can help all types of users because it provides many levels of instructional information, detailed reference and review materials, and links for where to get more information. The remainder of this introduction explains how to use the book to its fullest capacity. What You Can Gain from This Book This book helps you understand current and future products and technologies related to Informix. We describe \"how Informix works\" and how to use Informix servers and their application development tools. We help you with database administration, server setup, and operating system interaction. We also discuss new technologies like Web/database applications and Informix Internet Foundation.2000 and how they fit into the future of Informix. As previously described, one of the main values of this book is its Web site. The site turns the book into an ongoing reference–it provides updated information on each chapter, errata (correction of errors in the book), and numerous Web site links that are grouped by functional category. The book provides references and working examples of the main functional areas of Informix. Our intent is to let you use the book in many different ways, each helping you find information for the Informix product lines. The extensive cross-referencing helps train you where to look for more complete answers. By consulting with many others in the Informix world, we believe that the organization of the book provides a long-desired \"one-stop shopping\" reference for Informix. This is accomplished by: Organizing the sections into major functional areas Creating a Web site that provides ongoing information about Informix and its products Selecting writers that are well known in the Informix world Providing examples that apply to major areas of Informix usage, spanning different products and servers Supplying excellent cross-references to finding more detailed information by using other reading materials and the World Wide Web Using the CD-ROM to efficiently allow searching and referencing information The design of this book follows these principles and should allow you to know exactly how to find the information you need, be it from this book or another reference. How to Use This Book, the CD, and the Web Site This book provides a unique way to get the information you need about Informix. From its beginnings, the book itself was structured to help you understand the core information about various aspects of Informix. But as the book progressed, so did the Web and other technologies. At that point, I decided to create an even better way to get the information to you. Here’s how it works: This book usually serves as your starting point. You can try to find the exact information that you need in the appropriate chapter. If you can’t, each chapter has references that direct you to more information elsewhere in the book, Informix manuals, the Web, or other books. If convenient, you can check the other books or manuals, or continue with the rest of this list. Check the book’s Web site for the specific chapter. You might find updated information about the material or Web site links to direct you to more information. In addition, you can use the site’s search feature to try to find an answer. After that, you can use the site’s \"Information about Informix\" links. Finally, the site offers an e-newsletter that will keep you updated on news about Informix and the book. Check the book’s CD-ROM for additional answers. You can use the well-organized information in the CD to find documentation or tools that you’ll need. Also, be sure to watch the Web site for CD-ROM upgrades and search capabilities for the CD. All in all, the book, its CD, and Web site should help you find the answers you need. The following sections provide detail about each of these items. How This Book Is Organized Let’s take a look at the organization of this book. The book is broken into six major functional sections. You will be able to easily determine where to look for answers. Within each of the six sections, chapters provide more detail. Here is a summary of the sections: I. Core Concepts of Informix This section describes the Informix Corporation, its products, and the future plans of Informix. We begin by giving a history of the Informix Corporation and how it evolved into what it is today. We describe the different types of Informix databases and tools and how they fit into your needs. Chapter 3 helps you get started; it teaches you how to use Informix’s sample stores database and its utilities. Chapter 4 provides an extremely detailed view of what’s behind the architecture of Informix, now and into the future. Chapter 5 describes the Informix version of SQL and how to use it. Finally, the last two chapters in this section show you how to access data in Informix databases and describe Informix’s data warehousing direction. II. Informix SQL In this section, we provide detail about how to use Informix’s version of SQL. We describe and show you how to create databases, tables, and indexes. We give detailed examples and tips about how to use the Informix SELECT, UPDATE, INSERT, and DELETE statements. Stored procedures and triggers are discussed, as well as other miscellaneous Informix commands. Finally, Chapter 16 explains some of the additions to Informix in version 7.30. All in all, this section gets you \"online\" with Informix and allows you to access data. III. Server Administration This section explains how to administer Informix database servers. The section is split into two sub-sections: Setting Up Informix and Ongoing Administration. We describe everything from simple INFORMIX-SE installations to detailed Informix Dynamic Server administration. We provide detail about how to set up and debug various servers on UNIX, NT, and Windows 2000, and describe how to work with the operating system. We help you set up your configuration parameters (the onconfig file, for example) and troubleshoot problems. We provide a comprehensive functional reference of the command-line utilities, such as onstat (complete syntax for this command is given in the appendix). Finally, we help you learn how to keep your servers up and running and how to back them up. As always, we tell you where to find more detailed information. IV. Performance Tuning The Performance Tuning section describes performance tuning both for application developers and Informix administrators. We explain how to use the tools that Informix provides, how to interpret the output, and how to make changes. For application developers, we offer a summary of fundamental design and tuning issues, and information about how to work with Informix tuning methodologies such as SET EXPLAIN and UPDATE STATISTICS. We give a detailed description of how to use the newer tuning tools, including SMI and the sysmaster database. For administrators, detailed sections explain how to work with a number of tools and methodologies and how to continue to monitor performance. V. Application Development This section explores the application development tools and methodologies available for Informix products. We explain how to make your databases work on a network by using Informix connectivity tools. We describe overall strategies for application development and how to plan for the future. Detailed sections are available about specific Informix tools like 4GL, Dynamic 4GL, Ace Reports, Perform Screens, and reporting tools. VI. Web Applications and Object Relational Databases This section focuses mostly on Web applications and how object relational database management systems (ORDBMSs) might fit into your future. Simply put, no one can deny that objects and the Web will enable database systems well into the 21st century. This section goes into detail about what these methodologies mean, how they are used, and how they might be used with Informix products. The first two chapters provide an overview of current Web technologies and how to use them in a database-enabled Web application. After that, we describe how to use Informix Internet Foundation.2000, its DataBlades, and other tools. Again, we help point you to the right resources so that you can remain on top of object technologies and how they fit into your future. VII. Appendices The appendices provides copies of many useful reference materials, Web site addresses, tools, and other information. The appendices alone will serve as an excellent desktop reference for just about any Informix user! We include Informix utilities (which are also on the CD-ROM) and describe how they work. We show you how to maximize the Informix resources like Informix Developer’s Network, user groups, newsgroups, and the Web. The appendices also provides a comprehensive glossary of Informix-related terms and a more complete reference on INFORMIX-SQL and command-line utilities. Don’t miss Appendix F, \"Quick Up-and-Running Guide,\" which provides a quick reference of how to install and configure Informix products from the box to being online. After that, a list of sample queries and command line utilities help you see how to implement various Informix commands. Finally, the extremely detailed Glossary explains a large number of Informix-related terms and concepts. As you can see, we have very carefully split the sections of this book so that information is easy to find. We fully intend to provide an excellent reference for your Informix needs and make it very easy to use, now and long into the future. Now, let’s find out about Informix and why we’re doing this in the first place. Structure of Each Chapter The chapters are formatted to make finding information easy. Here is a summary of the items in each chapter: Summary of the information in the chapter. At the beginning of each chapter is a brief overview followed by a list of the major topics that are included in the chapter. List of topics, split functionally into subcategories. Within each chapter are several small sections, each explaining a certain category of information. Within each of these sections are sub-sections, providing details. By looking at the table of contents, you should be able to quickly find what you need. Notes, tips, warnings, Web links, and other chapters, code listings, and diagrams. The chapters are rich with specific items of interest (notes, tips, warnings) and references to other chapters, books, and Web sites. In addition, many graphical figures and code samples are provided to help enhance your understanding. References to other chapters. At the end of each chapter is a section called \"For More Information.\" This points you to other chapters in the book that relate to the current chapter. Informix and Other References. Following the \"For More Information\" section, this tells you which Informix manuals and other books can further help you. I’m confident that you’ll find the structure of these chapters very easy to use. You may want to take a quick look through some of the chapters or the table of contents to better understand this structure. Contents of the Web Site The Web site is one of the core parts of this book’s solution. Because it is so important, I described it in the previous section, \"The Web Site: An Ongoing Reference.\" To summarize, the site will be constantly updated, providing additional information about each chapter, as well as current and useful Web site links. The idea is to use the book in conjunction with the site to provide a complete solution. The site can be found at www.informixhandbook.com. Contents of the CD The CD includes a Web browser-driven interface that allows you to easily locate information by using your Web browser. Simply insert the CD and open the index.html file in the root directory. The CD includes a plethora of utilities and SQL files, allowing you to copy commands and utilities that you can use. In addition, the CD includes the following: Informix Guide to SQL Syntax The Administrator’s Guide for Informix Dynamic Server (official Informix version for 7.3) A copy of Informix Dynamic Server for Linux and NT All of the book’s SQL statements, scripts, and programs (i.e., all that were included as Listings) A computer-based training (SmartForce) course entitled \"Managing the Instance\" Several whitepapers Easy-to-use links to the book’s Web siteif you are online when using the CD, you can use various links that send you directly to the proper portion of the Web site Hundreds of utilities for administering or programming for Informix products. Products are written in shell scripts, SQL, 4GL, and C. A trial copy of Server Studio from AGS (www.agsltd.com), a comprehensive GUI-based tool for Informix databases In addition, on the Web site we will offer enhanced search functionality and a possible upgrade for the CD. As you can see, the CD, Web site, and the book work together to give you the information you need about Informix. Considering the Future One of the goals of this book is to help you consider the future of technologyand Informixin your design and development of applications. We, the authors of this book, made a special effort to consider how database technology and application development will be evolving. And you should, too. What works now might not integrate or make use of upcoming technologies. This book and its Web site provide you with details about how technology is changing and how to take keep up with its evolution. Again, we provide many cross-references so that you’re sure that you have the latest information. We have dedicated an entire section to Web technologies and object-relational databases. Section VI, \"Web Applications and Object Relational Databases,\" describes object technology and how to use Web applications and Informix Internet Foundation.2000 as well as DataBlades. The Web is going to be a big part of the future of database and application development. Chapter 41, \"Web Application Overview,\" explains the concepts behind Web computing, and Chapter 42, \"Building Web/Database Applications,\" explains how to use Java and other tools to create an Informix-enabled Web application. Again, using the book along with its Web site should help you keep current about the best ways to create Informix applications. For More Information... This introduction provided an explanation of the goals and layout of this book. Please skim through the book so that you can really understand how and why we organized it the way we did. We’re hoping that you find this book extremely easy to use, providing detail, reference, and even some amusement. Don’t forget to use the Web site or the CD-ROM and its HTML-driven menu. Here are some other good places to start: To find many different tools and references, see this book’s CD. For complete and up-to-date information on the material in the chapters and current Informix information, see the book’s Web site at www.informixhandbook.com. For more history of Informix, see Chapter 1, \"Now and the Future,\" and Chapter 2, \"History of Informix: Live from Silicon Valley.\" For an explanation of Informix database servers and products, see Chapter 1, \"Now and the Future.\" To find out how to start using Informix now, see Chapter 3, \"Creating and Using the stores Database.\" For an explanation of Informix architecture, see Chapter 4, \"Understanding Informix Architecture.\" For a complete reference and examples of Informix SQL, see Section II, \"Using Informix SQL.\" For complete details about administration, see Section III, \"Server Administration.\" To find out how to tune your Informix servers and programs, see Section IV, \"Performance Tuning.\" To obtain a better understanding of how to develop applications in Informix, see Section V, \"Application Development.\" For many references about the Web and object relational technology, see Section VI, \"Web Applications and Object Relational Databases.\" For large amounts of reference material, see the book’s appendices. Don’t miss Appendix F, \"Quick Up-and-Running Guide,\" or the intensive Glossary.",
    "author": [
      {
        "family": "Flannery",
        "given": "Ron M."
      }
    ],
    "edition": "1st",
    "id": "10.5555/517956",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "Pearson Higher Education",
    "title": "The informix handbook with cdrom",
    "type": "book"
  },
  {
    "ISBN": "1576103498",
    "abstract": "From the Book: Introduction Introduction This book is about power, the growing power of databases, computers, and networks to slash costs and dramatically increase effectiveness of communications and management. Databases touch everyone’s lives in some way or another, and a clear understanding of what works and what doesn’t puts that power within reach. This book is aimed at everyone who must participate in a database project to ensure success: database designers, end users, database administrators, senior managers, front-line managers, as well as those who must wear all these hats at once. • For experienced database designers and administrators, this book contains complete coverage of Microsoft Access 2000 in easy-to-understand (and use) examples, with plenty of reusable code and screen shots. • For managers and end users, this book contains plain-English explanations of how databases are constructed, what the limitations are, and a broad, exciting view of the potential. • For those who must act as designer, manager, and user, this book takes you from the most basic fundamentals to the most advanced programming steps, without requiring a degree in computer science. In every sense of the word, this book is a practical, day-to-day guide for people involved in building database solutions. Not only does it guide you through the phases of successful database projects (large and small) and the pitfalls that have ruined some, it teaches you the language and terminology used on all sides as you go: project management, process reengineering, relational models, programming fundamentals, and so on. The emphasis throughout the book is on enhancing communications, because clear and timely communication is the primary attribute of a successful database solution. Communication takes work. Everyone must be working from the same playbook for a database application to be effective and achieve widespread use. Traditionally, databases have been designed by computer scientists far removed from the day-to-day activities of work. A team of systems analysts would show up one day, gather what information they could about a process, then spend a year or two in the ivory tower building the application. The application would be instituted, workers trained to fill out the forms, and the reports would print, all according to the now-dated but assuredly very accurate specifications. For some applications, this system worked quite well, but for others it failed miserably. Where failure occurred, the primary cause was rapid change: changes in processes, requirements, business conditions, even changes in computer literacy. Today, because change is constant and the pace of change continues to accelerate, only excellent communication among everyone involved can overcome the swirling confusion born of change. This book gives everyone the playbook that they need to achieve these implementation goals. It takes the best of all traditional methodologies for rebuilding an organization’s processes and for developing and constructing database solutions, explains them concisely, and blends them together into a powerful toolkit for building effective applications in a rapidly changing environment. The power of Microsoft Access 2000 combined with the proven methods outlined in this book increase the probability that your database application, no matter the size, will \"work\" from all perspectives. For the managing members of the team, the book helps you create a plan for effective and consistent implementation of your applications, whether destined for internal use throughout the enterprise or for public consumption. For those responsible for the creation of the implementation-the developers, power users, and users who will interact with the application on a regular basis-this book teaches you everything you need to know about making the application not only perform its tasks, but perform them well. No matter what environment you are developing for-from standalone databases at workstations to databases that will serve intranet and Internet users-this book teaches you how to address development issues in that environment and make sure your product not only works, but shines. Real-world examples, step-by-step explanations, and thousands of lines of program code all work together to ensure that you have all the tools you need to be successful. Contents Of This Book This book is divided into 8 parts, intended to guide you through the steps of database development with Access from beginning to end. Part I, \"Fundamentals Of Information,\" contains three chapters that consider the nature of information and how information relates to the design of databases. The three chapters in the section, Chapter 1, \"Foundations For Database Construction,\" Chapter 2, \"The Nature Of Information,\" and Chapter 3, \"Data Organization,\" guide you through the principles of information theory and the ways in which data is organized. Each chapter provides you with important information that you must understand to master effective techniques of database design. Part II, \"Database Fundamentals,\" takes the information theory that you learned about in the first three chapters and brings it to the level of database design theory and principles. Chapter 4, \"Relational Databases,\" introduces you to the principles of database design when working with relational databases like Access 2000. Chapter 5, \"Database Structures,\" looks at the overall theory of database design and reviews the principles of relational database design that you learned in Chapter 4. Chapter 6, \"Advanced Database Systems,\" considers the nature of advanced database architectures and the networks required to support them. By the time you finish Part II, you will have a solid knowledge base for database design-not only with Access, but with any relational database product. Part III, \"Modern Database Implementation,\" moves on to some of the specific types of database uses in business today. Chapter 7, \"Data Warehousing,\" covers the construction of data warehouses in depth. Chapter 8, \"Applications and Operating Systems,\" covers practical application and operating systems (OS) issues, namely, how to decide whether to buy or make apps and OSs, and how to find and use them if you do decide to buy. Chapter 9, \"Marketing,\" discusses the important considerations for you to keep in mind when preparing to distribute your Access products. From identifying your target market to measuring and adjusting your market strategy, effective marketing techniques can make a product successful or, if implemented poorly, can ensure it never sells a copy. Part IV, \"Microsoft Access 2000 Overview,\" contains four chapters that address the specific improvements and changes to Access 2000, and the specific purposes for which Microsoft designed the Access 2000 product. Chapter 10, \"Access 2000 Technologies,\" gives you a broad overview of some of the many component technologies that Access uses to simplify user access. Chapter 11, \"New Features And Trends In Access 2000,\" considers some of the directions in which Microsoft has moved the Access product, including a discussion of the new Jet 4 engine and new integration with Microsoft’s BackOffice products, specifically SQL Server. Chapter 12, \"Access Purchasing And Installation,\" discusses such important implementation issues as who needs Access installations and what level they need, what the different types of Microsoft Office suites are, and specific installation concerns to keep in mind when purchasing the new Access 2000 product. Chapter 13, \"Access 2000 Distribution And Training,\" addresses specific issues related to the deployment of the Access program in your enterprise. It also discusses built-in training support in the Access product and issues to consider when determining how and who to train. Part V, \"Microsoft Access 2000 Usage,\" contains three chapters, each of which considers a general category of the target market for the Access product and how to design databases for that market. Chapter 14, \"Access For Personal And Small Office/Home Office Use,\" addresses common uses of Access at home and in the small office setting. It discusses both common situations in which you might use Access databases and ways in which to create those databases. Chapter 15, \"Using Access In A Corporate Environment,\" addresses common techniques for Access deployment within companies. It also contains your first introduction to the new Access Data Projects (ADPs) and their use as a SQL Server database front-end. Chapter 16, \"Using Access For Scientific And Medical Purposes,\" considers common methods and implementations for Access in the scientific and medical communities. It also provides an introduction to the use of Access’s graphing capabilities and presents useful information in both types of deployment environments. Part VI, \"Database Application Design Reference,\" moves on to the creation of databases in Access 2000. The five chapters in this section provide you with a method that you can use to define and create databases to meet any need. Chapter 17, \"Problem Definition And Design Planning,\" discusses the specific steps you should take in planning the design of a database to solve a particular problem and walks you through an extended example of these crucial steps in the design process. Chapter 18, \"Planning And Design,\" moves on to the specific discussion of designing a database in accordance with the design planning that you performed in Chapter 17. Chapter 19, \"Database Construction,\" shows you how to take an actual design diagram and convert it into table and database definitions in Access. Chapter 20, \"Implementation-Beta Testing And Bug Checking,\" moves on to the testing and implementation phases of application design, including discussions of the testing process you should use and more. Chapter 21, \"Completing The Implementation,\" discusses post-release improvements you can make to the application, including optimization, compacting, and repair of the database, as well as using the Access-provided tools to analyze and improve performance of your application. Part VII, \"Microsoft Access 2000 GUI And VBA Programming Reference,\" covers the low-level, \"nuts and bolts\" of Access 2000 programming. The chapters take you from the initial creation of a database and its component tables through advanced programming with ActiveX Data Objects (ADO), Data Access Objects (DAO), and database management and security. Chapter 22, \"Installation, Setup, And Configuration,\" discusses the installation specifics of the Access product, including the options you have during setup. It also introduces you to some of the specifics of Access database design-both for the standalone and the client-server environment. Chapter 23, \"Developing Tables And Relationships,\" introduces you to the specifics of table creation and relationship definition, the core of database design. Chapter 24, \"Creating Queries,\" takes you into the heart of relational database work, by teaching you how to create the different types of queries that lie at the heart of SQL’s power. Chapter 25, \"Creating Forms And Reports,\" teaches you the knowledge you need to create user interfaces and design effective reports that output data in the most usable form. Chapter 26, \"Creating Macros And Modules,\" explains Access’s macro language and introduces you to modules, which will contain Visual Basic for Applications code-code which will, in turn, unlock significant additional power for your database applications. Chapter 27, \"Using Modules And Visual Basic For Applications,\" builds on the knowledge you gained in Chapter 26 to teach you what you need to know about writing VBA programs to \"power-up\" your Access applications. Chapter 28, \"Working With DAO And ADO,\" introduces you to the database objects that VBA lets you use to manipulate Access, SQL Server, Oracle, and other ODBC- and OLE DB-compliant databases. Chapter 29, \"Using Class Modules With Access,\" describes some basics of object-oriented programming and how you can use VBA class modules to implement custom objects within your Access 2000 applications. Chapter 30, \"Advanced Database Design Techniques,\" shows you how to take advantage of VBA and Access’s built-in features to make your applications more professional. It also focuses in-depth on the administration of security within your Access database. Part VIII, \"Microsoft Access 2000 And Client-Server Development,\" contains five chapters that teach you about client-server programming with Access 2000 and different server-based database products, as well as how to create World Wide Web front-ends for Access or server databases. Chapter 31, \"Client-Server Programming With Access 2000,\" introduces you to SQL Server and working with back-end products from Access. It also covers, in detail, important conceptual information about client-server design that is applicable to any back-end. Chapter 31 also introduces you to the Microsoft SQL Developer Engine (MSDE), a local implementation of SQL Server that you can use to design SQL Server databases on your development machine. Chapter 32, \"Using Oracle And Access For Client-Server,\" teaches you the fundamental concepts of Oracle database design and the differences in development between Access front-ends for SQL Server and Oracle. Chapter 33, \"Advanced Client-Server Techniques,\" takes the knowledge from Chapters 31 and 32 and sends it to the next level with important information about topics such as triggers and stored procedures, transaction processing, Access Data Projects (ADPs), and more. Chapter 34, \"Web Front-End Development,\" moves to the largest client-server environment in the world-the Internet. It covers historically proven and commonly used techniques for exposing databases through HTML pages. Chapter 35, \"Using Data Access Pages For Web Front Ends,\" moves on to Microsoft’s proprietary Access front-end technology, Data Access Pages (DAPs), which let you develop highly customized, highly responsive front ends for your Access databases, all from within the Access Interactive Development Environment (IDE). In addition to a complete index, the book also contains an appendix of additional resources. From the first 9 chapters that step you through the fundamentals of database design and relate them to good programming practice and business process reengineering, to the next 26 chapters that cover every detail about how Access 2000 works (including how it interacts with the Web and mainframe databases), the purpose of this book is to build a common ground on which all people, from the novice user to the most sophisticated IT developer, can work together. Remember, people in organizations today recognize how important it is to make the powerful software tools on their desktops useful, and they need a tool like this book to make it happen.",
    "author": [
      {
        "family": "Klander",
        "given": "Lars"
      },
      {
        "family": "Mercer",
        "given": "Dave"
      }
    ],
    "id": "10.5555/553611",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "publisher": "Coriolis Group Books",
    "publisher-place": "USA",
    "title": "Access 2000 developer’s black book with cdrom",
    "type": "book"
  },
  {
    "ISBN": "0201758210",
    "abstract": "From the Book: Purpose of this Book The convenor of the OOSIG (object-oriented Special Interest Group) of the Australian Computer Society is occasionally referred to as Chairperson. For past two years, this honorary and honourable title has been conferred upon me and, as the title suggests, it provides me with — amongst other things — the unenviable job of moving and organising chairs before the monthly meeting starts and ensuring they are stacked back against the wall after the meeting in the societys office is over. Getting the flipcharts and whiteboard ready, booking the room, sending the invitations, organising coffee and keeping the data projector light bulb from blowing up are some things keep the adrenaline level of the chairperson always on high. However, I had no such challenges to face when Canada-based Bran Selic, kindly addressed my SIG. Many members turned up to listen to one of the original contributors to the Unified Modelling Languages meta-model, particularly to the behind-the-scene stories. One of the interesting features of Brans talk was the candid highlighting of the strengths and weaknesses of the UML. Couple of reasons for UMLs popularity, as emerged during the talk were: UML is a standard and therefore accepted within the larger IT community, and UML came on the IT scene at the right time. The UML fills the void that existed in software development — a modelling mechanism that enables capture and expression of requirements, documentation of design, facilitates architectural discussion and supports software implementation. The modelling capabilities of the UML, supported by CASE tools, are widely usedin numerous practical software projects. Further, professional training courses on business analysis, architecture, design and testing are routinely based on the UML standard. The UML is also popular in the academic world as many university courses use the standard notations and diagrams of the UML to teach the students principles of software engineering. Finally, through relatively less-technical and more business-focused works, object technology and the UML have shown to be capable of being used in non-software related work, such as modelling business processes (BPR), business workflows, and even software workflows. Despite its popularity, however, the UML literature still needs discussion on and application of quality with UML. While we have some excellent literature on the processes of software development it seems to fall short of separate and detailed discussions on quality. On the other hand, works like Binders focus on the technical aspects of testing, using the UML notations, do not provide the process-aspect of improving the quality of software development. Indeed, none of this literature deserves any criticism for the lack of quality discussion — because these literary works do not purport to be discussing quality. The focus of these respectable and popular works is either development or testing. This book is written with an aim of directly addressing the paucity of literature in the area of process quality assurance for UML-based projects. Good Quality is all about satisfying the needs of the user. However, good is a highly subjective term. The reference-point against which quality is judged depends on time, place, and situation — all of which can change! Hence, the essential ingredients in producing good quality are: A product that satisfies the changing needs of the user A process that enables creation, verification and validation of such a product A common mechanism to establish communication Continuous improvement of the process of producing product When applied to software development, these quality requirements translate into producing a software product that would evolve, scale and change, according to the needs of its users — primarily the business. Not only do we need a process for developing such a software product, we also need significant checking and crosschecking of the models and processes that have built the software product. There is a need to ensure the syntactical correctness, semantic consistency and aesthetic symmetry in the models that will be used to produce good quality software. There is also a need to create, follow and check all necessary process steps in order to achieve maturity of processes that will result in good quality software products. Furthermore, these process steps must be executed iteratively, incrementally and sufficiently. Process steps should also be malleable enough to suit various development environments, and various types and sizes of projects. The specific and significant areas of quality related work required in a process incorporating the UML are addressed in this book. The quality techniques discussed in this book include how to organize the overall quality function, the process steps to be followed in creation of UML diagrams, the steps in verification and validation of these diagrams, when to conduct such verificat how the interpret the results of quality activities, who should create and validate the UML diagrams, and how to create a quality control (testing) strategy. Because of the process focus in this book, the techniques of creation of UML diagrams is assumed to be known to the readers. Summary of the Book This book is divided into 6 chapters as summarized below. Chapter 1: The Quality Game In this background chapter on quality assurance we discuss the elusive nature of quality in the context of software. Modelling, particularly with the UML, is shown as means to improve communication and quality and is conducted in the three distinct yet related modelling spaces of Problem, Solution and Background. Process is discussed in the context of its three dimensions of technology (what), methodology (how) and sociology (who). This is followed by discussion on the various checks (syntax, semantics and aesthetics) needed to validate and verify UML-based models and the checks of necessity, sufficiency and malleability needed for a good quality process. Organization of the quality function, and its application to various types of projects (development, integration, package implementation, outsourcing, data warehousing, and educational) as well as various sizes (small, medium, large) of projects are also discussed here. Chapter 2: Quality Environment: Managing the Quality function Process aspect of quality encompasses the management functions of creating and managing a quality environment. This is because software quality is not just verifying and validating what has been produced but also a sustained effort at following the discipline of producing models and software. This discipline encompasses the process or the steps involved in producing good models and good software. This part of this book comprehensively considers organization and execution of the quality function with detailed emphasis on the process of developing UML based software. In other words we discuss how the quality function is organized and carried out in UML-based projects. The people issues (who) is also given due relevance in this part of the book. Chapter 3: Quality Process Architecture This chapter discusses what constitutes such a process, and how it will be helpful in enhancing quality in a UML-based project. This chapter does not propose a new process, but discusses a most generic Process including the Technological, Methodological and Sociological dimensions — what constitutes a process, and what are its major dimensions of a process is described here. The technological dimension of a process deal with the what, the methodological dimension with the how and the sociological dimension with the who, of an overall process. These dimensions are described with common workday examples. Furthermore, the generic process also describes the most commonly used activities and tasks that should be there in any process. These activities and tasks, and the related roles and deliverables, are described with the aim of improving the discipline in a process, resulting in enhanced quality of UML-based deliverables and eventually the software product. Chapter 4: Enacting the Quality Software Process In this chapter we discuss the enactment of an example process including practical issues of configuring an iterative, incremental and parallel project plan, based on the process-components discussed in the previous chapter, are discussed here. We also discuss practical issues of tracking the progress of a project as well as modifying the project plan based on that tracking. An iterative and incremental project plan will facilitate better absorption of changes than a sequential project plan. Creation and management of such a changing plan, derived from the malleability aspect of the process, are also discussed here. This chapter discusses what happens when the rubber hits the road in terms of application of a process. Chapter 5: Estimates and Metrics for UML-based Projects This chapter discusses the important issues of measurements and estimates in UML-based software projects. Starting with an argument for the need to make good estimates, and how good metrics help in making good estimates, this chapter delves into the importance of these measures and estimates in improving the quality of models and processes in the project. Technical measures related to sizes and complexities of the UML artefacts and diagrams is also discussed. Estimates for the example implementation project using the UML are shown with a view to demonstrate the application and significance of metrics in a practical project. Chapter 6: Testing the product This chapter will discuss in detail the quality control and testing aspect of a quality lifecycle. While we discussed process quality in previous chapters, quality control, or testing, is a major process-component dedicated to verifying and validating the results of our efforts thus far in creating models and following a process. Good quality control is inherently negative as it is aimed at breaking everything in a system — its logic, its execution, its performance. Thus, although Quality control is an integral part of quality assurance, but is not synonymous with it. This separation is given its due importance in this separate part of this book. CD &amp; Potential Web Support The CD contains details of the chapters, diagrams, and a set of templates that can be customised for use in projects. Suggested metrics for improving quality (e.g. size of use cases, effort in creating classes) are also incorporated in the CD. Evaluation copies of relevant process tools that deal with quality process have also been provided, with permissions. Literary Audience There are a large number of books written on UML and similarly on processes. Their scope encompasses both academic research and practical applications. This book attempts to synergies the application of quality processes in UML-based projects. With the process focus, the reader is expected to be familiar with UML and its modelling techniques as the book does not purport to discuss the modelling techniques of the UML. However, a person responsible for quality assurance will find this work self-sufficient and may even be encouraged after reading this material to extend their understanding further in to UML. Semantics This author firmly believes in gender-neuter language. Person is therefore used wherever possible. However, in order to maintain simplicity of reading he has been used as freely, and has been balanced by equal, if not more, use of she. Terms like programmer and quality manager, unless otherwise mentioned, represent roles performed by actors. These terms dont tie down real people like you and me who, in a short span of time, can jump from the role of a programmer to a quality manager to a director and back. It is also recognised that people may be playing more than one role at a time. For example, a business analyst may also be a part-time academic or a researcher. We throughout the text primarily refers to the reader and the author — you and me. Occasionally, we refers to the general IT community of which the author is a member. We also refers to the teams in which the author has worked. Therefore, although this is a single author book, you may encounter we as a reference by the author to himself, as well as to the IT community. Real conversations, as you and I are having through this work, cannot be statically typed. Mapping to a Workshop The practical aspects of UML and Quality, displayed in this book, have been popular in seminars and conferences. Amongst many presentation, particular noteworthy are its acceptance as a tutorial at the UML2001 conference in Toronto, Canada and the two-day seminar series in Mumbai, Bangalore and Delhi, in India. Here is a generic outline of the two-day workshop based on this book. For the education and academic community, each chapter in this book can correspond to a 3-hour lecture topic, with earlier part of the semester used in simply creating the UML-based models based on the case study. Acknowledgements Encouragement and support can take various forms —a word of encouragement here, hint of a smile there! And then there are those detailed discussions and arguments with honest reviewers of the manuscript on what should be included and how it should be presented. This is interspersed with the arduous task of typing sections of the manuscript, drawing the figures and the rather trying job of proofreading someone elses writing. All this has come to me through many wonderful people whom I acknowledge here gratefully: Anurag Agarwal Rajeev Arora Craig Bates Paul Becker Christopher Biltoft Bhargav Bhatt Graham Churchley Kamlesh Chaudhary Sandra Cormack Joanne Curry Sanjeev Dandekar Edward DSouza Con DiMeglio Julian Edwards Nandu Gangal Athula Ginige David Glanville Mark Glikson Nitin Gupta Brian Henderson-Sellers Murray Heke Ivar Jacobson Sudhir Joshi Ashish Kumar Vijay Khandelwal Akshay Kriplani Yi-chen Lan Chinar &amp; Girish Mamdapur Javed Matin Sid Mishra Rahul Mohod Navyug Mohnot Narayana Munagala Karin Ovari Les Parcell Chris Payne Andrew Powell Abhay Pradhan Amit Pradhan Anand Pradhan Prabhat Pradhan Rajesh Pradhan Tim Redrup Tracey Reeve Prashant Risbud James Ross Magdy Serour Bran Selic Ashish Shah Paresh Shah Prince &amp; Nithya Soundararajan Pinku Talati Amit Tiwary Murat Tanik Asha Unhelkar Sunil Vadnerkar Suresh Velgapudi John Warner Houman Younessi Paul Becker, my editor at Addison-Wesley, has provided invaluable support in this work and deserves special recognition. Bearing with my delayed submissions, passing encouraging comments when the progress was slow and accommodating my changes up to the last minute are some of the traits of this considerate editor that are gratefully acknowledged. Finally, my family makes all this possible by just being around me even, and especially, when I am mentally lost. I am grateful to my wife Asha, my daughter Sonki Priyadarshini whose view on quality took a jagged turn as she stepped into her teens, my son Keshav Raja who can appreciate quality in cars, bikes and planes — which is the ability of these tools of the kindergarten trade to withstand punishment meted out by rather tough 6 year olds. Finally, this work acknowledges all trademarks of respective organisations, whose names andor tools have been used in this book. Specifically, I acknowledge the trademarks of Rational (for ROSETM), TogetherSoft (for TogetherControlCenterTM), Object-oriented Pty Ltd (for ProcessMentorTM) and eTrackTM. Critiques It reflects a healthy state of affairs within the IT world, and especially the UML and process community, if work of this nature receives its due share of criticism. All criticisms have an underlying rationale and that they should all be accepted in a positive and constructive vein. All comments on this work, both positive and negative will be accepted positively. Thus, to all my prospective critics, whose criticisms will not only enrich my own knowledge and understanding of the quality topics discussed in this book, but which will also add to the general wealth of knowledge available to the IT community, I wish to say a big thank you in advance. Bhuvan UnhelkarSydney, July 2001",
    "author": [
      {
        "family": "Unhelkar",
        "given": "Bhuvan"
      }
    ],
    "id": "10.5555/579266",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Process quality assurance for uml-based projects",
    "type": "book"
  },
  {
    "ISBN": "1576102505",
    "abstract": "From the Book: As a programmer or budding developer of Oracle database applications, you’re starting at the right place and with the right product by reading this book. I’ll show you how you can become proficient in the use, design, and tuning of any Oracle database. This book is written to take anybody who has a basic grounding in the use of a PC and associated software through the maze of Oracle8. I say Oracle8, not Personal Oracle8, because while this book is based on Personal Oracle8, all of the features are exactly the same in every Oracle8 database, whether it’s running on Unix, VMS, Windows NT, or Windows 95. The main difference is that on Windows 95 and Windows NT, the product is more graphically oriented-for example, it uses wizards to create tables. For this reason, when any procedures in this book are shown using graphical tools, I’ll also describe how to do the procedure from the command line (which is sometimes the only way of doing things using such operating systems as Unix and VMS). By reading and understanding this book, you should accomplish four goals: • Design an efficient database from the ground up, using Oracle’s object technology • Write simple and efficient SQL and PL/SQL code to manipulate the data within a database • Gain a working knowledge of the Oracle8 database and all its object-oriented features • Receive a large salary increase Over the past eight years as a database administrator (DBA), I have looked for books associated with Oracle and have noticed that good books aimed at the intermediate level-those you can pick up and quicklybecome productive with-are few and far between. For this reason, I decided to write my own book, based on my own experience. Starting my programming experience with version 5 of Oracle, I came to realize that you have to learn by trying first, then reading later. Because most projects in the workplace are on fairly tight schedules, you need to be able to pick up a piece of software and become as productive as possible in as short a time as possible. This book will be the guide to Oracle8 that I wish had been available when I was learning. At the time of this writing, no other book is available commercially, outside of the Oracle manuals, that deals with Personal Oracle8 and associated tools from an intermediate perspective. The purpose of this book is to cover the development of applications using Personal Oracle8 in conjunction with the documentation on the Personal Oracle8 CD-ROM. What is Oracle Oracle is an extremely complex and high-powered database; in fact, it is the most widely used database in the world. For these and many other reasons, it is generally recognized by computer programmers worldwide as the best. The Oracle database is one of the most technically advanced pieces of software available. One of Oracle’s main selling points is that it and its applications are portable across any operating system. This means that an application developed using Personal Oracle8 could quite easily be scaled up and installed on a high-end Unix server with thousands of users accessing the data. One important point to make here is that the Oracle database will run on nearly any commercial operating system, using the same human interface, known as SQL*Plus or PL/SQL. First, let me take you through the progression of Oracle releases so you can visualize what the Oracle8 database is. Versions 6 and 7 of the Oracle database are relational, meaning that the data stored is referenced by unique identifiers and grouped by relationships. In technical speak, it uses primary and foreign keys (constraints) to enforce referential integrity. Version 8 is an object-relational database. This means that it still uses the relational theory, but has added extensions of object-oriented theory. In this book, these subjects will be dealt with in more detail, and you will use some of the object theory (even though you might not realize it). The extensions of object-oriented theory add further capability to the Oracle database, in some cases allowing the programmer to apply it more easily to real-life business applications. Intended Audience This book is aimed at the programmer or the home-computer hobbyist who wishes to find out more about Oracle. I have designed the book to be used in two different ways: • You can skim through chapters and just try the demos that appear throughout the book. This will give you a good understanding of how to use the product. You can later return to the related chapters to discover the theory behind the practice. • You can follow the chapters in order and gradually build up your expertise and overall knowledge, until you have a full working knowledge of how to build applications on Personal Oracle8. In writing this book, I have assumed that the reader has some knowledge of Windows 95 and has used a database (e.g., MS Access, FoxPro, or dBase). Other people who would benefit from reading this book are: • Oracle developers who wish to know more about developing/prototyping applications on Personal Oracle • College students who wish to get a good in-depth knowledge of relational databases • Other information technology professionals who wish to keep their skills up to date by using Personal Oracle8 Personal Oracle8 Personal Oracle8, a scaled-down version of Oracle’s popular database, is aimed primarily at the desktop market (rather than Oracle’s primary market, the high-end Unix or Windows NT servers). The Personal Oracle versions came about because Oracle wanted to give its customers a trial version of the software, which they could easily install and use. The primary difference between Oracle8 and Personal Oracle8 is that on the Personal version, only single-user access is available as a server-hence, the name Personal. Therefore, the software is ideally suited for use as a single-user prototyping tool. Again, because of Oracle’s portability, a Personal Oracle database can be easily exported and imported into a large multiuser Oracle platform. This gives users an ideal development platform, because all features available on a high-end server are available to the user on the desktop, including the ability to enable a database for the Web. Personal Oracle8 is designed to be used in conjunction with Oracle’s view of the future in information technology-the network computer (NC). Oracle8 (which according to its subtitle is \"The Database for Network Computing\") has been specifically designed with the NC architecture in mind. Some of the database’s key features are: • The ability to support any number of users (in the server versions) • The ability to support any amount of data • Faster application development • Increase in cost effectiveness In reality, what do you get on the Personal Oracle8 installation CD-ROM You get one of the most technically advanced pieces of software available today, as well as a ready-made development environment for any database application-all in a low-priced, cost-effective database package for Windows 95. The Personal Oracle8 database is way ahead of its competitors in the desktop market. This book will show you how easy it is to use and implement this software, and, more importantly, it will help you understand what is going on in the database and why. Oracle’s product suite Oracle Corporation produces a lot of software aimed at nearly every type of machine and operating system. A piece of software, which usually has a generic name such as Oracle Server, is available for virtually any type of operating system. The aim of this section is to give you an idea of where the Personal Oracle8 software sits in relation to other Oracle products. A list of Oracle’s main product areas follows. Oracle8 Universal Server The Oracle8 Universal Server is, as the name implies, a server that will encompass all. The server is the core database, and a number of add-ons provide even more functionality. Some of these add-ons are listed and described here: • WebServer Option-Allows access to your Oracle database from the Web. This will give anyone with a Web browser the ability to access your Web pages. Okay, you say, what’s so new about that This option allows you to tailor your Web pages to react differently to each user accessing them. For example, imagine having a Web page that realizes who you are and, accordingly, lets you access your information from the Internet. This is done by storing your information within the database; then, when you access the Web page, the database knows who you are and can show you relevant information. • Spatial Data Option-Widely used in very large databases, such as data warehouses. This option changes the way the data is stored, allowing for quicker access to data by using a different indexing strategy. • ConText-Basically, a text search engine embedded within the database. This allows you to search unstructured text within the database, because most information is of unstructured text format (e.g., newspaper articles). • OLAP-Stands for online analytical processing of data. This option allows you to store the data within the database in different dimensions. A dimension is the way the data is categorized. For a car dealership, for example, a dimension may be the customer name, the type of car purchased, or the amount of money spent. The OLAP option allows you to store your data in either a multidimensional or relational way. • Parallel Server-Allows you to have a single database that is accessed by multiple nodes. The database is stored on a shared disk array available to all nodes. This gives you more power, because a multiple-node database is more fault tolerant. If you have one machine and it fails, then you do not have access to the database. With Parallel Server, you have an instance of the database on each node, so if one goes down the other nodes will carry on. This is extremely useful if the database is mission critical. • Video Option-Allows you to store video and sound within the database. This video and sound can then be played back, in realtime, to anybody on the network. This is the technology behind \"video on demand.\" This will allow multiple users to view the same piece of video whenever they want. Personal Oracle8 And Personal Oracle Lite Personal Oracle and Oracle Lite are scaled-down versions of their big brother, Oracle8 Universal Server. They provide access to the Oracle database on the desktop. Oracle Lite is a \"lightweight relational database that runs in less than 1MB of RAM,\" according to Oracle. It is designed for use as a mobile application-i.e., to run on portable computers. Oracle Lite supports bidirectional replication with Oracle Universal Server. SQL*Plus All databases accept commands from the user in a common language: Structured Query Language (SQL). Oracle provides a tool, SQL*Plus, which is a standard SQL interpreter; the \"Plus\" is Oracle’s added functionality. SQL*Plus is Oracle’s command-line interface to the database. By using SQL*Plus, you can interrogate the database and format the output. SQL*Plus by itself is useful, but when you add the procedural capabilities of PL/SQL, you have a tool that can easily give you access to all of the features of Oracle8. SQL*Plus and PL/SQL are used in the creation of Oracle databases. The Personal Oracle8 database uses wizards to make tasks easier for you by converting your inputs into SQL commands, then executing them against the database. The procedural option allows you to use SQL*Plus type structures within procedures, giving you the flexibility needed to write simple or complex functions or packages. In this book, you’ll see exactly how SQL*Plus and PL/SQL are used to create such procedures and functions. Oracle8 Enterprise Manager The Oracle8 Enterprise Manager (OEM) is the tool for managing the whole Oracle environment. The Enterprise Manager includes tools to monitor and interact with the database, job scheduling, and automated backup management facilities. This tool is primarily for systems administration use. Oracle8 Enterprise Manager supports new features of Oracle8-e.g., object partitioning, server backups, and security management. OEM also handles the recovery of a corrupt database by using Recovery Manager. This speeds up the recovery of databases by the database administrator. Database administration tools are available through the Enterprise Manager. Designer/2000 Designer/2000 is a business-process modeling tool. It gives the user the ability to design complex business objects and rules in an easy-to-understand way. The rules can then be implemented on the server automatically. This data modeling tool allows the designer to model an application independently of the implementation, thus giving the power to implement on multiple platforms from a single model. Developer/2000 The Developer/2000 package has three main components: Reports, Forms, and Graphics. These components combine to create an easy-to-use application development package. The easy-to-use Reports tool enables the user to create detailed and complex reports from any Oracle database. You can use Oracle Reports against a Personal Oracle8 database to produce business standard reports quickly and easily. The reports can include embedded graphics and can easily be Web enabled. Forms is an extremely powerful tool for creating front-end data-input screens. The Forms tool allows the user to create applications very quickly. When this incorporates reports, you can quite easily create and produce a professional application in a relatively short time. The Graphics tool gives picture representations of data within a database. For example, creating a pie chart from data retrieved from the database is quite easy using Oracle Graphics. If you incorporate this with either Oracle Reports or Oracle Forms, you can build up graphical reports and forms from the database with very little effort. Object Database Designer Object Database Designer is aimed at anybody who designs and builds Oracle databases and is specifically helpful when creating object-relational databases, because it includes the ability to use user-defined types within the database model. Once the database model is designed, it can then be automatically implemented, because the Object Database Designer will create the required SQL statements and execute them for you. The advantage of this is that the design is viewed graphically and a change of design can quickly be implemented on the database. The designer is tightly integrated with C++, the most common object-oriented programming language. The next step This Introduction gives you an idea of Oracle’s history and product line. Now that you know where Personal Oracle is placed in the hierarchy of Oracle software, why not install it Chapter 1 covers the quick installation of Personal Oracle8.",
    "author": [
      {
        "family": "Fieldhouse",
        "given": "Richard"
      }
    ],
    "edition": "10th",
    "id": "10.5555/522237",
    "issued": {
      "date-parts": [
        [
          1998
        ]
      ]
    },
    "publisher": "Coriolis Group Books",
    "publisher-place": "USA",
    "title": "Personal Oracle8 explorer with cdrom",
    "type": "book"
  },
  {
    "ISBN": "0130337676",
    "author": [
      {
        "family": "Mullin",
        "given": "Eileen"
      },
      {
        "family": "Rubin",
        "given": "Jared T."
      }
    ],
    "id": "10.5555/558527",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Free-commerce: The ultimate guide to e-business on a budget",
    "title-short": "Free-commerce",
    "type": "book"
  },
  {
    "DOI": "10.1145/76619.76644",
    "ISBN": "0897912853",
    "URL": "https://doi.org/10.1145/76619.76644",
    "abstract": "Advice is cheap, and we all know that you get what you pay for. There are many books, courses, and seminars on how to start a business. They have been written or are presented by professionals usually with far greater experience than I. While my general management background has been invaluable, the thing that best qualifies me to address this subject is the fact that we at Strictly Business Computer Systems have recently established an Ada programming shop.I’ll share with you our experiences, from inception to the present. I must preface my remarks with the comment that they represent only our single effort in this area. I was fortunate in that my primary associates had successfully established and were operating a profitable business in the computer field, and it was their proven philosophy of adding value that became the keynote of our Ada effort.Additionally, we had the good fortune to make some valuable acquaintances early on in the process — relationships which enabled us to avoid some potentially costly pitfalls. Perhaps we can do the same for some of you.Now, to the subject at hand.What would seem to be the obvious first step in establishing any business is worth stating and that is the conscious act of making a commitment to the project. In our experience, the commitment was initially made about three years ago — two full years before the project was actually initiated. The delay occurred because the computer system integration business in which Strictly Business was totally immersed was growing at a pace that precluded devoting the time required to explore the Ada market.Then, a file less than a year ago, I joined Strictly Business with the sole responsibility of researching the Ada shop possibilities, and then managing the shop if the research was positive — which it obviously was. The fact that Strictly Business was willing to add me to the staff, as pure overhead from the business standpoint, clearly demonstrates that a true commitment existed. That commitment is really three-fold because undertaking such a project requires a dedication of, and money. Beyond that, you must assume the posture that characterizes the entrepreneur, and that is a total immersion in the business. You must identify with it and make it the focus of all that you do.If you and your organization are unwilling to pledge a full-fledged effort, your chances of success substantially diminish.Secondly, since the first phase of this project should be a marketing study, you must select an underlying theme that will provide a framework and give specific direction to your research. From the outset, we were convinced that within the Ada market a definite need existed for additional systems design and coding capacity. The corollary is that this appeared to provide a significant business opportunity. Our research was active — not passive or neutral. We saw an opportunity, and our purpose was to objectively and concretely confirm our perceptions.At each step in the process we were looking at what value was being added by the person, business or agency that we were exploring. Strictly Business was founded and has flourished on two basic concepts — namely, adding value through our involvement in each transaction and providing quality products and service to our clients. We scrupulously avoid being hardware and software “brokers” collecting fees for merely placing products with customers. We consider ourselves as partners with our clients and work to enhance their businesses with the products and services we provide.Having made the commitment and articulated your role and objectives, you must now begin the real work. This part of my message may be preaching to the choir. The fact that you are involved in the Ada community indicates that you have or are beginning to acquire a knowledge of the Ada marketplace. That’s essential.Gather as much information as possible about every aspect of Ada. If you know the language, great. If not, that should not deter you from learning as much as you can exclusive of Ada per se. No one in our organization knew Ada before we began hiring our staff, yet several of us became knowledgeable and conversant enough to find our way around Ada circles — and in the Ada community, that’s essential.Regardless of how much you learn in your explorations, the input of people active in Ada is indispensable. One of the most gratifying things our research revealed was the generosity and willingness of Ada experts to share their knowledge. We knocked on a lot of doors and did not find one that was not opened wide for us.Let me share with you some of the avenues we explored in trying to determine whet her or not a real Ada opportunity existed. We first had the advantage of coming from West Virginia whose senior U.S. Senator is Robert C. Byrd who has seen the potential of Ada and has for some years been one of its strongest advocates. With the assistance of two of his staff members, we were directed to the Software Valley Corporation which has been very much involved in bringing the advantages of Ada and Ada-related ventures to our Mountain State.Bob Verhotz, the Executive Director of Software Valley Corporation, in addition to other helpful suggestions, recommended that we contact Mr. Ralph Crafts. Bob had worked with Ralph on a number of occasions and spoke highly of his credentials and performance. We have not been disappointed.Ralph knows his way around the Ada community as well as anyone, and better than most. Almost a year ago, we employed Ralph as our consultant to define the state of the Ada market and give initial direction to our study. During intensive meetings with him, we received a great deal of background information and recommendations of additional areas into which we should extend our Ada network.These three initial contacts — Ralph, Software Valley, and Senator Byrd — confirmed that quality-conscious and professional systems developers could definitely find a place in the Ada market.At this point I think you can begin to see two things. The more obvious is the snowball effect of Ada contacts. Your first contact leads to two others which each lead to two or three more, and so on. The second thing is that we were strongly encouraged by each of these contacts, and our perceptions that excellent opportunities existed in Ada were reinforced. If anything, the potential began to look even greater than we had at first anticipated.Our tentacles, at that point, began to extend into additional areas of the Ada community. We have come to share Ralph’s belief that the more people you know in this still relatively small group, the better off you are.We traveled to Washington to visit again with Senator Byrd’s office. While there, with an introduction from the senator’s staff, we also met with a number of people at the Ada Joint Programming Office, including the then-Air Force Deputy Director Major Al Kopp. More support and encouragement. On the same trip we cultivated an acquaintance at the Ada Information Clearinghouse. More support, encouragement, and a wealth of published information. We also briefly visited the STARS office and met with someone who was encouraging and informative about that extensive Ada project. Each of these organizations and individuals had a specific mission designed to enhance and increase the value of the Ada contribution.At that point we had begun to look at equipment and it was here that we found one of our more valuable allies and associates. From our initial contact with the personnel at RATIONAL we found them to be most helpful and open. Our sales representative made it possible for us to meet with two large firms handling major project work in Ada for the Defense Department.I don’t need to tell you how valuable it can be to speak with someone who is engaged in the type of work you are contemplating and who has no ax to grind or hidden agendas as far as discussing things with you. Other vendors may have been equally helpful, but I doubt that any could have been more so. We met people doing actual project work in Ada for the government, extending our network and also making some contacts we would later pursue as we sought to put together our Ada staff.In March of this year, we attended the SlGAda conference in Phoenix where we researched a number of vendors, but more importantly, met others in the Ada community — on the commercial as well as the governmental side. We, admittedly, understood very little of the technical content of the meeting, but our purpose in attending was not technical in nature. We were networking, and our network was rapidly expanding.This might be a good point at which to remind you of the three-fold commitment required in this undertaking — time, energy, and money. By March our exploratory had gotten into its fifth month and had occupied practically all of my time and a substantial portion of the time of two of my colleagues at Strictly Business. Our travels had included a couple of trips to Washington and the trip to Phoenix as well as visits to Morgantown, WV (where the Software Valley Corporation is located) and Pittsburgh where we met with an active Ada development firm and some folks at the Software Engineering Institute of Carnegie-Mellon University. For a small firm such as ours, the budget for this venture was becoming substantial, but we were making valuable progress toward our objective.Speaking of budgets, probably the largest single start-up expenditure will be the development system you select. Spend sufficient time in making this decision. In equipment, you have a myriad of choices. With the recent validation of a large number of compilers, Ada development can be done, in one form or another, on anything from PC’s to the much more sophisticated full-blown systems requiring major financial expenditures — and cost, at least in our case, was a significant consideration. But cost was only one factor.We also were concerned with other areas. Our initial plans called for a system to support ten (10) developers designing systems and/or writing code. Most hardware suppliers could accommodate that in one way or another. With our lack of experience in Ada, we were also looking for ease of familiarization and operation. And we were very much concerned with the level of support a supplier could provide. Who seemed most qualified and willing to “hold our hand,” as it were, until we gained some experience?The last major consideration was credibility. We knew that as a start-up operation gaining entree and establishing our credentials with potential contractors was critical. Our development system could say a lot about our commitment and dedication. Technical capabilities being a given, we were willing to pay some premium to project the most professional image. Bottom Line: find the system that will best enable us to efficiently and effectively develop software — to give our future clients value for their programming expenditures.We investigated three major suppliers — DEC and DG, both of whom seemed quite capable; and RATIONAL, whose development environment was written in and expressly for Ada.Weighing all the factors — system capabilities, support, ease of integration and use, reputation, cost, efficiency, etc. — we came down on the side of RATIONAL, and later decided that we would supplement them with SUN Microsystems work stations.We’re happy with our decision and believe, as I said at the outset about the cost of advice, that you get what you pay for. At this time, we are confident that our system configuration will satisfy our objectives and meet our expectations. Something similar mayor may not be right for you. Your situation and needs, not our experience, should dictate your direction on equipment selection. We can only recommend that you thoroughly explore the alternatives.So where were we? We had done a lot of reading and travelling; met a lot of people with whom we’d like to be professionally associated: gotten a tremendous amount of encouragement that had been tempered with some pragmatic cautions; and made some preliminary system selections. Now we were getting down to the nitty-gritty — putting our plans and a proposal down on paper so that we could launch a sales effort to put together the financing needed to make it go.In formalizing your proposal or business plan, be prepared to spend a lot of hours at a desk with all of your background notes, a dictionary, a thesaurus, calculator, plenty of paper and pencils with generous erasers. With access to a word processor and a good spreadsheet program, you are facing a formidable task; without these two tools, it will seem, and may actually be, virtually “undoable.”Your proposal or business plan can take any of several forms, and no one is necessarily more or less appropriate or effective than any other. The plan should reflect your corporate style and philosophy. But regardless of the form, there are some elements which are indispensable.Your presentation must inspire confidence in a potential investor, assuming that you, like we, have to seek outside capital to launch your effort. The plan must clearly demonstrate that you have done your homework and thoroughly researched the subject and the market. It should deal with the principal players in your scenario, their credentials, and what they can contribute to the success of the venture — what value can each add? If yours is to be an extension of an existing business, the proposal must provide business and financial history in a realistic light, yet do so as favorably as possible. Finally, the plan must provide business forecasts in the form of projected financial statements and balance sheets. Have your accountant or someone with a strong financial background assist with the financials if that is not an area in which you have experience and confidence.Ultimately, the plan must convince its readers that you have (a) identified a need in the market and (b) that you are prepared and positioned to meet it. Experienced business pros will be reviewing the plan, so make the effort, and do it right. In preparing all of this information, keep in mind that an investor who decides to participate based on the plan will view it as your commitment. He very likely will measure your success, or lack of it, by using the plan as his yardstick. So, be conservative or at least realistic. Don’t put anything into your plan that you might regret. if it were referenced some time later.One of our new acquaintances offered to review our proposal. He was doing Ada work so he could evaluate the presentation from that perspective. He was also very much involved with a managing board composed of experienced venture capitalists, so he could also take a look from that viewpoint. He gave us sound advice.My point is that you should have some disinterested parties whose opinions you value and respect, and who can freely and dispassionately critique your work, review it before you run with it. And, believe me, unless you are superhuman, you will go through several drafts and revisions before you submit the plan for outsider review. Our final plan was the sixth major revision, excluding the many internal changes and edits. Preparing an acceptable and effective plan is a humbling experience that will teach you the value of patience.One final note regarding your proposal — don’t overlook its appearance. A copy of the plan and an introductory letter may be your only exposure as you try to get personal appointments to market your idea. Prepare them with care and attention to detail. Ensure that they reflect the high degree of professionalism that went into their re-search and preparation and which will characterize your business efforts. The content of the plan may not even be considered if the plan itself is not attractively presented.Now that you have what you believe is a good marketing piece, where do you go with it?Our objective was to secure local financing (within our community or at least within the state of West Virginia). We drew on personal contacts, a list of local venture capitalists that we obtained from the chamber of commerce, and suggestions offered by the CEO of one of the banks with whom we had an on-going personal and business relationship.We thoroughly explored various loan, grant, and incentive programs offered by municipal, county and state governments to attract business. If you have a university near you, they may have an office that assists with business start-ups. They may be very helpful if you choose to apply for loans or grants since this is an art form in itself. Don’t overlook these potentially attractive sources of advice or capital; they could make the difference.Be prepared to make phone calls, personal visits and send written correspondence in cultivating potential investors. And be sure to have your ducks in line because most of these people did not accumulate their wealth or acquire their positions because they are fiscally naive or stupid. They are, by and large, very good business people who ask direct and probing questions and expect direct, succinct, supportable answers — and a wrong answer can quickly kill an opportunity.If local capital is not available, you will have to look farther afield. That’s an area in which we can’t offer much advice as we did not have to pursue it. We anticipated that if we had had to look elsewhere we would have to be even more on our toes, since we would give up the advantage of common ground. We would be negotiating on their turf rather than being from the same community as the people we were soliciting.One of the biggest difficulties we encountered was in selling something intangible. As sophisticated as many lenders and investors are, some are still uncomfortable with the computer field, and especially software, as an area of opportunity.Unless high tech businesses are already an established and accepted investment arena in your area, lenders may have difficulty grasping the concept of investing in intellectual property. Loans or investments for plant and equipment are a piece of cake — you can survey, touch, walk around or kick the tires of the collateral. In dealing with software, you lose that advantage, and many people are still wary of getting financially involved with something they can’t see, touch, taste, or smell.Anticipate some initial skepticism and prepare to overcome it. BEGIN NOW. This is one area where you can’t start sowing seeds and nurturing them too soon. Look for or create occasions to discuss with the financial powers in your community the role and advantages and success stories and opportunities in software development. When you come across a good article — one that’s not too technical — that supports your point, send copies to appropriate people. Most will be read, and you’ll be strengthening your case and laying a foundation you can build on later.Aside from the “intangibility factor,” we found that the key concern of potential investors is the make-up of your staff. If you have on board people with strong credentials and proven track records in Ada, your job will be much easier. We didn’t. In fact, we had the chicken-and-egg situation of having financiers citing staff as a prerequisite on the one hand; and our inability to recruit and hire a staff until we had secured financing on the other. It was one of the most frustrating aspects of the whole process.We leaned heavily on the proven track records of those of us who were organizing the venture, even though they included no Ada experience. Special expertise has to be addressed, but good basic management skills and experience are highly regarded, well-respected, and carry a lot of weight. We also capitalized on the credentials of our consultant with whom we had reached an agreement for his continuing services after our start-up, making him a legitimate member of our team. It was true that we had considerable background in computer sales, and had on our staff experienced programmers doing custom work for clients, though not in Ada. Many people perceive experience in one area of the computer field as qualification to perform in what we knew to be largely unrelated areas. Since it worked to our advantage, we did not discourage that perception.While we were putting together our financing, we did some preliminary recruiting. We secured resumes and expressions of interest from programmers by contacting the colleges and universities that were graduating students from computer science programs in our area. From the outset, our objective had been to get our programmers locally, if possible. We believe that local residents, particularly in an area like ours, are more easily attracted to job opportunities near home and are more likely to remain with us because of their ties to the area.We recognized, however, that it was critical for us to attract at least one highly experienced Ada professional to direct the programming effort. We drew on the contacts we had made and also secured the services of two firms specializing in Ada placements. Use every tool you can muster, because this is a difficult area with the explosive growth that Ada is enjoying. Experienced people are hard to find, and you must be prepared for a difficult search and the possibility that you may not have adequately budgeted for this position. This person is key, however, and if you find the right one: the time, effort, and money expended in the search will have been well worth it.Look into training, particularly if you do as we did and recruit most of your staff with little or no practical Ada experience. Budget the time and money to allow for proper training of your people and recognize that they will be unproductive for some period of time after they come on board. We completed the hiring of our staff in early Fall. Theirs is a ten-week-long training program. We anticipate beginning work on our first contract no earlier than the first of the year. Our staff will have been on the payroll for more than three months before they take their first steps toward providing a return on the investment in them.So things have finally come together. With financing secured, you have ordered and scheduled installation of your system; hired and are training your staff; and are ready to undertake some work!Getting that first contract may be a challenge. Use every means at your disposal. If you can hire a professional who can bring contracts with him, so to speak, great! If the contacts you have made in your investigations can’t help open doors for you, then you haven’t been contacting the right people. If you have a Senator Byrd to lend support, bravo! Get all the help you can. Don’t be bashful — most people are more than willing to lend as much help as they’re able. Don’t leave any stone unturned. And don’t wait too late to begin looking.If, somehow, you can get a contract before you configure your shop it will certainly make it easier to attract financing. We were unable to do that. Few people will let a contract to a non-existent shop. We began to actively seek a contract as soon as we had our financing in place and our hiring underway.Use every advantage to secure that first contract, but recognize that future work will be contingent on your performance and the reputation for quality that you establish. Personal relationships will become much less a factor. Don’t bite off more than you can chew on that first contract. Find something manageable that will give you some experience, allow you to establish some credibility, and is small enough to be completed in a reasonable length of time. And go all out to deliver the best product possible on or ahead of schedule. Then you’re on our own, and relying on your performance record — and that’s as it should be. The ball will be in your court and how you handle it will determine the flow of the game for the future.I’ve covered a lot of ground, and again I emphasize that this has been a review of our experience - a case study in which the last chapters are just now being written - and not a “how to” course, per se. In retrospect, I don’t believe that there is much that we would do differently if we were to do it again. We approached the project as a marketing problem and treated it accordingly, drawing on the expertise of others in technical and financial areas. Some of the things we learned would enable us to compress the timeframe to establish a new venture if we were to do it again, but we are relatively well satisfied with how things went.Let me close by just saying that you can become discouraged if you allow it to happen. If you are like we were, the potential of the opportunity is so enormous and so obvious that you won’t be able to easily accept the reluctance and skepticism of others. Why can’t they see what’s as plain as day to us? Why are things taking so long? Be patient and persist. If you’re committed, do your homework, lay the groundwork, and do a good selling job, things will ultimately work out. Don’t lose your sense of urgency; don’t allow your interest to flag; and be patient…be patient…be patient.If we have been able to give you any ideas, then we’ve accomplished our objective. We wish you well. Thank you.",
    "author": [
      {
        "family": "Mayer",
        "given": "P. J."
      }
    ],
    "collection-title": "TRI-ada ’88",
    "container-title": "Proceedings of the conference on TRI-ada ’88",
    "id": "10.1145/76619.76644",
    "issued": {
      "date-parts": [
        [
          1989
        ]
      ]
    },
    "page": "567-580",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Entering the ada systems design and coding market",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1362702.1362708",
    "ISBN": "9781450378444",
    "URL": "https://doi.org/10.1145/1362702.1362708",
    "abstract": "The Interactive Media Lab (IML) builds shrink-wrapped educational software for medical professionals and first responders. We have teams focusing on media production, script-level authoring, and low-level engine development. Our most recent project is Virtual Terrorism Response Academy. VTRA uses 3D simulations to teach students about radiological, chemical and biological weapons. Our software is now undergoing trials at government training centers and metropolitan police departments. VTRA consists of approximately 60,000 lines of Scheme, and a similar amount of C++. All of our product-specific code is in Scheme, and we make extensive use of macros and domain-specific languages.From 1987 to 2002, we used a C++ multimedia engine scripted in 5L, the \"Lisp-Like Learning Lab Language\". This was Lisp-like in name only; it used a prefix syntax, but didn’t even support looping, recursion, or data structures. We needed something better for our next project! We ultimately chose to use Scheme, because (1) it was a well-known, general-purpose programming language, and (2) we could customize it extensively using macros. Migrating to Scheme proved tricky, because we needed to keep releasing products while we were building the new Scheme environment. We began by carefully refactoring our legacy codebase, allowing us to maintain our old and new interpreters in parallel. We then rewrote the front-end in a single, eight-day hacking session. But even once the Scheme environment was ready, few of our employees wanted to use it. In an effort to make Scheme programming more accessible, we invested significant effort in building an IDE. Today, our environment is much more popular—a third of our employees use it on a regular basis, including several professional artists.After migrating to Scheme, we added support for 3D simulations. And Scheme proved its worth almost immediately: we faced several hard technical problems, which we solved by building domain-specific languages using Scheme macros. First, we needed to simulate radiation meters. For this, we used a reactive programming language to implement a Model-View-Controller system. Second, we needed to guide students through the simulation and make teaching points. For this, we relied on a \"goal system\", which tracks what students need to accomplish and provides hints along the way. In both these cases, Scheme proved to be a significant competitive advantage. Not all problems have clean imperative solutions. A language which supports functional programming, macros, and combinator libraries allows us to do things our competitors can’t.This summer, we’ll be releasing our engine as open source, and starting work on a GUI editor. We welcome users and developers!",
    "author": [
      {
        "family": "Kidd",
        "given": "Eric"
      }
    ],
    "collection-title": "CUFP ’07",
    "container-title": "Proceedings of the 4th ACM SIGPLAN workshop on commercial users of functional programming",
    "id": "10.1145/1362702.1362708",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Terrorism response training in scheme",
    "type": "paper-conference"
  },
  {
    "ISBN": "0201770180",
    "abstract": "From the Book: Introduction Developing large distributed software systems is a complex and interesting challenge. A number of architectures have been developed to simplify this task and distract developers from the many interoperability issues associated with developing such systems. This book is predominantly about one of those architectures, Microsoft’s .NET Framework. An often-asked question is \"so what is new in the .NET Framework \" On one level the answer is \"not much.\" To put this answer into context, the same may be said of most recent software advancements. As an example, C++ was a significant step forward but it was the amalgamation of the object oriented concepts of Simula 67 and the efficiency of C. Java also contained very little new science, with the concepts of virtual machines and class libraries having been commonplace for many years. So how then do these advancements contribute Often they contribute via synergy, the combination of known technologies in a new and different manner that allows developers to combine two powerful concepts in a single architecture. So it is with the .NET Framework. Although there are significant benefits to be gained by using the Framework, many readers will be relieved to see that many familiar concepts exist in the environment, although their implementation may have changed. For example, a major concept pervading the .NET Framework is object orientation. Recently this paradigm has seen enormous acceptance in many areas from Graphic User Interface (GUI) development through to network programming. The .NET Framework provides support for all of the object oriented concepts such as classification, information hiding, inheritance andpolymorphism. What is new in the .NET Framework is that language boundaries have been removed. The .NET Framework also extends these concepts in concert with other concepts. For example inheritance can be subject to security constraints; just because you can use a type it may not follow that you can subtype from that type. Audience It is important to understand the target audience that this book was written for in order to know if this book is for you. This book is targeted at software developers who wish to: Understand the philosophy and architecture of the .NET Framework, Produce generic frameworks, libraries, classes and tools to be used in the .NET Framework, and Use multiple languages to develop in the .NET Framework. As this book is targeted at software developers, it not only describes the goals and architecture of the .NET Framework but also demonstrates how the technology implements facilities and services to meet these goals. Understanding the philosophy and architecture of .NET is important for any distributed system developer even if they do not use the .NET Framework. Why The .NET Framework represents Microsoft’s vision of distributed system development for the Internet. By understanding the architecture of the .NET Framework developers gain an insight into the issues associated with distributed systems development and Microsoft’s solution to these issues. Once developers have an understanding of the .NET Framework’s architecture, the next step is to develop software that utilizes the framework. The .NET Framework is not an abstract programming model, it is a full-featured system that allows developers to implement their sol and then make them available to other developers in a robust and secure environment. As the .NET Framework is language agnostic, developers can use the right language to develop parts of a system and then incorporate these parts together at runtime regardless of language differences. So who is this book not for This book is not an introduction to programming; readers should have experience developing software before reading this book. This book is also not the definitive guide to all aspects of the .NET Framework nor any single aspect of the .NET Framework. A single book that covered in detail all aspects of the .NET Framework would be almost indigestible. There will be books devoted to a single part of the .NET Framework, such as ASP.NET. Hopefully this book is a solid overview of fundamental aspects of the .NET architecture but for individual aspects, such as the security system, readers will have to refer to other texts or specific documentation for a complete treatment of a specific topic. Book Structure The structure of the book is fairly straightforward: The Introduction Section of the book describes the basic concepts and gives background information on the issues involved in distributed system development. The Runtime Section describes the issues that can be thought of as \"Programming in the small.\" This section deals with issues such as defining types, storing metadata and executing programs. The Building and Deployment Section deals with the hard issues in distributed systems development. Issues such as assembling and developing software from components and deployment issues are covered here. This section also covers the B the libraries used to build applications. Finally the appendixes contain important peripheral information that does not fit into the first three sections of the book. This includes experience reports from people who have developed compliers for the .NET Framework. Our motivation for writing the book \"So why are we writing the book \" We have asked this question many times over. In late 1998 Monash University was asked if it would like to be involved with Microsoft in the development of the \"next generation of COM\", which was then known as the COM Object Runtime (COR). The invitation to join Project 7, the name for this multinational joint collaboration between Microsoft and a number of universities, came from James Plamondon at Microsoft Research. Why was Monash University chosen The major reason was because of our association with Bertrand Meyer and his object oriented programming language Eiffel. Even at this early stage Microsoft was firmly focused on having as many languages as possible supported by the runtime. Monash University accepted the invitation and Damien attend an overview in Atlanta during early 1999. The idea of writing this book was first discussed at that meeting. Having just attended the preview of COR, which was now known as Lightning at this time, Damien asked James Plamondon if he knew of anyone that was writing a book on Lightning. Even at this early stage it was clear that a number of books would be required to cover all of the aspects of Lightning but Damien also wanted to see that the small, but hopefully beneficial, involvement of Project 7 members was recorded. James encouraged Damien to consider writing such a book and, after a few years numerous changes, this book is the outcome of that conversation. The appendixes in this book are the acknowledgement of the work done by many people outside of Microsoft on Project 7. Mark Hammond has been involved in Python development since 1991, developing and maintaining the Win32 extensions for Python, which includes the PythonWin IDE and the support libraries for COM. Mark had been involved with Microsoft since the mid 1990s in Python related projects, most notably the ActiveScripting and ActiveDebugging extensions for the Python language. In 2000 Mark released his first book, Python Programming on Win32, co-authored with Andy Robinson. In 1998, due to the increasing popularity of the Python programming language, the Project 7 team decided that Python should be one of the initial languages ported to the platform. Mark’s history with Microsoft meant that he was the obvious choice and being located in Melbourne Australia along with two other initial participants, Melbourne and Monash Universities, meant that a core group of Project 7 participants formed almost exactly on the other side of the world from Seattle. This is how Damien and Mark met. Brad was fortunate to be around for the birth of the Common Language Runtime, cutting his teeth in API design and working on fundamental types such as System.Object and System.String. He participated in the earliest design decisions that would later reflect across the breadth of the .NET Framework and in fact all .NET code. Brad was very enthusiastic about the cross language support being built into the runtime while leading the team that developed the Common Language Specification. Early in 1998 Adam Smith, a developer from another team, asked if he exposed properties from his library could VB (and other languages) consume his API. Brad did what any respectable Program Manager at Microsoft would do and called a one hour meeting to decide what features of the CLR would be available in all languages. That meeting didn’t resolve the issue, in fact it took well over three years and thousands of hours from key architects inside of Microsoft such as Anders Hejlsberg, Peter Kukol, Paul Vick, Alan Carter, Scott Wiltamuth, George Bosworth, Lauren Feaux, Ian Ellison-Taylor, Herman Venter, Jonathan Caves, Francis Hogle, Mark Hall, Daryl Olander, Craig Symonds and Brian Harry to answer this question. Later we reviewed and honed the CLS with a group of key language innovators outside of Microsoft, the Project 7 members. It is through this effort that Brad met Damien and Mark. As a byproduct of working out what was to be included in the CLS many \"Best Practices\" were developed. Brad started writing these best practices down in what would later become the .NET Framework Design Guidelines document. This document lead the way in driving for consistency and usability across the APIs exposed in the .NET Framework. The work on the CLS and the Design Guidelines document lead Brad into a unifying role as we took disparate groups across Microsoft and formed the .NET Framework team. Through this effort Brad gained an appreciation for the value of the different parts of the .NET Framework as well as the need for consistent usage of concepts across them. In addition to his day job, Brad joined a very small team tasked with creating the CLI and C# Language standards first through ECMA and then through ISO. Again the CLS and Design Guidelines got a careful review and honing from this group and with great help from Jim Miller they were published as part of the International standards for the CLI standard. Brad loves to talk about the .NET Framework and how it simplifies the lives of developers so agreeing to do this book was a no-brainer! To partially complete the naming history of the .NET Framework it was known as Project 42 before COR and was subsequently called Lightning, COM+2.0 and NGWS (Next Generation Web Services) before finally being renamed to the .NET Framework only weeks before its launch at the PDC in Orlando in July 2000. From our personal viewpoint, the major satisfaction gained from working on Project 7, as with all experiences in life, has come not from developing a technology but from working with such a large, diverse and talented group of developers from all over the world. An interesting aside about the history of the .NET Framework is to look into each and every .NET Framework executable for the string \"BSJB\". This magic number refers to some of the original developers of the .NET Framework, Brain Harry, Susan Radke-Sproull, Jason Zander and Bill Evans. ECMA Standardization Core elements of the .NET Framework have been standardized by the European Computer Manufactures Association (ECMA.) A major reason for standardizing the .NET Framework is so that other implementations of the .NET Framework can be built. Apart from the commercial Windows based implementation, Microsoft has built a shared source implementations for Windows and BSD UNIX, hopefully other implementations from different groups will follow. For information on the standardization effort, interested readers should visit: http://www.ecma.ch and in particular the .NET Framework standardization effort at: http://www.ecma.ch/ecma1/STAND/ecma-335.htm The C# language standard is at: http://www.ecma.ch/ecma1/STAND/ECMA-334.htm You can find out more about the Shard Source Implementations at: http://msdn.microsoft.com/net/sscli",
    "author": [
      {
        "family": "Watkins",
        "given": "Damien"
      },
      {
        "family": "Hammond",
        "given": "Mark"
      },
      {
        "family": "Abrams",
        "given": "Brad"
      }
    ],
    "id": "10.5555/579355",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Programming in the .net environment",
    "type": "book"
  },
  {
    "ISBN": "0672323664",
    "abstract": "From the Book: Introduction By Daniel Brookshier When thinking about how to introduce this book, I thought I might start by welcoming you to a new concept in software. I have worked with many types of software, and I have programmed exclusively in Java since it was introduced in 1995. I’ve seen my share of new concepts and ideas that would change the world. Java has had the biggest impact in my life, and I believe the evidence shows that it has changed the computer world. What about JXTA Why should you or I use a technology that is so new and a departure from Web Services and client server technology When I started looking around, I found that JXTA is not so much a new concept as it is a revolution. Not a revolution in the sense of new or groundbreakinga revolution like the French Revolution. As with most situations where things go wrong, you blame those in power. The French had some rather large grievances with their government. Under Louis XIV and Louis XV, there was extravagant spending, unpopular wars on foreign soil, state bankruptcy, and high taxes imposed mostly on the common man. The French revolutionaries decided that the monarchy and the elite class all had to go. And, as they say, heads would roll. Peer-to-peer is a response to a sort of server-based tyranny. Client-server, multi-tier, and Web server technologies are like kings. Servers concentrate power and resources, limit access, and restrict an individual’s ability to access and control his or her own data. This is not exactly an affront to our civil rights, but it can mean that a corporation has my data on their servers. There is also a barrier to the entry. The rich and noble born and elite of France controlled resources, and only large organizations have the resources to buy and maintain large servers. With the rise of Linux, you can create a shoestring operation, but you still need to pay for bandwidth and other resources. Servers hold the applications and data we use, but we have no stake or control in them. As individuals and even large groups, we cannot muster the resources to create our own servers unless we were born rich like a noble or have the resources like a corporation. Oust the king and suddenly you are looking for someone else to govern. The French, while architecting their revolution, had some of the same thoughts as today’s JXTA developers. On August 26, 1789, the National Assembly of France approved a document, entitled Declaration of the Rights of Man and of the Citizen. They based it somewhat on the declaration of independence written in America. The French document seems to be more about individuals operating in a society and, thus, more like a peer-to-peer system. Let’s look at a few of the articles of the declaration to see where the French revolutionaries and JXTA agree. Men are born and remain free and equal in rights. Social distinctions may be founded only upon the general good (Article 1). Peers also achieve social status via the information or unique processing they contribute. In a server world, the server has almost all resources, while clients have little or none. The principle of all sovereignty resides essentially in the nation. No body nor individual may exercise any authority which does not proceed directly from the nation (Article 3). JXTA creates a community where no individual computer has the ability to affect the entire network unless other member peers allow it. In a sense, this is like a democracy but on a more personal level, because you vote by participation in a group or application. Rights of individual computers are also granted by the protocols that every computer on the peer-to-peer network must follow. In a server environment, the client must follow the rules of the server software and the owners of the server. When there are many servers, there are also many masters, causing the clients to follow too many different and conflicting rules. Liberty consists in the freedom to do everything which injures no one else; hence the exercise of the natural rights of each man has no limits except those which assure to the other members of the society the enjoyment of the same rights. These limits can only be determined by law (Article 4). Liberty in JXTA, like real liberty, is difficult to define. But the key difference from client/server technology is the ability to be an acting part of the application. The benefits are a bit ethereal, but imagine the ability to truly control your data. You can also process the data at any time. Is this freedom Hard to say, but it is a start. JXTA promotes freedom as well as the right to punish those that abuse it. Even a free society has laws. For a network to succeed, there needs to be some way to know when others are harmed and provide a consequence to those responsible. In a P2P network, the ability of one member to do harm is limited. The redundancy of the network reduces the impact on the society of peers but, like any society, there are criminals (or at least perceived to be). JXTA has the notion of a credential. If a peer fails to be a good citizen, its rights may be forfeited and the credential invalidated. Server environments are a bit different. Beyond denial of service attacks, being a good or a bad client is a gray area, mainly because the applications are very constrained for normal users. The server is often cast as the villain, as a hoarder of data and even breaking the trust of clients by allowing the sale of a client’s data. All the citizens have a right to decide, either personally or by their representatives, as to the necessity of the public contribution; to grant this freely; to know to what uses it is put; and to fix the proportion, the mode of assessment and of collection and the duration of the taxes (Article 14). Taxation should be compared to a service fee or cost to create a service. A JXTA peer determines the level of participation in the network and, thus, the cost of its hardware and other resources. Like a consumption tax, there is a tendency to pay more, the more you use the network. Due to redundancy and shared processing, all users benefit, rather than suffering because of poor hardware. Users make their own decisions on how they configure and use their P2P software. Inappropriate and draconian controls instituted by a server’s owners or chosen software are eliminated. In another way, article 14 also shows the difference between server and P2P technology. With servers, an infrastructure must be maintained. Server software, because of its costs, looks like a government that requires a tax to operate that is usually flat rather than based on participation. With a peer network, peers share resources and each peer pays its share by its existence and level of participation. A society in which the observance of the law is not assured, nor the separation of powers defined, has no constitution at all (Article 16). This is sort of an obvious statement for JXTA. If you don’t use JXTA protocols (our Constitution and basic laws), you cannot be a member of the community. If you are using JXTA and do abuse its community, you are usually just hurting yourself. Since property is an inviolable and sacred right, no one shall be deprived thereof except where public necessity, legally determined, shall clearly demand it, and then only on condition that the owner shall have been previously and equitably indemnified (Article 17). P2P started to become popular with the introduction of Napster. Sadly, the implication was that P2P was associated with piracy. Although Napster was originally formed with the idea that only valid owners of music would access digital versions, there was probably more piracy than legitimate use. Consequently, Napster has suffered in court with a severe reduction in the number of users. P2P networks, such as Gnutella, are also devoid of rights management. These systems cannot be taken to court as Napster was because they are truly distributed. However, because of their uncontrolled nature, corporations and ISPs are restricting their traffic, and individual users are being charged with crimes or losing rights to services. It is highly probable that these systems will be disabled or at least inconvenienced. The ultimate goal for JXTA is to be a good citizen and respect copyright and property laws. The reason is simple, without respectability, JXTA is seen as another Napster or Gnutella and will be filtered by ISPs and corporations. Respect others’ rights to their property and you will be treated as a fellow citizen and allowed to use the Internet and corporate infrastructures. Most of us live in a commercial society, and we deal with commercial entities. Where there is unfair trade or criminal activity, the system of government or those affected will tend to remove those who abuse the system. Although you may argue that entities like record companies are not acting fairly, the fact is that the laws are currently written to protect themnot those who dislike the law and protest it by circumvention. Napster and the newer incarnations have not changed any laws through their public protests and active breaking of laws. We still need to follow the rule of law to succeed. JXTA Scale Another revolutionary idea of JXTA is what it empowers you to build. Without a central server, with its costs and limits, much more is possible. This does not necessarily mean new types of applications, just a greater scale than was possible in a server environment. A good example of the scalability of JXTA applications is simple catalog for e-commerce. Normally, you would need a large number of clustered servers to handle a large number of transactions. With JXTA, the catalog and its software are distributed automatically among peer computers. Instead of a server that must show the same catalog to millions of users, you just need one PC to distribute the first copy and any updates. All that needs to be centralized is the final order acceptance and credit card transaction, and even that is distributable to some extent. There are many benefits of a P2P catalog from cost savings to the ability of a user to access the catalog offline. The application also runs faster because the user is not as limited to his or her connection speed or waiting in a queue of other users. Add to this 100 percent availability to most users, and you ensure that the verities of the Internet or of a server farm are no longer a part of the risk equation. Another scale feature is raw computing power. In a server environment, each client has access only to limited resources that must be shared by all users. With JXTA, each peer has all the power of the machine it is running on, plus the shared power of all the other peers with which it is collaborating. Is JXTA a New Concept Just by reading this far, you may have seen very familiar concepts. In the prior examples on scale, it is very easy to associate the same goals with distributed computing. The examples of P2P throughout the book are all possible using other methods. However, the point of JXTA is not necessarily to replace these methods. JXTA is a platform with specific protocols to talk to other JXTA platforms in a peer-to-peer network. It is not an application or a library created to build specific applications. The reason JXTA exists is to enable the refactoring of many different applications in a P2P environment. Like the catalog example, the idea is to move away from centralized infrastructures to gain the benefits of a distributed system. RMI, CORBA, and Web Services are distant cousins of JXTA. They are either oriented toward a client/server or limited point-to-point communications. JXTA may seem to provide similar services, but the framework beneath is very different. For example, you can implement remote method invocation. The key difference between JXTA and others is that the delivery of the command to execute can span barriers like firewalls. The remote command can be sent to groups of computers or just a single computer, depending on the type of task. JXTA Risks I think we can safely agree that JXTA is not like anything else. Is JXTA something to bet your time as well as your fortune on There are risks. Some are new and others are well known. Some are being fixed as you read this book, and others simply need to be implemented on the current JXTA platform. The largest risk now is that JXTA will be in flux over the next couple of years. The good news is that the community of developers will try to keep the network stable for the purpose of keeping their products working. When you reach a certain point, developers learn to hate change, even when the project is open source. It is not all a bed of roses in other areas. There are aspects to a P2P system that can be problematic. In our catalog example, it does take time to propagate the catalog to all users. The same time delay is true of updates and transactions. We are at the start of the JXTA revolution. It is time to think revolutionarily thoughts. The reign of client server is about to fall. Read on and join the revolution. Viva la revolution! Daniel Brookshier JXTA Community Member, Java Consultant January 2002, Dallas, Texas What This Book Covers This book will only cover the Java J2SE reference platform implementation of JXTA. We will not cover the C++, J2ME, Pearl, or other languages that are being used to create JXTA platforms. The J2SE version is the reference platform and best for experimentation or explanation of JXTA protocols. Java is also the most popular language for JXTA development at this time. This book is intended to introduce new developers to the JXTA API and selected applications and services. Our goal is for the reader to understand P2P concepts and be able to build useful applications using JXTA. We do not cover detailed aspects of how the JXTA platform is implemented unless it adds value to the explanation on how to use it. Who Should Use This Book This book is written for readers who need an introduction to P2P and for those who want to learn JXTA. You should already be comfortable with Java. You do not need to know anything about JXTA or peer-to-peer programming. By the end of the book, you should be able to create simple P2P applications using JXTA and the J2SE JXTA reference platform. How This Book is Organized This book is organized with two goals. The first goal is to explain P2P and JXTA in general terms. The second goal is to create applications that use JXTA. Finally, we cover specific applications with the aim of furthering an understanding of JXTA while showing how more complete applications are written. This arrangement was chosen so that the reader can get an overview of JXTA and then build an understanding of how to use its various parts. Web Resources and Example Code You can download the source code for examples presented in this book from http://www.samspublishing.com. When you reach that page, enter this book’s ISBN number (0672323664) in the search box to access information about the book and a Source Code link. The NetBeans IDE was used for much of the code that is found in the book. NetBeans is available at http://www.netbeans.org. Because Forte from Sun Microsystems is derived from NetBeans, it should work as well. You can also use your favorite editor or IDE, but the ANT scripts were created within NetBeans and Forte. Also on the site are files that can be used with MagicDraw from NoMagic at http://www.MagicDraw.com. The tool is written in Java and runs on most Java-compatible platforms. The demo version will allow you to browse and print the JXTA diagrams used in the book, but it will not allow you to save changes. The MagicDraw files follow the XMI standard for UML representation in XML, so other UML tools that support the standard should work (drawings may look different). © Copyright Pearson Education. All rights reserved.",
    "author": [
      {
        "family": "Brookshier",
        "given": "Daniel"
      },
      {
        "family": "Govoni",
        "given": "Darren"
      },
      {
        "family": "Krishnan",
        "given": "Navaneeth"
      },
      {
        "family": "Soto",
        "given": "Juan Carlos"
      }
    ],
    "id": "10.5555/560389",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Sams",
    "publisher-place": "USA",
    "title": "JXTA: Java P2P programming",
    "title-short": "JXTA",
    "type": "book"
  },
  {
    "DOI": "10.1504/ijlt.2023.131313",
    "ISSN": "1477-8386",
    "URL": "https://doi.org/10.1504/ijlt.2023.131313",
    "abstract": "Teaching programming and computational thinking to young students has gained increasing attention in recent years. This great attention is attributed partially to the emergence of easy-to-use visual programming environments. These environments help students focus on the logic and concepts of programming and at the same time enhance their engagement. It has been shown that the characteristics of visual programming environments influence students’ engagement with programming. However, there is still no systematic investigation of these characteristics. This study aims to provide insights on the characteristics of visual programming environments for K-9 education based on a systematic literature review of 83 empirical studies on K-9 teaching and learning programming. These characteristics are analysed based on the following four levels: a) functional features; b) student experience; c) teacher experience; d) disadvantages. Finally, herein we discuss the features that a programming environment for K-9 education could have to improve the experience of students and teachers.",
    "author": [
      {
        "family": "Trakosas",
        "given": "Dimitrios"
      },
      {
        "family": "Tikva",
        "given": "Christina"
      },
      {
        "family": "Tambouris",
        "given": "Efthimios"
      }
    ],
    "container-title": "Int. J. Learn. Technol.",
    "id": "10.1504/ijlt.2023.131313",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2023,
          1
        ]
      ]
    },
    "keyword": "visual programming environments, computational thinking environments, K-9 education",
    "page": "94-121",
    "publisher": "Inderscience Publishers",
    "publisher-place": "Geneva 15, CHE",
    "title": "Visual programming and computational thinking environments for k-9 education: A systematic literature review",
    "title-short": "Visual programming and computational thinking environments for k-9 education",
    "type": "article-journal",
    "volume": "18"
  },
  {
    "DOI": "10.1007/s10515-023-00410-z",
    "ISSN": "0928-8910",
    "URL": "https://doi.org/10.1007/s10515-023-00410-z",
    "abstract": "Various development tools have been introduced and the choice of suitable development tool depends on the particular context like the type of application to be developed, the development process and application domain, etc. The real challenge is to deliver new features at the right time with a faster development cycle. The selection of suitable development tools will help developers to save time and effort. In this research, we will explore software engineering repositories (like StackOverflow) to collect feedback from developers about development tools. This will explore which features in a development tool are most important, which features are missing, and which features require changes. The answers to these questions can be found by mining the community question-answering sites (CQA). We will use user feedback to innovate the new features in the development tool. Various techniques of Big Data, Data Mining, Deep Learning, and Transformers including Generative Pre-Training Transformer will be used in our research. Some of the major techniques include (i) data collection from CQA sites like StackOverflow, (ii) data preprocessing (iii) categories the data into various topics using topic modeling (iv) sentiment analysis of data to get positive or negative aspects of features (v) ranking of users and their feedback. The output of this research will categorize the users feedback into various ideas, this will help organizations to decide which features are required, which features are not required, which features are difficult or confusing, and which new features should be introduced into a new release.",
    "author": [
      {
        "family": "Anwar",
        "given": "Zeeshan"
      },
      {
        "family": "Afzal",
        "given": "Hammad"
      }
    ],
    "container-title": "Automated Software Engg.",
    "id": "10.1007/s10515-023-00410-z",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2024,
          1
        ]
      ]
    },
    "keyword": "Open innovation, Community question answering, Topic modeling, Sentiment analysis, Quality assessment, Crowd sourcing",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Mining crowd sourcing repositories for open innovation in software engineering",
    "type": "article-journal",
    "volume": "31"
  },
  {
    "ISBN": "0769505155",
    "abstract": "Electronic Blocks are a new programming interface, designed for children aged between three and eight years. The Electronic Blocks programming environment includes sensor blocks, action blocks and logic blocks. By connecting these blocks children can program structures that interact with the environment. The Electronic Block programming interface design is based on principles of developmentally appropriate practices in early childhood education. As a result the blocks provide young children with a programming environment that allows them to explore quite complex programming principles. The simple syntax of the blocks provides opportunities for young children unavailable through the use of traditional programming languages. The blocks allow children to create and use simple code structures. The Electronic Block environment provides a developmentally appropriate environment for planning overall strategies for solving a problem, breaking a strategy down into manageable units, and systematically determining the weakness of the solution. Electronic Blocks are the physical embodiment of computer programming. They have the unique dynamic and programmable properties of a computer minus its complexity.",
    "author": [
      {
        "family": "Wyeth",
        "given": "Peta"
      },
      {
        "family": "Purchase",
        "given": "Helen C."
      }
    ],
    "collection-title": "AUIC ’00",
    "container-title": "Proceedings of the first australasian user interface conference",
    "id": "10.5555/582910.786750",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "keyword": "Early Childhood Education, Electronic Building Blocks, Physical Programming",
    "page": "141",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Programming without a computer: A new interface for children under eight",
    "title-short": "Programming without a computer",
    "type": "paper-conference"
  },
  {
    "ISBN": "0769524966",
    "abstract": "Large scientific applications developed as recently as five to ten years ago are often at a disadvantage in current computing environments. Due to frequent acquisition decisions made for reasons such as priceperformance, in order to continue production runs it is often necessary to port large scientific applications to completely different architectures than the ones on which they were developed. Since the porting step does not include optimizations necessary for the new architecture, performance often suffers due to various architectural features. The Programming Environment and Training (PET) Computational Environments (CE) team has developed and deployed different procedures and mechanisms for collection of performance data and for profiling and optimizations of these applications based on that data. The paper illustrates some of these procedures and mechanisms.",
    "author": [
      {
        "family": "Moore",
        "given": "Shirley"
      },
      {
        "family": "Cronk",
        "given": "David"
      },
      {
        "family": "Wolf",
        "given": "Felix"
      },
      {
        "family": "Purkayastha",
        "given": "Avi"
      },
      {
        "family": "Teller",
        "given": "Patricia"
      },
      {
        "family": "Araiza",
        "given": "Robert"
      },
      {
        "family": "Aguilera",
        "given": "Maria Gabriela"
      },
      {
        "family": "Nava",
        "given": "Jamie"
      }
    ],
    "collection-title": "DOD_UGC ’05",
    "container-title": "Proceedings of the 2005 users group conference on 2005 users group conference",
    "id": "10.5555/1114280.1114372",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "394",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Performance profiling and analysis of DoD applications using PAPI and TAU",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/TKDE.2008.144",
    "ISSN": "1041-4347",
    "URL": "https://doi.org/10.1109/TKDE.2008.144",
    "abstract": "Active learning and training is a particularly effective form of education. In various domains, skills are equally important to knowledge. We present an automated learning and skills training system for a database programming environment that promotes procedural knowledge acquisition and skills training. The system provides meaningful knowledge-level feedback such as correction of student solutions and personalized guidance through recommendations. Specifically, we address automated synchronous feedback and recommendations based on personalized performance assessment. At the core of the tutoring system is a pattern-based error classification and correction component that analyzes student input in order to provide immediate feedback and in order to diagnose student weaknesses and suggest further study material. A syntax-driven approach based on grammars and syntax trees provides the solution for a semantic analysis technique. Syntax tree abstractions and comparison techniques based on equivalence rules and pattern matching are specific approaches.",
    "author": [
      {
        "family": "Pahl",
        "given": "Claus"
      },
      {
        "family": "Kenny",
        "given": "Claire"
      }
    ],
    "container-title": "IEEE Trans. on Knowl. and Data Eng.",
    "id": "10.1109/TKDE.2008.144",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2009,
          6
        ]
      ]
    },
    "keyword": "Applications and Expert Knowledge-Intensive Systems, Artificial intelligence, Artificial intelligence—applications and expert knowledge-intensive systems, Data Structures, Education, Query languages, applications and expert knowledge-intensive systems, data structures, education, programming languages, query languages.",
    "page": "854-866",
    "publisher": "IEEE Educational Activities Department",
    "publisher-place": "USA",
    "title": "Interactive correction and recommendation for computer language learning and training",
    "type": "article-journal",
    "volume": "21"
  },
  {
    "ISBN": "0493035788",
    "abstract": "Multi-FPGA systems offer the potential to deliver higher performance solutions than traditional computers for some low-level computing tasks. This requires a flexible hardware substrate and an automated mapping system. CHAMPION is an automated mapping system for implementing image processing applications in multi-FPGA systems under development at the University of Tennessee. CHAMPION will map applications in the Khoros Cantata graphical programming environment to hardware. The work described in this dissertation involves the automation of the CHAMPION back-end design flow, which includes the partitioning problem, netlist to structural VHDL conversion, synthesis and placement and routing, and host code generation. The primary goal is to investigate the development and evaluation of three different k-way partitioning approaches. In the first and the second approaches, we discuss the development and implementation of two existing algorithms. The first approach is a hierarchical partitioning method based on topological ordering (HP). The second approach is a recursive algorithm based on the Fiduccia and Mattheyses bipartitioning heuristic (RP). We extend these algorithms to handle the multiple constraints imposed by adaptive computing systems. We also introduce a new recursive partitioning method based on topological ordering and levelization (RPL). In addition to handling the partitioning constraints, the new approach efficiently addresses the problem of minimizing the number of FPGAs used and the amount of computation, thereby overcoming some of the weaknesses of the HP and RP algorithms.",
    "author": [
      {
        "family": "Kerkiz",
        "given": "Nabil Fouad"
      },
      {
        "family": "Bouldin",
        "given": "Dan"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/932896",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "note": "AAI9996361",
    "publisher": "The University of Tennessee",
    "title": "Development and experimental evaluation of partitioning algorithms for adaptive computing systems",
    "type": "thesis"
  },
  {
    "ISBN": "0591944391",
    "abstract": "While parallel computing offers an attractive perspective for the future, developing efficient parallel applications today is a labor-intensive process that requires an intimate knowledge of the machines, the applications, and many subtle machine-application interactions. Optimizing applications so that they can achieve their full potential on parallel machines is often beyond the programmer’s or the compiler’s ability; furthermore its complexity will not be reduced with the increasingly complex computer architectures of the foreseeable future. In this dissertation, we discuss how application performance can be optimized systematically. We show how insights regarding machine-application pairs and the weaknesses in their delivered performance can be derived by characterizing the machine, the application, and the machine-application interactions. We describe a general performance tuning scheme that can be used for selecting and applying a broad range of performance tuning actions to solve major performance problems in a structured sequence of steps, and discuss the interrelationship among and between performance problems and performance tuning actions. To guide programmers in performance tuning, we developed a goal-directed performance tuning methodology that employs hierarchical performance bounds to characterize the delivered performance quantitatively and explain where potential performance is lost. To reduce the complexity of performance tuning, we developed an innovative performance modeling scheme to quickly derive machine-application interactions from abstract representations of the machine and application of interest.Collectively, this dissertation unifies a range of research work done within the Parallel Performance Project at the University of Michigan over the past seven years and significantly improves the state-of-the-art in parallel application development environments.",
    "author": [
      {
        "family": "Hung",
        "given": "Shih-Hao"
      },
      {
        "family": "Davidson",
        "given": "Edward S."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/927446",
    "issued": {
      "date-parts": [
        [
          1998
        ]
      ]
    },
    "note": "AAI9840559",
    "publisher": "University of Michigan",
    "publisher-place": "USA",
    "title": "Optimizing parallel applications",
    "type": "thesis"
  },
  {
    "DOI": "10.1109/DIGITEL.2007.31",
    "ISBN": "0769528015",
    "URL": "https://doi.org/10.1109/DIGITEL.2007.31",
    "abstract": "The concept of edutainment or \"education and entertainment\" is not new in a learning environment and its purpose is to make the learning process more enjoyable. This project integrated mobile game technology into a Mobile Learning system to make the learning process more fun and effective for its student end-users. The current generation prefers to spend time in front of the computer playing games instead of studying, so the project merged the technology so they can still play games but study at the same time. Even though mobile technology has many weaknesses (e.g., limited screen size), the project used this technology because it can be played anywhere, anytime, by any mobile device. The main end-users of the project are students or anyone who is learning the subject. For the time being, the project focuses on C++ programming as its domain. Basically, once a student executes the application, he or she can play the game by using C++ programming knowledge. The game starts by displaying a question. The player is represented by a small car that can shoot by using bullets. Within a time limit, the player must shoot the correct answer to a practical programming question. If the player shoots the wrong answer, the wrong answer will try to shoot the player back. The game was developed using J2ME as its development tool and Adobe Photoshop as its graphic design tool.",
    "author": [
      {
        "family": "Hamid",
        "given": "Siti Hafizah Ab"
      },
      {
        "family": "Fung",
        "given": "Leong Yu"
      }
    ],
    "collection-title": "DIGITEL ’07",
    "container-title": "Proceedings of the the first IEEE international workshop on digital game and intelligent toy enhanced learning",
    "id": "10.1109/DIGITEL.2007.31",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "page": "170-172",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Learn programming by using mobile edutainment game approach",
    "type": "paper-conference"
  },
  {
    "abstract": "The training of raters is one practical way for enhancing the accuracy of performance ratings. Traditional methods for presenting the training, such as lecture, group discussion, and practice/feedback, are subject to certain weaknesses. A new ICART training method, which is an application of knowledge-based systems, was suggested to overcome the weaknesses of these traditional training methods. The objectives of this study were three-fold: (1) preparing a proposal for training raters, (2) developing the ICART system according to proposal guidelines, and (3) examining whether the developed ICART system may improve the accuracy of performance ratings.The fault tree analysis technique was used to effectively define the training content. During this analysis of the problem domain, biases that occurred in judgmental activities were considered as rating-error sources. Based on a questionnaire survey and factor analysis, relationships between rating errors and error sources were explored. The results of the fault tree analysis defined the scope and the order of training tasks.Based on the defined training content, the ICART system was developed as a prototype in accordance with formalities of intelligent tutoring systems. The system was composed of three functional modules: a domain-expert knowledge module, a teaching knowledge module, and a user-interface module. Production systems and hypertext techniques were utilized to represent knowledge for the modules in the system. The Exsys Professional shell was used as a development tool.The developed ICART system was tested in the situation of evaluating an individual performing a briefing. A total of twenty-eight ROTC cadets participated in two scheduled training sessions. The control group was trained by the traditional lecture and practice method; the experimental group was trained by interacting with the ICART system. Five accuracy components, elevation, differential elevation, stereotype accuracy, differential accuracy, and overall accuracy, were used as dependent variables for analyzing training effects. It was found that training by the ICART system improved accuracy components of differential elevation and overall accuracy.",
    "author": [
      {
        "family": "Jeong",
        "given": "Jong Sik"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/221842",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "note": "UMI Order No. GAX94-29236",
    "publisher": "University of Alabama",
    "publisher-place": "USA",
    "title": "An intelligent computer-assisted rater trainer with fault tree analysis for isolating",
    "type": "thesis"
  },
  {
    "DOI": "10.1109/ISSRE.2004.21",
    "ISBN": "0769522157",
    "URL": "https://doi.org/10.1109/ISSRE.2004.21",
    "abstract": "Software testing is an integral part of the software development process. Some software developers, particularly those who use the Extreme Programming test-driven development practice, continuously write automated tests to verify their code. We present a tool to complement the feedback loops created by continuous testing. The tool combines static source code metrics with dynamic test coverage for use throughout the development phase to predict a reliability estimate based on a linear combination of these values. Implemented as an open source plug-in to the Eclipse IDE, the tool facilitates the rapid transition between unit test case completions and testing feedback. The color-coded results highlight inadequate testing efforts as well as weaknesses in overall program structure. To illustrate the tool’s efficacy, we share the results of its use on university software engineering course projects.",
    "author": [
      {
        "family": "Davidsson",
        "given": "Martin"
      },
      {
        "family": "Zheng",
        "given": "Jiang"
      },
      {
        "family": "Nagappan",
        "given": "Nachiappan"
      },
      {
        "family": "Williams",
        "given": "Laurie"
      },
      {
        "family": "Vouk",
        "given": "Mladen"
      }
    ],
    "collection-title": "ISSRE ’04",
    "container-title": "Proceedings of the 15th international symposium on software reliability engineering",
    "id": "10.1109/ISSRE.2004.21",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "page": "269-280",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "GERT: An empirical reliability estimation and testing feedback tool",
    "title-short": "GERT",
    "type": "paper-conference"
  },
  {
    "ISBN": "0782118348",
    "abstract": "From the Book: This book will provide you with a thorough understanding of Director. It also focuses on the dramatic new flood of Xtras and XObjects that, thanks to Macromedia’s Open Architecture (MOA), may well elevate Director to the lofty status of a true application development environment that goes far beyond C++. The long heralded 5GL (fifth generation language) that was hype ten years ago is today’s Director. Where will it go How high will it fly You’ll never know unless you’ve been there! Mastering Macromedia Director 5 and the accompanying Directions CD-ROM will guide you on your first steps down a path toward becoming a player in the media revolution. You can use this book and CD-ROM to start preparing for the big changes that will undoubtedly rock our culture and challenge our perceptions about media before we ring out the millennium. Why This Book This book is intended for the quick learner. Someone who can seize Director as the opportunity of a lifetime and run with it. As difficult as Director and Lingo (Director’s companion scripting language) can be at times, Director is nevertheless the quickest route to professional quality and highly creative multimedia authoring. I have endeavored to write a companion text to Macromedia’s own documentation. A book that would provide an additional perspective to concepts and procedures that might otherwise be unnecessarily complicated. I have also attempted to write a book that, once basic concepts were thoroughly understood, could metamorphose into a quick-reference tool. In short, I have tried to write a book for myself. A book that you can pick up, thumb through to a specific section, andquickly get that, \"Oh yeah, I remember how you do that!\" feeling. The fast changing nature of software in general, and Internet and multimedia applications specifically, doom any printed work on the subject to almost instant obsolescence. For this reason, I have attempted to include those subjects and concepts- Director, Lingo, and Shockwave (Director for the Internet) that will have enduring value. Nevertheless, I implore you to use this book only as a starting point. Learn to prowl the Internet for the latest and most compelling new techniques and extensions that allow you to get the most out of Director, for therein lies the future of the multimedia industry and, if you so choose, a career in multimedia application development. Places to constantly browse include: www.macromedia.com - with thousands of pages of technical notes, tips and techniques, this web site is the Holy Grail of Director devotees - Macromedia’s own web site. www.macromedia.com/AYS/Tech.support/Technotes/Director/index.html - more specifically, check out the tech notes available concerning Director at the Macromedia site. hakatai.mcli.dist.maricopa.edu/director/index.html - this Arizona community college has the most potent following of Lingo hackers and splicers in the world. hakatai.mcli.dist.maricopa.edu/director/digest/today.txt - check out daily Lingo expository, DirectL, the Director listserv of the airwaves. www.blarge.net/ cagles/lingo/ - Kirt Cagle always waxing poetic on the vagaries of Lists and such. www..shocker.com/shocker/cool.html - want shocked Try the best of the best Shockwave sites from Shocker! Www.gmatter.com - the most comprehensive source for new Xtras is g/matter, Inc. Check out XtraNet, a networking Xtra with unknown potential for integrating Director movies and Internet/Intranet works. www.hyperstand.com - New Media’s own home page with tracks to the MacroMedia User Jourinal’s web pages. How This Book Is Organized This book has 22 chapters divided into four parts. An appendix is also included. The book begins with a discourse on what we may well back on as the greatest media revolution in all of history, what I have called the multimedia/Internet revolution. This epic change in the way we communicate, entertain, educate, and play might well compete with reality itself, and lead to unimagined worlds that are limited, not by technology, but by our imaginations.\"Part 1: The Essentials of Director\" (Chapters 1-10) continues by presenting an all encompassing overview of the premiere multimedia author tool, Director. Tutorials, demonstrations, and straightforward discussions lead you through the first ten chapters.\"Part 2: The Linguistics of Lingo\" (Chapters 11-16) transports readers to the world of Director’s embedded scripting language, Lingo. Once you have mastered Lingo-from controlling objects to becoming intimate with the elements of Lingo style-you have mastered Director.\"Part 3: Putting It All Together\" (Chapters 17-20) combines every aspect of Director you have learned throughout the first 16 chapters and demonstrates how you can use all these elements to create multimedia products. You will also explore Director’s Internet version called Shockwave.\"Part 4: Xtras\" (Chapters 21-22) is over 200 pages dedicated entirely to revealing dozens of new third-party extensions to Director called Xtras and their still valid predecessors, XObjects.Finally, Appendix A is an extensive listing of Lingo Command References.Mastering Macromedia Director 5uses various conventions to help you find the information you need quickly and effortlessly. Tips, Notes, and Warnings are placed strategically throughout the book to help you focus in on important information quickly. Long but important or interesting digressions are set aside as boxed text, called sidebars. Because building any multimedia product-whether it is for CD-ROM distribution or for Internet/Intranet distribution - must be capable ( running on both Microsoft’s Windows 95 and NT (Windows), an Apple’s Macintosh Operating System (MacOS), I have tailored the book to cross-platforrn developers. In situations where significant differences in the two systems can be found, there will be notes and side bars that draw the distinction. Throughout the book I have used the following generalized conventions to distinguish between Macintosh, Power Mac, Power Mac Clones, Windows 95, and Windows NT:MacOS refers to any machine running under the Apple Macintosh Operating System. Except where noted, there is no difference between the Power PC compatible versions and 680x0 versions of the MacOSWindows refers to any machine running under the Microsoft Windows 95 and NT operating systems. Except where noted, there is no difference ( (from the standpoint of the Director author) between Windows 95 and Windows NT. References to Windows 3.1 have, for the most part, not been included. About the CD-ROM Inside the back cover of this book you will find the Directions CD-ROM. This disc contains cross-platform versions of all the tutorials and examples of techniques and Lingo code used throughout the book You will also find a save-disabled version of Director 5.0 (for both the MacOS and Windows) and save-disabled versions of many other Macromedia multimedia tools for both the MacOS and Windows. The save-disabled version of Director will allow you to open and experiment with all the tutorials and demonstration Director movies on the CD-ROM. The only drawback is you won’t be able to save any of your changes. Finally, we have endeavored to include as many demonstrations of Xtras and XObjects as possible. Open these demonstrations using the save-disabled version of Director and test drive these Xtras before you purchase them.Good luck! And remember to experiment, and then experiment some more. It’s only through actually trying the processes and techniques described herein that you will discover the multimedia modalities that work for you. Ultimately, you must become your own teacher.",
    "author": [
      {
        "family": "Henderson",
        "given": "Chuck"
      }
    ],
    "edition": "5th",
    "id": "10.5555/524373",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "publisher": "SYBEX Inc.",
    "publisher-place": "USA",
    "title": "Mastering macromedia director 5 for windows and mac, with CD-ROM (mastering)",
    "type": "book"
  },
  {
    "ISBN": "9781124220956",
    "abstract": "Formal methods are a class of techniques for automatically verifying software correctness. They are a common topic in computer science research. However, they are less well-known in software development and in undergraduate computer science education. As society’s reliance on software increases so does the potential severity of the consequences of software failure. Formal methods are the surest way of guaranteeing software correctness. Moreover, the study of formal methods leads to better informal understanding of software correctness and thus to better software. Unfortunately, the study and use of formal methods can be difficult and this impedes their adoption in software engineering and the computer science curriculum. Coq is an automated proof-assistant for developing certified programs and proofs. It is powerful and expressive and has been used in a large variety of significant developments. Experienced developers are accustomed to picking up new languages rapidly. Unfortunately, it is difficult for a new user to learn the use of any proof-assistant with anything like the same rapidity. Furthermore, developers have become accustomed to sophisticated IDEs with tools for refactoring and for auto-generating code. Very little such support is available for proof-assistants. Coq suffers from both these drawbacks. Our work addresses these problems in several ways. We provide two alternative approaches that facilitate general induction and recursion. We demonstrate methods for enhancing structural recursion principles to increase their generality and transparency. We demonstrate graphical techniques for improved proof visualization and an impact analysis tool for predicting the consequences of a proof refactoring.",
    "author": [
      {
        "family": "Mulhern",
        "given": "Anne"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/2019765",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "note": "AAI3424020",
    "publisher": "University of Wisconsin at Madison",
    "publisher-place": "USA",
    "title": "Polytypic proving",
    "type": "thesis"
  },
  {
    "DOI": "10.1002/cae.21757",
    "ISSN": "1061-3773",
    "URL": "https://doi.org/10.1002/cae.21757",
    "author": [
      {
        "family": "Genç",
        "given": "Hasan Hakan"
      },
      {
        "family": "Aydin",
        "given": "Serkan"
      }
    ],
    "container-title": "Comput. Appl. Eng. Educ.",
    "id": "10.1002/cae.21757",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2016,
          11
        ]
      ]
    },
    "keyword": "STEM, complex problems, computer aided, programming, visualization",
    "page": "876-886",
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "Education on visualization of some complex physics problems in programing environment",
    "type": "article-journal",
    "volume": "24"
  },
  {
    "DOI": "10.1007/978-3-030-63212-0_8",
    "ISBN": "978-3-030-63211-3",
    "URL": "https://doi.org/10.1007/978-3-030-63212-0_8",
    "abstract": "A large number of introductory programming environments for K-12 education have become widely used across the world. One of the main ideas behind these environments is introducing basic programming concepts more effectively by incorporating different visualization strategies. There have been attempts to classify introductory programming tools, however, certain critical aspects have not yet been discussed within the existing classifications, especially those related to user engagement in the programming environment. In this paper we introduce an engagement taxonomy for introductory programming tools (ETIP) built on a concept of engagement taxonomy for software visualization and previous classifications of programming learning tools. The new taxonomy is then used to inclusively review introductory programming environments for secondary education used today with a focus on user engagement in a learning environment. Our review illustrates how majority of introductory programming tools do not fully explore the ways visualizations could help with tackling the problems of beginner programming comprehension. There is still a lack of knowledge about the importance of the level of engagement in visual introductory programming tools and the suggested taxonomy could be used for future research of computer science education.",
    "author": [
      {
        "family": "Šiaulys",
        "given": "Tomas"
      }
    ],
    "container-title": "Informatics in schools. Engaging learners in computational thinking: 13th international conference, ISSEP 2020, tallinn, estonia, november 16–18, 2020, proceedings",
    "id": "10.1007/978-3-030-63212-0_8",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "Introductory programming, Software visualization, Engagement taxonomy",
    "page": "94-106",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Engagement taxonomy for introductory programming tools: Failing to tackle the problems of comprehension",
    "title-short": "Engagement taxonomy for introductory programming tools",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3392063.3394437",
    "ISBN": "9781450379816",
    "URL": "https://doi.org/10.1145/3392063.3394437",
    "abstract": "Previous attempts to make block-based programming accessible to visually impaired children have mostly focused on audio-based challenges, leaving aside spatial constructs, commonly used in learning settings. We sought to understand the qualities and flaws of current programming environments in terms of accessibility in educational settings. We report on a focus group with IT and special needs educators, where they discussed a variety of programming environments for children, identifying their merits, barriers and opportunities. We then conducted a workshop with 7 visually impaired children where they experimented with a bespoke tangible robot-programming environment. Video recordings of such activity were analyzed with educators to discuss children’s experiences and emergent behaviours. We contribute with a set of qualities that programming environments should have to be inclusive to children with different visual abilities, insights for the design of situated classroom activities, and evidence that inclusive tangible robot-based programming is worth pursuing.",
    "author": [
      {
        "family": "Pires",
        "given": "Ana Cristina"
      },
      {
        "family": "Rocha",
        "given": "Filipa"
      },
      {
        "dropping-particle": "de",
        "family": "Barros Neto",
        "given": "Antonio José"
      },
      {
        "family": "Simão",
        "given": "Hugo"
      },
      {
        "family": "Nicolau",
        "given": "Hugo"
      },
      {
        "family": "Guerreiro",
        "given": "Tiago"
      }
    ],
    "collection-title": "IDC ’20",
    "container-title": "Proceedings of the interaction design and children conference",
    "id": "10.1145/3392063.3394437",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "accessible, children, educators, programming, robots, tangible, visual impairments",
    "page": "148-160",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring accessible programming with educators and visually impaired children",
    "type": "paper-conference"
  },
  {
    "DOI": "10.23919/FRUCT.2017.8071326",
    "URL": "https://doi.org/10.23919/FRUCT.2017.8071326",
    "abstract": "This paper presents TRIK Studio - an environment for visual (and textual) programming of robotic kits, which is used in educational organizations across Russia and Europe. First part of the article provides overview of the system - its purpose, features, differences from similar programming environments, general difficulties of robot programming and solutions proposed by TRIK Studio. Second part presents implementation details of TRIK Studio and its most interesting components. This article combines five fields of study: robotics, domain-specific visual modeling, education, formal methods and methods of program analysis. Main contribution of this article is detailed technical description of TRIK Studio as complex and successful open-source cross-platform robot programming environment written in C++/Qt, and first part of the article can also be interesting for teachers as it provides an overview of existing robot programming tools and related problems.",
    "author": [
      {
        "family": "Mordvinov",
        "given": "Dmitry"
      },
      {
        "family": "Litvinov",
        "given": "Yurii"
      },
      {
        "family": "Bryksin",
        "given": "Timofey"
      }
    ],
    "collection-title": "FRUCT ’17",
    "container-title": "Proceedings of the 20th conference of open innovations association FRUCT",
    "id": "10.23919/FRUCT.2017.8071326",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "Code generation, Data-flow languages, Educational robotics, Robotics, Visual programming",
    "page": "296-308",
    "publisher": "FRUCT Oy",
    "publisher-place": "Helsinki, Uusimaa, FIN",
    "title": "TRIK studio: Technical introduction",
    "title-short": "TRIK studio",
    "type": "paper-conference"
  },
  {
    "abstract": "The purposes of this study were to evaluate the effectiveness of programming instruction on students’ problem-solving abilities, and to explore whether a logic programming or a procedural programming environment results in different degrees of cognitive transfer in terms of procedural, declarative, and conditional thinking skills. In an attempt to identify factors which influence programming learning, this study investigated interaction effects between types of programming instruction and students’ aptitude variables, gender and computer anxiety. Three intact classes of 35 students each from the Department of Mathematics and Science Education at Pingtung Teacher’s College in Taiwan were randomly assigned to a procedural programming group (QuickBASIC), a logic programming group (Turbo Prolog), and a control group. The study followed a nine-week schedule, the first and the last weeks designated for administration of pre-and post-tests, respectively. An ANCOVA analysis and a multiple regression analysis were used to test statistical hypotheses about programming effects and interactions.Findings of this study indicate that procedural programming is effective in developing procedural thinking skills, while logic programming is effective in developing declarative thinking skills. Neither programming environment had a significant effect on the development of conditional thinking skills. In terms of cognitive development, female students performed better than male students in a logic programming environment, while the reverse was true in a procedural programming environment. No significant interaction was found between computer anxiety and types of programming instruction.Implications of this study for teaching practice are (a) serious consideration of including both procedural programming and logic programming environments in the school curriculum, (b) developing optimum computing environments that foster all procedural thinking, declarative thinking, and conditional thinking skills, (c) cultivating students’ abilities to solve daily-life oriented problems with logic programming environments, and (d) adapting programming environments to individual differences. In addition, future studies should concentrate more on identifying near transfer rather than far transfer effects. Recommendations for future research are provided in this dissertation.",
    "author": [
      {
        "family": "Chou",
        "given": "Wen-Chung"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/163789",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "note": "UMI Order No. GAX93-28999",
    "publisher": "University of Illinois at Urbana-Champaign",
    "publisher-place": "USA",
    "title": "The effects of programming instruction in procedural programming and logic programming environments on problem-solving ability",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3563657.3596042",
    "ISBN": "9781450398930",
    "URL": "https://doi.org/10.1145/3563657.3596042",
    "abstract": "Hybrid learning modalities, where learners can attend a course in-person or remotely, have gained particular significance in post-pandemic educational settings. In introductory programming courses, novices’ learning behaviour in the collaborative context of classrooms differs in hybrid mode from that of a traditional setting. Reflections from conducting an introductory programming course in hybrid mode led us to recognise the need for re-designing programming tools to support students’ collaborative learning practices. We conducted a participatory design study with nine students, directly engaging them in design to understand their interaction needs in hybrid pedagogical setups to enable effective collaboration during learning. Our findings first highlighted the difficulties that learners face in hybrid modes. The results then revealed learners’ preferences for design functionalities to enable collective notions, communication, autonomy, and regulation. Based on our findings, we discuss design principles and implications to inform the future design of collaborative programming environments for hybrid modes.",
    "author": [
      {
        "family": "Goswami",
        "given": "Lahari"
      },
      {
        "family": "Zeinoddin",
        "given": "Pegah Sadat"
      },
      {
        "family": "Estier",
        "given": "Thibault"
      },
      {
        "family": "Cherubini",
        "given": "Mauro"
      }
    ],
    "collection-title": "DIS ’23",
    "container-title": "Proceedings of the 2023 ACM designing interactive systems conference",
    "id": "10.1145/3563657.3596042",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "collaboration, hybrid classroom, participatory design, programming environment",
    "page": "1248-1262",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting collaboration in introductory programming classes taught in hybrid mode: A participatory design study",
    "title-short": "Supporting collaboration in introductory programming classes taught in hybrid mode",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2676723.2693622",
    "ISBN": "9781450329668",
    "URL": "https://doi.org/10.1145/2676723.2693622",
    "abstract": "Graphical blocks-based programming environments, such as Scratch and Snap!, are becoming increasingly popular tools for introducing learners to programming in formal educational settings. However, a growing body of research is finding that students struggle when transitioning from these tools to more conventional, text-based programming languages. To better understand students’ difficulties and begin to explore potential solutions to facilitate this transition, a 10-week, quasi-experimental study was conducted with 80 students across three high-school introductory programming classes. Each class spent five weeks working with different version of a blocks-based programming tool, each of which integrated text-based programming in a different way. After working in the introductory environments, students transitioned to Java for the remainder of the study. The goal of this project is to understand the affects of blocks-based programming on students’ emerging understandings, document challenges students face in transitioning from blocks-based to text-based programming, and investigate potential ways to bridge these two modalities. To answer these questions, a mixed-method approach was taken that included cognitive interviews with learners, automated collection of student authored programs, and pre/mid/post attitudinal and content assessments.",
    "author": [
      {
        "family": "Weintrop",
        "given": "David"
      }
    ],
    "collection-title": "SIGCSE ’15",
    "container-title": "Proceedings of the 46th ACM technical symposium on computer science education",
    "id": "10.1145/2676723.2693622",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "blocks-based programming, high school computer science, introductory programming environments",
    "page": "720",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Minding the gap between blocks-based and text-based programming (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/949344.949394",
    "ISBN": "1581137516",
    "URL": "https://doi.org/10.1145/949344.949394",
    "abstract": "In the second-semester programming course at the University of Utah, we have observed that our students suffer unnecessarily from a mismatch between the course content and the programming environment. The course is typical, in that it exposes students to Java a little at a time. The programming environments are also typical, in that they report compilation and run-time errors in the jargon of professional programmers who use the full Java language. As a result, students rely heavily on teaching assistants to interpret error messages, and valuable classroom time is wasted on syntactic diversions.ProfessorJ is our new programming environment that remedies this problem. Like other pedagogical environments, such as BlueJ and DrJava, ProfessorJ presents the student with a simplified interface to the Java compiler and virtual machine. Unlike existing environments, ProfessorJ tailors the Java language and error messages to the students’ needs. Since their needs evolve through the course, ProfessorJ offers several language levels, from Beginner Java to Full Java.",
    "author": [
      {
        "family": "Gray",
        "given": "Kathryn E."
      },
      {
        "family": "Flatt",
        "given": "Matthew"
      }
    ],
    "collection-title": "OOPSLA ’03",
    "container-title": "Companion of the 18th annual ACM SIGPLAN conference on object-oriented programming, systems, languages, and applications",
    "id": "10.1145/949344.949394",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "page": "170-177",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ProfessorJ: A gradual introduction to java through language levels",
    "title-short": "ProfessorJ",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/FIE44824.2020.9273982",
    "URL": "https://doi.org/10.1109/FIE44824.2020.9273982",
    "abstract": "This Research Full Paper presents our experience in analyzing and selecting block-based programming environments to support the teaching of algorithms for the students starting the introductory courses of a Computer Science major. The teaching of algorithms and programming concepts to students of the first years of Computer Science and Engineering courses has been a major challenge because students often have difficulty understanding the logic and abstraction, leading to a high dropout rate. Some strategies have been conducted to further the mission of helping students understand better those basic concepts, but this topic still remains a major problem for students in the initial grades of those courses. In previous projects developed at our university, we have already proposed the use of learning objects and gamification, with very positive results. One of the questions that arise when we adopt new teaching approaches is to know how this new path will contribute to the student’s learning. In this project, we conducted a study on eight block-based programming environments and sought to identify which aspects of those environments comply with the Computer Science reference curriculum. Our work was based on the joint task force on Computing Curricula conducted by the ACM and IEEE Computer Society CS2013 curriculum guidelines for undergraduate programs in Computer Science. We studied the virtual programming environments Alice, MIT App Inventor, Blockly Games, Code.org, Gameblox, Pencil Code, Microsoft MakeCode and Scratch. Then, we crossed the characteristics of each, identified the positive and negative points of each teaching environment in relation to the topics established by the guidelines. We have classified the main characteristics of those programming environments, establishing criteria such as: prior programming knowledge requirements; ease of interaction with users; programming language code; availability of documentation for learning; programming practices addressed by the environment; and ease of learning programming. We believe that this work can contribute to the selection process of a suitable programming environment to be adopted in an introductory course of computer programming.",
    "author": [
      {
        "family": "Carlos Begosso",
        "given": "Luiz"
      },
      {
        "family": "Ricardo Begosso",
        "given": "Luiz"
      },
      {
        "family": "Aragao Christ",
        "given": "Natalia"
      }
    ],
    "container-title": "2020 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE44824.2020.9273982",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "page": "1-5",
    "publisher": "IEEE Press",
    "publisher-place": "Uppsala",
    "title": "An analysis of block-based programming environments for CS1",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/299649.299718",
    "ISBN": "1581130856",
    "URL": "https://doi.org/10.1145/299649.299718",
    "abstract": "Recursion is a powerful and essential computational problem solving tool, but the concept of recursion is difficult to comprehend. Students that master the conventional programming construct of iteration in procedural programming environments, find it hard to utilize recursion.This study started as a test of CS College students’ utilization of recursion. It was conducted after they have completed CS1, where they studied recursion with the C programming language. The test revealed that students adhere to the iterative pattern of \"forward accumulation\", due to their confidence with the iteration construct, but lack of trust of the recursion mechanism. These results motivated us to get more insight into the nature of recursion difficulties and ways to overcome them.In this paper we describe the difficulties we observed, and present a declarative, abstract, approach that contributed to overcome them. We question the emphasis that should be put on the basic computing model when presenting recursion, and argue for emphasis on the declarative approach for teaching recursion formulation in a procedural programming environment.",
    "author": [
      {
        "family": "Ginat",
        "given": "David"
      },
      {
        "family": "Shifroni",
        "given": "Eyal"
      }
    ],
    "collection-title": "SIGCSE ’99",
    "container-title": "The proceedings of the thirtieth SIGCSE technical symposium on computer science education",
    "id": "10.1145/299649.299718",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "keyword": "problem decomposition, recursive formulation",
    "page": "127-131",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Teaching recursion in a procedural environment—how much should we emphasize the computing model?",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3287324.3293798",
    "ISBN": "9781450358903",
    "URL": "https://doi.org/10.1145/3287324.3293798",
    "abstract": "With national K-12 education initiatives such as \"CSForAll,\" block-based programming environments have emerged as widely used tools for teaching novice programming. A key challenge presented by block-based programming environments is assessing students’ computational thinking (CT) and programming competencies. Developing assessment methods that can evaluate students’ use of CT practices such as testing and refining, and developing and using appropriate algorithms, can help teachers evaluate students learning and provide appropriate scaffolding. In this work, we utilize an evidence-centered assessment design approach to devise a three-dimensional assessment to evaluate students’ CT competencies based on evidence extracted from their programming trajectories in a block-based programming environment. In this assessment, the first dimension assesses students’ knowledge of essential CT concepts, the second dimension assesses students’ dynamic testing and refining strategies, and the third dimension assesses their overall problem-solving efficiency. We apply the assessment framework to data collected from students’ interactions with a game-based learning environment designed to develop middle-grade students’ CT competencies and programming skills. The results demonstrate that students’ knowledge of basic CT constructs, such as appropriate use and combination of control structures, serves as the foundation for designing and implementing effective algorithms. Further, we assessed students testing and refining strategies over the three dimensions of novelty, positivity, and scale. The results demonstrate that students with higher algorithmic capabilities tend to make more novel, positive, and small-scale changes. The results reveal distinctive patterns in students’ approaches to computational thinking problem solving and make a step toward identifying and assessing productive computational thinking practices.",
    "author": [
      {
        "family": "Akram",
        "given": "Bita"
      },
      {
        "family": "Min",
        "given": "Wookhee"
      },
      {
        "family": "Wiebe",
        "given": "Eric"
      },
      {
        "family": "Mott",
        "given": "Bradford"
      },
      {
        "family": "Boyer",
        "given": "Kristy Elizabeth"
      },
      {
        "family": "Lester",
        "given": "James"
      }
    ],
    "collection-title": "SIGCSE ’19",
    "container-title": "Proceedings of the 50th ACM technical symposium on computer science education",
    "id": "10.1145/3287324.3293798",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "block-based programming, computational thinking assessment, evidence-centered design, game-based learning, programming trajectories",
    "page": "1269",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Assessing middle school students’ computational thinking through programming trajectory analysis",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/62115.62131",
    "ISBN": "0897912764",
    "URL": "https://doi.org/10.1145/62115.62131",
    "abstract": "For three years, members of the Computer Science Department at the University of Rochester have used a collection of BBN Butterfly™ Parallel Processors to conduct research in parallel systems and applications. For most of that time, Rochester’s 128-node machine has had the distinction of being the largest shared-memory multiprocessor in the world. In the course of our work with the Butterfly we have ported three compilers, developed five major and several minor library packages, built two different operating systems, and implemented dozens of applications. Our experience clearly demonstrates the practicality of large-scale shared-memory multiprocessors, with non-uniform memory access times. It also demonstrates that the problems inherent in programming such machines are far from adequately solved. Both locality and Amdahl’s law become increasingly important with a very large number of nodes. The availability of multiple programming models is also a concern; truly general-purpose parallel computing will require the development of environments that allow programs written under different models to coexist and interact. Most important, there is a continuing need for high-quality programming tools; widespread acceptance of parallel machines will require the development of programming environments comparable to those available on sequential computers.",
    "author": [
      {
        "family": "LeBlanc",
        "given": "Thomas J."
      },
      {
        "family": "Scott",
        "given": "Michael L."
      },
      {
        "family": "Brown",
        "given": "Christopher M."
      }
    ],
    "collection-title": "PPEALS ’88",
    "container-title": "Proceedings of the ACM/SIGPLAN conference on parallel programming: Experience with applications, languages and systems",
    "id": "10.1145/62115.62131",
    "issued": {
      "date-parts": [
        [
          1988
        ]
      ]
    },
    "page": "161-172",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Large-scale parallel programming: Experience with BBN butterfly parallel processor",
    "title-short": "Large-scale parallel programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.compedu.2016.01.010",
    "ISSN": "0360-1315",
    "URL": "https://doi.org/10.1016/j.compedu.2016.01.010",
    "abstract": "This study aims to advocate that a visual programming environment offering graphical items and states of a computational problem could be helpful in supporting programming learning with computational problem-solving. A visual problem-solving environment for programming learning was developed, and 158 college students were conducted in a computational problem-solving activity. The students’ activities of designing, composing, and testing solutions were recorded by log data for later analysis. To initially unveil the students’ practice and strategies exhibited in the visual problem-solving environment, this study proposed several indicators to quantitatively represent students’ computational practice (Sequence, Selection, Simple iteration, Nested iteration, and Testing), computational design (Problem decomposition, Abutment composition, and Nesting composition), and computational performance (Goal attainment and Program size). By the method of cluster analysis, some empirical patterns regarding the students’ programming learning with computational problem-solving were identified. Furthermore, comparisons of computational design and computational performance among the different patterns of computational practice were conducted. Considering the relations of students’ computational practice to computational design and performance, evidence-based suggestions on the design of supportive programming environments for novice programmers are discussed. A visual problem-solving environment was proposed to support programming learning.Students exhibited different patterns of computational practice in the environment.Patterns of computational practice were correlated with computational design and performance.",
    "author": [
      {
        "family": "Chao",
        "given": "Po-Yao"
      }
    ],
    "container-title": "Comput. Educ.",
    "id": "10.1016/j.compedu.2016.01.010",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2016,
          4
        ]
      ]
    },
    "keyword": "Computer programming, Students programming patterns, Visual problem solving",
    "page": "202-215",
    "publisher": "Elsevier Science Ltd.",
    "publisher-place": "GBR",
    "title": "Exploring students’ computational practice, design and performance of problem-solving through a visual programming environment",
    "type": "article-journal",
    "volume": "95"
  },
  {
    "DOI": "10.4018/IJWLTT.2017100106",
    "ISSN": "1548-1093",
    "URL": "https://doi.org/10.4018/IJWLTT.2017100106",
    "abstract": "Teaching programming is a complex task. The task is even more challenging for introductory modules. There is an ongoing debate in the teaching community over the best approach to teaching introductory programming. Visual block-based programming environments allow school students to create their own programs in ways that are more accessible than in textual programming environments. These environments designed for education allow students to program without the obstacle of syntax errors errors in typing commands found in traditional text-based languages. In this paper, the authors focus on the use of App Inventor and Scratch as blocks-based programming environments designed explicitly with novices in mind. In the authors’ analysis, both Novice Programming Environments NPEs seemed to be attractive platforms for introducing fundamental concepts in computer programming and both look appealing for both majors and non-majors.",
    "author": [
      {
        "family": "Papadakis",
        "given": "Stamatios"
      },
      {
        "family": "Kalogiannakis",
        "given": "Michail"
      },
      {
        "family": "Orfanakis",
        "given": "Vasileios"
      },
      {
        "family": "Zaranis",
        "given": "Nicholas"
      }
    ],
    "container-title": "Int. J. Web-Based Learn. Teach. Technol.",
    "id": "10.4018/IJWLTT.2017100106",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2017,
          10
        ]
      ]
    },
    "keyword": "App Inventor for Android AIA, Novice Programmers, Novice Programming Environments NPEs, Primary Education, Scratch, Secondary Education",
    "page": "58-77",
    "publisher": "IGI Global",
    "publisher-place": "USA",
    "title": "The appropriateness of scratch and app inventor as educational environments for teaching introductory programming in primary and secondary education",
    "type": "article-journal",
    "volume": "12"
  },
  {
    "DOI": "10.1109/ICALT.2005.310",
    "ISBN": "0769523382",
    "URL": "https://doi.org/10.1109/ICALT.2005.310",
    "abstract": "This paper discusses the pilot testing and evaluation of a database-driven web-based programming environment called WIPE (Web Integrated Programming Environment). WIPE is a teaching tool for secondary education students that are introduced to the principles of programming. The programming environment was used in secondary schools in Greece and the results of its evaluation demonstrate that it successfully deals with the difficulties novices meet.",
    "author": [
      {
        "family": "Evangelidis",
        "given": "Georgios"
      }
    ],
    "collection-title": "ICALT ’05",
    "container-title": "Proceedings of the fifth IEEE international conference on advanced learning technologies",
    "id": "10.1109/ICALT.2005.310",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "928-932",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "WIPE \" pilot testing and comparative evaluation",
    "type": "paper-conference"
  },
  {
    "ISBN": "9798728297147",
    "abstract": "Blocks-based programming environments have become commonplace in introductory computing courses in K-12 schools and some college level courses. In comparison, most college-level introductory computer science courses teach students text-based languages which are more commonly used in industry and research. However, the literature provides evidence that students may face difficulty moving to text-based programming environments even when moving from blocks-based environments, and some perceive blocks-based environments as inauthentic. Bi-directional dual-modality programming environments, which provide multiple representations of programming language constructs (such as blocks and text) and allow students to transition between them freely, offer a potential solution to issues of authenticity and syntax challenges for novices and those with prior experience in blocks by making clear the connection between blocks and text representations of programs. While previous research has investigated transition from blocks-based to textual environments, there is limited research on dual-modality programming environments.The goal of my dissertation work is to identify how use of bi-directional dual-modality programming environments connects with learning in introductory programming instruction at the college level. I have developed a bi-directional dual-modality Java language plugin and evaluated the use of said tool within an introductory computer science (CS1) course. In my work I analyzed understanding and retention of specific computing / programming concepts, how any connections vary according to prior programming experience, and in what ways dual-modality programming environments affect the classroom learning experience.",
    "author": [
      {
        "family": "Blanchard",
        "given": "Jeremiah J."
      },
      {
        "family": "Boyer",
        "given": "Kristy"
      },
      {
        "family": "Huggins-Manley",
        "given": "Anne"
      },
      {
        "family": "Weintrop",
        "given": "David"
      },
      {
        "family": "Wilson",
        "given": "Joseph"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI28087160",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "note": "AAI28087160",
    "publisher": "University of Florida",
    "publisher-place": "USA",
    "title": "Building bridges: Dual-modality instruction and introductory programming coursework",
    "title-short": "Building bridges",
    "type": "thesis"
  },
  {
    "ISBN": "3540426094",
    "abstract": "The need for realistic simulations of complex systems relevant to the modeling of several modern technologies and environmental phenomena increasingly stimulates the development of advanced computing approaches. Nowadays it is possible to cluster or couple a wide variety of resources including supercomputers, storage systems, data sources, and special classes of devices distributed geographically and use them as a single unified resource, thus forming what is popularly known as a \"computational grid\" [1,2].Grid Computing enables the development of large scientific applications on an unprecedented scale. Grid-aware applications (meta-applications, multidisciplinary applications) make use of coupled computational resources that cannot be replicated at a single site. In this light, grids let scientists solve larger or new problems by pooling together resources that could not be coupled easily before. Designing and implementing grid-aware applications often require interdisciplinary collaborations involving aspects of scientific computing, visualization, and data management [3]. Multi-disciplinary applications are typically composed of large and complex components, and some of them are characterized by huge high performance requirements [4,5,6,7]. In order to get better performance, the challenge is to map each component onto the best candidate computational resource having a high degree of affinity with the software component. This kind of mapping is a non-trivial task. Moreover, it is well known that, in general, the programmer’s productivity in designing and implementing efficient parallel applications on high performance computers remains a very time-consuming task. Grid computing makes the situation worse as heterogeneous computing environments are combined so that the programmer must manage an enormous amount of details. Consequently, the development of grid programming environments that would enable programmers to efficiently exploit this technology is an important and hot research issue. A grid programming environment should include interfaces, APIs, utilities and tools so as to provide a rich development environment. Common scientific languages such as C, C++, Java and Fortran should be available, as should application-level interfaces like MPI and PVM. A range of programming paradigms should be supported, such as message passing and distributed shared memory. In addition, a suite of numerical and other commonly used libraries should be available.Today, an interesting discussion is opened about the need to thinkat new abstract programming models and develop novel programming techniques addressing specifically the grid, which would deal with the heterogeneity and distributed computing aspects of grid programming [8].In this talk, after an introduction on the main grid programming issues, an overview of the most important approaches/projects conducted in this field worldwide will be presented. In particular, the speaker’s contribution in designing some grid extension for a new programming environment will be shown. This workconstitutes a joint effort conducted by some academic and industrial Italian partners, in particular the Department of Computer Science of the Pisa University and CNUCE-CNR, in the frameworkof the ASI-PQE2000 National Project aimed at building ASSIST (A Software development System based on Integrated Skeleton Technology) [9,10,11]. The main target for the ASSIST Team is to build of a new programming environment for the development of high performance applications, based on the integration of the structured parallel programming model and the objects (components) model. In this way, ASSIST should be available for a wide range of hardware platforms from the homogeneous parallel computers (MPP, SMP, CoWs) to the heterogeneous ones (Grids).",
    "author": [
      {
        "family": "Laforenza",
        "given": "Domenico"
      }
    ],
    "container-title": "Proceedings of the 8th european PVM/MPI users’ group meeting on recent advances in parallel virtual machine and message passing interface",
    "id": "10.5555/648138.746794",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "page": "8-9",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Programming high performance applications in grid environments",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3328778.3372699",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3372699",
    "abstract": "Computational thinking (CT) is a problem solving approach that is becoming prominent in educational settings. To help ease students into the world of programming, visual programming tools such as Scratch are used. Researchers are also developing various tools in an attempt to assess students’ proficiency in thought processes that make up CT. However, current existing tools mainly utilize students’ final code products when evaluating their demonstration of CT, losing their opportunity to understand students’ actual learning and programming procedures. This work presents a logging methodology that records programming actions of students in the Scratch block coding environment to enable an in-depth analysis of students’ programming process. With this logging methodology, we conducted a case study with introductory programmers to study how the logs of students’ programming processes can provide insight into how they practice CT during programming.",
    "author": [
      {
        "family": "Kong",
        "given": "Minji"
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3372699",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "block-based-programming, computational-thinking, logging, novice-programmer-learning",
    "page": "1422",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Increasing understanding of students’ programming process through scratch programming event data analysis",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3328778.3366865",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3366865",
    "abstract": "In college-level introductory computer science courses, students traditionally learn to program using text-based languages which are common in industry and research. This approach means that learners must concurrently master both syntax and semantics. Blocks-based programming environments have become commonplace in introductory computing courses in K-12 schools and some colleges in part to simplify syntax challenges. However, there is evidence that students may face difficulty moving to text-based programming environments when starting with blocks-based environments. Bi-directional dual-modality programming environments provide multiple representations of programming language constructs (in both blocks and text) and allow students to transition between them freely. Prior work has shown that some students who use dual-modality environments to transition from blocks to text have more positive views of text programming compared to students who move directly from blocks to text languages, but it is not yet known if there is any impact on learning. To investigate the impact on learning, we conducted a study at a large public university across two semesters in a CS1 course (N=673). We found that students performed better on typical course exams when they were taught using dual-modality representations in lecture and were provided dual-modality tools. The results of our work support the conclusion that dual-modality instruction can help students learn computational concepts in early college computer science coursework.",
    "author": [
      {
        "family": "Blanchard",
        "given": "Jeremiah"
      },
      {
        "family": "Gardner-McCune",
        "given": "Christina"
      },
      {
        "family": "Anthony",
        "given": "Lisa"
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3366865",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "computer science education, cs1, blocks-based programming environments, dual-modality programming environments, novice programmers, programming languages",
    "page": "818-824",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Dual-modality instruction and learning: A case study in CS1",
    "title-short": "Dual-modality instruction and learning",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3290511.3290525",
    "ISBN": "9781450365178",
    "URL": "https://doi.org/10.1145/3290511.3290525",
    "abstract": "In Japan, all high school students will study programming in next teaching guidelines. It is important to use suitable environment or tool for programming education. Some current textbooks show programs written in JavaScript and instruct students to use text editor and browser as development environment. But such environment has some problems; it requires students to manage multiple applications, to find errors with little information and to type long statements. We developed \"Bit Arrow\", an online programming environment. The environment helps students to find errors. Also the environment provides API to write statements shortly. In this report, we describe design and evaluation of Bit Arrow from students’ log data.",
    "author": [
      {
        "family": "Nagashima",
        "given": "Kazuhei"
      },
      {
        "family": "Cho",
        "given": "Shinya"
      },
      {
        "family": "Horikoshi",
        "given": "Masayuki"
      },
      {
        "family": "Manabe",
        "given": "Hiroki"
      },
      {
        "family": "Kanemune",
        "given": "Susumu"
      },
      {
        "family": "Namiki",
        "given": "Mitaro"
      }
    ],
    "collection-title": "ICETC ’18",
    "container-title": "Proceedings of the 10th international conference on education technology and computers",
    "id": "10.1145/3290511.3290525",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "Javascript, education support, programming education, web-based environment",
    "page": "85-91",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design and development of bit arrow: A web-based programming learning environment",
    "title-short": "Design and development of bit arrow",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1002/cae.6180020105",
    "ISSN": "1061-3773",
    "URL": "https://doi.org/10.1002/cae.6180020105",
    "abstract": "The CH programming environment is an open system. Users can enhance the system through its various user interfaces. CH is specially designed for applications in mechanical systems engineering, although it is applicable to many other disciplines as well. CH has been successfully used as a teaching and learning tool for an undergraduate course, Computer-Aided Mechanism Design, at the University of California, Davis in Fall 1993. In this article we will present the CH programming environment and programming features developed for teaching and student learning. We will describe how a teaching toolbox is developed and used for teaching mechanism design. Source codes in the teaching toolbox are available to students so that they can study the software implementation of algorithms and modify the codes to solve similar problems. Although the developed teaching toolbox is specific for instruction on mechanism design, the CH programming environment and ideas presented in this article are general, and they are applicable to instructional improvement for a wide range of subjects in engineering.",
    "author": [
      {
        "family": "Cheng",
        "given": "Harry H."
      }
    ],
    "container-title": "Comput. Appl. Eng. Educ.",
    "id": "10.1002/cae.6180020105",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1994,
          1
        ]
      ]
    },
    "page": "23-39",
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "Pedagogically effective programming environment for teaching mechanism design",
    "type": "article-journal",
    "volume": "2"
  },
  {
    "DOI": "10.1145/3568812.3603492",
    "ISBN": "9781450399753",
    "URL": "https://doi.org/10.1145/3568812.3603492",
    "abstract": "Authentic learning, characterized by engagement with real-world problems and tools, has long been of interest in education due to its impact on student motivation and learning outcomes [2, 7]. In computer science (CS) education, however, students and teachers face the challenge of balancing the desire to teach and learn \"real\" programming with the need for a gentle and scaffolded introduction to this highly abstract and cognitively demanding discipline [4]. As a tool-dependent discipline, the tension between authentic and scaffolded is particularly evident in the perceived in-authenticity of educational programming tools. While scaffolded blocks-based programming tools are approachable [14] and beneficial for learning [3, 10], they are often perceived as less authentic by high school students [4, 14], which can be demotivating. Conversely, \"real\" text-based programming, while authentic, can be difficult and intimidating, creating a barrier to learning and engagement [10, 14]. This dichotomy exemplifies a challenge in CS education: how can we provide an authentic learning experience through tools that are both approachable and representative of authentic programming practice? Addressing this challenge necessitates understanding what \"authenticity\" means in the context of CS education. Authenticity, a multi-dimensional and complex concept, encompasses dimensions of real-world relevance, disciplinary relevance, and personal relevance, each of which can be further decomposed [8, 9, 11, 12, 13]. Crucially, it is each individual student’s perception of authenticity, rather than an objective measure, that impacts their learning [2, 5]. While efforts have been made to create more authentic educational programming tools and curricula [1, 4, 6], these efforts adopt a top-down approach, with limited understanding of students’ rich, multi-faceted perceptions of authentic programming. Our study takes a bottom-up approach. We aim to first understand high school students’ perceptions of authentic programming. Our research questions for this study are: (1) What do students mean by “real programming”? (2) Do theories of authenticity accurately model students’ perception of authentic educational programming tools? (3) How do students assess existing educational programming tools’ authenticity and what affects that assessment? (4) How does identity, background, and experience affect perceptions of authenticity? We employ a mixed-methods approach, combining quantitative surveys with qualitative interviews. Informed by frameworks [8] and models [11] of authentic learning, we have designed a survey instrument to explore our research questions. Subsequent interviews will identify the characteristics of a given tool that lead to student perceptions of its authenticity, and probe how these perceptions affect student motivation to learn using said tool. This first stage of our research will enhance our understanding of the qualities of programming tools that affect students’ perception of authenticity. This understanding could lead to insights about the design of authentic learning tools and how to match students with educational programming tools that they find to be authentic. A later stage will leverage those insights to discover design techniques to create a sense of authenticity without sacrificing scaffolded learning. Overall, our research aims to contribute to an understanding of authentic learning in CS education and to develop theories and methods to design for perceived authenticity.",
    "author": [
      {
        "family": "Tran",
        "given": "Caryn"
      },
      {
        "family": "O’Rourke",
        "given": "Eleanor"
      }
    ],
    "collection-title": "ICER ’23",
    "container-title": "Proceedings of the 2023 ACM conference on international computing education research - volume 2",
    "id": "10.1145/3568812.3603492",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "authentic learning, high school, programming, student perception",
    "page": "37-38",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "UUnderstanding novices’ perceptions of “authentic” programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3328778.3366943",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3366943",
    "abstract": "Pair Programming is often employed in educational settings as a means of promoting collaboration and scaffolding the assignment difficulty for teams. While much research supports its inclusion as a pedagogical practice at the university level, some research has demonstrated in K-12 contexts, it can potentially lead to inequitable learning enviroments and create dynamics between partners that might negatively effect novice learners. New block-based programming environments like Netsblox have attempted to address this by creating ways for both partners to program simultaneously, but this feature has yet to be examined in detail. In this paper, we introduce several modes of Collaboration afforded by Netsblox. This includes Pair-Separate, Pair-Together, and Partner Puzzles - a mode that Splits the necessary blocks to build the assignment between team members. From an initial pilot study involving 25 pairs of middle and high school students, we find that most pairs preferred working on assignments in the Partner Puzzle mode as it presented a fun challenge to teams. We end on recommendations for building assignments using this methodology and future research directions investigating the role of collaboration in programming",
    "author": [
      {
        "family": "Lytle",
        "given": "Nicholas"
      },
      {
        "family": "Milliken",
        "given": "Alexandra"
      },
      {
        "family": "Cateté",
        "given": "Veronica"
      },
      {
        "family": "Barnes",
        "given": "Tiffany"
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3366943",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "block-based environments, collaboration, pair-programming",
    "page": "832-838",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating different assignment designs to promote collaboration in block-based environments",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1595356.1595361",
    "ISBN": "9781605583853",
    "URL": "https://doi.org/10.1145/1595356.1595361",
    "abstract": "At schools special learning and programming environments are often used in the field of algorithm. Particularly with regard to informatics lessons in secondary education they should help novices to learn the basics of programming. In several parts of Germany (e. g. Bavaria) these fundamentals are even taught in the 7th grade, when pupils are 12 to 13 years old. Age-based designed learning and programming environments such as Karel, the robot and Kara, the programmable ladybug, are employed there, however learners still underachieve. One possible approach to improve both teaching and learning process is specifying the knowledge concerning the learners’ individual problem solving strategies, when they create their solutions in consideration of the solution attempt’s quality.A goal of the research project described here is being able to identify and categorise several problem solving strategies automatically. Due to this knowledge learning and programming environments can be improved which will optimise the informatics lessons, in which they are applied. Therefore the environments must be enhanced with special analytic and diagnostic modules, whose results can be given to the learner in the form of individualized system feedback messages in the future.In this text preliminary considerations are demonstrated. The research methodology as well as the design and the implementation of the research instruments are explained. We describe first studies, whose results are presented and discussed.",
    "author": [
      {
        "family": "Kiesmüller",
        "given": "Ulrich"
      }
    ],
    "collection-title": "Koli ’08",
    "container-title": "Proceedings of the 8th international conference on computing education research",
    "id": "10.1145/1595356.1595361",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "Kara, algorithms, didactics of informatics, problem solving process, secondary computer science education, tool-based analysis",
    "page": "16-24",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Diagnosing learners’ problem solving strategies using learning environments with algorithmic problems in secondary education",
    "type": "paper-conference"
  },
  {
    "abstract": "This study investigates the HyperCard programming environment from the perspectives of the educator, student and software developer. It is designed to provide a full-spectrum evaluation of HyperCard and its utility in education. First, the study attempts to determine if HyperCard is appropriate as an instructional language. Second, the study examines HyperCard’s potential as a programming environment for teachers and students. Finally, this report provides educators with extensive HyperCard programming examples and lesson plans. Two courses in HyperCard programming were designed and taught by the investigator. One course was presented to in-service teachers, the other to high school students. Student’s work was collected and evaluated for inclusion in the report. Three individuals from each course were selected as clinical study subjects. In-depth case studies chronicling each subject’s experiences and development are included in the report. The investigator also undertook two educationally relevant programming projects with HyperCard. One project involved the development of an administrative scheduling package for a high school. The second project used HyperCard to develop a library control and query package for a medium-sized library. These projects were intentionally selected to challenge HyperCard’s capabilities.Based upon the evaluations conducted, it appears that HyperCard can be mastered by teachers and students with little or no programming experience. Some of the in-service teachers with prior programming experience appeared to have difficulty adapting to certain aspects of the HyperCard environment. These individuals seemed reluctant to discard certain outdated programming habits and techniques. Students in the high school class achieved greater overall success in HyperCard programming. Information gleaned from the investigator’s experiences developing the software projects indicates that HyperCard is well-suited for the development of complex programs for use in educational settings. HyperCard facilitated the inclusion of graphics, sounds and other sophisticated features in the investigator’s programs.HyperCard seems to possess excellent potential for enriching education. HyperCard appears to be an effective medium for presenting introductory and advanced computer programming topics. HyperCard may also be used to create educational software which appropriately incorporates the capabilities of modern computing hardware. Further research is needed to evaluate HyperCard’s multimedia-oriented capabilities and their applications in education.",
    "author": [
      {
        "family": "Vogeli",
        "given": "Christian Bruce"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/125370",
    "issued": {
      "date-parts": [
        [
          1991
        ]
      ]
    },
    "note": "UMI Order No. GAX91-21218",
    "publisher": "Columbia University",
    "publisher-place": "USA",
    "title": "The applications of hypercard in an educational environment",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/2839509.2850528",
    "ISBN": "9781450336857",
    "URL": "https://doi.org/10.1145/2839509.2850528",
    "abstract": "Computational Thinking (CT) has been widely introduced and investigated in recent years, particularly in the U.S. since the born of visual, block-based, drag-drop programming environments such as Kodu, Scratch, Minecraft and App Inventor. Although the user interface is mainly in English, the characteristics of these easy-to-use, game-based, and interactive tools attract many teachers and researchers in the world to pay much attention to the possibilities and opportunities of introducing these tools to students. Recently, some primary school teachers in Hong Kong begin to independently introduce some of these programming tools to students at age 7 - 11 as a part of learning activities in their computer lessons. Their motives are similar but not the same, such as making a fun learning and teaching experience, motivating students for active and collaborative participation, and introducing CT concepts to develop generic skills (e.g. problem solving skills, creativity, and critical thinking). However, there is an absence of well-developed and planned curriculum for \"coding education\" to introduce computational thinking systematically to students in the local context with expected learning outcomes. Due to the uniqueness of K-12 curriculum in Hong Kong, the existing curriculum model in the U.S. may need to be customized and redesigned to become suitable for integrating into the curriculum in Hong Kong. In this poster, it describes the first proposed coding education curriculum in Hong Kong primary education (Primary 4 to Primary 6) with relevant objectives, structures, contents, and learning outcomes. A new pedagogical design framework for CT is introduced in this poster, which could be generalizable and yet to be evaluated. This new curriculum will serve as the curriculum guide to local teachers, and is the first research initiative of a three-year longitudinal study investigating the impact of CT activities to students particularly in Hong Kong. The experience of this curriculum development for CT concepts in K-12 education can inspire teachers and researchers in other parts of the world when adopting and internationalizing CT activities based on the curriculum model developed under the U.S. education.",
    "author": [
      {
        "family": "Wong",
        "given": "Gary K. W."
      },
      {
        "family": "Zhu",
        "given": "Kening"
      },
      {
        "family": "Ma",
        "given": "Xiaojuan"
      },
      {
        "family": "Huen",
        "given": "John"
      }
    ],
    "collection-title": "SIGCSE ’16",
    "container-title": "Proceedings of the 47th ACM technical symposium on computing science education",
    "id": "10.1145/2839509.2850528",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "coding education, computational thinking, international outreach for cs education, k-12 curriculum development",
    "page": "685",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The development of internationalized computational thinking curriculum in hong kong primary education (abstract only)",
    "type": "paper-conference"
  },
  {
    "ISBN": "9781605580845",
    "abstract": "Although Smalltalk is one of the oldest object-oriented programming languages, its conception and programming environment can still be considered as a design pearl and as a beacon in the realm of programming languages and programming environments. Other dynamic languages (such as Lisp, Scheme, Self,...) were similarly influential in expanding what software engineers can express with their programs.With the rising popularity of languages like Ruby, Python, Javascript, PHP, and with the growing challenges of aspect-orientation, pervasive computing, mobile code, and context-aware computing, dynamic languages are a worthy topic for further research. Therefore, ESUG decided to broaden the scope of the formerly \"Smalltalk only\" research track of its yearly meeting in order to enable cross-fertilization with research conducted using other dynamic languages. This way we hope to obtain more significant scientific results on various aspects of dynamicity in programming languages.This volume holds the papers that were presented during the 2007 edition of the conference which was held in Lugano, Switzerland. After careful reviewing by at least three reviewers we selected 11 papers out of 16 for inclusion in the conference. We took great care to avoid conflicts of interest by ensuring that reviewers did not have any formal connections to one of the authors of the papers they reviewed, namely (a) working in the same institution, university, or research group, (b) having written joint papers, (c) supervised earlier work, (d) had family ties, (e) or otherwise felt uncomfortable reviewing the work. The papers were reviewed using the typical academic standards: (a) present sound scientific work (a relevant problem, a convincing solution described in sufficient detail to allow replication, a sound validation, cite related work), (b) help the community (have something interesting to say to researchers working on dynamic programming languages in general and Smalltalk in particular), (c) reports something worthwhile for further reference (other researchers will cite this work in the future).",
    "id": "10.1145/1352678",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ICDL ’07: Proceedings of the 2007 international conference on dynamic languages: In conjunction with the 15th international smalltalk joint conference 2007",
    "title-short": "ICDL ’07",
    "type": "book"
  },
  {
    "DOI": "10.1109/ICSE.2017.59",
    "ISBN": "9781538638682",
    "URL": "https://doi.org/10.1109/ICSE.2017.59",
    "abstract": "In integrated development environments, developers receive compiler error messages through a variety of textual and visual mechanisms, such as popups and wavy red underlines. Although error messages are the primary means of communicating defects to developers, researchers have a limited understanding on how developers actually use these messages to resolve defects. To understand how developers use error messages, we conducted an eye tracking study with 56 participants from undergraduate and graduate software engineering courses at our university. The participants attempted to resolve common, yet problematic defects in a Java code base within the Eclipse development environment. We found that: 1) participants read error messages and the difficulty of reading these messages is comparable to the difficulty of reading source code, 2) difficulty reading error messages significantly predicts participants’ task performance, and 3) participants allocate a substantial portion of their total task to reading error messages (13",
    "author": [
      {
        "family": "Barik",
        "given": "Titus"
      },
      {
        "family": "Smith",
        "given": "Justin"
      },
      {
        "family": "Lubick",
        "given": "Kevin"
      },
      {
        "family": "Holmes",
        "given": "Elisabeth"
      },
      {
        "family": "Feng",
        "given": "Jing"
      },
      {
        "family": "Murphy-Hill",
        "given": "Emerson"
      },
      {
        "family": "Parnin",
        "given": "Chris"
      }
    ],
    "collection-title": "ICSE ’17",
    "container-title": "Proceedings of the 39th international conference on software engineering",
    "id": "10.1109/ICSE.2017.59",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "compiler errors, eye tracking, integrated development environments, programmer comprehension, reading, visual attention",
    "page": "575-585",
    "publisher": "IEEE Press",
    "publisher-place": "Buenos Aires, Argentina",
    "title": "Do developers read compiler error messages?",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1594399.1594402",
    "URL": "https://doi.org/10.1145/1594399.1594402",
    "abstract": "At schools special learning and programming environments are often used in the field of algorithms. Particularly with regard to computer science lessons in secondary education, they are supposed to help novices to learn the basics of programming. In several parts of Germany (e.g., Bavaria) these fundamentals are taught as early as in the seventh grade, when pupils are 12 to 13 years old. Designed age-based learning and programming environments such as Karel the robot and Kara, the programmable ladybug, are used, but learners still underachieve. One possible approach to improving both the teaching and the learning process is to specify the knowledge concerning the learners’ individual problem solving strategies, their solutions, and their respective quality.A goal of the research project described here is to design the learning environment so that it can identify and categorize several problem-solving strategies automatically. Based on this knowledge, learning and programming environments can be improved, which will optimize the computer science lessons in which they are applied. Therefore, the environments must be enhanced with special analytic and diagnostic modules, the results of which can be given to the learner in the form of individualized system feedback messages in the future.In this text preliminary considerations are demonstrated. The research methodology as well as the design and the implementation of the research instruments are explained. We describe first studies, whose results are presented and discussed.",
    "author": [
      {
        "family": "Kiesmüller",
        "given": "Ulrich"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/1594399.1594402",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2009,
          9
        ]
      ]
    },
    "keyword": "Kara, Secondary computer science education, algorithms, didactics of informatics, problem solving process, tool-based analysis",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Diagnosing learners’ problem-solving strategies using learning environments with algorithmic problems in secondary education",
    "type": "article-journal",
    "volume": "9"
  },
  {
    "DOI": "10.1145/2897586.2897613",
    "ISBN": "9781450341554",
    "URL": "https://doi.org/10.1145/2897586.2897613",
    "abstract": "Team collaboration plays a key role in the success of any multi-user activity. Software engineering is a highly collaborative activity, where multiple developers and designers work together to solve a common problem. Meaningful and effective designer-developer collaboration improves the user experience, which can improve the chances of success for the project. Learning to program is another activity that can be implemented in a more collaborative way, students can learn in an active style by working with others. The growth of online classes, from small structured seminars to massive open online courses (MOOCs), and the isolation and impoverished learning experience some students report in these, points to an urgent need for tools that support remote pair programming in a distributed educational setting.In this paper, we describe Jimbo, a collaborative integrated development environment (IDE) that we believe is beneficial and effective in both aforementioned activities. Jimbo integrates many features that support better collaboration and communication between designers and developers, to bridge communication gaps and develop mutual understanding. These novel features can improve today’s CS education by bringing students closer to each other and their instructors as well as training them to collaborate which is consistent with current practices in software engineering.",
    "author": [
      {
        "family": "Ghorashi",
        "given": "Soroush"
      },
      {
        "family": "Jensen",
        "given": "Carlos"
      }
    ],
    "collection-title": "CHASE ’16",
    "container-title": "Proceedings of the 9th international workshop on cooperative and human aspects of software engineering",
    "id": "10.1145/2897586.2897613",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "IDE, Jimbo, collaboration, collaborative learning, communication, designer-developer collaboration, distance learning, live preview, pair programming, user awareness, web development",
    "page": "104-107",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Jimbo: A collaborative IDE with live preview",
    "title-short": "Jimbo",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3478432.3499122",
    "ISBN": "9781450390712",
    "URL": "https://doi.org/10.1145/3478432.3499122",
    "abstract": "Interest in computer-based assessment has increased in recent years, most certainly due to a shift to online learning due to the COVID pandemic. Instructors are creating questiongenerators for Computer Science classes on PrairieLearn (PL), an open-source platform developed at the University of Illinois at Urbana-Champaign PrairieLearn. The software generates differentvariants of each question to students through randomization. The challenge up to now has been that automatically graded coding problems in RISC-V or Snap!, some of the significant languages used in undergraduate Computer Science courses at our university, weren’t possible to do within the software. Thequestion could be displayed, but then the student would have to load their favorite integrated development environment (IDE), code it up, and thenreturn to PL to upload their solution. This poster discusses our approach to embedding interactive development environments for Venus (RISC-V) and Snap! directly into PrairieLearn, so students never have to leave the browser tab!",
    "author": [
      {
        "family": "Yagubyan",
        "given": "Abel"
      },
      {
        "family": "Garcia",
        "given": "Dan"
      }
    ],
    "collection-title": "SIGCSE 2022",
    "container-title": "Proceedings of the 53rd ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3478432.3499122",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "computer-based testing, mastery learning",
    "page": "1168",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Seamless embedding of programming IDEs into computer-based testing software",
    "type": "paper-conference"
  },
  {
    "ISBN": "1526205092",
    "abstract": "The BBC micro:bit is a credit sized computer based on a highly popular and high performance ARM processor. The device is designed by a group of 29 partners for use in computer education in the UK and will be given free of charge to every secondary school student in the UK. This book is about the use of the BBC micro:bit computer in practical projects. The BBC micro:bit computer can be programmed using several different programming languages, such as Microsoft Block Editor, Microsoft Touch Develop, mikroPython, and JavaScript. The easy and popular Block Editor programming tool is used in this book. This is a graphical programming tool which is ideal for the beginners such as the year 7 students in UK. The book covers more than 27 tested and working projects using the Block Editor programming. The following are given for each project: Title of the project Description of the project Aim of the project Difficulty level Program listing Results Try for yourself",
    "author": [
      {
        "family": "Ibrahim",
        "given": "Dogan"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3066196",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Dogan Ibrahim",
    "title": "BBC micro: Bit 27 projects for students level 1 - simple projects",
    "title-short": "BBC micro",
    "type": "book"
  },
  {
    "DOI": "10.1007/s10639-022-11445-2",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-022-11445-2",
    "abstract": "Computational thinking is considered to be an important competence in the intelligent era, and the incorporation of computational thinking as an integral part of school education beginning in childhood has been proposed. However, the ways in which computational thinking can be taught more effectively the context of in K-12 programming teaching remain unclear. This paper reports the results of a meta-analysis of 28 empirical studies on K-12 programming teaching that were published in international education journals in the 21st century to determine which teaching methods and programming tools are most effective in promoting the computational thinking of K-12 students. The results show that (1) programming teaching can promote the improvement of K-12 students’ computational thinking (ES = 0.72, z = 9.9, P &lt; 0.01), with an overall effect at the upper-middle level (95",
    "author": [
      {
        "family": "Xu",
        "given": "Enwei"
      },
      {
        "family": "Wang",
        "given": "Wei"
      },
      {
        "family": "Wang",
        "given": "Qingxia"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-022-11445-2",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2022,
          11
        ]
      ]
    },
    "keyword": "Computational thinking, Programming tool, Teaching method, Effectiveness, Meta-analysis",
    "page": "6619-6644",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "A meta-analysis of the effectiveness of programming teaching in promoting k-12 students’ computational thinking",
    "type": "article-journal",
    "volume": "28"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "This paper reports our experiences using Eclipse for Java in our two-semester Java programming course sequence. Eclipse for Java is a fully featured professional Integrated Development Environment (IDE) with many advanced features. These features may overwhelm some of our students, especially those who have no programming background. In order to balance the use of an IDE that connects potential programmers with a professional community and our students’ learning needs, we have conducted various experiments for the last two years. We found that for teaching-oriented colleges like ours, one effective way to reach that balance is to introduce Java concepts and syntax using the JDK directly for several weeks at first and then gradually present IDE features using Eclipse for Java for the rest of the course sequence. Students who have gone through this process were able to learn language syntax and problem solving skills in addition to understanding the value of an IDE, giving them a level of confidence and excitement for using a professional development tool.",
    "author": [
      {
        "family": "Chen",
        "given": "Zhixiong"
      },
      {
        "family": "Marx",
        "given": "Delia"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1089053.1089068",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2005,
          12
        ]
      ]
    },
    "page": "104-112",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Experiences with eclipse IDE in programming courses",
    "type": "article-journal",
    "volume": "21"
  },
  {
    "DOI": "10.1145/3450613.3456833",
    "ISBN": "9781450383660",
    "URL": "https://doi.org/10.1145/3450613.3456833",
    "abstract": "Block-based programming environments are widely used in computer science education. However, these environments pose significant challenges for student modeling. Given a series of problem-solving actions taken by students in block-based programming environments, student models need to accurately infer problem-solving students’ programming abilities in real time to enable adaptive feedback and hints that are tailored to students’ abilities. While student models for block-based programming offer the potential to support student-adaptivity, creating student models for these environments is challenging because students can develop a broad range of solutions to a given programming activity. To address these challenges, we introduce a progression trajectory-based student modeling framework for modeling novice student block-based programming across multiple learning activities. Student trajectories utilize a time series representation that employs code analysis to incrementally compare student programs to expert solutions as students undertake block-based programming activities. This paper reports on a study in which progression trajectories were collected from more than 100 undergraduate students engaging in a series of block-based programming activities in an introductory computer science course. Using progression trajectory-based student modeling, we identified three distinct trajectory classes: Early Quitting, High Persistence, and Efficient Completion. Analysis of these trajectories revealed that they exhibit significantly different characteristics with respect to students’ actions and can be used to accurately predict students’ programming behaviors on future programming activities compared to competing baseline models. The findings suggest that progression trajectory-based student models can accurately model students’ block-based programming problem solving and hold potential for informing adaptive support in block-based programming environments.",
    "author": [
      {
        "family": "Morshed Fahid",
        "given": "Fahmid"
      },
      {
        "family": "Tian",
        "given": "Xiaoyi"
      },
      {
        "family": "Emerson",
        "given": "Andrew"
      },
      {
        "family": "B. Wiggins",
        "given": "Joseph"
      },
      {
        "family": "Bounajim",
        "given": "Dolly"
      },
      {
        "family": "Smith",
        "given": "Andy"
      },
      {
        "family": "Wiebe",
        "given": "Eric"
      },
      {
        "family": "Mott",
        "given": "Bradford"
      },
      {
        "family": "Elizabeth Boyer",
        "given": "Kristy"
      },
      {
        "family": "Lester",
        "given": "James"
      }
    ],
    "collection-title": "UMAP ’21",
    "container-title": "Proceedings of the 29th ACM conference on user modeling, adaptation and personalization",
    "id": "10.1145/3450613.3456833",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "189-200",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Progression trajectory-based student modeling for novice block-based programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2676723.2691916",
    "ISBN": "9781450329668",
    "URL": "https://doi.org/10.1145/2676723.2691916",
    "abstract": "Introducing programming concepts to children early in their education can be beneficial because the type of problem solving that encompasses computational thinking is becoming increasingly relevant in our daily lives. A relatively new breed of programming environments has emerged to address this need. Visual programming languages (VPLs) allow programming logic to be represented with diagrams that illustrate its execution flow. Popular VPLs (e.g., Scratch, Snap, Alice, App Inventor) exist as full-featured, stand-alone programming environments with diagrammatic representations of the program instructions. This representation removes the syntactical barrier to entry that may exist with textual languages.Blockly, developed by Google, is a type of block language development kit that allows the rapid construction of new block-based visual programming languages to address a specific pedagogical or content focus. This poster provides a brief tutorial on the steps used to create a new Blockly environment, along with two case studies demonstrating the power of Blockly. The two environments introduced are focused on the manipulation of images via operations on pixels (Pixly), and programmatic control of a Sphero robot (Spherly). The construction and specific details of these two environments are described and illustrated with html, xml, and Javascript code examples and some of their potential applications. More information about Pixly and Spherly can be found at: http://outreach.cs.ua.edu/pixly and http://outreach.cs.ua.edu/spherly",
    "author": [
      {
        "family": "Trower",
        "given": "Jake"
      },
      {
        "family": "Gray",
        "given": "Jeff"
      }
    ],
    "collection-title": "SIGCSE ’15",
    "container-title": "Proceedings of the 46th ACM technical symposium on computer science education",
    "id": "10.1145/2676723.2691916",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "blockly, media computation, robotics programming",
    "page": "677",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Creating new languages in blockly: Two case studies in media computation and robotics (abstract only)",
    "title-short": "Creating new languages in blockly",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-319-43518-3_7",
    "ISBN": "9783319435176",
    "URL": "https://doi.org/10.1007/978-3-319-43518-3_7",
    "abstract": "We developed a card-type programming tool \"Pro-Tan\" as an education tool for beginners in programming. This tool was designed to be usable without any instruction on its operations. In the experiment, we did not tell the users how to use any of the tools. The subjects were instructed to create a program by themselves. We found problems of Pro-Tan’s design in the experiment. In this paper, we report the system configuration of Pro-Tan and problem of Pro-Tan’s design.",
    "author": [
      {
        "family": "Tetsumura",
        "given": "Naoki"
      },
      {
        "family": "Oshima",
        "given": "Toru"
      },
      {
        "family": "Koyanagi",
        "given": "Ken’Ichi"
      },
      {
        "family": "Masuta",
        "given": "Hiroyuki"
      },
      {
        "family": "Motoyoshi",
        "given": "Tatsuo"
      },
      {
        "family": "Kawakami",
        "given": "Hiroshi"
      }
    ],
    "collection-title": "ICIRA 2016",
    "container-title": "Proceedings, part II, of the 9th international conference on intelligent robotics and applications - volume 9835",
    "id": "10.1007/978-3-319-43518-3_7",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "Active learning, Beginners, Programming education tool, RFID system, Tangible interface",
    "page": "71-77",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Interface design proposal of card-type programming tool",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/C5.2006.43",
    "ISBN": "0769525636",
    "URL": "https://doi.org/10.1109/C5.2006.43",
    "abstract": "We have designed a Problem-based Learning (PBL) curriculum called ISEC-SeT, which is designed for information science education in high schools using computer programming as a tool for problem solving. We adopted Squeak eToy and Excel VBA as programming environments for the PBL, and have practiced ISEC-SeT at Horikawa High School in Kyoto, Japan, from October 2004 to September 2005. Evaluation by teachers and students focused on the students’ presentations and essays on the projects shows that the students achieved problem solving abilities through the curriculum and that Squeak eToy provides them with a better environment for PBL than Excel VBA.",
    "author": [
      {
        "family": "Fujioka",
        "given": "Takeshi"
      },
      {
        "family": "Takada",
        "given": "Hideyuki"
      },
      {
        "family": "Kita",
        "given": "Hajime"
      }
    ],
    "collection-title": "C5 ’06",
    "container-title": "Proceedings of the fourth international conference on creating, connecting and collaborating through computing",
    "id": "10.1109/C5.2006.43",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "page": "42-49",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "What does squeak provide students with?— a comparative study of squeak eToy and excel VBA as tools for problem-solving learning in high school—",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800037.800962",
    "ISBN": "0897910362",
    "URL": "https://doi.org/10.1145/800037.800962",
    "abstract": "The first course in Computer Science at the University of Scranton has evolved over a number of years as a course in problem solving utilizing the computer. Bearing in mind that such a course should provide relatively standard programming tools, the course uses a structured derivative of FORTRAN promoting top-down stepwise refinement in programming methodology as well as encourages the utilization of “packaged programs”. We now have a course that provides a solid foundation for computer science majors as well as offers an excellent introduction to computing to those students for whom the course has a service purpose. This has been accomplished with a minimal faculty at a small university.",
    "author": [
      {
        "family": "Meinke",
        "given": "John G."
      },
      {
        "family": "Beidler",
        "given": "John A."
      }
    ],
    "collection-title": "SIGCSE ’81",
    "container-title": "Proceedings of the twelfth SIGCSE technical symposium on computer science education",
    "id": "10.1145/800037.800962",
    "issued": {
      "date-parts": [
        [
          1981
        ]
      ]
    },
    "keyword": "Algorithm development, Stepwise refinement, Structured programming, Top-down design",
    "page": "57-60",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Alternatives to the traditional first course in computing",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/971300.971403",
    "ISBN": "1581137982",
    "URL": "https://doi.org/10.1145/971300.971403",
    "abstract": "Various methods have been proposed in the past to improve student learning by introducing new styles of working with assignments. These include problem-based learning, use of case studies and apprenticeship. In most courses, however, these proposals have not resulted in a widespread significant change of teaching methods. Most institutions still use a traditional lecture/lab class approach with a strong separation of tasks between them. In part, this lack of change is a consequence of the lack of easily available and appropriate tools to support the introduction of new approaches into mainstream courses.In this paper, we consider and extend these ideas and propose an approach to teaching introductory programming in Java that integrates assignments and lectures, using elements of all three approaches mentioned above. In addition, we show how the BlueJ interactive programming environment [7] (a Java development environment aimed at education) can be used to provide the type of support that has hitherto hindered the widespread take-up of these approaches. We arrive at a teaching method that is motivating, effective and relatively easy to put into practice. Our discussion includes a concrete example of such an assignment, followed by a description of guidelines for the design of this style of teaching unit.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      },
      {
        "family": "Barnes",
        "given": "David J."
      }
    ],
    "collection-title": "SIGCSE ’04",
    "container-title": "Proceedings of the 35th SIGCSE technical symposium on computer science education",
    "id": "10.1145/971300.971403",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "keyword": "Java, objects-first, pedagogy",
    "page": "286-290",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Enhancing apprentice-based learning of java",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800104.803356",
    "ISBN": "9781450374071",
    "URL": "https://doi.org/10.1145/800104.803356",
    "abstract": "Much has been said about the importance of teaching top-down program design and structured programming in computer programming courses. However, instruction in these concepts has usually been limited to short homework assignments and at most to term projects. This type of experience is very different from the production programming environment encountered in industry, where the problems tackled are generally more complex and on a larger scale. Also, in many cases industrial programs are produced by a programming team under constraints in both time and resources. For students who aspire to a career in the software area, experience in a realistic production programming environment is desirable. Such experience is not provided in the traditional courses and novel ways have to be devised in order to bring it on campus.At Harvey Mudd College, an academic program, called the Mathematics Clinic, has been institured with the aim of providing this type of realistic experience to the student. The Mathematics Clinic brings problems from industry to be studied and solved by small teams of students under faculty supervision. The problems are selected for their educational value, but attention is paid to the feasibility of producing results that are of value to the sponsoring industrial concern.The general organization of the Clinic program has been described by Spanier (1). In the present paper, a production programming project undertaken by the Mathematics Clinic is described with emphasis placed on the mode of instruction and the experience gained by the students.",
    "author": [
      {
        "family": "Tam",
        "given": "W. C."
      },
      {
        "family": "Busenberg",
        "given": "S. N."
      }
    ],
    "collection-title": "SIGCSE ’77",
    "container-title": "Proceedings of the seventh SIGCSE technical symposium on computer science education",
    "id": "10.1145/800104.803356",
    "issued": {
      "date-parts": [
        [
          1977
        ]
      ]
    },
    "page": "31-36",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Practical experience in top-down structured software production in an academic setting",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3572549.3572610",
    "ISBN": "9781450397766",
    "URL": "https://doi.org/10.1145/3572549.3572610",
    "abstract": "Teaching introductory computer programming for first-year college students has been challenging. The challenges stem from the fact that teachers often struggle to find the best pedagogical strategies that address the cognitive needs and learning styles of a diverse group of learners. This paper discusses the results of a systematic study we have conducted to assess the effectiveness of improving students’ learning through active engagement, participation, and commitment. In particular, the study combines the utilization of multiple programming tools and learning aids along with carefully designed collaborative problem-solving activities and lab-based projects. The results of the study show evidence that such a combination promotes active learning and sharpens students’ problem-solving skills.",
    "author": [
      {
        "family": "Liu",
        "given": "Hong"
      },
      {
        "family": "Hossain",
        "given": "Md Nour"
      },
      {
        "family": "Alnusair",
        "given": "Awny"
      }
    ],
    "collection-title": "ICETC ’22",
    "container-title": "Proceedings of the 14th international conference on education technology and computers",
    "id": "10.1145/3572549.3572610",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "Active learning, Problem-based learning, Programing Tools",
    "page": "379-385",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Fostering active learning in introductory programming courses by utilizing multiple programming tools and enrichment activities",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1822090.1822134",
    "ISBN": "9781605588209",
    "URL": "https://doi.org/10.1145/1822090.1822134",
    "abstract": "To be able to support learners adequately in logic programming courses, it is crucial to know about their current level of competency during the learning process. Based on this, the course can be adapted and individual support can be given. In a traditional lecture the learning process is often a black box for the teacher, so there is no possibility to incorporate it. This paper describes how an architecture consisting of an online programming environment, private blogs and a reporting application can be used to solve the problem and shows how it was applied in the context of university lectures.",
    "author": [
      {
        "family": "Friese",
        "given": "Stefan"
      }
    ],
    "collection-title": "ITiCSE ’10",
    "container-title": "Proceedings of the fifteenth annual conference on innovation and technology in computer science education",
    "id": "10.1145/1822090.1822134",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "learning process evaluation, programming language education, reflection",
    "page": "152-154",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Measuring of and reacting to learners’ progress in logic programming courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2677089",
    "URL": "https://doi.org/10.1145/2677089",
    "abstract": "This article describes how smartphones, studio-based learning, and extensive scaffolding were used in combination in the teaching of a freshman Introduction to Programming course. To reduce cognitive overload, a phased approach was followed in introducing programming concepts and development environments, beginning with the visual programming environment Scratch and culminating with Java development for Android smartphones. Studio-based learning, a pedagogical approach long established in the fields of architecture and design education, was used as the basis for a collaborative social constructivist—and constructionist—approach to learning. Smartphones offered students the potential to develop applications for a context that is both immediate and clearly relevant to the ways in which they utilize and interact with technology.The research was carried out over three full academic years and included 53 student participants. An exploratory case study methodology was used to investigate the efficacy of the approach in helping to overcome the barriers faced by novice programmers. The findings indicate that the approach has merit. The students were motivated and engaged by the learning experience and were able to develop sophisticated applications that incorporated images, sound, arrays, and event handling. There is evidence that aspects of the studio-based learning approach, such as the scope that it gave students to innovate and the open feedback during student presentations, provided a learning environment that was motivating. Overall, the combination of smartphones, studio-based learning, and appropriate scaffolding offers an effective way to teach introductory programming courses.",
    "author": [
      {
        "family": "Reardon",
        "given": "Susan"
      },
      {
        "family": "Tangney",
        "given": "Brendan"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/2677089",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2014,
          12
        ]
      ]
    },
    "keyword": "Smartphones, contextualized learning",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Smartphones, studio-based learning, and scaffolding: Helping novices learn to program",
    "title-short": "Smartphones, studio-based learning, and scaffolding",
    "type": "article-journal",
    "volume": "14"
  },
  {
    "DOI": "10.1109/ICASSP.2018.8461781",
    "URL": "https://doi.org/10.1109/ICASSP.2018.8461781",
    "abstract": "This paper describes an Arduino Due based platform for digital signal processing (DSP) education. The platform consists of an in-house developed shield for robust interfacing with analog audio signals and user inputs, and an off-the-shelf Arduino Due that executes the students’ DSP code. This combination enables direct use of the Arduino integrated development environment (IDE), with its low barrier to entry for students, its low maintenance need and cross platform interoperability, and its large user base. Relevant hardware and software features of the platform are discussed throughout, as are design choices made in relation to learning objectives, and the planned use of the platform in our own DSP course.",
    "author": [
      {
        "family": "Jaldén",
        "given": "Joakim"
      },
      {
        "family": "Moreno",
        "given": "Xavier Casas"
      },
      {
        "family": "Skog",
        "given": "Isaac"
      }
    ],
    "container-title": "2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)",
    "id": "10.1109/ICASSP.2018.8461781",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "page": "6468-6472",
    "publisher": "IEEE Press",
    "publisher-place": "Calgary, AB, Canada",
    "title": "Using the arduino due for teaching digital signal processing",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3412382.3458780",
    "ISBN": "9781450380980",
    "URL": "https://doi.org/10.1145/3412382.3458780",
    "abstract": "While educational robotics and makerspaces are useful to modern STEM education, they introduce both physical and economic barriers to entry. By creating a simulated, networked environment, we can facilitate instruction on cyber-physical systems and related topics while reducing cost and complexity. The virtual environment created is connected to a block-based programming language, NetsBlox, to allow students to engage with the curriculum regardless of programming experience. The networked simulation and collaborative programming environment combine to become especially effective for distance learning. This demonstration showcases example scenarios providing students with a simple interface to interact with a simplified sensor network in a small area of a smart city and solve robot challenges.",
    "author": [
      {
        "family": "Stein",
        "given": "Gordon"
      },
      {
        "family": "Jean",
        "given": "Devin"
      },
      {
        "family": "Lédeczi",
        "given": "Ákos"
      }
    ],
    "collection-title": "IPSN ’21",
    "container-title": "Proceedings of the 20th international conference on information processing in sensor networks (co-located with CPS-IoT week 2021)",
    "id": "10.1145/3412382.3458780",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "computer science education, distance learning, educational robotics",
    "page": "394-395",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Distributed virtual CPS environment for K12: Demo abstract",
    "title-short": "Distributed virtual CPS environment for K12",
    "type": "paper-conference"
  },
  {
    "ISBN": "3540654593",
    "abstract": "Many modern computer vision systems are built by chaining together standard vision procedures, often in graphical programming environments such as Khoros, CVIPtools or IUE. Typically, these procedures are selected and sequenced by an ad-hoc combination of programmer’s intuition and trial-and-error. This paper presents a theoretically sound method for constructing object recognition strategies by casting object recognition as a Markov Decision Problem (MDP). The result is a system called ADORE (Adaptive Object Recognition) that automatically learns object recognition control policies from training data. Experimental results are presented in which ADORE is trained to recognize five types of houses in aerial images, and where its performance can be (and is) compared to optimal.",
    "author": [
      {
        "family": "Draper",
        "given": "Bruce A."
      },
      {
        "family": "Bins",
        "given": "José"
      },
      {
        "family": "Baek",
        "given": "Kyungim"
      }
    ],
    "collection-title": "ICVS ’99",
    "container-title": "Proceedings of the first international conference on computer vision systems",
    "id": "10.5555/645549.659020",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "page": "522-537",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "ADORE: Adaptive object recognition",
    "title-short": "ADORE",
    "type": "paper-conference"
  },
  {
    "ISBN": "158603796X",
    "abstract": "ParCo2007 marks a quarter of a century of the international conferences on parallel computing that started in Berlin in 1983. The aim of the conference is to give an overview of the state-of-the-art of the developments, applications and future trends in high performance computing for all platforms. The conference addresses all aspects of parallel computing, including applications, hardware and software technologies as well as languages and development environments. Special emphasis was placed on the role of high performance processing to solve real-life problems in all areas, including scientific, engineering and multidisciplinary applications and strategies, experiences and conclusions made with respect to parallel computing. The book contains papers covering: 1) Applications; The application of parallel computers to solve computationally challenging problems in the physical and life sciences, engineering, industry and commerce. The treatment of complex multidisciplinary problems occurring in all application areas was discussed. 2) Algorithms; Design, analysis and implementation of generic parallel algorithms, including their scalability, in particular to a large number of processors (MPP), portability and adaptability and 3) Software and Architectures; Software engineering for developing and maintaining parallel software, including parallel programming models and paradigms, development environments, compile-time and run-time tools. A number of symposia on specialized topics formed part of the scientific program. The following topics were covered: Parallel Computing with FPGAs, The Future of OpenMP in the Multi-Core Era, Scalability and Usability of HPC Programming Tools, DEISA: Extreme Computing in an Advanced Supercomputing Environment and Scaling Science Applications on Blue Gene. The conference was organized by the renowned research and teaching institutions Forschungszentrum Julich and the RWTH Aachen University in Germany.IOS Press is an international science, technical and medical publisher of high-quality books for academics, scientists, and professionals in all fields. Some of the areas we publish in: -Biomedicine -Oncology -Artificial intelligence -Databases and information systems -Maritime engineering -Nanotechnology -Geoengineering -All aspects of physics -E-governance -E-commerce -The knowledge economy -Urban studies -Arms control -Understanding and responding to terrorism -Medical informatics -Computer Sciences",
    "author": [
      {
        "family": "Bischof",
        "given": "C."
      },
      {
        "family": "Bischof",
        "given": "C."
      },
      {
        "family": "Bucker",
        "given": "M."
      },
      {
        "family": "Gibbon",
        "given": "P."
      },
      {
        "family": "Joubert",
        "given": "G."
      },
      {
        "family": "Lippert",
        "given": "T."
      }
    ],
    "id": "10.5555/1796091",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Parallel computing: Architectures, algorithms and applications - volume 15 advances in parallel computing",
    "title-short": "Parallel computing",
    "type": "book"
  },
  {
    "ISBN": "3319253263",
    "abstract": "This comprehensive and stimulating introduction to Matlab, a computer language now widely used for technical computing, is based on an introductory course held at Qian Weichang College, Shanghai University, in the fall of 2014. Teaching and learning a substantial programming language arent always straightforward tasks. Accordingly, this textbook is not meant to cover the whole range of this high-performance technical programming environment, but to motivate first- and second-year undergraduate students in mathematics and computer science to learn Matlab by studying representative problems, developing algorithms and programming them in Matlab. While several topics are taken from the field of scientific computing, the main emphasis is on programming. A wealth of examples are completely discussed and solved, allowing students to learn Matlab by doing: by solving problems, comparing approaches and assessing the proposed solutions.",
    "author": [
      {
        "family": "Gander",
        "given": "Walter"
      }
    ],
    "edition": "1st",
    "id": "10.5555/2857306",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "Learning MATLAB: A problem solving approach",
    "title-short": "Learning MATLAB",
    "type": "book"
  },
  {
    "ISSN": "1648-5831",
    "abstract": "Kids’ Club is a research laboratory where school children of age 10 to 14, in collaboration with university students and researchers, apply and create novel information and communication technologies (ICT) for learning. The technical environment includes visualization and concretization tools, such as a visual programming environment, control technologies, and programmable bricks. As of pedagogical models, the laboratory makes use of problem-based learning (PBL), creative problem solving, and group processes Preliminary results show that the environment provides a promising platform for developing educational technologies by getting immediate and constructive feedback from potential users. In addition, visual and particularly concretizing tools offer an attractive learning environment for learning abstract skills, like programming.",
    "author": [
      {
        "family": "Eronen",
        "given": "Pasi J."
      },
      {
        "family": "Sutinen",
        "given": "Erkki"
      },
      {
        "family": "Vesisenaho",
        "given": "Mikko"
      },
      {
        "family": "Virnes",
        "given": "Marjo"
      }
    ],
    "container-title": "Informatics in Education",
    "id": "10.5555/827120.827126",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2002,
          9
        ]
      ]
    },
    "keyword": "ICT in education, concretizing tools, constructionism, kids’ club, problem-based learning, technology education",
    "page": "61-72",
    "publisher": "Institute of Mathematics; Informatics",
    "publisher-place": "LTU",
    "title": "Kids’ club as an ICT-based learning laboratory",
    "type": "article-journal",
    "volume": "1"
  },
  {
    "ISBN": "9781577353232",
    "abstract": "It is well known how challenging is the task of coding complex agents for virtual environments. This difficulty in developing and maintaining complex agents has been plaguing commercial applications of advanced agent technology in virtual environments. In this paper, we discuss development of a commercial-grade integrated development environment (IDE) and agent architecture for simulation and training in a high-fidelity virtual environment. Specifically, we focus on two key areas of contribution. First, we discuss the addition of an explicit recipe mechanism to Soar, allowing reflection. Second, we discuss the development and usage of an IDE for building agents using our architecture; the approach we take is to tightly-couple the IDE to the architecture. The result is a complete development and deployment environment for agents situated in a complex dynamic virtual world.",
    "author": [
      {
        "family": "Yakir",
        "given": "Ari"
      },
      {
        "family": "Kaminka",
        "given": "Gal"
      }
    ],
    "collection-title": "IAAI’07",
    "container-title": "Proceedings of the 19th national conference on innovative applications of artificial intelligence - volume 2",
    "id": "10.5555/1620113.1620136",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "page": "1826-1832",
    "publisher": "AAAI Press",
    "publisher-place": "Vancouver, British Columbia, Canada",
    "title": "An integrated development environment and architecture for soar-based agents",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s10639-021-10811-w",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-021-10811-w",
    "abstract": "With future shortage of professionals with programming and computing skills, many countries have made programming part of kindergarten – grade 12 curriculum (K-12). A possible approach is to make programming part of an already existing subject. Sweden has chosen this approach and in 2017 programming was integrated in the subject content of K-12 mathematics and technology. Integrating programming is at the expense of extra workload on teachers. Teachers affected by these changes will face new challenges in their teaching and learning activities. The aim of the study is to examine K-12 teachers’ use and perceived affordances of programming as a tool for teaching and learning activities in mathematics and technology. Data were collected through focus group discussions with three teacher teams in mathematics and technology from three K-12 schools in the mid Sweden region. 21 teachers participated in the study. Thematic analysis with a mixture of deductive and inductive coding were used to analyse the data. Theory of affordances was used to structure findings in themes of interests and answer the study’s aim and research questions. Results show that the teachers use a variety of programming tools in their teaching and learning activities. The use of programming in mathematics and technology can be understood in five main perceived affordances: 1) Play, 2) Discovery, 3) Adaptation, 4) Control, and 5) Freedom; which relate to both student motivation and subject content. Teachers also perceive obstacles and opportunities in using programming, that relates to different programming tools’ ability to support teaching and learning activities. The findings of this study can be drawn upon by teachers and other stakeholders in the integration of programming in K-12 education, and in the design of teaching and learning activities with programming.",
    "author": [
      {
        "family": "Humble",
        "given": "Niklas"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-021-10811-w",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2022,
          5
        ]
      ]
    },
    "keyword": "Programming, Teaching and learning, K-12 education, Affordances, Teacher perspective",
    "page": "4887-4904",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Teacher observations of programming affordances for k-12 mathematics and technology",
    "type": "article-journal",
    "volume": "27"
  },
  {
    "DOI": "10.1145/3162087.3162092",
    "ISBN": "9781450363389",
    "URL": "https://doi.org/10.1145/3162087.3162092",
    "abstract": "The computer science discipline is evolving with problems in both technological and pedagogical aspects almost worldwide. With the advent of new technologies and approaches for teaching programming at all ages, many countries including Turkey have revised their computer science curriculum. These revisions have resulted in serious training needs being highlighted for teachers with inadequate competencies to meet the expected learning outcomes. Hence, the purpose of this study was to explore; (a) the self-perceived competencies of teachers about the topics in the curriculum, (b) perceptions about programming, programming tools and approaches, and (c) contribution of university education to their teaching profession. The findings revealed that most teachers believe they are not sufficiently competent to be an effective computer science teacher. Related to this finding, most of them especially mentioned their training needs for programming, emerging tools and technologies. Plus more than half of the participants think that the higher education curriculum is inadequate to meet teacher expectations and to create competent teachers.",
    "author": [
      {
        "family": "Gülbahar",
        "given": "Yasemin"
      },
      {
        "family": "Kalelioğlu",
        "given": "Filiz"
      }
    ],
    "collection-title": "CSERC ’17",
    "container-title": "Proceedings of the 6th computer science education research conference",
    "id": "10.1145/3162087.3162092",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "Computer science teacher competencies, computer science teacher training",
    "page": "26-31",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Competencies of high school teachers and training needs for computer science education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.2312/eged.20171024",
    "URL": "https://doi.org/10.2312/eged.20171024",
    "abstract": "Teaching fundamental principles of Computer Graphics requires a thoroughly prepared lecture alongside practical training. Modern graphics programming rarely provides a straightforward application programming interface (API) and the available APIs pose high entry barriers to students. Shader-based programming of standard graphics pipelines is often inaccessible through complex setup procedures and convoluted programming environments. In this paper we discuss an undergraduate entry level lecture with its according lab exercises. We present a programming framework that makes interactive graphics programming accessible while allowing to design individual tasks as instructive exercises to solidify the content of individual lecture units. The discussed teaching framework provides a well defined programmable graphics pipeline with geometry shading stages and image-based post processing functionality based on framebuffer objects. It is open-source and available online.",
    "author": [
      {
        "family": "Toisoul",
        "given": "Antoine"
      },
      {
        "family": "Rueckert",
        "given": "Daniel"
      },
      {
        "family": "Kainz",
        "given": "Bernhard"
      }
    ],
    "collection-title": "EG ’17",
    "container-title": "Proceedings of the european association for computer graphics: Education papers",
    "id": "10.2312/eged.20171024",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "page": "35-42",
    "publisher": "Eurographics Association",
    "publisher-place": "Goslar, DEU",
    "title": "Accessible GLSL shader programming",
    "type": "paper-conference"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "The increasing awareness of \"big data\" is transforming the academic and business landscape across many disciplines. Yet, big data programming environments are still too complex for non-programmers to utilize. To our knowledge, only computer scientists are ever exposed to big data processing concepts and tools in undergraduate education. Furthermore, non-computer scientists may lack sufficient common ground with computer scientists to explain their specialized big data processing needs. In order to bridge this gap and enhance collaboration among persons with big data processing needs and persons who are trained in programming and system building, we propose the foundations of a cross-disciplinary pedagogy that exposes big data processing paradigms and design decisions at an abstract level. With these tools, students and experts from different disciplines can more effectively collaborate on solving big data problems.",
    "author": [
      {
        "family": "Eckroth",
        "given": "Joshua"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/2835377.2835394",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2016,
          1
        ]
      ]
    },
    "page": "110-118",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Foundations of a cross-disciplinary pedagogy for big data",
    "type": "article-journal",
    "volume": "31"
  },
  {
    "DOI": "10.1145/2063348.2063374",
    "ISBN": "9781450311397",
    "URL": "https://doi.org/10.1145/2063348.2063374",
    "abstract": "Computing plays an indispensable role in scientific research. Presently, researchers in science have different problems, needs, and beliefs about computation than professional programmers. In order to accelerate the progress of science, computer scientists must understand these problems, needs, and beliefs. To this end, this paper presents a survey of scientists from diverse disciplines, practicing computational science at a doctoral-granting university with very high research activity. The survey covers many things, among them, prevalent programming practices within this scientific community, the importance of computational power in different fields, use of tools to enhance performance and software productivity, computational resources leveraged, and prevalence of parallel computation. The results reveal several patterns that suggest interesting avenues to bridge the gap between scientific researchers and programming tools developers.",
    "author": [
      {
        "family": "Prabhu",
        "given": "Prakash"
      },
      {
        "family": "Jablin",
        "given": "Thomas B."
      },
      {
        "family": "Raman",
        "given": "Arun"
      },
      {
        "family": "Zhang",
        "given": "Yun"
      },
      {
        "family": "Huang",
        "given": "Jialu"
      },
      {
        "family": "Kim",
        "given": "Hanjun"
      },
      {
        "family": "Johnson",
        "given": "Nick P."
      },
      {
        "family": "Liu",
        "given": "Feng"
      },
      {
        "family": "Ghosh",
        "given": "Soumyadeep"
      },
      {
        "family": "Beard",
        "given": "Stephen"
      },
      {
        "family": "Oh",
        "given": "Taewook"
      },
      {
        "family": "Zoufaly",
        "given": "Matthew"
      },
      {
        "family": "Walker",
        "given": "David"
      },
      {
        "family": "August",
        "given": "David I."
      }
    ],
    "collection-title": "SC ’11",
    "container-title": "State of the practice reports",
    "id": "10.1145/2063348.2063374",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A survey of the practice of computational science",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2616498.2616568",
    "ISBN": "9781450328937",
    "URL": "https://doi.org/10.1145/2616498.2616568",
    "abstract": "This paper presents our experiences and outcomes using Scratch to teach parallel computing concepts to students just learning about computer science. We presented versions of this material to middle school and high school girls during a STEM workshop and then to undergraduate university students enrolled in an introductory computer science course. Using the Scratch development environment, students are able to build, modify and observe the changes in the performance of applications which utilize multi-threaded, concurrent, operations. This includes scenarios which involve more advanced topics such as race conditions and mutex locks.Developing these materials has allowed us to introduce these concepts in a programming environment much earlier than we have previously, giving instructors in down-stream courses the ability to build upon this early exposure. Survey results show that this approach resulted in a significant increase in both of these areas. For example, the number of students in our CS0 course who felt they could apply parallel programming to other problems using Scratch more than doubled, rising from 25 to 55 (out of 61 students that responded to both surveys). Likewise, the number of students who felt they understood what parallel programming means rose from 27 to 56. These results were achieved after just one class period. Similarly, 27 of the 37 girls responding to the workshop survey felt that they were capable of learning to write computer programs and 22 of 41 indicated they had an interest in a job using HPC to solve problems.",
    "author": [
      {
        "family": "Feldhausen",
        "given": "Russell"
      },
      {
        "family": "Bell",
        "given": "Scott"
      },
      {
        "family": "Andresen",
        "given": "Daniel"
      }
    ],
    "collection-title": "XSEDE ’14",
    "container-title": "Proceedings of the 2014 annual conference on extreme science and engineering discovery environment",
    "id": "10.1145/2616498.2616568",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Minimum time, maximum effect: Introducing parallel computing in CS0 and STEM outreach activities using scratch",
    "title-short": "Minimum time, maximum effect",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1287/isre.8.1.25",
    "ISSN": "1526-5536",
    "URL": "https://doi.org/10.1287/isre.8.1.25",
    "abstract": "Our theoretical framework views programming as search in three problem spaces: rule, instance, and representation. The main objectives of this study are to find out how programmers change representation while working in multiple problem spaces, and how representation change increases the difficulty of programming tasks. Our theory of programming indicates that programming is similar to the way scientists discover and test theories. That is, programmers generate hypotheses in the rule space and test these hypotheses in the instance space. Moreover, programmers change their representations in the representation space when rule development becomes too difficult or alternative representations are available. We conducted three empirical studies with different programming tasks: writing a new program, understanding an existing program, and reusing an old program. Our results indicate that considerable cognitive difficulties stem from the need to change representations in these tasks. We conclude by discussing the implications of viewing programming as a scientific discovery for the design of programming environments and training methods.",
    "author": [
      {
        "family": "Kim",
        "given": "Jinwoo"
      },
      {
        "family": "Lerch",
        "given": "F. Javier"
      }
    ],
    "container-title": "Info. Sys. Research",
    "id": "10.1287/isre.8.1.25",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1997,
          3
        ]
      ]
    },
    "keyword": "empirical studies of programmers, multiple problem spaces, object-oriented programming, scientific discovery",
    "page": "25-50",
    "publisher": "INFORMS",
    "publisher-place": "Linthicum, MD, USA",
    "title": "Why is programming sometimes so difficult? Programming as scientific discovery in multiple problem spaces",
    "type": "article-journal",
    "volume": "8"
  },
  {
    "DOI": "10.2478/v10065-009-0017-9",
    "ISSN": "1732-1360",
    "URL": "https://doi.org/10.2478/v10065-009-0017-9",
    "abstract": "Computer science would not exist without the concept of algorithm. Therefore design of algorithms plays an important role in education while implementation is usually considered to be straightforward. Increasing variety of programming languages, wealth of possible constructions, programming environments and tools makes programming difficult for the beginners.Apart from the idea of problem solution, it is important to teach programming skills. Size of classes of 10-20 pupils and a limited number of lessons and their short time are the major problem. The teacher has to check solution of every pupil, compile it and run tests. This is definitely a time-consuming process which makes teaching difficult. In this paper the authors present the use of problem solutions validation systems during classes. With the help of such a system called ZawodyWEB, the authors teach algorithms and programming for the secondary school students.",
    "author": [
      {
        "family": "KluszczyńSki",
        "given": "Rafał"
      },
      {
        "family": "Mikulski",
        "given": "ŁUkasz"
      },
      {
        "family": "Nowicki",
        "given": "Marek"
      },
      {
        "family": "BałA",
        "given": "Piotr"
      }
    ],
    "container-title": "Ann. UMCS, Inf.",
    "id": "10.2478/v10065-009-0017-9",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2009,
          1
        ]
      ]
    },
    "page": "213-224",
    "publisher": "Versita",
    "publisher-place": "Warsaw, POL",
    "title": "Contests hosting service as a tool to teach programming",
    "type": "article-journal",
    "volume": "9"
  },
  {
    "DOI": "10.1016/j.compedu.2006.04.005",
    "ISSN": "0360-1315",
    "URL": "https://doi.org/10.1016/j.compedu.2006.04.005",
    "abstract": "Program animation systems have not been as widely adopted by computer science educators as we might expect from the firm belief that they can help in enhancing computer science education. One of the most notable obstacles to their adoption is the considerable effort that the production of program animations represents for the instructor. We present here an approach to reduce such a workload based on the automatic generation of visualizations and animations. The user may customize them in a user-friendly way to construct more expressive program animations. These operations are carried out by means of a user-friendly manipulation based on the metaphor of office documents. We have applied this approach to the functional paradigm by extending the WinHIPE programming environment. Finally, we report on the successful results of an evaluation performed to measure its ease of use.",
    "author": [
      {
        "family": "Velázquez-Iturbide",
        "given": "J. Ángel"
      },
      {
        "family": "Pareja-Flores",
        "given": "Cristóbal"
      },
      {
        "family": "Urquiza-Fuentes",
        "given": "Jaime"
      }
    ],
    "container-title": "Comput. Educ.",
    "id": "10.1016/j.compedu.2006.04.005",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2008,
          1
        ]
      ]
    },
    "keyword": "Authoring tools and methods, Evaluation of CAL systems, Improving classroom teaching, Interactive learning environments, Programming and programming languages",
    "page": "179-192",
    "publisher": "Elsevier Science Ltd.",
    "publisher-place": "GBR",
    "title": "An approach to effortless construction of program animations",
    "type": "article-journal",
    "volume": "50"
  },
  {
    "ISBN": "159140102X",
    "abstract": "Programming is a demanding task with an education program that requires the assistance of complex tools such as programming environments, algorithm animators, problem graders, etc. In this chapter, we give a comprehensive presentation of tools for program execution and visualization on the Web. We summarize the technical evolution of these tools, describe educational uses, report lessons learned, and look at formal evaluations of their educational effectiveness. We also deal with a closely related matter, namely, collections of Web documents containing programming exercises. Finally, we outline our view of future trends in the use of the Web for programming education, and we give our personal conclusions. This chapter is of interest to educators and researchers, because it gives a comprehensive presentation of the main issues and results of a field where most of the contributions are sparse in the literature.",
    "author": [
      {
        "family": "Pareja-Flores",
        "given": "C."
      },
      {
        "family": "Velázquez-Iturbide",
        "given": "J. Á."
      }
    ],
    "container-title": "Web-based education: Learning from experience",
    "id": "10.5555/949921.949938",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "page": "236-259",
    "publisher": "IGI Global",
    "publisher-place": "USA",
    "title": "Program execution and visualization on the web",
    "type": "chapter"
  },
  {
    "DOI": "10.1145/1822090.1822167",
    "ISBN": "9781605588209",
    "URL": "https://doi.org/10.1145/1822090.1822167",
    "abstract": "Learning and programming environments used in computer science education give feedback to the users by system messages. These are triggered by programming errors and give only \"technical\" hints without regard to the learners’ problem solving process. To adapt the messages not only to the factual but also to the procedural knowledge of the learners, their problem solving strategies have to be identified automatically and in process. This article describes a way to achieve this with the help of pattern recognition methods. Using data from a study with 65 learners aged 12 to 13 using a learning environment for programming, a classification system based on hidden Markov models is trained and integrated in the very same environment. We discuss findings in that data and the performance of the automatic online identification, and present first results using the developed software in class.",
    "author": [
      {
        "family": "Kiesmueller",
        "given": "Ulrich"
      },
      {
        "family": "Sossalla",
        "given": "Sebastian"
      },
      {
        "family": "Brinda",
        "given": "Torsten"
      },
      {
        "family": "Riedhammer",
        "given": "Korbinian"
      }
    ],
    "collection-title": "ITiCSE ’10",
    "container-title": "Proceedings of the fifteenth annual conference on innovation and technology in computer science education",
    "id": "10.1145/1822090.1822167",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "algorithms, computer science education, pattern recognition, problem solving strategies, secondary education, tool-based analysis",
    "page": "274-278",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Online identification of learner problem solving strategies using pattern recognition methods",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ACIT-CSI.2015.73",
    "ISBN": "9781467396424",
    "URL": "https://doi.org/10.1109/ACIT-CSI.2015.73",
    "abstract": "When a novice programmer starts learning computer programming, C or Java are often employed. They are general purpose and useful languages, but for Japanese novice programmers these programming languages are difficult. One reason for this difficulty is English keywords employed in these programming languages, that is, these words are not in Japanese learner’s native language. Recently, for Japanese novice programmers, \"Nihongo-based\" programming languages have been developed in Japan. PEN is a Nihongo-based programming language for education. A programming environment has been developed for PEN, and the environment has an interpreter. However, there has not been developed a compiler for PEN. In this paper, we aim to develop a compiler for PEN language, actually, we develop a translator from PEN into C, and we finally obtain a binary code with a C compiler such as gcc.",
    "author": [
      {
        "family": "Kato",
        "given": "Yoshitaka"
      },
      {
        "family": "Ozaki",
        "given": "Masaya"
      },
      {
        "family": "Kani",
        "given": "Jun’ya"
      },
      {
        "family": "Ito",
        "given": "Nobuhiro"
      },
      {
        "family": "Kawabe",
        "given": "Yoshinobu"
      }
    ],
    "collection-title": "ACIT-CSI ’15",
    "container-title": "Proceedings of the 2015 3rd international conference on applied computing and information technology/2nd international conference on computational science and intelligence",
    "id": "10.1109/ACIT-CSI.2015.73",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "page": "387-392",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Developing compiler for nihongo programming language PEN",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3397537.3397561",
    "ISBN": "9781450375078",
    "URL": "https://doi.org/10.1145/3397537.3397561",
    "abstract": "The syntax of a programming language is the textual form - that conforms to a grammar - to express instructions of a programming model. The key idea of structured code editors is to constrain editing to syntactically valid program code, that is, the modifications ensure that the source code always conforms to the grammar. Syntax is considered an entry barrier when learning how to program. In this work we rehash the concept of structured code editors targeting programming education. We present Javardise, a structured editor for a subset of the Java language, and discuss its features in the light of programming pedagogy.",
    "author": [
      {
        "family": "Santos",
        "given": "André L."
      }
    ],
    "collection-title": "Programming ’20",
    "container-title": "Companion proceedings of the 4th international conference on art, science, and engineering of programming",
    "id": "10.1145/3397537.3397561",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "Java, Structured editors, programming pedagogy",
    "page": "120-125",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Javardise: A structured code editor for programming pedagogy in java",
    "title-short": "Javardise",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.neucom.2022.11.056",
    "ISSN": "0925-2312",
    "URL": "https://doi.org/10.1016/j.neucom.2022.11.056",
    "author": [
      {
        "family": "Komorniczak",
        "given": "Joanna"
      },
      {
        "family": "Ksieniewicz",
        "given": "Paweł"
      }
    ],
    "container-title": "Neurocomput.",
    "id": "10.1016/j.neucom.2022.11.056",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2023,
          2
        ]
      ]
    },
    "keyword": "Problem complexity, Classification, Regression, Python",
    "page": "126-136",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Problexity—an open-source python library for supervised learning problem complexity assessment",
    "type": "article-journal",
    "volume": "521"
  },
  {
    "DOI": "10.1145/3027063.3027129",
    "ISBN": "9781450346566",
    "URL": "https://doi.org/10.1145/3027063.3027129",
    "abstract": "There has been increasing attention paid to the necessity of Computational Thinking (CT) and CS education in recent years. To address this need, a broad spectrum of animation programming environments and games have been created to engage learners. However, most of these tools are designed for the touchpad/mouse and keyboard, and few have been evaluated to assess their efficacy in developing CT/programming skills. This is problematic when trying to understand the validity of such designs for CS education, and whether there are alternative approaches that may prove more effective. My dissertation work helps address this problem. After creating a framework based on a meta-review that carefully dissects embodiment strategies in learning games, I am building and evaluating tangible and augmented reality versions of a CT game. I plan to examine how these different forms of physical interaction help to facilitate and enhance meaning-making during the learning process, and whether/how they improve related learning factors such as self-belief and enjoyment.",
    "author": [
      {
        "family": "Melcer",
        "given": "Edward"
      }
    ],
    "collection-title": "CHI EA ’17",
    "container-title": "Proceedings of the 2017 CHI conference extended abstracts on human factors in computing systems",
    "id": "10.1145/3027063.3027129",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "computational thinking, educational games, embodied cognition, embodied interaction, physical embodiment, programming",
    "page": "301-306",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Moving to learn: Exploring the impact of physical embodiment in educational programming games",
    "title-short": "Moving to learn",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2593801.2593809",
    "ISBN": "9781450328463",
    "URL": "https://doi.org/10.1145/2593801.2593809",
    "abstract": "We investigate natural language as an alternative to programming languages. Natural language would empower anyone to program with minimal training. In this paper, we solve an ordering problem that arises in natural-language programming. An emprical study showed that users do not always provide the strict sequential order of steps needed for execution on a computer. Instead, temporal expressions involving \"before\", \"after\", \"while\", \"at the end\", and others are used to indicate an order other than the textual one. We present an analysis that extracts the intended time line by exploiting temporal clues. The technique is analyzed in the context of Alice, a 3D programming environment, and AliceNLP, a system for programming Alice in ordinary English. Extracting temporal order could also be useful for analyzing reports, question answering, help desk requests, and big data applications.",
    "author": [
      {
        "family": "Landhäußer",
        "given": "Mathias"
      },
      {
        "family": "Hey",
        "given": "Tobias"
      },
      {
        "family": "Tichy",
        "given": "Walter F."
      }
    ],
    "collection-title": "RAISE 2014",
    "container-title": "Proceedings of the 3rd international workshop on realizing artificial intelligence synergies in software engineering",
    "id": "10.1145/2593801.2593809",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "Alice, Natural language processing, end-user programming, programming with natural language, temporal expressions, temporal reasoning, time lines",
    "page": "45-51",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Deriving time lines from texts",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/MSR.2017.10",
    "ISBN": "9781538615447",
    "URL": "https://doi.org/10.1109/MSR.2017.10",
    "abstract": "The availability of large corpora of online software-related documents today presents an opportunity to use machine learning to improve integrated development environments by first automatically collecting code examples along with associated descriptions. Digital libraries of computer science research and education conference and journal articles can be a rich source for code examples that are used to motivate or explain particular concepts or issues. Because they are used as examples in an article, these code examples are accompanied by descriptions of their functionality, properties, or other associated information expressed in natural language text. Identifying code segments in these documents is relatively straightforward, thus this paper tackles the problem of extracting the natural language text that is associated with each code segment in an article. We present and evaluate a set of heuristics that address the challenges of the text often not being colocated with the code segment as in developer communications such as online forums.",
    "author": [
      {
        "family": "Chatterjee",
        "given": "Preetha"
      },
      {
        "family": "Gause",
        "given": "Benjamin"
      },
      {
        "family": "Hedinger",
        "given": "Hunter"
      },
      {
        "family": "Pollock",
        "given": "Lori"
      }
    ],
    "collection-title": "MSR ’17",
    "container-title": "Proceedings of the 14th international conference on mining software repositories",
    "id": "10.1109/MSR.2017.10",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "code snippet description, information extraction, mining software repositories, text analysis",
    "page": "91-101",
    "publisher": "IEEE Press",
    "publisher-place": "Buenos Aires, Argentina",
    "title": "Extracting code segments and their descriptions from research articles",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s10846-015-0202-6",
    "ISSN": "0921-0296",
    "URL": "https://doi.org/10.1007/s10846-015-0202-6",
    "abstract": "Basic Programming is a first year mandatory course of the Computer Engineering degree. Both students and teachers face difficulties in this course, which has high failure and drop-out rates. Several authors have proposed the use of visual programming environments and robots to overcome the difficulties of this course, some of which have been successful. This paper presents the two-year experiment using Lego Robots carried out at the University of the Basque Country (UPV/EHU) with around 100 students, along with the results. Satisfactory results have been obtained regarding both motivation and the perception of the students of their learning process; moreover the drop-out rate decreased even though no statistical significance was obtained regarding the final marks of the course. From those results and the analysis of the data it was derived that robot sessions should be more integrated in the curriculum, giving them greater relevance in the final marks. In addition, it is indispensable to classify course students and adapt learning sessions to each student type due to the high student heterogeneity.",
    "author": [
      {
        "family": "Álvarez",
        "given": "Ainhoa"
      },
      {
        "family": "Larrañaga",
        "given": "Mikel"
      }
    ],
    "container-title": "J. Intell. Robotics Syst.",
    "id": "10.1007/s10846-015-0202-6",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2016,
          1
        ]
      ]
    },
    "keyword": "Basic Programming, Lego Mindstorms, Robots in Computer Engineering Education",
    "page": "117-129",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Experiences incorporating lego mindstorms robots in the basic programming syllabus: Lessons learned",
    "title-short": "Experiences incorporating lego mindstorms robots in the basic programming syllabus",
    "type": "article-journal",
    "volume": "81"
  },
  {
    "ISSN": "1753-5255",
    "abstract": "Coding is part of logical thinking and is one of the basic skills which are known as ’21st-century skills’. Coding acquisition is necessary as it is used in a wide range of occupations. However, computer programing is difficult to learn and programing courses often have high drop-out rates. Novice programmers suffer from a wide range of difficulties and deficits. Research in teaching and learning programing across different countries and educational contexts reveal that novice programmers face the same challenges in their efficiency of writing, debugging and running programs. These difficulties have led those involved in the teaching of programing to further consider the most effective ways that can facilitate novice programmers in learning the basic programing concepts. Visual programing environments which support the construction of programs through a drag-and-drop interface are among the most popular coding tools for teaching novice programmers. In this paper, we investigate the use of Alice and App Inventor for Android, with regard to their effectiveness for teaching and learning programing in secondary education students.",
    "container-title": "Int. J. Technol. Enhanc. Learn.",
    "id": "10.5555/3202163.3202166",
    "issue": "1–2",
    "issued": {
      "date-parts": [
        [
          2018,
          1
        ]
      ]
    },
    "page": "44-72",
    "publisher": "Inderscience Publishers",
    "publisher-place": "Geneva 15, CHE",
    "title": "Comparing novice programing environments for use in secondary education: App inventor for android vs. alice",
    "title-short": "Comparing novice programing environments for use in secondary education",
    "type": "article-journal",
    "volume": "10"
  },
  {
    "ISBN": "9780549933465",
    "abstract": "In this high tech world of globalization it is paramount that students know how to think critically, and know how to identify, analyze, and solve problems quickly and effectively. Computer programming courses can provide students with a good foundation in these basic skill sets however, in many U.S. colleges and universities student enrollment in computer related majors is declining. In the fall of 2006 only 1.1 percent of incoming freshmen expressed any interest in computer science as a major. Enrollment in Computer Science needs to increase if we are to remain competitive. Often students enrolled in introductory computer programming courses find the subject difficult. Several studies have concluded that even after students successfully complete an introductory programming course, they still find it difficult to design and code programming solutions. This research investigates the effectiveness of using digital game playing to bring computer programming education into the world of experience of novice programming students enrolled in a college-level introductory computer programming course. The research determines whether or not digital game playing improves the effective transfer of the students’ problem solving, critical thinking, logical, and programming knowledge from game playing to a formal programming environment. This research also explores whether this method is more effective for certain majors.",
    "author": [
      {
        "family": "Westcott",
        "given": "Sandra"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1571208",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "note": "AAI3338734",
    "publisher": "Pace University",
    "publisher-place": "USA",
    "title": "Effectiveness of using digital game playing in a first-level programming course",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/2591635.2591641",
    "ISBN": "9781450328401",
    "URL": "https://doi.org/10.1145/2591635.2591641",
    "abstract": "In the late 1980’s, I was recovering from a long stint as the manager of Paris University computing facility (yes, there were still computing facilities, and PCs were just coming of age) and I was teaching old fashioned automatic parallelization to postgraduate students. I had heard of scalar expansion and privatization, and it was a natural question whether it could be extended to arrays. I first concocted partial solutions - for instance, valid only for the innermost loop - and then decided to try for the general case: converting array accesses to single assignment form. I soon realized that this implied finding the source, or last write before a given read, and that the solution must be a function of the position of the read in the temporal execution of the program. It was obvious that this could not be done for arbitrary complex programs, hence I specified a set of restriction: the polyhedral model. I also introduced the execution order, now known as the ’happens-before’ relation. Finding the last write then became an integer programming problem with some unfamiliar features: lexicographic order took the place of the economic function, the problem had to be solved exactly, and the coordinates of the read operation were acting as parameters. Hence, I had first to build PIP (a parametric integer programming tool [2]) before solving my problem. PIP was developed on a 80286 PC, using Borland TurboC and LeLisp.It then took me about two years to have an improved form of the ICS paper published by a journal [3]. Here, the emphasis was more on single assignment conversion and its use for program comprehension. I also formalized a comparison algorithm, which is needed when there are several potential sources. But it was not until [4] that I managed to prove its termination.Meanwhile, the ICS paper had attracted attention from the other side of the Atlantic. Most important was Bill Pugh’s work [6], in which the problem was reformulated in term of affine relations, and solved by Bill’s own linear programming tool, Omega. I remember that we exchanged our benchmarks, and found that our results were equivalent. An early example of reproducible research!!",
    "author": [
      {
        "family": "Feautrier",
        "given": "Paul"
      }
    ],
    "container-title": "ACM international conference on supercomputing 25th anniversary volume",
    "id": "10.1145/2591635.2591641",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "page": "6",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Author retrospective for array expansion, array shrinking, or there and back again",
    "type": "paper-conference"
  },
  {
    "DOI": "10.5220/0005922204730482",
    "ISBN": "9789897581878",
    "URL": "https://doi.org/10.5220/0005922204730482",
    "abstract": "IT related jobs present a good opportunity for better paying positions for people with disabilities (PWD). Online training seems to be an interesting approach, due to its reach. Building and delivering online content for this population is challenging, especially for those who are deaf or hearing impaired (DHI). We face many problems in the process of teaching the DHI student. Initially we have language related issues, the vocabulary of the Brazilian Sign Language (Libras) is poor when it comes to specific content such as IT. Then, we confront the problem of having very few tutors versed in Libras. Content format, how can we present the information to the DHI considering visual aspects__ __ Accessible learning objects, accessible programming environment, online collaboration between DHI and Non-DHI. Real word task analysis are all discussed in the current text. We present a series of studies our lab conducted and is conducting as we create and deliver IT online content for the PWD.",
    "author": [
      {
        "family": "Oliveira",
        "given": "Francisco C. de M. B."
      },
      {
        "dropping-particle": "de",
        "family": "Freitas",
        "given": "Adriano T."
      },
      {
        "dropping-particle": "de",
        "family": "Araujo",
        "given": "Thiago A. C."
      },
      {
        "family": "Silva",
        "given": "Lidiane C."
      },
      {
        "family": "Queiroz",
        "given": "Bruno da S."
      },
      {
        "family": "Soares",
        "given": "Éder F."
      }
    ],
    "collection-title": "ICEIS 2016",
    "container-title": "Proceedings of the 18th international conference on enterprise information systems",
    "id": "10.5220/0005922204730482",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "Accessible Content, Employability, Online Collaboration, Sign Language.",
    "page": "473-482",
    "publisher": "SCITEPRESS - Science; Technology Publications, Lda",
    "publisher-place": "Setubal, PRT",
    "title": "IT education strategies for the deaf",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s10639-022-11019-2",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-022-11019-2",
    "abstract": "In order to teach Computational Thinking (CT) skills to young students, Block-Based Programming Environments (BBPEs) are integrated into secondary school computer science (CS) education curricula. As a CT skill, abstraction is one of the prominent skills, which is difficult to enhance and measure. Researchers developed some scales for measuring abstraction in BBPEs; however, it is still quite difficult to measure abstraction and understand students’ abstraction behaviors. The aim of this study is to suggest tasks that could help enhance students’ abstraction skills while teaching CT via block-based programming. In addition, a rubric to score the students’ abstraction behaviors in the problem solving process was created and validated. A framework with regard to the definitions of abstraction skill was adopted and the way to isolate it from other CT-skills was proposed. As a result, pattern recognition, generalizing, decomposition, focusing and eliminating were defined as indicators of abstraction in the problem solving process via BBPEs. The study also informed computer science educators about the relations between teaching CT via BBPEs, affordances of BBPEs and nature of abstraction.",
    "author": [
      {
        "family": "Çakiroğlu",
        "given": "Ünal"
      },
      {
        "family": "Çevik",
        "given": "undefinedsak"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-022-11019-2",
    "issue": "7",
    "issued": {
      "date-parts": [
        [
          2022,
          8
        ]
      ]
    },
    "keyword": "Block based environments, Abstraction, Computational thinking, Problem solving",
    "page": "9455-9484",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "A framework for measuring abstraction as a sub-skill of computational thinking in block-based programming environments",
    "type": "article-journal",
    "volume": "27"
  },
  {
    "DOI": "10.1109/FIE.2018.8659327",
    "URL": "https://doi.org/10.1109/FIE.2018.8659327",
    "abstract": "This research full paper presents that Brazilian deaf community has conquered rights in the area of education, and in recent years, with the increase of the enrollment of deaf people in educational establishments, there is a need to elaborate new specific signs of LIBRAS for technical terms of specific courses in different areas. The objective of this work is develop a computational glossary of signals in LIBRAS with the reserved words of the SuperLOGO programming environments and the NXT robotics software. In addition, programming logic and geometry learning in deaf students will be stimulated. The work will be carried out in a bilingual high school, in the mathematics discipline. To validate the glossary and the development process of the students’ knowledge will be used categories of pedagogical evaluation and content analysis. The use of these programming softwares combined with the glossary demonstrated the ability to build knowledge in programming logic and geometry that would be hampered by the language barrier. We conclude that the signs developed for the glossary enable the deaf to access complex terms of computing, providing the same possibilities of educational development as their fellow listeners.",
    "author": [
      {
        "family": "Granada",
        "given": "Rafael Pinto"
      },
      {
        "family": "Barwaldt",
        "given": "Regina"
      },
      {
        "family": "Espı́ndola",
        "given": "Danbia Bueno"
      }
    ],
    "container-title": "2018 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE.2018.8659327",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "page": "1-7",
    "publisher": "IEEE Press",
    "publisher-place": "San Jose, CA, USA",
    "title": "Glossary of computational terms as a stimulus to programming logic: A case study with deaf students",
    "title-short": "Glossary of computational terms as a stimulus to programming logic",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3230977.3231013",
    "ISBN": "9781450356282",
    "URL": "https://doi.org/10.1145/3230977.3231013",
    "abstract": "Computational thinking (CT), a transversal intellectual foundation integral to computer science, is making its way into compulsory comprehensive education worldwide. Students are expected to attain skills and knowledge in such interdisciplinary CT principles as Algorithmic thinking, Data representation, and Debugging. Problem-solving by designing and manipulating interactive media with Scratch, a graphical programming tool, is popular especially at the primary school level. However, there has been confusion regarding how introductory CT can be operationalized for educational practice. Teachers and students need research-based knowledge for setting appropriate learning goals in addition to instruments for formative assessment that potentially improve the quality of learning. This study contributes to these issues by developing the assessment for learning of CT via Scratch in primary school settings. A review on prior studies involving the assessment of CT-related computational ideas in Scratch has led to the conceptualization of a revised assessment framework. Next steps in the study are analyzing fourth grade students’ (N=58) Scratch projects and exploring complementary methods for analyzing CT in video recordings of the students’ programming processes.",
    "author": [
      {
        "family": "Fagerlund",
        "given": "Janne"
      }
    ],
    "collection-title": "ICER ’18",
    "container-title": "Proceedings of the 2018 ACM conference on international computing education research",
    "id": "10.1145/3230977.3231013",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "assessment, computational thinking, education, graphical programming, primary school, scratch",
    "page": "264-265",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A study on the assessment of introductory computational thinking via scratch programming in primary schools",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/IPDPSW.2015.51",
    "ISBN": "9781467376846",
    "URL": "https://doi.org/10.1109/IPDPSW.2015.51",
    "abstract": "Despite the fact that we are firmly in the multicore era, the use of parallel programming is not as widespread as it could be - in the software industry or in education. There have been many calls to incorporate more parallel programming content into undergraduate computer science education. One obstacle to doing this is that the programming languages most commonly used for parallel programming are detailed, low-level languages such as C, C++, Fortran (with OpenMP or MPI), OpenCL and CUDA. These languages allow programmers to write very efficient code, but that is not so important for those whose goal is to learn the concepts of parallel computing. This paper introduces a parallel programming language called Tetra which provides parallel programming features as first class language features, and also provides garbage collection and is designed to be as simple as possible. Tetra also includes an integrated development environment which is specifically geared for debugging parallel programs and visualizing program execution across multiple threads.",
    "author": [
      {
        "family": "Finlayson",
        "given": "Ian"
      },
      {
        "family": "Mueller",
        "given": "Jerome"
      },
      {
        "family": "Rajapakse",
        "given": "Shehan"
      },
      {
        "family": "Easterling",
        "given": "Daniel"
      }
    ],
    "collection-title": "IPDPSW ’15",
    "container-title": "Proceedings of the 2015 IEEE international parallel and distributed processing symposium workshop",
    "id": "10.1109/IPDPSW.2015.51",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "Debugging, Education, Parallel Programming",
    "page": "746-751",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Introducing tetra: An educational parallel programming system",
    "title-short": "Introducing tetra",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3306214.3338570",
    "ISBN": "9781450363143",
    "URL": "https://doi.org/10.1145/3306214.3338570",
    "abstract": "In recent years, there has been a trend in teaching programming in elementary schools around the world. When teaching programming to lower grader students, robots and puzzles are often used to learn programming for easy understanding. However, those tools have limitations in execution results. Higher graders often use visual programming as a learning material. However, there is a problem that visual programming requires one computer for each individual student, and many students have to learn how to use a computer first. Therefore we propose a programming tool using tangible blocks and AR. This makes it possible to learn programming intuitively with fewer restrictions. Our tool is operated using a smartphone and tangible blocks without using a computer. By using AR, it is possible to create an intuitive programming that can interact with reality. We asked teachers who have experience teaching programming to children to assess the usefulness of our tool within programming education in school. As a result, there was an opinion that it might be suitable for multi-person programming.",
    "author": [
      {
        "family": "Hattori",
        "given": "Keisuke"
      },
      {
        "family": "Hirai",
        "given": "Tatsunori"
      }
    ],
    "collection-title": "SIGGRAPH ’19",
    "container-title": "ACM SIGGRAPH 2019 posters",
    "id": "10.1145/3306214.3338570",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "AR, creativity, education, physically coding, programming",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An intuitive and educational programming tool with tangible blocks and AR",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/2.58220",
    "ISSN": "0018-9162",
    "URL": "https://doi.org/10.1109/2.58220",
    "abstract": "A description is given of five testbeds developed to examine gigabit applications and network technologies: Aurora, Blanca, Casa, Nectar, and Vistanet. Aurora is an experimental wide-area network testbed whose main objective is to explore and evaluate technologies for phase three of the proposed gigabit National Research and Education Network. The goals of the Blanca network research program are to develop technologies supporting gigabit/second networks, to develop programming tools supporting advanced network-based applications, and to explore the relationships between network technology paradigms and application requirements. The intent of the Casa testbed is to demonstrate that distributed supercomputing using wide-area high-speed networks can provide new levels of computational resources for leading-edge scientific problems. For the Nectar testbed project, a gigabit/second or higher experimental network will be developed to connect a variety of high-performance hosts. The Vistanet research project is intended to help determine whether networks based on emerging public-network standards will satisfy the goals of the National Research and Education Network and to provide information on specifications for those standards.",
    "author": [
      {
        "family": "Staff",
        "given": "Computer"
      }
    ],
    "container-title": "Computer",
    "id": "10.1109/2.58220",
    "issue": "9",
    "issued": {
      "date-parts": [
        [
          1990,
          9
        ]
      ]
    },
    "page": "77-80",
    "publisher": "IEEE Computer Society Press",
    "publisher-place": "Washington, DC, USA",
    "title": "Gigabit network testbeds",
    "type": "article-journal",
    "volume": "23"
  },
  {
    "abstract": "Supervised learning models have been used in various domains such as lending, college admission, face recognition, natural language processing, etc. However, they may inherit pre-existing biases from training data and exhibit discrimination against protected social groups. Various fairness notions have been proposed to address unfairness issues. In this work, we focus on Equalized Loss (EL), a fairness notion that requires the expected loss to be (approximately) equalized across different groups. Imposing EL on the learning process leads to a non-convex optimization problem even if the loss function is convex, and the existing fair learning algorithms cannot properly be adopted to find the fair predictor under the EL constraint. This paper introduces an algorithm that can leverage off-the-shelf convex programming tools (e.g., CVXPY (Diamond and Boyd, 2016; Agrawal et al., 2018)) to efficiently find the global optimum of this non-convex optimization. In particular, we propose the ELminimizer algorithm, which finds the optimal fair predictor under EL by reducing the non-convex optimization to a sequence of convex optimization problems. We theoretically prove that our algorithm finds the global optimal solution under certain conditions. Then, we support our theoretical results through several empirical studies.",
    "author": [
      {
        "family": "Khalili",
        "given": "Mohammad Mahdi"
      },
      {
        "family": "Zhang",
        "given": "Xueru"
      },
      {
        "family": "Abroshan",
        "given": "Mahed"
      }
    ],
    "collection-title": "ICML’23",
    "container-title": "Proceedings of the 40th international conference on machine learning",
    "id": "10.5555/3618408.3619075",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "publisher": "JMLR.org",
    "publisher-place": "<conf-loc>, <city>Honolulu</city>, <state>Hawaii</state>, <country>USA</country>, </conf-loc>",
    "title": "Loss balancing for fair supervised learning",
    "type": "paper-conference"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Matthias Felleisen was awarded the 2011 SIGCSE Award for Outstanding Contribution to Computer Science Education for his and his research team’s work on the TeachScheme! project, which was begun in 1995, and is now called \"Program by Design\". This functions-first approach to teaching introductory programming and problem-solving features a robust software design methodology called the design recipe, and emphasizes good software engineering practices, such as early testing, from the beginning. These are combined with an integrated development environment (IDE), DrRacket, designed for beginners, featuring different language levels of the Scheme-like language, Racket, that combines simple syntax with customized error messages and support for graphics and animation accessible even for beginning programmers. The Program by Design project then includes support for transitioning to object-oriented programming in Java. However, many of this approach’s concepts can be applied in different programming languages (such as Java, Python, or C++), or one can choose to start with this approach and then transition to different programming paradigms and/or languages at a pace appropriate to your situation.",
    "author": [
      {
        "family": "Tuttle",
        "given": "Sharon M."
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/2037151.2037174",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2011,
          10
        ]
      ]
    },
    "page": "101",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Introducing programming in a functions-first manner, using the \"program by design\" approach",
    "type": "article-journal",
    "volume": "27"
  },
  {
    "DOI": "10.1145/3012430.3012495",
    "ISBN": "9781450347471",
    "URL": "https://doi.org/10.1145/3012430.3012495",
    "abstract": "This study seeks to extend the existing research on the use of visual programming tools to work and develop computational thinking. We show the primary education students’ perceptions of the use of the software Lego Education WeDo in the subject of natural sciences to promote the computational thinking. We tried to test the following hypotheses: Students will learn to build and program 3D models with Lego Education WeDo (H1), students will think creatively to solve the problems (H2), Lego Education WeDo will help pupils to know the relationship between cause and effect (H3), and the tasks developed will allow pupils to reflect about the possibilities they have and to find the correct answer (H4). Based on the result analysis there were evidences of the effectiveness of the project to increase the participants’ awareness of the computational thinking. The research also concluded that according to learners’ perception, the way in which activities were designed provided them possibilities to learn to build models in 3D and program them. Moreover, the findings of the study also demonstrated that the success of the project also depended on the teacher’s role as a guide in the teaching-learning process.",
    "author": [
      {
        "family": "Pinto-Llorente",
        "given": "Ana M"
      },
      {
        "family": "Martı́n",
        "given": "Sonia Casillas"
      },
      {
        "family": "González",
        "given": "Marcos Cabezas"
      },
      {
        "family": "Garcı́a-Peñalvo",
        "given": "Francisco José"
      }
    ],
    "collection-title": "TEEM ’16",
    "container-title": "Proceedings of the fourth international conference on technological ecosystems for enhancing multiculturality",
    "id": "10.1145/3012430.3012495",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "collaborative learning, computational thinking, introductory programming, natural sciences, visual programming tool",
    "page": "45-50",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Developing computational thinking via the visual programming tool: Lego education WeDo",
    "title-short": "Developing computational thinking via the visual programming tool",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/LaTiCE.2013.44",
    "ISBN": "9780769549606",
    "URL": "https://doi.org/10.1109/LaTiCE.2013.44",
    "abstract": "Discussing the use of plans in programming and in programming education, Solo way describes a programming task that has come to be known as the rainfall problem. This problem was used in a number of empirical experiments in the 1980s and 1990s, and was generally recognised as being quite difficult for student programmers. This paper reports that when the rainfall problem was recently used as an examination question in an introductory programming course, the students performed extremely poorly on it. These students are presumably no better than the many students who have been set this problem in the past, but it also appears that the problem has become harder than it was 20 years ago. For example, the problem assumes that loop-controlled keyboard input is standard, whereas in many programming environments nowadays the standard has become event-driven GUI input. As a consequence of this change, students are less likely to be familiar with loop-controlled keyboard input and with the use of a sentinel to terminate input, another feature of the rainfall problem. While there is potential value in comparing the performance of today’s students with that in the literature of past decades, it is important to consider changes in technology that might impose a different level of challenge on the same problem.",
    "author": [
      {
        "family": "Simon"
      }
    ],
    "collection-title": "LATICE ’13",
    "container-title": "Proceedings of the 2013 learning and teaching in computing and engineering",
    "id": "10.1109/LaTiCE.2013.44",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "keyword": "Soloway, programming education, rainfall",
    "page": "130-135",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Soloway’s rainfall problem has become harder",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3478431.3499393",
    "ISBN": "9781450390705",
    "URL": "https://doi.org/10.1145/3478431.3499393",
    "abstract": "With the widespread introduction of computer science as a new school subject, programming is experiencing a strong and promising upswing in primary school education. Programming concepts can be taught in a constructive manner, fostering students’ precision and algorithmic problem-solving skills. Simultaneously, this form of learning is also inherently challenging and error-prone. During a year-long study, we collected a trace of all failing Logo programs committed in the xlogo programming environment. Analyzing this data set allows us to confirm that Logo errors follow the same patterns as many other programming languages. In particular, we shed a light on the following three areas of Logo programming: (i) we determine which programming errors occur and their respective frequency, (ii) we verify previous work confirming that a handful of error classes account for the vast majority of all errors committed, and (iii) we highlight that some errors are rooted in deep misunderstandings of programming concepts rather than mere syntactical flaws. A core tenet, we argue, is that whilst errors cannot be eliminated entirely they offer an opportunity for both researchers and pupils alike.",
    "author": [
      {
        "family": "Staub",
        "given": "Jacqueline"
      },
      {
        "family": "Chothia",
        "given": "Zaheer"
      }
    ],
    "collection-title": "SIGCSE 2022",
    "container-title": "Proceedings of the 53rd ACM technical symposium on computer science education - volume 1",
    "id": "10.1145/3478431.3499393",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "frequency analysis, programming education, runtime error, syntax errors",
    "page": "571-577",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Large-scale analysis of error frequencies in logo programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "0769514952",
    "abstract": "It is difficult and challenging to comprehend the internal aspects of a program. The internal aspects are seen as contrasts to end user aspects and interface aspects. Internal program documentation is relevant for almost any kind of software. The internal program documentation represents the original as well as the accumulated understanding of the program, which is very difficult to extract from the source program and its modifications over time. Elucidative Programming is a documentation technique that originally is inspired by Literate Programming. As an important difference between the two, Elucidative Programming does not call for any reorganization of the source programs, as required by Literate Programming tools. Elucidative Programming provides for mutual navigation in between program source files and sections of the documentation. The navigation takes place in an Internet browser applying a two-framed layout. In this paper we investigate the applicabilityof Elucidative Programming in a number of areas related to internal program documentation. It is concluded that Elucidative Programming can solve a number of concrete problems in the areas of program tutorials, frameworks, and program reviews. In addition we see positive impacts of Elucidative Programming in the area of programming education.",
    "author": [
      {
        "family": "Vestdam",
        "given": "Thomas"
      },
      {
        "family": "N\"rmark",
        "given": "Kurt"
      }
    ],
    "collection-title": "IWPC ’02",
    "container-title": "Proceedings of the 10th international workshop on program comprehension",
    "id": "10.5555/580131.857009",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "page": "43",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Aspects of internal program documentation \" an elucidative perspective",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3638067.3638076",
    "ISBN": "9798400717154",
    "URL": "https://doi.org/10.1145/3638067.3638076",
    "abstract": "Assistive Technology (AT) has facilitated the integration and inclusion of people with disabilities in society. Regarding the visually impaired, the use of AT can be crucial in ensuring access to Information and Communication Technologies. However, in technical and higher-level courses related to computing, the use of AT may not be sufficient to ensure that these students comprehend the concepts addressed in the subjects and have access to all the resources provided by the tools necessary for their professional training. This is because screen readers, the main accessibility resource used by the visually impaired to interact with digital systems, generally perform a linear reading of the content available in the graphical interface, which can demand more time and effort from users. Additionally, this approach may limit access to information. This is particularly relevant in the case of Integrated Development Environment (IDEs), which have complex visual interfaces that may not be accessible to screen readers if accessibility requirements are not correctly implemented. Therefore, this study seeks to identify the barriers to interaction with IDEs faced by students in Computer Programming classes. The research involved surveying 12 professors of disciplines related to the area of Computer Programming who taught students with visual impairment. Additionally, interviews were conducted with 6 students and graduates with visual impairments from Technical and Higher Education courses in the area of Computing. The data were analyzed using Content Analysis. The results confirmed those already identified in the literature and also revealed new barriers.",
    "author": [
      {
        "family": "Zen",
        "given": "Eliana"
      },
      {
        "family": "Da Costa",
        "given": "Vinicius Kruger"
      },
      {
        "family": "Tavares",
        "given": "Tatiana Aires"
      }
    ],
    "collection-title": "IHC ’23",
    "container-title": "Proceedings of the XXII brazilian symposium on human factors in computing systems",
    "id": "10.1145/3638067.3638076",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "Accessibility, Assistive Technology, Computer Programming, Human-Computer Interaction, Visual Impairment",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding the accessibility barriers faced by learners with visual impairments in computer programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "9798662517028",
    "abstract": "This thesis represents the submission to the Open University for the degree of Master of Philosophy. The research topic lies within the discipline of computer science and in particular problems associated with the transportability of computer software are investigated. The study period was organised into 3 parts:• A literature search to look at what work had been done in the area.• The design of an intermediate language for a compiler.• The specification, design and implementation of a functional programming language in order to develop a portable programming environment. This thesis covers the work of the period Sep. 1978 to Jun. 1982, all of which was performed by part time study. The Thesis comprises 4 major sections and an appendix which shows program listings. The sections are as follows:• Section 1: The introduction• Section 2: The result of a literature search.• Section 3: A design for a compiler intermediate language, Ivor, covering the architecture of the underlying abstract machine and the structure of the intermediate language.• Section 4: The design and implementation of a function based programming language. Mule, including the structure of the language and a description of the implementation.",
    "author": [
      {
        "family": "Smith",
        "given": "R. P."
      }
    ],
    "genre": "Master’s thesis",
    "id": "10.5555/AAI28104555",
    "issued": {
      "date-parts": [
        [
          1986
        ]
      ]
    },
    "note": "AAI28104555",
    "publisher": "Open University (United Kingdom)",
    "title": "Software portability",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/13677.22723",
    "ISSN": "0734-2071",
    "URL": "https://doi.org/10.1145/13677.22723",
    "abstract": "The monitoring of distributed systems involves the collection, interpretation, and display of information concerning the interactions among concurrently executing processes. This information and its display can support the debugging, testing, performance evaluation, and dynamic documentation of distributed systems. General problems associated with monitoring are outlined in this paper, and the architecture of a general purpose, extensible, distributed monitoring system is presented. Three approaches to the display of process interactions are described: textual traces, animated graphical traces, and a combination of aspects of the textual and graphical approaches. The roles that each of these approaches fulfill in monitoring and debugging distributed systems are identified and compared. Monitoring tools for collecting communication statistics, detecting deadlock, controlling the non-deterministic execution of distributed systems, and for using protocol specifications in monitoring are also described.Our discussion is based on experience in the development and use of a monitoring system within a distributed programming environment called Jade. Jade was developed within the Computer Science Department of the University of Calgary and is now being used to support teaching and research at a number of university and research organizations.",
    "author": [
      {
        "family": "Joyce",
        "given": "Jeffrey"
      },
      {
        "family": "Lomow",
        "given": "Greg"
      },
      {
        "family": "Slind",
        "given": "Konrad"
      },
      {
        "family": "Unger",
        "given": "Brian"
      }
    ],
    "container-title": "ACM Trans. Comput. Syst.",
    "id": "10.1145/13677.22723",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          1987,
          3
        ]
      ]
    },
    "page": "121-150",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Monitoring distributed systems",
    "type": "article-journal",
    "volume": "5"
  },
  {
    "DOI": "10.1145/2700519",
    "URL": "https://doi.org/10.1145/2700519",
    "abstract": "The Object-Oriented Programming (OOP) technique is nowadays the most popular programming technique among tertiary education institutions. However, learning OOP is a cognitively demanding task for undergraduate students. Several difficulties and misconceptions have been recorded in the literature for both OOP concepts and languages, mainly Java. This article focuses on reviewing and advancing research on the most fundamental OOP concepts, namely, the concepts of “object” and “class” and their role during program execution. The results of a long-term investigation on the subject are presented, focusing on a study exploring undergraduate students’ conceptions on “objects” and “classes.” The study advances related research on categories of conceptions on “objects” and “classes” by providing quantitative results, in addition to qualitative results, regarding the frequency of the recorded conceptions. Nearly half the students seem to comprehend the modeling and static/dynamic aspects of the concepts “object” and “class.” Implications for achieving a deep conceptual understanding of text, action, and modeling aspects of these fundamental concepts are also discussed. Information regarding the programming environments utilized in the course and key features of the applied teaching approach are presented, in order to facilitate both a better understanding of the context and a better employment of the results of the presented study. Finally, proposals for enhancing the contribution of this and similar studies are made.",
    "author": [
      {
        "family": "Xinogalos",
        "given": "Stelios"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/2700519",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2015,
          7
        ]
      ]
    },
    "keyword": "Object-oriented programming, class, conceptions, misconceptions, object, teaching/learning programming",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Object-oriented design and programming: An investigation of novices’ conceptions on objects and classes",
    "title-short": "Object-oriented design and programming",
    "type": "article-journal",
    "volume": "15"
  },
  {
    "DOI": "10.1145/3328778.3366838",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3366838",
    "abstract": "Students who study problem solving and programming (in a language such as Python) at University level encounter a range of challenges, from low-level issues with code that won’t compile to misconceptions about the threshold concepts and skills. The current study complements existing findings on errors, misconceptions, difficulties and challenges obtained from students after-the-fact through instruments such as questionnaires and interviews. In our study, we analysed the posts from students of a large cohort (textasciitilde1500) of first-year University distance learning students to an online ’Python help forum’ - recording issues and discussions as the students encountered specific challenges. Posts were coded in terms of topics, and subsequently thematically grouped into Python-related, problem solving/generic programming related, and module specific. We discuss the set of topics and rank these in terms of the number of forum discussions in which they occur (as a proxy for their prevalence). The top challenges we identified concern student understanding and use of a mix of programming environments (in particular, Python IDLE for offline programming and CodeRunner for programming quizzes) and code fragment problems. Apart from these, Python-specific topics include, among others, collections, functions, error messages, iteration, outputting results, indentation, variables and imports. We believe that the results provide a good insight into the challenges that students encounter em as they learn to program. In future work we intend to study the discussions in further detail in terms of theories of conceptual change.",
    "author": [
      {
        "family": "Piwek",
        "given": "Paul"
      },
      {
        "family": "Savage",
        "given": "Simon"
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3366838",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "challenges, misconceptions, online student discussions, problem solving, programming, python, threshold concepts and skills",
    "page": "494-499",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Challenges with learning to program and problem solve: An analysis of student online discussions",
    "title-short": "Challenges with learning to program and problem solve",
    "type": "paper-conference"
  },
  {
    "ISBN": "0889865809",
    "abstract": "Visual Motor Integration tests, which involve a subject copying geometric shapes, are often used as one of a battery of tests to assess the needs of a child who may have a specific learning difficulty (SpLD). As part of the Dyslexia Early Screening Test (DEST), the resulting freehand sketches are assessed by an expert who analyses them visually and decides on the degree of similarity between the sketches and a shape copying scoring template. The assessment is time-consuming and rather subjective. In this paper, we investigate the use of Zernike moment descriptors as a feature extraction technique for training a k-nearest neighbour classifier to recognise and automatically assign scores to a set of hand-sketched shapes. A prototype shape copying assessment system DESCAR has been implemented using the Matlab programming environment. Scoring classification accuracy has been evaluated on a test corpus of 840 sketches comprising 120 different drawings of each of 7 different shapes used in the DEST study [16]. Experimental results show that machine score accuracy rates in the range 63.6-77.9",
    "author": [
      {
        "family": "Naftel",
        "given": "Andrew"
      },
      {
        "family": "Throuvalas",
        "given": "Antonios"
      },
      {
        "family": "Evans",
        "given": "Gareth"
      }
    ],
    "collection-title": "SPPRA’06",
    "container-title": "Proceedings of the 24th IASTED international conference on signal processing, pattern recognition, and applications",
    "id": "10.5555/1169107.1169155",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "keyword": "classification, dyslexia testing, moment descriptors, sketch recognition",
    "page": "262-267",
    "publisher": "ACTA Press",
    "publisher-place": "USA",
    "title": "Machine assessment of shape copying tests using zernike moment descriptors",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3241815.3242586",
    "ISBN": "9781450359542",
    "URL": "https://doi.org/10.1145/3241815.3242586",
    "abstract": "Engaging underrepresented populations of women and minorities in Computer Science (CS) represents our greatest untapped resource for increasing the STEM workforce. In recent years, tremendous efforts have been geared towards developing learning materials to increase the interest of underrepresented students in CS. More recently, CS education researchers are beginning to recognize the need to apply the learning sciences to develop age- and grade-appropriate curricula and pedagogies for developing computing competencies among children. One effective approach to build learning competencies among young underrepresented students is through Collaborative Learning, which is an educational approach that involves groups of learners working together to solve a problem or create a product. Our goal, in this paper, is to report our experiences on designing and delivering a curriculum that teaches programming to middle school students using App Inventor through collaborative learning. Our curriculum is developed on the hypothesis that visual programming environment, in this case, App Inventor, present an alternative way of learning programming, which in the collaborative learning environment can enhance programming competencies and interests in underrepresented students. In this experience report, we will describe how we implemented this curriculum as a block course; present our lessons learned, and few findings from the evaluation.",
    "author": [
      {
        "family": "Rahman",
        "given": "Farzana"
      }
    ],
    "collection-title": "SIGITE ’18",
    "container-title": "Proceedings of the 19th annual SIG conference on information technology education",
    "id": "10.1145/3241815.3242586",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "appinventor, collaborative learning, programming fundamentals, visual programming language",
    "page": "172-177",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Leveraging visual programming language and collaborative learning to broaden participation in computer science",
    "type": "paper-conference"
  },
  {
    "ISBN": "0262534800",
    "abstract": "A completely revised edition, offering new design recipes for interactive programs and support for images as plain values, testing, event-driven programming, and even distributed programming. This introduction to programming places computer science at the core of a liberal arts education. Unlike other introductory books, it focuses on the program design process, presenting program design guidelines that show the reader how to analyze a problem statement, how to formulate concise goals, how to make up examples, how to develop an outline of the solution, how to finish the program, and how to test it. Because learning to design programs is about the study of principles and the acquisition of transferable skills, the text does not use an off-the-shelf industrial language but presents a tailor-made teaching language. For the same reason, it offers DrRacket, a programming environment for novices that supports playful, feedback-oriented learning. The environment grows with readers as they master the material in the book until it supports a full-fledged language for the whole spectrum of programming tasks. This second edition has been completely revised. While the book continues to teach a systematic approach to program design, the second edition introduces different design recipes for interactive programs with graphical interfaces and batch programs. It also enriches its design recipes for functions with numerous new hints. Finally, the teaching languages and their IDE now come with support for images as plain values, testing, event-driven programming, and even distributed programming.",
    "author": [
      {
        "family": "Felleisen",
        "given": "Matthias"
      },
      {
        "family": "Findler",
        "given": "Robert Bruce"
      },
      {
        "family": "Flatt",
        "given": "Matthew"
      },
      {
        "family": "Krishnamurthi",
        "given": "Shriram"
      }
    ],
    "id": "10.5555/3265452",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "publisher": "The MIT Press",
    "title": "How to design programs: An introduction to programming and computing",
    "title-short": "How to design programs",
    "type": "book"
  },
  {
    "DOI": "10.1145/2576768.2598264",
    "ISBN": "9781450326629",
    "URL": "https://doi.org/10.1145/2576768.2598264",
    "abstract": "This paper presents Kaizen Programming, an evolutionary tool based on the concepts of Continuous Improvement from Kaizen Japanese methodology. One may see Kaizen Programming as a new paradigm since, as opposed to classical evolutionary algorithms where individuals are complete solutions, in Kaizen Programming each expert proposes an idea to solve part of the problem, thus a solution is composed of all ideas together. Consequently, evolution becomes a collaborative approach instead of an egocentric one. An idea’s quality (analog to an individual’s fitness) is not how good it fits the data, but a measurement of its contribution to the solution, which improves the knowledge about the problem. Differently from evolutionary algorithms that simply perform trial-and-error search, one can determine, exactly, parts of the solution that should be removed or improved. That property results in the reduction in bloat, number of function evaluations, and computing time. Even more important, the Kaizen Programming tool, proposed to solve symbolic regression problems, builds the solutions as linear regression models - not linear in the variables, but linear in the parameters, thus all properties and characteristics of such statistical tool are valid. Experiments on benchmark functions proposed in the literature show that Kaizen Programming easily outperforms Genetic Programming and other methods, providing high quality solutions for both training and testing sets while requiring a small number of function evaluations.",
    "author": [
      {
        "family": "De Melo",
        "given": "Vinı́cius Veloso"
      }
    ],
    "collection-title": "GECCO ’14",
    "container-title": "Proceedings of the 2014 annual conference on genetic and evolutionary computation",
    "id": "10.1145/2576768.2598264",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "collaborative problem solving, curve-fitting, evolutionary algorithm, genetic programming, linear regression, symbolic regression",
    "page": "895-902",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Kaizen programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2872521",
    "URL": "https://doi.org/10.1145/2872521",
    "abstract": "The past few years has seen a proliferation of novice programming tools. The availability of a large number of systems has made it difficult for many users to choose among them. Even for education researchers, comparing the relative quality of these tools, or judging their respective suitability for a given context, is hard in many instances. For designers of such systems, assessing the respective quality of competing design decisions can be equally difficult.Heuristic evaluation provides a practical method of assessing the quality of alternatives in these situations and of identifying potential problems with existing systems for a given target group or context. Existing sets of heuristics, however, are not specific to the domain of novice programming and thus do not evaluate all aspects of interest to us in this specialised application domain.In this article, we propose a set of heuristics to be used in heuristic evaluations of novice programming systems. These heuristics have the potential to allow a useful assessment of the quality of a given system with lower cost than full formal user studies and greater precision than the use of existing sets of heuristics. The heuristics are described and discussed in detail. We present an evaluation of the effectiveness of the heuristics that suggests that the new set of heuristics provides additional useful information to designers not obtained with existing heuristics sets.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      },
      {
        "family": "McKay",
        "given": "Fraser"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/2872521",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2016,
          6
        ]
      ]
    },
    "keyword": "HCI, heuristic evaluation, introductory programming tools",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Heuristic evaluation for novice programming systems",
    "type": "article-journal",
    "volume": "16"
  },
  {
    "DOI": "10.1145/3408877.3432389",
    "ISBN": "9781450380621",
    "URL": "https://doi.org/10.1145/3408877.3432389",
    "abstract": "Collaborative learning has been effective and widely adopted in Computer Science education. Existing studies have controlled for group sizes by assigning members to determine the optimal collaboration environment, with some focusing on a peer-programming environment and others observing a wider range of sizes and tasks.We analyzed collaboration trends through an observational study of 189 students in a large upper-level Computer Science algorithms course, which uses a less-constrained collaborative setting. In the course, the collaboration policy encourages students to choose their own groups for each assignment, up to four other students, offering insight into how groups evolve in size and membership when students are given the freedom to self-select. Since each student is required to submit their own individual work, we collected information about the grade and self-reported collaborators of each research participant for nine assignments, including written and coding homework.Our results show that any collaboration improved individual performance on average. For programming assignments, groups of size four were optimal. Across both written and programming assignments, larger groups performed better, including chains of collaboration greater than the course policy allowed. However, sizes 4-5 performed best within the bounds of the policy. We also demonstrate that factors impacting collaboration include homework difficulty, time of grade release, students’ relative performance with respect to the class, as well as the homework type.",
    "author": [
      {
        "family": "Lin",
        "given": "Xinyue"
      },
      {
        "family": "Connors",
        "given": "James"
      },
      {
        "family": "Lim",
        "given": "Chang"
      },
      {
        "family": "Hott",
        "given": "John R."
      }
    ],
    "collection-title": "SIGCSE ’21",
    "container-title": "Proceedings of the 52nd ACM technical symposium on computer science education",
    "id": "10.1145/3408877.3432389",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "collaboration groups, collaborative learning, computer science education, group formation",
    "page": "212-218",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How do students collaborate? Analyzing group choice in a collaborative learning environment",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800174.809773",
    "ISBN": "0897910850",
    "URL": "https://doi.org/10.1145/800174.809773",
    "abstract": "The Ada programming language has gone public. The Department of Defense originally sponsored the effort in order to develop a high level language which could be used in real time computer systems. Such systems are written in assembly language or in obscure languages such as CMS (Navy), JOVIAL (Air Force), and TACPOL (Army). Each of the high level languages in current use by the services has deficiencies which require the use of assembly language in almost all applications. In fact, most of the real time applications which are written supposedly in a high level language are written actually in assembly language because the compilers accept assembly language statements. This sad state of affairs has resulted because none of the current language can handle all of the requirements of real time applications. For example, there exist at least four dialects of JOVIAL (J2, J3, J3B, and J73) none of which have a basic input or output capability.Some of the problems which result from the use of assembly language and obscure languages are logistical rather than technical: a small number of people know these languages; there is a dearth of training material and courses; there is no portability of programs or people between systems which use these languages; the programming environments for each of the languages is poor; the languages are not available on many computer systems.",
    "author": [
      {
        "family": "Saib",
        "given": "Sabina H."
      }
    ],
    "collection-title": "ACM ’82",
    "container-title": "Proceedings of the ACM ’82 conference",
    "id": "10.1145/800174.809773",
    "issued": {
      "date-parts": [
        [
          1982
        ]
      ]
    },
    "page": "118-120",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Issues in ada’s future sponsored by ACM/adatc (panel discussion)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3408877.3432554",
    "ISBN": "9781450380621",
    "URL": "https://doi.org/10.1145/3408877.3432554",
    "abstract": "There has been a worldwide surge in programming education initiatives for children and teenagers. In Brazil, this trend faces some challenges, namely inadequate infrastructure of most schools, notably public ones, that lack access to computers and tablets, and basic education curricular requirements not contemplating computer science concepts. This article reports on the five-year experience of an outreach project from a public university in Brazil. The project aims to promote computer science education and to teach programming to children and teenagers. Undergraduate engineering students who participate in the project as members engage in activities such as planning the courses and their schedules, creating partnerships with local schools and other educational projects, giving lectures, producing scientific research and educational materials, as well as promoting the project on social media. The courses use free online programming tools, Python, MIT App Inventor, and Arduino to cover fundamental concepts of programming and computational thinking. They vary approaches and tools according to the age range and available technological resources of the target audience. The use of unplugged activities means to assist in learning and to circumvent computer access problems. Furthermore, they serve for introducing basic programming concepts in classes and motivating students with dynamic activities. Over its five-year existence, the project has achieved its purpose, by reaching a total of 2639 students through 45 workshops and 94 courses. It has provided courses in eleven public schools, created two booklets and one app as free educational material, along with presented papers and posters in scientific conferences.",
    "author": [
      {
        "family": "Branco",
        "given": "André"
      },
      {
        "family": "Dutra",
        "given": "Claudia"
      },
      {
        "family": "Zumpichiatti",
        "given": "Débora"
      },
      {
        "family": "Campos",
        "given": "Francisco Augusto"
      },
      {
        "family": "SantClair",
        "given": "Gabriel"
      },
      {
        "family": "Mello",
        "given": "Jhulian"
      },
      {
        "family": "Moreira",
        "given": "João Victor"
      },
      {
        "family": "Godinho",
        "given": "Julia"
      },
      {
        "family": "Marotti",
        "given": "Julia"
      },
      {
        "family": "Gomide",
        "given": "Janaina"
      }
    ],
    "collection-title": "SIGCSE ’21",
    "container-title": "Proceedings of the 52nd ACM technical symposium on computer science education",
    "id": "10.1145/3408877.3432554",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "computational thinking, computer science education, didactic strategies, k-12, programming",
    "page": "411-417",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Programming for children and teenagers in brazil: A 5-year experience of an outreach project",
    "title-short": "Programming for children and teenagers in brazil",
    "type": "paper-conference"
  },
  {
    "abstract": "Distributed Array Query and Visualization (DAQV) is a Parallel Tools Consortium sponsored project to create a tool for visualizing distributed data in High Performance Fortran (HPF). The DAQV tool is currently maintained at the University of Oregon, and our goals here at the Cornell Theory Center (CTC) are to verify the work done by the people there, and port the DAQV tool and its associated visualization clients to our IBM SP2 and IBM”s HPF compiler, XL HPF. We describe in this paper the installation of the DAQV tool first on an SGI Onyx, using Portland Group Inc.”s HPF compiler, pghpf, which was already supported by DAQV. We make various modifications to the distribution to generalize the installation, and then port the DAQV tool to the IBM SP2, also using the pghpf compiler. Finally, we accomplish the port of DAQV to IBM”s XL HPF compiler. We describe our approaches to overcoming various obstacles encountered in the porting process. These include re-analyzing the DAQV design to accommodate distinctions between the pghpf and XL HPF compiler run time implementations. The end result is not a single portable reference implementation of the DAQV tool, as was originally planned, but rather two different portable implmentations that demonstrate different ways in which a vendor may choose to perform the gathering of distributed data from HPF programs in a DAQV-like tool. Keywords: multiprocessors, parallel programming tools, data access, DAQV, data distribution, data parallel, Fortran, HPF, SP2, SPMD",
    "author": [
      {
        "family": "Presberg",
        "given": "David"
      },
      {
        "family": "Jaeger",
        "given": "Christopher"
      }
    ],
    "id": "10.5555/867115",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "publisher": "Cornell University",
    "publisher-place": "USA",
    "title": "Porting the distributed array query and visualization tool for high performance fortran to the SP2",
    "type": "report"
  },
  {
    "DOI": "10.1145/2676723.2677337",
    "ISBN": "9781450329668",
    "URL": "https://doi.org/10.1145/2676723.2677337",
    "abstract": "The recent successes of Computer Science Education Week and code.org’s Hour of Code have meant that more K-12 students than ever are being given an authentic, engaging and eye-opening exposure to the wonders of computer science. There are resources aplenty to help high school and college faculty with outreach. These range from easy-to-learn, open-ended programming environments (Scratch, Alice, Snap!), to online coding challenges (code.org, Lite-bot), to non-computer activities with live performances (CS Unplugged, cs4fn), to having the entire outreach experience delivered \"in a box\", thanks to NCWIT.We wanted to bring educators together to share experiences with what they’ve done specifically with a one-day event, given these vast resources. Now that there are so many online coding experiences, it is enough to shuttle young students into a computer room, point their browser at one of these experiences, and answer questions as they come up? Is it important to include hands-on and hands-off (e.g., nifty demos, inspiring talks) components, and if so, in what order? What do different demographics find the most engaging? Is there any chance that we can do \"damage\", since these highlight-reel experiences might over-simplify how hard some of the problems are, and that not every important result has a flashy payoff? Do some of the early experiences leave students with the impression that computer science is only (say) apps, interactive multimedia programs or solving mazes? Finally, when it’s over, what follow-up is appropriate? Participants on the panel will share best practices, common pitfalls, and advice.",
    "author": [
      {
        "family": "Garcia",
        "given": "Daniel D."
      },
      {
        "family": "Ding",
        "given": "Wei"
      },
      {
        "family": "Cohen",
        "given": "Joseph"
      },
      {
        "family": "Ericson",
        "given": "Barbara"
      },
      {
        "family": "Gray",
        "given": "Jeff"
      },
      {
        "family": "Reed",
        "given": "Dale"
      }
    ],
    "collection-title": "SIGCSE ’15",
    "container-title": "Proceedings of the 46th ACM technical symposium on computer science education",
    "id": "10.1145/2676723.2677337",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "computer science education, k-12, outreach",
    "page": "520-521",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "One-day activities for k-12 face-to-face outreach",
    "type": "paper-conference"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "A number of colleges and universities are using robots as a focus in introductory computer science courses to try to stimulate students’ interest in computer science. Several colleges have integrated robots into their CS1 courses or even built an entire course around robots [1, 2, 3, 4]. Other colleges have integrated robots into CS0 courses [5, 6]. In this poster, we present the experiences we had when incorporating robotics into our service course, which is designed to be neither a CS0 nor a CS1 course.Our course, Introduction to Information Technology, aims to introduce students to the concepts in information technology and their uses in the workplace. Because of breadth of this subject, we are only able to devote 1–1.5 weeks to any particular topic, including introducing students to computer programming. The course is almost entirely populated by students who will not major in computer science, although on rare occasions, a student taking this course will continue on to CS1 and the computer science major. Previously, we introduced programming with Scratch and also had students play a game called LightBot, which requires students to \"program\" a virtual robot to light up tiles [7, 8]. Many of the students had a lot of success with LightBot and enjoyed it. Conversely, a large portion of the students did not appear to be engaged with Scratch.This year, following the success of using LightBot, we considered alternate methods to introduce programming and chose to use robots in the course to introduce students to computer programming. We used the Scribbler robots from Parallax, Inc. in three of our four sections of Introduction to Information Technology this fall [9]. The Scribbler robot comes with a graphical programming environment that can be used by students instead of using the Basic Stamp editor that also comes with the robot. Students were taught how to use the graphical programming environment to make the Scribblers move, make decisions using if/else statements, repeat tasks with a while loop, and detect obstacles using the robot’s sensors. The students were encouraged to play with the robots for the 50 minute class period to get comfortable with them. They were told that during the following class, which was 100 minutes, their assignment would be to program the robots to navigate a simple U-shaped maze. The students were told that their robot should be able to be placed at either entrance of a maze by the professor and be able to enter the maze and exit out the other side.We had mixed results and encountered several unexpected challenges when conducting the lab. The success rate of the students was low and few students were able to complete the exercise the way we had hoped they would. This may have been due to some of the many problems we encountered while conducting this lab. However, the reason for changing the vehicle for introducing programming was to try to engage more students and a greater proportion of the students appeared to be engaged in trying to make the robot traverse the maze than had been engaged by Scratch last year. We also noticed that several students who had not seemed to be particularly engaged during the course were working hard on the lab and appeared to be enjoying themselves. Given that we were primarily looking to engage the students more successfully than last year, the lab may have worked better than the success rate indicated.",
    "author": [
      {
        "family": "Toth",
        "given": "David"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1791129.1791185",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2010,
          6
        ]
      ]
    },
    "page": "256-258",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Our experiences incorporating robotics into our service course: Poster session",
    "title-short": "Our experiences incorporating robotics into our service course",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "DOI": "10.1109/TE.2023.3281825",
    "ISSN": "0018-9359",
    "URL": "https://doi.org/10.1109/TE.2023.3281825",
    "abstract": "Contribution: A multidisciplinary computational framework to support undergraduate engineering education is introduced. It is posed as an open-source tool that students can use to understand and apply computational methods commonly required in engineering problems. Background: This framework development is motivated by past experiences of teaching courses as segregated disciplines within an aerospace engineering curriculum. Reviewing pedagogical approaches shows that current university practices do not adequately emphasize or demonstrate the importance of interdisciplinary relationships. This framework is also motivated by the apparent need for engineering graduates to study these relationships by learning computational engineering via programming, in which proficiency is becoming increasingly important for their future careers. Intended Outcomes: 1) To effectively teach multidisciplinary engineering concepts to students via the integration of cross-disciplinary content from various courses and 2) To improve computational and programming literacy among undergraduate students in engineering studies. Application Design: A multidisciplinary design optimization approach is adopted to develop a framework called Multidisciplinary Aircraft Design Education (MADE), which provides functionalities for studying engineering disciplines within a computational programming environment. MADE makes the related course contents more accessible and intuitive to students by using reactive computational notebooks in lectures, tutorials, and assignments. Findings: MADE is assessed based on the learning outcomes and feedback from undergraduate students of two courses within an aerospace engineering curriculum. These assessments indicate an improved understanding of multidisciplinary concepts and their applications via computational programming, as reflected in the positive responses from the students.",
    "author": [
      {
        "family": "Seth",
        "given": "Arjit"
      },
      {
        "family": "Redonnet",
        "given": "Stephane"
      },
      {
        "family": "Liem",
        "given": "Rhea P."
      }
    ],
    "container-title": "IEEE Trans. on Educ.",
    "id": "10.1109/TE.2023.3281825",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2023,
          6
        ]
      ]
    },
    "page": "622-631",
    "publisher": "IEEE Press",
    "title": "MADE: A multidisciplinary computational framework for aerospace engineering education",
    "title-short": "MADE",
    "type": "article-journal",
    "volume": "66"
  },
  {
    "ISBN": "0130960934",
    "abstract": "From the Publisher:This comprehensive book teaches the reader how to design and write portable elementary, intermediate and advanced batch and interactive ANSI C programs in their entirety, that are easy to read, debug, modify and maintain. The book and accompanying programs comprise a total package designed to satisfy all ANSI C needs in any of the programming environments that embrace the C Standard. The authors incorporate a build-as-you go method beginning the text with a complete billing application programming problem and progressively solving the problem chapter by chapter as programming knowledge grows thereby training the reader to develop programs in a modular, top-down way, as well as maintain and modify code. It also provides useful techniques for maintaining and modifying older “legacy” programs and covers information processing and system concepts. Building Blocks, Using Variables, Introduction to I/O, Expressions, Operators, and Type Conversion, Loops and Conditional Statements, Arrays, Pointers and Strings, Functions, String-Handling &amp; Buffer Functions, Scope and Duration, The Preprocessor, Byte Structure and Bit Manipulation, Complex Data Types and Type Conversion, Files, Dynamic Data Structures and Memory Allocation, Working with the System, Projects &amp; Program Chaining, Controlling the PC Console - Escape Sequences, Memory and Interrupts on the PC, Video Services Interrupts on the PC, Direct Memory Access on the PC, Graphics Mode and the Mouse on the PC, ASCII/EBCDIC Characters, and Extended Keyboard Codes. For programmers, systems administrators, or anyone responsible for programming or maintaining programs and systems written in ANSI C.",
    "author": [
      {
        "family": "Austell-Wolfson",
        "given": "Barry M."
      },
      {
        "family": "Otieno",
        "given": "Derek"
      }
    ],
    "edition": "1st",
    "id": "10.5555/555119",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "The complete book of c programming",
    "type": "book"
  },
  {
    "ISBN": "9780549699514",
    "abstract": "Although advances in parallel hardware continue to deliver a measurable increase in execution performance, corresponding improvements in the programmability and thereby productivity of HPC systems remain hard to quantify. Several factors such as the parallel programming language, the hardware architecture, and programmer aptitude influence the achieved performance and the required effort. While there exists a rich body of work to characterize system and application performance, the effect of factors such as programming languages and programmer workflows on performance and productivity is poorly understood. Traditional benchmarks narrowly focus on raw performance and fail to evaluate these factors. This dissertation presents an empirical approach to study the effect of these factors, especially programming languages, on productivity using experimental studies with human subjects. We leverage the development experience of students in HPC classroom studies to collect empirical data for our experimental analysis. Collecting high-quality data across multiple classroom studies is a challenging problem. We present a data collection methodology and an operational system that captures an accurate and concise view of the development workflow. Our system uses instrumented tools along with a high-level development framework to capture development activities of subjects with minimal intrusiveness. We address practical issues such as reproducibility, noise, and privacy that arise during data analysis. Using our system, we have consistently collected several high-quality datasets during a series of replicated studies.The dissertation presents a statistical approach for using this data to formally evaluate several hypotheses about the relative productivity of two parallel language extensions, MPI and UPC, that represent two mainstream parallel programming models. We formulate hypothesis tests for comparing the performance and productivity of these two models and present several statistically significant results. While the statistical method analyzes the data related to the developed software, a workflow model explains the development process and effort of the programmer. We propose a Hidden Markov Model to representatively model the workflow followed by subjects when using a given programming language. We present results from training and building these models on our datasets. We also describe GRID* p , a MATLAB-based programming environment that demonstrates the productivity and performance of high-level development tools for large-scale computations on the Grid. Results of developing two typical parallel applications show that GRID* p delivers promising performance for highly parallel applications with minimal development effort.",
    "author": [
      {
        "family": "Patel",
        "given": "Imran S."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1559634",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "note": "AAI3316493",
    "publisher": "University of California at Santa Barbara",
    "publisher-place": "USA",
    "title": "Empirical evaluation of software development productivity in high performance computing",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3077618",
    "URL": "https://doi.org/10.1145/3077618",
    "abstract": "Efforts to improve computer science education are underway, and teachers of computer science are challenged in introductory programming courses to help learners develop their understanding of programming and computer science. Identifying and addressing students’ misconceptions is a key part of a computer science teacher’s competence. However, relevant research on this topic is not as fully developed in the computer science education field as it is in mathematics and science education. In this article, we first review relevant literature on general definitions of misconceptions and studies about students’ misconceptions and other difficulties in introductory programming. Next, we investigate the factors that contribute to the difficulties. Finally, strategies and tools to address difficulties including misconceptions are discussed.Based on the review of literature, we found that students exhibit various misconceptions and other difficulties in syntactic knowledge, conceptual knowledge, and strategic knowledge. These difficulties experienced by students are related to many factors including unfamiliarity of syntax, natural language, math knowledge, inaccurate mental models, lack of strategies, programming environments, and teachers’ knowledge and instruction. However, many sources of students’ difficulties have connections with students’ prior knowledge. To better understand and address students’ misconceptions and other difficulties, various instructional approaches and tools have been developed. Nevertheless, the dissemination of these approaches and tools has been limited. Thus, first, we suggest enhancing the dissemination of existing tools and approaches and investigating their long-term effects. Second, we recommend that computing education research move beyond documenting misconceptions to address the development of students’ (mis)conceptions by integrating conceptual change theories. Third, we believe that developing and enhancing instructors’ pedagogical content knowledge (PCK), including their knowledge of students’ misconceptions and ability to apply effective instructional approaches and tools to address students’ difficulties, is vital to the success of teaching introductory programming.",
    "author": [
      {
        "family": "Qian",
        "given": "Yizhou"
      },
      {
        "family": "Lehman",
        "given": "James"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/3077618",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2017,
          10
        ]
      ]
    },
    "keyword": "Misconceptions, conceptual change, constructivism, difficulties, introductory programming",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Students’ misconceptions and other difficulties in introductory programming: A literature review",
    "title-short": "Students’ misconceptions and other difficulties in introductory programming",
    "type": "article-journal",
    "volume": "18"
  },
  {
    "DOI": "10.1007/s100090100054",
    "ISSN": "1433-2779",
    "URL": "https://doi.org/10.1007/s100090100054",
    "abstract": "In this article we give an overview of the worst-case execution time (WCET) analysis research performed by the WCET group of the ASTEC Competence Centre at Uppsala University. Knowing the WCET of a program is necessary when designing and verifying real-time systems. The WCET depends both on the program flow, such as loop iterations and function calls, and on hardware factors, such as caches and pipelines. WCET estimates should be both safe (no underestimation allowed) and tight (as little overestimation as possible). We have defined a modular architecture for a WCET tool, used both to identify the components of the overall WCET analysis problem, and as a starting point for the development of a WCET tool prototype. Within this framework we have proposed solutions to several key problems in WCET analysis, including representation and analysis of the control flow of programs, modeling of the behavior and timing of pipelines and other low-level timing aspects, integration of control flow information and low-level timing to obtain a safe and tight WCET estimate, and validation of our tools and methods. We have focussed on the needs of embedded real-time systems in designing our tools and directing our research. Our long-term goal is to provide WCET analysis as a part of the standard tool chain for embedded development (together with compilers, debuggers, and simulators). This is facilitated by our cooperation with the embedded systems programming-tools vendor IAR Systems.",
    "author": [
      {
        "family": "Engblom",
        "given": "Jakob"
      },
      {
        "family": "Ermedahl",
        "given": "Andreas"
      },
      {
        "family": "Sjödin",
        "given": "Mikael"
      },
      {
        "family": "Gustafsson",
        "given": "Jan"
      },
      {
        "family": "Hansson",
        "given": "Hans"
      }
    ],
    "container-title": "Int. J. Softw. Tools Technol. Transf.",
    "id": "10.1007/s100090100054",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2003,
          8
        ]
      ]
    },
    "keyword": "Embedded systems, Hard real-time, Programming tools, Software architecture, WCET analysis",
    "page": "437-455",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Worst-case execution-time analysis for embedded real-time systemsTHANKSREF=\"*\"ID=\"*\"this work was performed within the advanced software technology (ASTEC, http: //www.astec.uu.se) competence center, supported by the swedish national board for industrial and technical development (NUTEK, http://www.nutek.se).",
    "title-short": "Worst-case execution-time analysis for embedded real-time systemsTHANKSREF=\"*\"ID=\"*\"this work was performed within the advanced software technology (ASTEC, http",
    "type": "article-journal",
    "volume": "4"
  },
  {
    "DOI": "10.1145/3361721.3361729",
    "ISBN": "9781450377041",
    "URL": "https://doi.org/10.1145/3361721.3361729",
    "abstract": "Coding as a practical skill and computational thinking (CT) as a cognitive ability have become an important topic in education and research. It has been suggested that CT, as an early predictor of academic success, should be introduced and fostered early in education. However, there is no consensus on the underlying cognitive correlates of CT in young elementary school children. Therefore, the present work aimed at (i) assessing CT and investigating its associations to established cognitive abilities, and (ii) evaluating a newly developed CT course for elementary school children.As such, 31 7-10-year-old children took part in 10 lessons of a structured CT course. The course aimed at introducing and fostering CT concepts in both unplugged and plugged-in ways, incorporating life-size board games, Scratch, Scratch for Arduino, and Open Roberta programming environments. In a pre-/post-test design, we assessed several cognitive abilities using standardized tests on nonverbal-visuospatial and verbal reasoning abilities, numeracy, as well as short-term memory, and measured CT using an adapted version of the only existing validated test CTt, to accommodate it to the younger sample.We identified significant associations between CT and nonverbal-visuospatial reasoning, as well as different aspects of numeracy (e.g., fact retrieval and problem completion). In line with recent theoretical accounts and empirical investigations for other age groups, these findings specify the underlying cognitive mechanism of CT in elementary school. Moreover, our results indicated that students were able to specifically improve their CT abilities through the course, as assessed by the adapted version of the CTt.",
    "author": [
      {
        "family": "Tsarava",
        "given": "Katerina"
      },
      {
        "family": "Leifheit",
        "given": "Luzia"
      },
      {
        "family": "Ninaus",
        "given": "Manuel"
      },
      {
        "family": "Román-González",
        "given": "Marcos"
      },
      {
        "family": "Butz",
        "given": "Martin V."
      },
      {
        "family": "Golle",
        "given": "Jessika"
      },
      {
        "family": "Trautwein",
        "given": "Ulrich"
      },
      {
        "family": "Moeller",
        "given": "Korbinian"
      }
    ],
    "collection-title": "WiPSCE ’19",
    "container-title": "Proceedings of the 14th workshop in primary and secondary computing education",
    "id": "10.1145/3361721.3361729",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "cognitive skills, computational thinking, computational thinking assessment, computational thinking curriculum",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Cognitive correlates of computational thinking: Evaluation of a blended unplugged/plugged-in course",
    "title-short": "Cognitive correlates of computational thinking",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICHIT.2008.243",
    "ISBN": "9780769533285",
    "URL": "https://doi.org/10.1109/ICHIT.2008.243",
    "abstract": "The present web has not provided the function of more than the information store in that the collected and retrieved information should be interpreted and be purified though the present Web has a merit that can search correlated information easily through simple connections between documents. So, to overcome the limitation of the existing web like this, researches for Semantic web ontology languages (RDF, RDFS, OWL and so on) prescribed as standard of W3C and for the related technologies have conducted actively. Also, recently the interest for Jena2, Java framework, including rule-based inference engine and the programming environment for the languages like RDF, FDFS, OWL, SPARQL and so on has been heightened. Jena2 has problems that the performance for simple selection operation and the performance for the query that join operations are required slow down, and the performance in processing OWL data slows down because storing document information in a single table. This paper designed and realized OWL Translator to move to the relational database designing in this paper the data being in Multiple Translator and Jena Relational Database for storing each data information in a separate table after dividing the meaning of OWL documents into Class, Property, Individual to solve this problem. Also, this paper compared the processing performances of the engine quality realizing by using Multiple Translator and OWL Translator and the engine realizing by applying as it is the functions providing in Jena2 by using University Ontology providing in SPARQL engine of Jena2.",
    "author": [
      {
        "family": "Heo",
        "given": "Sun-Young"
      },
      {
        "family": "Kim",
        "given": "Eun-Gyung"
      }
    ],
    "collection-title": "ICHIT ’08",
    "container-title": "Proceedings of the 2008 international conference on convergence and hybrid information technology",
    "id": "10.1109/ICHIT.2008.243",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "ERD, Inference Engine, Jena, OWL, OWL-QL, Ontology, Semantic Web",
    "page": "678-681",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "A study on the improvement of query processing performance of OWL data based on Jena2",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-030-77961-0_60",
    "ISBN": "978-3-030-77960-3",
    "URL": "https://doi.org/10.1007/978-3-030-77961-0_60",
    "abstract": "Extracting scientific facts from unstructured text is difficult due to challenges specific to the complexity of the scientific named entities and relations to be extracted. This problem is well illustrated through the extraction of polymer names and their properties. Even in the cases where the property is a temperature, identifying the polymer name associated with the temperature may require expertise due to the use of complicated naming conventions and by the fact that new polymer names are being “introduced” into the lexicon as polymer science advances. While domain-specific machine learning toolkits exist that address these challenges, perhaps the greatest challenge is the lack of—time-consuming, error-prone and costly—labeled data to train these machine learning models. This work repurposes Snorkel, a data programming tool, in a novel approach as a way to identify sentences that contain the relation of interest in order to generate training data, and as a first step towards extracting the entities themselves. By achieving 94",
    "author": [
      {
        "family": "Murphy",
        "given": "Erin"
      },
      {
        "family": "Rasin",
        "given": "Alexander"
      },
      {
        "family": "Furst",
        "given": "Jacob"
      },
      {
        "family": "Raicu",
        "given": "Daniela"
      },
      {
        "family": "Tchoua",
        "given": "Roselyne"
      }
    ],
    "container-title": "Computational science – ICCS 2021: 21st international conference, krakow, poland, june 16–18, 2021, proceedings, part i",
    "id": "10.1007/978-3-030-77961-0_60",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Information extraction, Data labeling, Relations extraction, Snorkel, Data programming, Polymers",
    "page": "750-764",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Ensemble labeling towards scientific information extraction (ELSIE)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3481312.3481318",
    "ISBN": "9781450385718",
    "URL": "https://doi.org/10.1145/3481312.3481318",
    "abstract": "Block-based programming languages, and Scratch in particular, are widely used to introduce young learners to programming. As these students progress through their education, they want or need to transition to using text-based systems and encounter a number of challenges as they do so. Issues with syntax, text editing, and memorisation are all significant, but the change of programming paradigm is also a challenge. This paper discusses the design and development of a system to help students make the transition to text-based programming environments more easily. Sprites, animations and sound form the basis of most Scratch programs and these engaging features become unavailable at the same time as students are facing transition difficulties related to text editing and program structure. From programs designed in an actor-based event-driven system with easy concurrency, students have to move to procedural or class-based programs where multimedia features are accessed quite differently and programs are designed around explicit event loops. In this paper we introduce a new programming system, Pytch, which embodies “Scratch-Oriented programming” in Python. Using a web-based environment that requires no local setup, students can build Python programs using the familiar sprites and concurrent event-driven model learned in Scratch. The system offers the programming model inspired by Scratch through a Python library and a runtime augmented with a form of managed concurrency. The motivation and related work are discussed, and the system is presented in its current form. The next stage will be to evaluate the effectiveness of the system with users.",
    "author": [
      {
        "family": "Strong",
        "given": "Glenn"
      },
      {
        "family": "North",
        "given": "Ben"
      }
    ],
    "collection-title": "WiPSCE ’21",
    "container-title": "Proceedings of the 16th workshop in primary and secondary computing education",
    "id": "10.1145/3481312.3481318",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Education, Games, Programming languages, Python, Scratch",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Pytch — an environment for bridging block and text programming styles (work in progress)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800179.810207",
    "ISBN": "9781450339216",
    "URL": "https://doi.org/10.1145/800179.810207",
    "abstract": "AI-CAI, the application of artificial intelligence techniques to the design of personal learning environments, is an enterprise encompassing both theoretical and practical concerns. In the short term, the process of developing and testing intelligent tutoring programs serves as a new experimental vehicle for exploring alternative cognitive and pedagogical theories. In the long term, such programs will supplement the educational supervision and guidance provided by human teachers.The lesson of AI-CAI to date has been that the critical component for a successful system is a model of the expertise to be conveyed which is modular, comprehensible, and articulate. Hence, as a step toward an AI-CAI tutor for elementary graphics programming, a rule-based theory of the planning and debugging of programs is explored.The rules are formalized as a context free grammar. This grammar is used to reveal the constituent structure of problem solving episodes, by parsing protocols in which programs are written, tested and debugged. This is illustrated by the analysis of a session with a beginning student. The virtues of the approach for constructing models of individual students’ skills are discussed; limitations and extensions of the approach are also considered.",
    "author": [
      {
        "family": "Miller",
        "given": "Mark L."
      },
      {
        "family": "Goldstein",
        "given": "Ira P."
      }
    ],
    "collection-title": "ACM ’77",
    "container-title": "Proceedings of the 1977 annual conference",
    "id": "10.1145/800179.810207",
    "issued": {
      "date-parts": [
        [
          1977
        ]
      ]
    },
    "keyword": "Artificial intelligence, Computer aided instruction, Computer science education, Computer uses in education, Context free grammars, Information processing psychology, Logo, Personal learning environments, Planning and debugging, Problem solving, Program understanding, Programming environments, Protocol analysis, Structured programming",
    "page": "220-226",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Problem solving grammars as formal tools for intelligent CAI",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1023/B:EMSE.0000027778.69251.1f",
    "ISSN": "1382-3256",
    "URL": "https://doi.org/10.1023/B:EMSE.0000027778.69251.1f",
    "abstract": "Software “design patterns” seek to package proven solutions to design problems in a form that makes it possible to find, adapt and reuse them. To support the industrial use of design patterns, this research investigates when, and how, using patterns is beneficial, and whether some patterns are more difficult to use than others. This paper describes a replication of an earlier controlled experiment on design patterns in maintenance, with major extensions. Experimental realism was increased by using a real programming environment instead of pen and paper, and paid professionals from multiple major consultancy companies as subjects. Measurements of elapsed time and correctness were analyzed using regression models and an estimation method that took into account the correlations present in the raw data. Together with on-line logging of the subjects’ work, this made possible a better qualitative understanding of the results. The results indicate quite strongly that some patterns are much easier to understand and use than others. In particular, the Visitor pattern caused much confusion. Conversely, the patterns Observer and, to a certain extent, Decorator were grasped and used intuitively, even by subjects with little or no knowledge of patterns. The implication is that design patterns are not universally good or bad, but must be used in a way that matches the problem and the people. When approaching a program with documented design patterns, even basic training can improve both the speed and quality of maintenance activities.",
    "author": [
      {
        "family": "Vokáč",
        "given": "Marek"
      },
      {
        "family": "Tichy",
        "given": "Walter"
      },
      {
        "family": "Sjøberg",
        "given": "Dag I. K."
      },
      {
        "family": "Arisholm",
        "given": "Erik"
      },
      {
        "family": "Aldrin",
        "given": "Magne"
      }
    ],
    "container-title": "Empirical Softw. Engg.",
    "id": "10.1023/B:EMSE.0000027778.69251.1f",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2004,
          9
        ]
      ]
    },
    "keyword": "Controlled experiment, design patterns, qualitative results, real programming environment",
    "page": "149-195",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "A controlled experiment comparing the maintainability of programs designed with and without design patterns—a replication in a real programming environment",
    "type": "article-journal",
    "volume": "9"
  },
  {
    "DOI": "10.1007/s10639-023-11625-8",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-023-11625-8",
    "abstract": "Programming education is an important educational process that enables the development of children’s problem solving and algorithmic thinking skills. It is known that children frequently encounter syntax problems in coding activities. Many block-based programming software has been developed to eliminate this difficulty in the learning process. Block-based programming software is widely used all over the world because of its colorful features and providing a coding environment that children can learn easily. However, analyzes on the usefulness of such widely used block-based programming software cannot be found in the literature. In this study, the usability of code.org block-based coding environment was analyzed through the coding practices of children. The study group was consisted of 14 children aged between 9 and 13. Analyzes were made in terms of efficacy, efficiency, and satisfaction. For the efficacy analysis of the programming environment, it was observed that all the children completed the tasks assigned to them. In efficiency analysis; task times, task step counts, need for assistance in the process of using software, overall focus data, heat maps, eye scanning data and focus levels in the guided area of the participants were examined. In satisfaction analysis; satisfaction level of participants was examined. As a result of the research; usability data for Code.org environment has been tried to be presented in detail. In the efficacy dimension, while there were generally no problems regarding the task completion status of the participants; in efficiency dimension, suggestions were made regarding the placement of the blocks, block sizes and application methods. In satisfaction dimension, it was seen that children faced with problems during the block search process.",
    "author": [
      {
        "family": "Dilmen",
        "given": "Kaan"
      },
      {
        "family": "Kert",
        "given": "Serhat Bahadır"
      },
      {
        "family": "Uğraş",
        "given": "Tuba"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-023-11625-8",
    "issue": "9",
    "issued": {
      "date-parts": [
        [
          2023,
          2
        ]
      ]
    },
    "keyword": "Coding education, Programming, Usability, Block-based environment, Secondary education",
    "page": "10839-10864",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Children’s coding experiences in a block-based coding environment: A usability study on code.org",
    "title-short": "Children’s coding experiences in a block-based coding environment",
    "type": "article-journal",
    "volume": "28"
  },
  {
    "DOI": "10.1006/ijhc.1994.1032",
    "ISSN": "1071-5819",
    "URL": "https://doi.org/10.1006/ijhc.1994.1032",
    "abstract": "This paper explores the relationship between knowledge structure and organization and the development of expertise in a complex problem-solving task. An empirical study of skill acquisition in computer programming is reported, providing support for a model of knowledge organization that stresses the importance of knowledge restructuring processes in the development of expertise. This is contrasted with existing models which have tended to place emphasis upon schemata acquisition and generalization as the fundamental modes of learning associated with skill development. The work reported in this paper suggests that a fine-grained restructuring of individual schemata takes place during the later stages of skill development. It is argued that those mechanisms currently thought to be associated with the development of expertise may not fully account for the strategic changes and the types of error typically found in the transition between intermediate and expert problem solvers. This work has a number of implications. Firstly, it suggests important limitations of existing theories of skill acquisition. This is particularly evident in terms of the ability of such theories to account for subtle changes in the various manifestations of skilled performance that are associated with increasing expertise. Secondly, the work reported in this paper attempts to show how specific forms of training can give rise to this knowledge restructuring process. It is argued that the effects of particular forms of training are of primary importance, but these effects are often given little attention in theoretical accounts of skill acquisition. Finally, the work presented here has practical relevance in a number of applied areas including the design of intelligent tutoring systems and programming environments.",
    "author": [
      {
        "family": "Davies",
        "given": "Simon P."
      }
    ],
    "container-title": "Int. J. Hum.-Comput. Stud.",
    "id": "10.1006/ijhc.1994.1032",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1994,
          4
        ]
      ]
    },
    "page": "703-726",
    "publisher": "Academic Press, Inc.",
    "publisher-place": "USA",
    "title": "Knowledge restructuring and the acquisition of programming expertise",
    "type": "article-journal",
    "volume": "40"
  },
  {
    "abstract": "One of the most exciting aspects of modern computer science is the transformation of programming from an art to a science. Program reliability, software management, and structured programming are all helping produce quality programs. An important contribution to the ever increasing excellence of software is the improvement of computer science education at the earliest levels. A new programming language, KL, has been designed and developed specifically for use in introductory computer science courses. The developmental goals of KL were: (1) inclusion of structured-programming tools, (2) simplicity for the user, (3) straightforward implementation, and (4) adaptability to small computers.These goals were accomplished in a number of ways. The structure of KL requires that each statement begin with a keyword and end with a semi-colon. This decreases the implementation effort and adds to the simplicity of the language. This form also eliminates the necessity for reserved words which often cause difficulty for the user. The keywords have been chosen to be meaningful and, when possible, short. Restricting the number of different statements available supports all four goals.The tools needed for abstraction are included in KL. User-defined data types are available in KL. Procedures and functions are also available for dividing a computer problem into subtasks.KL is a suitable language for teaching programming for several reasons. It requires structured programming techniques because no other constructs are available. This should start good programming habits. The concepts of structured programming can be learned using KL and later applied to other less structured languages. The concepts of structured programming are language independent and KL enables the learning of these concepts early in a computer scientist’s career.",
    "author": [
      {
        "family": "Van Houten",
        "given": "Karen Jane Hamilton"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/909456",
    "issued": {
      "date-parts": [
        [
          1980
        ]
      ]
    },
    "note": "AAI8019797",
    "publisher": "University of Idaho",
    "publisher-place": "USA",
    "title": "Kl, a well-structured beginning computer language",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3551349.3556939",
    "ISBN": "9781450394758",
    "URL": "https://doi.org/10.1145/3551349.3556939",
    "abstract": "Game-like programs have become increasingly popular in many software engineering domains such as mobile apps, web applications, or programming education. However, creating tests for programs that have the purpose of challenging human players is a daunting task for automatic test generators. Even if test generation succeeds in finding a relevant sequence of events to exercise a program, the randomized nature of games means that it may neither be possible to reproduce the exact program behavior underlying this sequence, nor to create test assertions checking if observed randomized game behavior is correct. To overcome these problems, we propose Neatest, a novel test generator based on the NeuroEvolution of Augmenting Topologies (NEAT) algorithm. Neatest systematically explores a program’s statements, and creates neural networks that operate the program in order to reliably reach each statement—that is, Neatest learns to play the game in a way to reliably cover different parts of the code. As the networks learn the actual game behavior, they can also serve as test oracles by evaluating how surprising the observed behavior of a program under test is compared to a supposedly correct version of the program. We evaluate this approach in the context of Scratch, an educational programming environment. Our empirical study on 25 non-trivial Scratch games demonstrates that our approach can successfully train neural networks that are not only far more resilient to random influences than traditional test suites consisting of static input sequences, but are also highly effective with an average mutation score of more than 65",
    "author": [
      {
        "family": "Feldmeier",
        "given": "Patric"
      },
      {
        "family": "Fraser",
        "given": "Gordon"
      }
    ],
    "collection-title": "ASE ’22",
    "container-title": "Proceedings of the 37th IEEE/ACM international conference on automated software engineering",
    "id": "10.1145/3551349.3556939",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "Automated Testing, Game Testing, Neuroevolution, Scratch",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Neuroevolution-based generation of tests and oracles for games",
    "type": "paper-conference"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Algorithms have existed for at least 2,000 years (e.g., Euclid’s algorithm). In music and art, algorithms appear as early as Guido d’Arezzo (ca. 1000 A.D.), and in compositions by Bach, Mozart, John Cage, Iannis Xenakis, among others. Modern examples include data sonification for scientific or aesthetic purposes, such as sonifying biosignals, images, orbits of planets, and human movement (e.g., dance), among others. This talk will focus on Computing in the Arts (CITA), an NSF-funded model curriculum, which combines creativity, problem solving, and computer programming to prepare students for graduate school and careers in technology and arts industries of the 21st century. CITA is part of the new movement to combine art and design with science, technology, engineering and math (STEM + Art = STEAM). Several examples will be presented, including:• SoundMorpheus (an innovative interface for positioning sounds via arm movements);• Diving into Infinity (a motion-based system which explores depictions of infinity in M.C. Escher’s works); and• JythonMusic (a programming environment for developing interactive music experiences and systems).Bill Manaris is Professor of Computer Science, and Director of the Computing in the Arts program at the College of Charleston. His areas of expertise include computer music, human-computer interaction and artificial intelligence. He explores interaction design, modeling of aesthetics and creativity, sound spatialization, and telematics. As an undergraduate, he studied computer science and music at the University of New Orleans, and holds M.S. and Ph.D. degrees in Computer Science from the University of Louisiana. He also studied classical and jazz guitar. Recently, he published a textbook in Computer Music and Creative Programming. His research has been supported by the National Science Foundation, Google, IBM, the Louisiana Board of Regents, and the Stavros Niarchos Foundation.",
    "author": [
      {
        "family": "Manaris",
        "given": "Bill"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/3205191.3205192",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2018,
          6
        ]
      ]
    },
    "page": "5-6",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Computing in the arts: The algorithm is the medium",
    "title-short": "Computing in the arts",
    "type": "article-journal",
    "volume": "33"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "• This tutorial will demonstrate Greenfoot, a programming environment developed by the creators of BlueJ, that allows teaching of object-oriented programming concepts – using Java – in a highly engaging and motivating context.• One of the major problems in teaching computing today is the lack of interest in many young people. Computing suffers from a disastrous reputation (to a great extent wrongly). It is perceived as boring, geeky, unrewarding, and antisocial. Popular preconceptions of overweight male teenagers with thick glasses and skin problems sitting alone in windowless cellar rooms in front of a computer screen with pizza boxes strewn around them do little to attract a more diverse group to computer science.• Greenfoot is designed to enable teachers to bring fun and engagement back into computing, while teaching real programming concepts, and without trivializing the subject matter. Students quickly start to program graphical, interactive applications, such as games and simulations. A very diverse set of possible projects and sample programs serves to attract groups of students who would not normally take an interest in programming.• The Greenfoot environment provides tools for students to achieve real successes quickly, while providing tools for teachers to illustrate and discuss fundamental concepts of object-oriented programming. Once completed, student work can easily be published and shared on the Internet.• Greenfoot should be of interest to anyone teaching Java, especially in early programming courses, at schools and colleges.• Greenfoot is available from www.greenfoot.org. The tutorial is practically oriented and allows participants to use Greenfoot in their classroom immediately. Audience members with laptops will be encouraged to play along during the tutorial, giving a chance to get some first-impression, hands-on experience with the software during the session.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1629116.1629136",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2010,
          1
        ]
      ]
    },
    "page": "117",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Greenfoot: Introduction to java with games and simulations",
    "title-short": "Greenfoot",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "ISBN": "9608457297",
    "abstract": "Accurate classification of human blood cells plays a decisive role in the diagnosis and treatment of diseases. Artificial Neural Networks (ANNs) have been consistently used as a trusted classification tool for this type of analysis. In the present case study, two approaches are implemented on two different parametric data clusters in a multidimensional space using ANNs trained with cross-validation. Beckman-Coulter Corporation supplied flow cytometry data of numerous patients as training sets for the first approach to exploit the physiological characteristics of the different blood cells provided. The goal was to establish a programming tool for the identification of different white blood cell categories of a given blood sample and provide information to medical doctors in the form of diagnostic references for the specific disease state that is considered for this study, namely Acute Lymphoblastic Leukemia (ALL). Successful initial results of this first approach have been published. The second approach is focusing on the gene expression profiling of ALL to classify its six subtypes. Generated by the oligonucleotide microarrays, this data provides additional insights into the biology underlying the clinical differences between these leukemia subgroups. With the application of the hypothesis space, along with the learning bias, the system is also trained to assess the inherent problem of data overlap and be able to recognize abnormal blood cell patterns. An analysis of the systems regarding computational load and receiver-operating characteristic (ROC) was conducted. The algorithms as proposed provide solutions to data overlap from our initial results. And by applying ANNs, the classification accuracy of the first approach is remarkably improved up to 100",
    "author": [
      {
        "family": "Zong",
        "given": "Nuannuan"
      },
      {
        "family": "Adjouadi",
        "given": "Malek"
      },
      {
        "family": "Ayala",
        "given": "Melvin"
      }
    ],
    "collection-title": "ICCOMP’05",
    "container-title": "Proceedings of the 9th WSEAS international conference on computers",
    "id": "10.5555/1369599.1369663",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "keyword": "acute lymphoblastic leukemia (ALL), artificial neural networks (ANNs), cross-validation, gene expression profiling, microarrays, receiver operating characteristics (ROC) analysis, white blood cell",
    "publisher": "World Scientific; Engineering Academy; Society (WSEAS)",
    "publisher-place": "Stevens Point, Wisconsin, USA",
    "title": "Artificial neural networks approaches for multidimensional classification of acute lymphoblastic leukemia gene expression samples",
    "type": "paper-conference"
  },
  {
    "abstract": "A major problem in the area of software development is how to produce a quality software product at the lowest possible cost. Software is fast becoming the largest cost component in a computer information system. Even after large sums of money have been spent on development of software, it may still be incorrect. This is the major reason that the highest percentage of a computing budget of many businesses is spent on maintenance of this software. The purpose of this study was to examine the effects of a design walkthrough upon software development in the college programming environment. Both third and fourth generation languages were used for this research. Students in the experimental group were required to participate in a design walkthrough. Time required to develop a program, compiles used in development, and correctness of the final solution were studied.The sample included 148 undergraduate students enrolled in the College of Business Administration at the University of Toledo. Eight sections of three different courses were randomly assigned to the control or experimental group. Students in the experimental group were asked to design a two-level control break program with one of several design techniques and then participate in a design walkthrough with the course instructor prior to coding the program.There was a significant difference in the correctness of the student’s program solutions for both the third and fourth generation languages. Those students in the experimental group developed programs that were more correct than those who did not participate in the design walkthroughs. There was no significant difference in the mean time to develop the software, the mean compiles used in development, or mean time spent with the instructor for the experimental and control groups.The results support the hypothesis that walkthroughs help to reduce the number of errors in completed software. However, the results did not support the hypothesis that the use of structured design techniques reduces the number of resources needed for program development.",
    "author": [
      {
        "family": "Mcginnis",
        "given": "Denise R."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/913492",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "note": "AAI8722200",
    "publisher": "The University of Toledo",
    "title": "The effects of structured design techniques on software development in a business programming course",
    "type": "thesis"
  },
  {
    "ISBN": "0470229888",
    "abstract": "Professional Visual Studio 2008 Microsoft Visual Studio 2008 is the latest version in the ongoing evolution of the Integrated Development Environment (IDE), and this resource examines the diverse facets of the IDEfrom common tasks to intricate functions to the powerful tools that accompany the main code editing and design windows. Written by a unique author duo and offering an in-depth look at the powerful and fascinating features and techniques of the IDE, this book explores each aspect of the development life cycle from the perspective of how Visual Studio 2008 can make your life easier. Each chapter is packed with examples that illustrate uses for various tools, commands, and shortcuts of Visual Studio 2008. You will gradually learn to identify where a feature is used, conclude how you can use it to its fullest potential, and then seamlessly apply that feature to help solve real-world problems. What you will learn from this book How to create project templates and wizards Methods for using IntelliSense, code refactoring, class modeling, and unit testing Tips for using DataSets, LINQ, and Synchronization Services for working with data How to build web applications using ASP.NET AJAX, Silverlight, and ASP.NET MVC Ideas for building Office and Mobile applications, WPF, WCF, and WF projects Ways to effectively analyze and identify bugs using the advanced debugging features How to automate repetitive tasks using the Visual Studio 2008 add-ins and macros Suggestions for using Visual Studio Team System components coupled with Team Foundation Server Techniques for building more secure applications Who this book is for This book is for programmers who want to become proficient with the latest version of Visual Studio and are interested in the advanced capabilities of the IDE. Wrox Professional guides are planned and written by working programmers to meet the real-world needs of programmers, developers, and IT professionals. Focused and relevant, they address the issues technology professionals face every day. They provide examples, practical solutions, and expert education in new technologies, all designed to help programmers do a better job.",
    "author": [
      {
        "family": "Randolph",
        "given": "Nick"
      },
      {
        "family": "Gardner",
        "given": "David"
      }
    ],
    "id": "10.5555/1477711",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "Wrox Press Ltd.",
    "publisher-place": "GBR",
    "title": "Professional visual studio 2008",
    "type": "book"
  },
  {
    "DOI": "10.1145/3372923.3404798",
    "ISBN": "9781450370981",
    "URL": "https://doi.org/10.1145/3372923.3404798",
    "abstract": "Despite significant research into authoring tools for interactive narratives and a number of established authoring platforms, there is still a lack of understanding around the authoring process itself, and the challenges that authors face when writing hypertext and other forms of interactive narratives. This has led to a monolithic view of authoring, which has hindered tool design, resulting in tools that can lack focus, or ignore important parts of the creative process. In order to understand how authors practise writing, we conducted semi-structured interviews with 20 interactive narrative authors. Using a qualitative analysis, we coded their comments to identify both processes and challenges, and then mapped these against each other in order to understand where issues occurred during the authoring process. In our previous work we were able to gather together a set of authoring steps that were relevant to interactive narratives through a review of the academic literature. Those steps were: Training/Support, Planning, Visualising/Structuring, Writing, Editing, and Compiling/Testing. In this work we discovered two additional authoring steps, Ideation and Publishing that had not been previously identified in our reviews of the academic literature - as these are practical concerns of authors that are invisible to researchers. For challenges we identified 18 codes under 5 themes, falling into 3 phases of development: Pre-production, where issues fall under User/Tool Misalignment and Documentation; Production, adding issues under Complexity and Programming Environment; and Post-production, replacing previous issues with longer term issues related to the narrative’s Lifecycle. Our work shows that the authoring problem goes beyond the technical difficulties of using a system, rather it is rooted in the common misalignment between the authors’ expectations and the tools capabilities, the fundamental tension between expressivity and complexity, and the invisibility of the edges of the process to researchers and tool builders. Our work suggests that a less monolithic view of authoring would allow designers to create more focused tools and address issues specifically at the places in which they occur.",
    "author": [
      {
        "family": "Kitromili",
        "given": "Sofia"
      },
      {
        "family": "Jordan",
        "given": "James"
      },
      {
        "family": "Millard",
        "given": "David E."
      }
    ],
    "collection-title": "HT ’20",
    "container-title": "Proceedings of the 31st ACM conference on hypertext and social media",
    "id": "10.1145/3372923.3404798",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "authoring, authoring tools, authors, digital interactive narratives, digital interactive storytelling, hypertext fiction, interactive fiction",
    "page": "9-16",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "What authors think about hypertext authoring",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/S1571-0661(05)80684-X",
    "ISSN": "1571-0661",
    "URL": "https://doi.org/10.1016/S1571-0661(05)80684-X",
    "abstract": "This issue of ENTCS is an unrefereed conference record of talks presented at the Second Workshop on Higher Order Operational Techniques in Semantics (HOOTS II) held at Stanford University, December 8-11, 1997. The meeting was organised by A. Gordon, A. Pitts and C. Talcott with generous sponsorship from Harlequin Ltd, NSF and ONR. The first HOOTS workshop was held October 28-30, 1995 as part of the University of Cambridge Isaac Newton Institute research programme on Semantics of Computation (July-Dec 1995).The study of operational techniques for higher-order languages is now a thriving area, with much research activity going on world-wide. An important open problem is a theory of program equivalence for languages with higher-order features, including functions and objects. Techniques for defining and reasoning about equivalence and other properties of higher-order programs have emerged in distinct communities, including the concurrency, functional programming and type theory communities. The purpose of the HOOTS workshops was to bring researchers from these communities together to discuss current trends in the theory of operational semantics, its application to higher-order languages and its connection with more established semantic techniques.Papers presented at HOOTS II covered a broad range of topics: techniques such as bisimulation and logical relations for reasoning about contextual equivalence alternative program relations such as operational subsumption, and evaluation rules for program contexts operational models including adaptation of big-step evaluation semantics to provide capabilities of small-step and denotational semantics forms, flow graphs, and history dependent automata higher-order programming calculi including: imperative call-by-need lambda calculus, action calculi, process calculi for reasoning about mobility and security, interaction of actors and pi calculus agents approaches to program analysis and verification, including: logics for control flow analysis, monadic type systems, and diagramatic specification notation for actor systems; programming environment tools such a type systems for Java byte-code, and higher-order program units for modularity.Programs and participants lists for HOOTS I and II and other information about HOOTS, past and future can be found here",
    "author": [
      {
        "family": "Andrew",
        "given": "Gordon"
      },
      {
        "family": "Carolyn",
        "given": "Pitts"
      },
      {
        "family": "Andrew",
        "given": "Talcott"
      }
    ],
    "container-title": "Electron. Notes Theor. Comput. Sci.",
    "id": "10.1016/S1571-0661(05)80684-X",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          1998,
          5
        ]
      ]
    },
    "page": "1",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Preface",
    "type": "article-journal",
    "volume": "10"
  },
  {
    "ISBN": "0769517455",
    "abstract": "Debugging is an important and challenging component of the software development cycle. The utilization of proper tools that help trace execution, inspect variable values, do postmortem analysis, dynamically attach to running processes, among other tasks can greatly increase programmer productivity by reducing the time to understand incorrect behavior. It is well known that many more hours are spent debugging software than compiling source code [11], therefore having the appropriate tools and making the best use of information provided by them is fundamental. When a programmer deals with parallel programs in shared or distributed memory settings, debugging becomes quite complicated given the various potential interactions that may occur between threads and processes. Data races, deadlocks, synchronization issues, and communication problems must be dealt with in addition to the traditional sequential (single process) problems such as memory leaks, memory overruns, etc. Since debugging is clearly important in both sequential and parallel/distributed environments, much effort has been focused on this task. It ranges from standardization initiatives [6] and list of requirements [3], to specific research prototypes [5, 14, 15], and commercial and open source products [4, 7, 9, 10, 13].GDB [12] is freely available and omnipresent in most research labs and universities, which contributes to its status as a debugging tool of choice for many programmers writing sequential code. On the other hand, it does not target the particular debugging issues presented by parallel/distributed applications as does, for example, TotalView [4]. Nevertheless, GDB’s newer versions are well capable of dealing with multi-threaded programs. There are also many capable parallel/cluster programming environments that go beyond the ideas presented in this paper. We present this work as strategies that can be implemented without capital expenditure 1 somewhat easily into existing projects without adopting a programming environment.In this work, we will show how five low-cost and non-intrusive techniques that work using free commodity tools such as GDB can be used to improve the debugging process of multi-threaded and/or distributed parallel programs. These techniques have been used in the development of two major software middlewares DataCutter [2] and MQO [1] and have proven their value by lowering the time necessary to detect and correct bugs.",
    "author": [
      {
        "family": "Beynon",
        "given": "Michael D."
      },
      {
        "family": "Andrade",
        "given": "Henrique"
      },
      {
        "family": "Saltz",
        "given": "Joel"
      }
    ],
    "collection-title": "CLUSTER ’02",
    "container-title": "Proceedings of the IEEE international conference on cluster computing",
    "id": "10.5555/792762.793279",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "page": "439",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Low-cost non-intrusive debugging strategies for distributed parallel programs",
    "type": "paper-conference"
  },
  {
    "ISBN": "9781267377678",
    "abstract": "The accurate prediction of material behaviors is one of the most important fields in both science and engineering communities. Understanding the mechanisms of material behaviors sometimes needs us to study the material over a wide span of length scales. In this work we present a new methodology which is able to coarse-grain the atomistic dynamics of fracture by finite element method. First, based on the Atomistic Field Theory (AFT) (Chen and Lee 2005, Chen et al. 2006, Chen 2009), a finite elements method with built in atomistic information is presented. Then a high efficiency parallel code for large scale computation is described. This code was written in FORTRAN language and uses the standard parallel programming environment message passing interface (MPI). The performance of the parallel code was tested on the supercomputer Trestle of SDSC (San Diego Supercomputer Center). Through the comparison of the coarse-grained (CG) simulation results with the molecular dynamics (MD) simulation results, it is found that the new CG method is able to predict the crack tip stress, dynamic crack propagation and even crack branching, with results similar to that of the atomic-level molecular dynamicssimulations. Finally, both 2D (2 dimensional) and 3D (3 dimensional) dynamic fracture problems were computed through the CG method. In 2D dynamic fracture simulations, the relationship between stress waves and crack propagations was studied. It is found that the stress waves reflected back from the boundary can trigger the dynamic crack branching. In 3D simulations, the dynamic fractures under different loading were simulated. The largest 3D model is composed of over 0.1 million elements which are equivalent to over 0.1 billion atoms. To show the performance of the parallel code in dealing with large number of processors, the crack surface evolution in this model was simulated using 512 processors. All of simulations conducted in this study show the robustness of the parallel code in dealing with dynamic fracture problems. (Full text of this dissertation may be available via the University of Florida Libraries web site. Please check http://www.uflib.ufl.edu/etd.html)",
    "author": [
      {
        "family": "Deng",
        "given": "Qian"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/2521911",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "note": "AAI3514944",
    "publisher": "University of Florida",
    "publisher-place": "USA",
    "title": "Coarse-graining atomistic dynamics of fracture by finite element method: Formulation, parallelization and applications",
    "title-short": "Coarse-graining atomistic dynamics of fracture by finite element method",
    "type": "thesis"
  },
  {
    "DOI": "10.1155/2022/7048698",
    "ISSN": "1939-0114",
    "URL": "https://doi.org/10.1155/2022/7048698",
    "abstract": "Domestic education and scientific nature of realization automatic evaluation have become issues of concern. The integration of information technology in the teaching field of ideological and political theory courses in colleges and universities (hereinafter referred to as “ideological and political courses”) inevitably has an important impact on the teaching of traditional ideological and political courses. ASP.NET is the main interface technology of .NET. .NET is an environment that can provide support for building development and execution in multiple languages, and realizes the functions of language development, code compilation, building configuration, program operation, and object interaction. The system development tool is ASP.NET (Visual Studio 2013), the background database development tool is Microsoft SQL Server 2008, and the system development environment is Windows 7 64. The core of the system is multisource data fusion. Firstly, the data are preprocessed to extract useful information data to form data object fusion. Then, convert the code table into a transaction library. In view of the large amount of data to be mined and easily affect mining quality, the improved Apriori-P algorithm based on partitioning in association with rule technology is applied. This algorithm is used to generate frequent itemsets. According to the given minimum confidence, a data fusion rule is generated. Then, the fusion result is generated from the corresponding data report. Before data fusion, system administrators should select data sources from historical databases or existing evaluation databases. When querying rules, different users can log in to the system to query their own data content, students can query the teacher’s evaluation results, teachers can query their own evaluation results, and school administrators can view the data fusion results. After evaluating teachers through the campus network, all evaluation data can be integrated and analyzed, and the system automatically generates analysis results corresponding to users. The stability of the teaching evaluation system is better, and the system performance can reach 89",
    "author": [
      {
        "family": "Zhou",
        "given": "Jieqiong"
      },
      {
        "family": "Wei",
        "given": "Zhenhua"
      },
      {
        "family": "Shi",
        "given": "Jianwei"
      },
      {
        "family": "Khan",
        "given": "Mohammad Ayoub"
      }
    ],
    "container-title": "Sec. and Commun. Netw.",
    "id": "10.1155/2022/7048698",
    "issued": {
      "date-parts": [
        [
          2022,
          1
        ]
      ]
    },
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "Teaching application and evaluation of ideological and political courses based on multisource data fusion",
    "type": "article-journal",
    "volume": "2022"
  },
  {
    "abstract": "Cluster analysis is a generic term coined for procedures that are used objectively to group entities based on their similarities and differences. The primary objective of these procedures is to group n items into up to K mutually exclusive clusters so that items within each cluster are relatively homogeneous in nature while the clusters themselves are distinct. Statistical methods attempt to lower the interaction between each observation and the group mean or median. In contrast, optimal clustering techniques not only finds the best possible solution, but also accounts for total group interaction. In this research, we develop, implement, and evaluate a parallel algorithm (PGROUPS) to solve clustering problems to optimality. PGROUPS was implemented using one to eight processors on the IBM PowerParallel System (SP-2) at University Computing &amp; Network Services at The University of Georgia using the xlf (f77) Fortran compiler under the AIX Version 3.2 (Unix) operating system. Our programming environment is the Parallel Virtual Machine (PVM) and we used the user mode (the communication channel switch) so that more than one process can be activated on a single processor. PGROUPS is based on the model and serial solution methodology (GROUPS) due to Aronson and Klein (1989) and Klein and Aronson (1991).Prior to developing PGROUPS, the serial solution methodology was enhanced by developing a new heuristic to obtain the initial upperbound and eliminating the evaluation of lower bounds for some nodes that are already bound fathomed. The two enhancements decreased the overall solution CPU time for GROUPS, for the test problems, by an average of 27.1",
    "author": [
      {
        "family": "Iyer",
        "given": "Lakshmi"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/266873",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "note": "UMI Order No. GAX97-35526",
    "publisher": "University of Georgia",
    "publisher-place": "USA",
    "title": "Parallel optimal clustering",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/2462476.2462493",
    "ISBN": "9781450320788",
    "URL": "https://doi.org/10.1145/2462476.2462493",
    "abstract": "We have developed a tool that enables learners to observe the process by which they program through visualization of data that are recorded in the source code editor. One purpose of the tool is to assist learners by using the Personal Software Process (PSP) to allow them to analyze the process by which they program by using the tool after completing a programming task. The proposed tool has functions for A) replaying a process using animation; B) automatic calculation of metrics; C) support for inputting subtasks; and D) process analysis report generation. An evaluation experiment was conducted with participants from the second-level introductory programming course at our university. The results were that 1) the accuracy of effort estimation dropped, although we clearly found that the reason for the drop was the difficulty of the second assignment; 2) according to a questionnaire, students reported both the effectiveness of the observation task and the effectiveness of the tool; and 3) there was large differences between students in terms of the description level of subtasks.",
    "author": [
      {
        "family": "Matsuzawa",
        "given": "Yoshiaki"
      },
      {
        "family": "Okada",
        "given": "Ken"
      },
      {
        "family": "Sakai",
        "given": "Sanshiro"
      }
    ],
    "collection-title": "ITiCSE ’13",
    "container-title": "Proceedings of the 18th ACM conference on innovation and technology in computer science education",
    "id": "10.1145/2462476.2462493",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "keyword": "process, programing education, psp, visualize",
    "page": "46-51",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Programming process visualizer: A proposal of the tool for students to observe their programming process",
    "title-short": "Programming process visualizer",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3482632.3483098",
    "ISBN": "9781450390255",
    "URL": "https://doi.org/10.1145/3482632.3483098",
    "abstract": "Entrepreneurship through the use of Internet platforms has now become a common situation in the social environment, and as college students themselves, they are also the most direct beneficiaries of this type of entrepreneurial platform. However, it should be noted that in today’s rapid Internet development environment Next, as a college student, it is not only the improvement of opportunities, but also the existence of great challenges. By discussing the current problems in college students’ entrepreneurship and innovation education, the article points out that the government, colleges should establish a unified management entrepreneurship and innovation education system. Promote \"Internet +\" entrepreneurship and innovation skills training, enrich multi-student entrepreneurial practice activities, and more entrepreneurship projects are introduced in colleges, while enhancing the role of teachers as entrepreneurial mentors.",
    "author": [
      {
        "family": "Gu",
        "given": "Ran"
      }
    ],
    "collection-title": "ICISCAE 2021",
    "container-title": "2021 4th international conference on information systems and computer aided education",
    "id": "10.1145/3482632.3483098",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "1126-1130",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Analysis on the construction of diversified innovation and entrepreneurship education mode in colleges under the background of \"internet +\"",
    "type": "paper-conference"
  },
  {
    "ISBN": "0131429019",
    "abstract": "\"Reading this book has filled a gap in my education. I feel a sense of completion, understand that UNIX is really a style of community. Now I get it, at least I get it one level deeper than I ever did before. This book came at a perfect moment for me, a moment when I shifted from visualizing programs as things to programs as the shadows cast by communities. From this perspective, Eric makes UNIX make perfect sense.\" –Kent Beck, author of Extreme Programming Explained, Test Driven Development, and Contributing to Eclipse\"A delightful, fascinating read, and the lessons in problem-solvng are essential to every programmer, on any OS.\" –Bruce Eckel, author of Thinking in Java and Thinking in C++Writing better software: 30 years of UNIX development wisdomIn this book, five years in the making, the author encapsulates three decades of unwritten, hard-won software engineering wisdom. Raymond brings together for the first time the philosophy, design patterns, tools, culture, and traditions that make UNIX home to the world’s best and most innovative software, and shows how these are carried forward in Linux and today’s open-source movement. Using examples from leading open-source projects, he shows UNIX and Linux programmers how to apply this wisdom in building software that’s more elegant, more portable, more reusable, and longer-lived.Raymond incorporates commentary from thirteen UNIX pioneers: Ken Thompson, the inventor of UNIX. Ken Arnold, part of the group that created the 4BSD UNIX releases and co-author of The Java Programming Language. Steven M. Bellovin, co-creator of Usenet and co-author of Firewalls and Internet Security. Stuart Feldman, a member of the Bell Labs UNIX development group and the author of make and f77. Jim Gettys and Keith Packard, principal architects of the X windowing system. Steve Johnson, author of yacc and of the Portable C Compiler. Brian Kernighan, co-author of The C Programming Language, The UNIX Programming Environment, The Practice of Programming, and of the awk programming language. David Korn, creator of the korn shell and author of The New Korn Shell Command and Programming Language. Mike Lesk, a member of the Bell Labs development group and author of the ms macro package, the tbl and refer tools,lex and UUCP. Doug McIlroy, Director of the Bell Labs research group where UNIX was born and inventor of the UNIX pipe. Marshall Kirk McKusick, developer of the 4.2BSD fast filesystem and a leader of the 4.3BSD and 4.4BSD teams. Henry Spencer, a leader among early UNIX developers, who created getopt, the first open-source string library, and a regular-expression engine used in 4.4BSD.",
    "author": [
      {
        "family": "Raymond",
        "given": "Eric S."
      }
    ],
    "id": "10.5555/829549",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "publisher": "Pearson Education",
    "title": "The art of UNIX programming",
    "type": "book"
  },
  {
    "DOI": "10.1145/2700514",
    "URL": "https://doi.org/10.1145/2700514",
    "abstract": "Many people are first exposed to code through web development, yet little is known about the barriers beginners face in these formative experiences. In this article, we describe a study of undergraduate students enrolled in an introductory web development course taken by both computing majors and general education students. Using data collected during the initial weeks of the course, we investigate the nature of the syntax errors they make when learning HTML and CSS, and how they resolve them. This is accomplished through the deployment of openHTML, a lightweight web-based code editor that logs user activity. Our analysis reveals that nearly all students made syntax errors that remained unresolved in their assessments, and that these errors continued weeks into the course. Approximately 20",
    "author": [
      {
        "family": "Park",
        "given": "Thomas H."
      },
      {
        "family": "Dorn",
        "given": "Brian"
      },
      {
        "family": "Forte",
        "given": "Andrea"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/2700514",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2015,
          3
        ]
      ]
    },
    "keyword": "Web development, code editors, computational literacy",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An analysis of HTML and CSS syntax errors in a web development course",
    "type": "article-journal",
    "volume": "15"
  },
  {
    "ISBN": "1492719161",
    "abstract": "C++11 has arrived: thoroughly master it, with the definitive new guide from C++ creator Bjarne Stroustrup, C++ Programming Language, Fourth Edition! The brand-new edition of the world’s most trusted and widely read guide to C++, it has been comprehensively updated for the long-awaited C++11 standard. Extensively rewritten to present the C++11 language, standard library, and key design techniques as an integrated whole, Stroustrup thoroughly addresses changes that make C++11 feel like a whole new language, offering definitive guidance for leveraging its improvements in performance, reliability, and clarity. C++ programmers around the world recognize Bjarne Stoustrup as the go-to expert for the absolutely authoritative and exceptionally useful information they need to write outstanding C++ programs. Now, as C++11 compilers arrive and development organizations migrate to the new standard, they know exactly where to turn once more: Stoustrup’s C++ Programming Language, Fourth Edition. C++ Programming in Easy Steps instructs you how to program in the powerful C++ language, giving complete examples that illustrate each aspect. C++ Programming in Easy Steps begins by explaining how to download and install a free C++ compiler so you can quickly begin to create your own executable programs by copying the book’s examples. It demonstrates all the C++ language basics before moving on to provide examples of Object Oriented Programming. The book concludes by demonstrating how you can use your acquired knowledge to create programs graphically in the free Microsoft Visual C++ Express Integrated Development Environment (IDE). C++ Programming in Easy Steps makes no assumption you have previous knowledge of any programming language so it’s ideal for the newcomer to computer programming. It has an easy-to-follow style that will appeal to programmers moving from another programming language, and to the student who is studying C++ programming at school or college, and to those seeking a career in computing who need a fundamental understanding of object oriented programming. Want to learn to code? Want to learn C++? Struggling to follow your lecturer or books and tutorials written for experts? You’re not alone. As a professional C++ developer and former Harvard teaching fellow, I know what you need to know to be a great C++ programmer, and I know how to teach it, one step at a time. I know where people struggle, and why, and how to make it clear. I cover every step of the programming process, including: Getting the tools you need to program and how to use them Basic language feature like variables, loops and functions How to go from an idea to code A clear, understandable explanation of pointers Strings, file IO, arrays, references Classes and advanced class design C++-specific programming patterns Object oriented programming Data structures and the standard template library (STL) Key concepts are reinforced with quizzes and over 75 practice problems.",
    "author": [
      {
        "family": "Choudhary",
        "given": "Hariom"
      }
    ],
    "edition": "5th",
    "id": "10.5555/2566754",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "CreateSpace Independent Publishing Platform",
    "publisher-place": "North Charleston, SC, USA",
    "title": "C++ programming- final golden edition.: Beginners to experts approach guide - with easy learning &amp; problem analysis to program design &amp; development.",
    "title-short": "C++ programming- final golden edition.",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Computer Science has problems attracting and retaining students. One response has been the development of new curricula, which often originate at large research universities. This paper looks at the issue of adapting one such curriculum to a small liberal arts college. Our focus is on changing the supporting tool set - language, development environment, editors, etc. We discuss the criteria that lead to these choices, particularly the related to differences in students.",
    "author": [
      {
        "family": "Hunt",
        "given": "John M."
      },
      {
        "family": "Matzko",
        "given": "Sarah"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1292428.1292462",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2007,
          12
        ]
      ]
    },
    "page": "195-201",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Retooling a curriculum",
    "type": "article-journal",
    "volume": "23"
  },
  {
    "DOI": "10.1145/3183440.3195061",
    "ISBN": "9781450356633",
    "URL": "https://doi.org/10.1145/3183440.3195061",
    "abstract": "Mobile application development (MAD) has became, or is considering to be a part of the academic curricula in Computer Science courses. However, training students on mobile application development inherits the challenges of teaching software engineering where the target computer is a device that has a large number of features accessible by software. Furthermore, the most related experience in teaching students reveals difficulties in developing software engineering competencies. In this paper we present results from a case study conducted in four universities in Brazil. We have investigated the adoption of Challenge-Based Learning (CBL) framework and agile practices for training students in software engineering applied in mobile application development environments.",
    "author": [
      {
        "family": "Santos",
        "given": "Alan"
      },
      {
        "family": "Sales",
        "given": "Afonso"
      },
      {
        "family": "Fernandes",
        "given": "Paulo"
      },
      {
        "family": "Kroll",
        "given": "Josiane"
      }
    ],
    "collection-title": "ICSE ’18",
    "container-title": "Proceedings of the 40th international conference on software engineering: Companion proceeedings",
    "id": "10.1145/3183440.3195061",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "agile practices, challenge-based learning, mobile, software development, software engineering education",
    "page": "155-156",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Challenge-based learning: A brazilian case study",
    "title-short": "Challenge-based learning",
    "type": "paper-conference"
  },
  {
    "ISBN": "9798480642926",
    "abstract": "Accessibility failures in mobile applications (apps) create barriers for disabled people and people who use assistive technologies. Given the growing role of apps in everyone’s daily life, equitable access is imperative. Toward this goal, I created a conceptual framework for understanding and improving app accessibility at scale inspired by epidemiology. My epidemiology‑inspired framework poses app accessibility failures as \"diseases\" in a \"population\" of apps. This perspective forefronts a population-level perspective within an ecosystem of factors that impact app accessibility (e.g., developer tools, guidelines, company culture, and many more). In this dissertation, I demonstrate my thesis that applying my epidemiology‑inspired framework, which emphasizes large‑scale and multi‑factor approaches, (1) can reveal population‑level trends of accessibility failures, (2) can aid in identifying a range of factors that impact app accessibility, and (3) can inform the design of tools for identifying and repairing accessibility failures in apps.To enhance our understanding of the state of app inaccessibility, I performed the first large‑scale analyses of Android app accessibility. My results measured the prevalence of accessibility failures across apps and identified classes of elements that frequently had accessibility failures. Missing labels was one of the most prevalent failures; 23",
    "author": [
      {
        "family": "Ross",
        "given": "Anne Spencer"
      },
      {
        "family": "Jennifer",
        "suffix": "Mankoff"
      },
      {
        "family": "Meredith",
        "suffix": "Ringel Morris"
      },
      {
        "family": "Mark",
        "suffix": "Harniss"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI28649526",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "note": "AAI28649526",
    "publisher": "University of Washington",
    "title": "A large scale, multi factor approach to understanding and improving mobile application accessibility",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/1028664.1028677",
    "ISBN": "1581138334",
    "URL": "https://doi.org/10.1145/1028664.1028677",
    "abstract": "Smells are architectural, rather than functional, flaws in software that tend to reduce maintainability, extensibility, modularity, testability, or other software quality measures. Common smells include overly-long method bodies, message chains, parallel inheritance, use of switch statements to implement polymorphic behavior, data clumps, overly specific variable types, and duplicated code. Code duplication in particular is a well-known source of maintenance problems. Because smells do not represent functional flaws, they can be remediated by behavior-preserving transformations (i.e. refactorings).We will demonstrate a nascent extensible smell detection framework for Java, implemented for the Eclipse IDE (www.eclipse.org). Our framework provides a simple Eclipse extension point for defining smell detectors, along with several basic smell detectors, including a reasonably efficient code duplication detector. Several of our smell detectors feature Eclipse quick-fix refactorings to automatically remediate smells upon the user’s request. This transforms the tool from a mere problem indicator into a tool that actively assists developers in improving their code. We believe that such a facility has significant potential in educational settings, in directing a student’s attention to software engineering principles while coding.Our demonstration will consist of two parts. First, we’ll demonstrate some of our smell detectors on realistic source code bases (including Eclipse itself), along with their corresponding quick-fix support. Second, we’ll walk through the implementation of a very simple smell detector within our framework, along with a very simple remediation.",
    "author": [
      {
        "family": "Bhattacharrya",
        "given": "Arnab"
      },
      {
        "family": "Fuhrer",
        "given": "Robert"
      }
    ],
    "collection-title": "OOPSLA ’04",
    "container-title": "Companion to the 19th annual ACM SIGPLAN conference on object-oriented programming systems, languages, and applications",
    "id": "10.1145/1028664.1028677",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "keyword": "code smells, refactoring, software engineering, software quality",
    "page": "22",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Smell detection for eclipse",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/181505.181515",
    "ISSN": "0097-8930",
    "URL": "https://doi.org/10.1145/181505.181515",
    "abstract": "The unprecedented freedom for users to control the scope and sequence of their interactions with hypermedia systems presents many challenges to those who design and study these systems in educational settings. Early efforts to develop hypermedia systems revealed that the node-link structure of such systems is both advantageous and problematic (Conklin, 1987). When users have the freedom to follow any of a multitude of link permutations, disorientation often results. Further, without appropriate training, novice users do not possess the strategies necessary for effective \"browsing\" of large hypermedia documents (Duffy &amp; Knuth, 1991). It has also been noted that the purpose for using the system or the task that the users are engaged in can influence patterns of interaction with hypermedia systems (Nelson, 1991). Many designers, therefore, advocate that features such as visual maps, database search facilities and guided tours be included in hypermedia systems to alleviate some of these problems (e.g. Hammond, 1989; Laurel, 1990, 1991).With the emergence of hypermedia systems as a major architecture for educational and other information-oriented software comes the related problem of how to document and analyze user interactions with such systems for the purposes of research and evaluation. There are a variety of interface design strategies that impact on how a system performs and should be evaluated. Many hypermedia systems to date have employed a \"browsing\" interface, but alternative approaches are also emerging (Nelson &amp; Palumbo, 1992). Regardless of the type of interface, many questions can be generated when studying the interactions of users with hypermedia systems. For example, how many users chose to follow a particular link, and why was one link chosen over another? How does the choice of one link affect choices of subsequent links? When are graphic images, animations and video segments accessed? What user tasks are appropriate for guiding interaction with the system? What kinds of strategies do users develop while working with hypermedia systems? These and many other questions need answers when designing, developing and evaluating hypermedia applications for education and other settings, and provide the focus for this short article.A wealth of user interaction data can be easily collected within many hypermedia development environments in order to study aspects of the interface, including the nature of user navigation patterns, the time spent at each node and the use of help and orienting facilities. The data can represent the paths a user follows through the system, and the choices made at each node in the system. The problem is that because of the nature of this data, traditional methods of analysis such as surveys or pretest-posttest designs, are not particularly effective for determining usability or comparing alternative interface designs. Researchers have had to develop new techniques for analyzing patterns of user interaction in order to evaluate the design and effectiveness of hypermedia systems (Misanchuk &amp; Schwier, 1992). There is a need to categorize and compare groups of users in order to compare the effectiveness of alternative system features, as well as describing characteristics of interaction by individual users within the same system.",
    "author": [
      {
        "family": "Nelson",
        "given": "Wayne A."
      }
    ],
    "container-title": "SIGGRAPH Comput. Graph.",
    "id": "10.1145/181505.181515",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1994,
          2
        ]
      ]
    },
    "page": "43-45",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Analyzing user interactions with hypermedia systems",
    "type": "article-journal",
    "volume": "28"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Student participation in free and open source software (FOSS) has potential to improve student learning in computing majors. Participation can include contributing bug fixes, testing, writing documentation and developing new features[1]. These opportunities enable students to learn in a more authentic environment developing technical skills as well as teamwork and communication skills. However learning curves related to a large complex code base, use of development tools, understanding of community interactions, and scheduling of class deliverables with the FOSS calendar are only a few of the hurdles to education inherent in learning in a FOSS environment.",
    "author": [
      {
        "family": "Purcell",
        "given": "Michelle"
      },
      {
        "family": "Ellis",
        "given": "Heidi J. C."
      },
      {
        "family": "Hislop",
        "given": "Gregory W."
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/2460156.2460195",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2013,
          6
        ]
      ]
    },
    "page": "199-200",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "An approach for evaluating open source projects for student participation",
    "type": "article-journal",
    "volume": "28"
  },
  {
    "DOI": "10.1145/1131322.1131323",
    "ISSN": "0163-5980",
    "URL": "https://doi.org/10.1145/1131322.1131323",
    "abstract": "Operating system courses teach students much more when they provide hands-on kernel-level project experience with a real operating system. However, enabling a large class of students to do kernel development can be difficult. To address this problem, we created a virtual kernel development environment in which operating systems can be developed, debugged, and rebooted in a shared computer facility without affecting other users. Using virtual machines and remote display technology, our virtual kernel development laboratory enables even distance learning students at remote locations to participate in kernel development projects with on-campus students. We have successfully deployed and used our virtual kernel development environment together with the open-source Linux kernel to provide kernel-level project experiences for over nine hundred students in the introductory operating system course at Columbia University.",
    "author": [
      {
        "family": "Nieh",
        "given": "Jason"
      },
      {
        "family": "Vaill",
        "given": "Chris"
      }
    ],
    "container-title": "SIGOPS Oper. Syst. Rev.",
    "id": "10.1145/1131322.1131323",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2006,
          4
        ]
      ]
    },
    "keyword": "computer science education, open-source software, operating systems, virtual machines, virtualization",
    "page": "100-104",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Experiences teaching operating systems using virtual platforms and linux",
    "type": "article-journal",
    "volume": "40"
  },
  {
    "DOI": "10.1145/3568294.3580102",
    "ISBN": "9781450399708",
    "URL": "https://doi.org/10.1145/3568294.3580102",
    "abstract": "When robots are used for physical therapy, programming becomes too important to be left to programmers. Developing programs for training robots is time-consuming and requires expertise within multiple engineering domains, combined with physical training, therapy, and human interaction competencies. In this paper, we present Platypus: an end-user development environment that encompasses the design and execution of custom activities for robot-assisted physical training. The current version ships a set of plugins for Eclipse’s IDE and uses a block-based visual language to specify the robot’s behaviors at a high abstraction level, which are translated into the low-level code specifications followed by the robot. As a use case, we present its implementation on RoboTrainer, a modular, rope-based pulling device for training at home. While user tests suggest that the platform has the potential to reduce the technical obstacles for building custom training scenarios, informational and design learning barriers were revealed during the tests.",
    "author": [
      {
        "family": "De la Rosa Gutierrez",
        "given": "Jose Pablo"
      },
      {
        "family": "Sørensen",
        "given": "Anders Stengaard"
      }
    ],
    "collection-title": "HRI ’23",
    "container-title": "Companion of the 2023 ACM/IEEE international conference on human-robot interaction",
    "id": "10.1145/3568294.3580102",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "assistive technology, end-user development, human-computer interaction, robot-assisted training",
    "page": "342-346",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PLATYPUS: An environment for end-user development of robot-assisted physical training",
    "title-short": "PLATYPUS",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1384271.1384389",
    "ISBN": "9781605580784",
    "URL": "https://doi.org/10.1145/1384271.1384389",
    "abstract": "The purpose of this poster is to share our experience of a staff development tool that has been developed to raise awareness amongst staff about issues that students with disabilities might face. A computer-based test has been created as a training tool to raise awareness among university academic staff of some common experiences faced by people with visual, mobility, hearing and cognitive difficulties when using a computer [1]. The development team is based at Leeds Metropolitan University and is part of a UK centrally-funded \"Centre for Excellence in Teaching and Learning\" (CETL) [2], in collaboration with the Universities of Durham, Newcastle and Leeds. The Centre is devoted to promoting \"Active Learning in Computing\" (ALiC) [3] and is the only CETL within the Computer Science academic area. This test simulates experiences of disabled students who use computers and take computer-based tests, and provides advice and guidance to university teaching staff on how they may best cater for the needs of such students. The poster presents the reasons for creating such a tool in such a format, its structure and content.",
    "author": [
      {
        "family": "Gray",
        "given": "John"
      },
      {
        "family": "Harrison",
        "given": "Gill"
      },
      {
        "family": "Gorra",
        "given": "Andrea"
      },
      {
        "family": "Sheridan-Ross",
        "given": "Jakki"
      },
      {
        "family": "Finlay",
        "given": "Janet"
      }
    ],
    "collection-title": "ITiCSE ’08",
    "container-title": "Proceedings of the 13th annual conference on innovation and technology in computer science education",
    "id": "10.1145/1384271.1384389",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "computer assisted test, disability awareness, staff development",
    "page": "347",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A computer-based test to raise awareness of disability issues",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/AGILE.2010.14",
    "ISBN": "9780769541259",
    "URL": "https://doi.org/10.1109/AGILE.2010.14",
    "abstract": "Little is known about problems encountered in distributed Agile development environments. There have been some case studies reporting on them. However, these studies have been mainly limited to the scope and context of only one or a few companies. As a result, we do not possess an overall picture of what types of problems and challenges the companies may encounter in distributed Agile environments. In this paper, we analyze twelve case studies from the existing literature, identify thirteen problems reported in them and their solutions, and we group the problems into six classes: Culture, Time Zone, Communication, Customer Collaboration, Trust, Training and Technical Issues.",
    "author": [
      {
        "family": "Kajko-Mattsson",
        "given": "Mira"
      },
      {
        "family": "Azizyan",
        "given": "Gayane"
      },
      {
        "family": "Magarian",
        "given": "Miganoush Katrin"
      }
    ],
    "collection-title": "AGILE ’10",
    "container-title": "Proceedings of the 2010 agile conference",
    "id": "10.1109/AGILE.2010.14",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "communication, culture, customer availability, time zones, trust",
    "page": "51-58",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Classes of distributed agile development problems",
    "type": "paper-conference"
  },
  {
    "ISBN": "0818672498",
    "abstract": "As part of Motorola’s efforts to establish PowerPC systems as the platform of choice in the industry, Motorola’s RISC Software department provides software development tools and operating systems support for the PowerPC architecture. The department has responded with enthusiasm to Motorola’s corporate software initiatives that strive to increase even further the quality of our software products. The World Wide Web was found to be a useful tool in the group’s software engineering education efforts. The Web has helped remove many obstacles encountered on the road to implementing software quality initiatives. This paper discusses how the World Wide Web technology helped bridge various levels of communication gaps and at the same time served as a catalyst for improving and distributing the group’s software engineering education efforts.",
    "author": [
      {
        "family": "Takvorian",
        "given": "Alexis"
      },
      {
        "family": "Maranian",
        "given": "Ken"
      },
      {
        "family": "Zack",
        "given": "David"
      }
    ],
    "collection-title": "CSEE ’96",
    "container-title": "Proceedings of the 9th conference on software engineering education",
    "id": "10.5555/525263.793947",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "page": "270",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Using the world wide web to promote software engineering education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3334480.3382879",
    "ISBN": "9781450368193",
    "URL": "https://doi.org/10.1145/3334480.3382879",
    "abstract": "Many non-expert Machine Learning users wish to apply powerful deep learning models to their own domains but encounter hurdles in the opaque model tuning process. We introduce SCRAM, a tool which uses heuristics to detect potential error conditions in model output and suggests actionable steps and best practices to help such users tune their models. Inspired by metaphors from software engineering, SCRAM extends high-level deep learning development tools to interpret model metrics during training and produce human-readable error messages. We validate SCRAM through three author-created example scenarios with image and text datasets, and by collecting informal feedback from ML researchers with teaching experience. We finally reflect upon our feedback for the design of future ML debugging tools.",
    "author": [
      {
        "family": "Schoop",
        "given": "Eldon"
      },
      {
        "family": "Huang",
        "given": "Forrest"
      },
      {
        "family": "Hartmann",
        "given": "Björn"
      }
    ],
    "collection-title": "CHI EA ’20",
    "container-title": "Extended abstracts of the 2020 CHI conference on human factors in computing systems",
    "id": "10.1145/3334480.3382879",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "debugging, interactive visualization, machine learning, tutorial systems",
    "page": "1-10",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SCRAM: Simple checks for realtime analysis of model training for non-expert ML programmers",
    "title-short": "SCRAM",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/EEEE.2009.60",
    "ISBN": "9780769539072",
    "URL": "https://doi.org/10.1109/EEEE.2009.60",
    "abstract": "Gardner’s multiple intelligence theory provides a new thought for the colleges’ cultivation of talents by its rich educational content. The multiple intelligence theory enlightens us that the intelligence structure of the creative talents is an integrated system where various intelligence essential factors are realigned, maintaining close ties with each other and make the mode of thinking diversified. In this paper, in view of the problems in the talents training of computer professional, we combine multiple intelligence theory with the characteristics of computer science to optimize instructional design, condense course content, create multi-intelligence development environment, implement effective teaching method and teaching means and adopt variety of evaluation methods to cultivate student’s comprehensive ability.",
    "author": [
      {
        "family": "Qi",
        "given": "Chengming"
      },
      {
        "family": "Cui",
        "given": "Shoumei"
      },
      {
        "family": "Sun",
        "given": "Jianjing"
      }
    ],
    "collection-title": "EEEE ’09",
    "container-title": "Proceedings of the 2009 international conference on e-learning, e-business, enterprise information systems, and e-government",
    "id": "10.1109/EEEE.2009.60",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "Computer professional, Multiple intelligence theory, Talents training",
    "page": "129-132",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "On the talents cultivation and evaluation strategy",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1080/07421222.2005.11045849",
    "ISSN": "0742-1222",
    "URL": "https://doi.org/10.1080/07421222.2005.11045849",
    "abstract": "Software developers face a constant barrage of innovations designed to improve the development environment. Yet stress/strain among software developers has been steadily increasing and is at an all-time high, while their productivity is often questioned. Why, if these innovations are meant to improve the environment, are developers more stressed and less productive than they should be? Using a combination of cognitive style and person-environment fit theories as the theoretical lens, this study examines one potential source of stress/strain and productivity impediment among software developers. Specifically, this paper examines the fit between the preferred cognitive style of a software developer and his or her perception of the cognitive style required by the job environment, and the effect of that fit on stress/strain and performance. Data collected from a field study of 123 (object-oriented) software developers suggest that performance decreases and stress increases as this gap between cognitive styles becomes wider. Using surface response methodology, the precise fit relationship is modeled. The interaction of the developer and the environment provides explanatory power above and beyond either of the factors separately, suggesting that studies examining strain and performance of developers should explicitly consider and measure the cognitive style fit between the software developer and the software development environment. In practice, managers can use the results to help recognize misfit, its consequences, and the appropriate interventions (such as training or person/task matching).",
    "author": [
      {
        "family": "Chilton",
        "given": "Michael A."
      },
      {
        "family": "Hardgrave",
        "given": "Bill C."
      },
      {
        "family": "Armstrong",
        "given": "Deborah J."
      }
    ],
    "container-title": "J. Manage. Inf. Syst.",
    "id": "10.1080/07421222.2005.11045849",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2005,
          11
        ]
      ]
    },
    "keyword": "Adaptioninnovation Theory, Personjob Fit, Software Developers, Software Development, Strain",
    "page": "193-226",
    "publisher": "M. E. Sharpe, Inc.",
    "publisher-place": "USA",
    "title": "Person-job cognitive style fit for software developers: The effect on strain and performance",
    "title-short": "Person-job cognitive style fit for software developers",
    "type": "article-journal",
    "volume": "22"
  },
  {
    "ISBN": "0909925941",
    "abstract": "The purpose of this paper is to describe in detail the current development status of the innovative Environment for Learning to Program (ELP) which provides an interactive web-based environment for teaching programming to the first year Information Technology students at Queensland University of Technology (QUT). ELP allows students to program at the early stages of their course without the need to familiarize themselves with a program development environment. Most importantly, it eliminates all the difficulties associated with installing and running a Java compiler. Using ELP, students learn and develop their problem solving skills by working with program template exercises on the web. ELP provides a learning environment which meets the diverse needs of students.",
    "author": [
      {
        "family": "Truong",
        "given": "Nghi"
      },
      {
        "family": "Bancroft",
        "given": "Peter"
      },
      {
        "family": "Roe",
        "given": "Paul"
      }
    ],
    "collection-title": "ACSC ’03",
    "container-title": "Proceedings of the 26th australasian computer science conference - volume 16",
    "id": "10.5555/783106.783135",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "keyword": "Java, XML, computer programming, online learning, tutoring system, web",
    "page": "255-264",
    "publisher": "Australian Computer Society, Inc.",
    "publisher-place": "AUS",
    "title": "A web based environment for learning to program",
    "type": "paper-conference"
  },
  {
    "DOI": "10.3103/S0005105518050060",
    "ISSN": "0005-1055",
    "URL": "https://doi.org/10.3103/S0005105518050060",
    "abstract": "This article describes the development of recommendations for using the project thinking approach in training and university education of future digital economy specialists. An overview of the key design thinking methodologies is presented. Recommendations for implementing the design thinking approach in academic disciplines are given through an example of a step-by-step description of a specific case. The design thinking approach aims to develop a person’s creative abilities through empirical rules and experience, emotional intelligence and recognizing the value of other people’s opinions. The article describes the methods used in design thinking: visualization tools (empathy, customer journey, and stakeholder maps), Customer Development tools, guerrilla ethnography, POV articulating, and rapid prototyping.The article also presents the primary tools used in design workshops for developing innovative ideas and adaptive problem solving. A case in formulating design thinking, titled \"How can one improve the impression left on the students of professional refresher courses?\" is detailed and accompanied by comments on the solutions the participants of presented design workshops.",
    "author": [
      {
        "family": "Vasilieva",
        "given": "E. V."
      }
    ],
    "container-title": "Autom. Doc. Math. Linguist.",
    "id": "10.3103/S0005105518050060",
    "issue": "5",
    "issued": {
      "date-parts": [
        [
          2018,
          9
        ]
      ]
    },
    "keyword": "IT education, competency-based learning, design thinking, digital competence, digital economy, information technology, innovation, soft skills",
    "page": "248-256",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Developing the creative abilities and competencies of future digital professionals",
    "type": "article-journal",
    "volume": "52"
  },
  {
    "DOI": "10.1145/2538862.2538970",
    "ISBN": "9781450326056",
    "URL": "https://doi.org/10.1145/2538862.2538970",
    "abstract": "This paper reports on part of the findings of a mixed-methods study which explored the educational experiences of Computing Professionals who design and develop educational software. A particular focus is given on the gaps professionals perceive between what was covered in their formal (university) education and the skills and knowledge that have been most important to them in their professional roles. Discrepancies were found particularly in areas related to practical skills (such as testing, maintaining code over time, use of source code control and development tools), communication, critical thinking and problem solving, and strategies used to continue learning on-the-job. Participant suggestions for improving university programs focused largely on the use of large scale, complex, authentic projects of significant duration. The author recommends further consideration be given to explicitly teaching the type of self-learning skills and strategies used by experienced professionals.",
    "author": [
      {
        "family": "Exter",
        "given": "Marisa"
      }
    ],
    "collection-title": "SIGCSE ’14",
    "container-title": "Proceedings of the 45th ACM technical symposium on computer science education",
    "id": "10.1145/2538862.2538970",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "computer science education, computing education, curriculum, informal education, non-formal education, pedagogy",
    "page": "355-360",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Comparing educational experiences and on-the-job needs of educational software designers",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/FIE43999.2019.9028606",
    "URL": "https://doi.org/10.1109/FIE43999.2019.9028606",
    "abstract": "This paper presents an interdisciplinary approach designed to join theoretical foundations required in software engineering with practice required for professional performance in software industry. Although this is a recurring issue on software engineering education, students still have difficulties in dealing with software development environments that are usually more complex than any software projects they have worked at university courses. We developed an approach aligned with market demands and theoretical requirements in software engineering education that incorporates principles of Project Based Learning (PBL) and Agile Methods. It aims to support development of student technical and soft skills in three different, but related, disciplines: Software Engineering Practice, Database Practice and Software Project Management. We describe a set of seven recommendations on how we used largely adopted tools in software development industry in order to develop student technical and soft skills. We describe two case studies: (1) an exploratory case study with three professors and 24 students involving multiple projects; and (2) a confirmatory case study with three professors and 15 students involving a large-scale project. As a result, we point seven recommendations for tool adoption on capstone courses based on lessons learned.",
    "author": [
      {
        "family": "Fontão",
        "given": "Awdren"
      },
      {
        "family": "Gadelha",
        "given": "Bruno"
      },
      {
        "family": "Júnior",
        "given": "Alberto Castro"
      }
    ],
    "container-title": "2019 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE43999.2019.9028606",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "page": "1-8",
    "publisher": "IEEE Press",
    "publisher-place": "Covington, KY, USA",
    "title": "Balancing theory and practice in software engineering education – a PBL, toolset based approach",
    "type": "paper-conference"
  },
  {
    "ISBN": "9798535592121",
    "abstract": "Compilers are among the most fundamental programming tools for building software. However, production compilers remain buggy. GNU compiler collection (GCC), as a long-lasting software released in 1987, provided as a standard compiler for most Unix-like operating systems, has caught over 3,410 bugs from the day they were created. Fuzzing is often leveraged for stress testing purposes with newly-generated, or mutated inputs to find new security vulnerabilities. In our study, we propose a grammar-based compiler fuzzing framework called DᴇᴇᴘFᴜᴢᴢ that continuously synthesizes well-formed C programs to trigger internal compiler errors or \"bugs\", as they are commonly called. In this framework, we are interested in how to apply generative deep neural networks (DNNs), such as the sequence-to-sequence model, to synthesize well-formed C programs based on training through syntax-correct programs. We are also interested in how to synthesize programs using a novel form of reinforcement learning, where the model becomes its teacher to start with a random neural network with no training data and trains itself through self-play. We will use a synthesized set of new C programs to fuzz off-the-shelf C compilers, e.g., GCC and Clang/LLVM. This thesis describes our analysis of neural program synthesis for compiler fuzzing in three steps.First, we conduct a first-step study by implementing DᴇᴇᴘFᴜᴢᴢ that deploys a sequence-to-sequence model to synthesize C programs. We have performed a detailed case study on analyzing the pass rate of generating well-formed programs and achieving the goal of fuzz testing, which requires a certain degree of variation. In general, DᴇᴇᴘFᴜᴢᴢ generated 82.63",
    "author": [
      {
        "family": "Liu",
        "given": "Xiao"
      },
      {
        "family": "Beth",
        "given": "Mary",
        "suffix": "Rosson"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI28778306",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "note": "AAI28778306",
    "publisher": "The Pennsylvania State University",
    "title": "Neural program synthesis for compiler fuzzing",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/305786.305828",
    "ISBN": "1581130872",
    "URL": "https://doi.org/10.1145/305786.305828",
    "abstract": "Problem-Based Learning (PBL) has been an effective technique in developing self-directed learning and problem-solving skills in students — especially in the medical school environment. This paper looks at some preliminary results of an ethnographic study of students in a software development environment trying to use PBL. Our findings indicate that students need explicit training in group dynamics, students tend to rely excessively on existing knowledge, and they focus almost solely on product-related issues versus process-related ones. We then present some suggested improvements and future planned research.",
    "author": [
      {
        "family": "McCracken",
        "given": "Michael"
      },
      {
        "family": "Waters",
        "given": "Robert"
      }
    ],
    "collection-title": "ITiCSE ’99",
    "container-title": "Proceedings of the 4th annual SIGCSE/SIGCUE ITiCSE conference on innovation and technology in computer science education",
    "id": "10.1145/305786.305828",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "keyword": "Computer Science Education, Information Systems Education, Problem Based Learning",
    "page": "9-12",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Why? When an otherwise successful intervention fails",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1067445.1067452",
    "ISBN": "1595930248",
    "URL": "https://doi.org/10.1145/1067445.1067452",
    "abstract": "Computer-based tutoring systems which assist students in solving introductory programming problems have significant potential for improving the quality of programming education and reducing the instructor’s work load. The innovative Environment for Learning to Program (ELP) provides an interactive web-based environment for teaching programming to first year Information Technology students at Queensland University of Technology (QUT). ELP allows students to undertake programming exercises by \"filling in the gaps\" of a partial computer program presented in a web page and to receive guidance in getting their programs to compile and run. Feedback on quality and correctness is provided through a program analysis framework. Students are given the opportunity to produce working programs at the early stages of their course without the need to familiarize themselves with a complex program development environment.",
    "author": [
      {
        "family": "Truong",
        "given": "Nghi"
      },
      {
        "family": "Bancroft",
        "given": "Peter"
      },
      {
        "family": "Roe",
        "given": "Paul"
      }
    ],
    "collection-title": "ITiCSE ’05",
    "container-title": "Proceedings of the 10th annual SIGCSE conference on innovation and technology in computer science education",
    "id": "10.1145/1067445.1067452",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "keyword": "computer programming, feedback, flexible delivery, online learning, tutoring system, web",
    "page": "9-13",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Learning to program through the web",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1113549.1113559",
    "ISBN": "0897910079",
    "URL": "https://doi.org/10.1145/1113549.1113559",
    "abstract": "With the recent improvements in the technology of inlegrated circuits there has been increasing interest in task-oriented computer architectures. At Carnegie-Mellon University we have built a multi-microprocessor architecture tailored to the execution of the Harpy speech understanding system (Harpy Machine). While doing this, we have been confronted with the non-trivial problem of developing software for a lask-oriented multiprocessor. This paper is concerned with one approach to the problem of software development: the use of an ad-hoc simulator as a cheap software development tool (as opposed to the typical use of a simulator as a design evaluation tool). The experience made with the simulator in the development of the software for the Harpy Machine is also discussed.",
    "author": [
      {
        "family": "Bisiani",
        "given": "R."
      }
    ],
    "collection-title": "SIGSMALL/PC",
    "container-title": "Proceedings of the second symposium on small systems",
    "id": "10.1145/1113549.1113559",
    "issued": {
      "date-parts": [
        [
          1979
        ]
      ]
    },
    "keyword": "debugging, microprocessors, multiprocessor systems, simulation, software development, speech recognition systems, task-oriented computer architecture",
    "page": "69-74",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The role of simulation in the development of task-oriented computer architectures",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1155/2022/4127924",
    "ISSN": "1058-9244",
    "URL": "https://doi.org/10.1155/2022/4127924",
    "abstract": "With the great changes of social development environment and the lack of psychological preparation of many students, many college students have many psychological problems in the process of adapting to the environment. If the problem cannot be solved in time, it will seriously affect their future adaptation and mental health. In order to solve the psychological problems of college students, the networked dynamic model constructed by using big data modeling technology can realize the system functions required by users and model the model accordingly. The main research direction of this paper is to study the influencing factors and change trend of college students’ mental health under the background of big data. In the network-oriented scenario, the missing value of the data is supplemented, and the sequence prediction technology is added to the data. Finally, by adding corresponding data samples to the improved big data dynamic model, the results of the addition completion method and data sequence prediction technology are analyzed.",
    "author": [
      {
        "family": "Fu",
        "given": "Qi"
      },
      {
        "family": "Bin",
        "given": "Sheng"
      }
    ],
    "container-title": "Sci. Program.",
    "id": "10.1155/2022/4127924",
    "issued": {
      "date-parts": [
        [
          2022,
          1
        ]
      ]
    },
    "publisher": "Hindawi Limited",
    "publisher-place": "London, GBR",
    "title": "Dynamic modeling of influencing factors and change trend of college students’ mental health based on big data",
    "type": "article-journal",
    "volume": "2022"
  },
  {
    "DOI": "10.1007/s10639-010-9139-3",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-010-9139-3",
    "abstract": "The process of comprehending a problem, strategically developing a solution and translating the solution into an algorithm is arguably the single most important series of skills acquired during the education of an undergraduate computer science or information technology major. With this in mind, much care should be taken when choosing a programming language to deploy in the first University programming course. BLAKE, Beginners Language for Acquiring Key programming Essentials, is designed specifically for use in a Programming I class. BLAKE aids in enforcing fundamental object-oriented practices while simultaneously facilitating the transition to subsequent programming languages. BLAKE’s major features include; consistent parameter passing, single inheritance, non-redundant control structures, a simple development environment, and hardware independent data types. The syntax remains relatively small while still facilitating a straightforward transition to industry standard programming languages.",
    "author": [
      {
        "family": "Blake",
        "given": "Ben"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-010-9139-3",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2010,
          12
        ]
      ]
    },
    "keyword": "Curriculum, Grammar, Object oriented, Programming language, Syntax",
    "page": "277-291",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "BLAKE: A language designed for programming i",
    "title-short": "BLAKE",
    "type": "article-journal",
    "volume": "15"
  },
  {
    "DOI": "10.1109/ICESS.2009.90",
    "ISBN": "9780769536781",
    "URL": "https://doi.org/10.1109/ICESS.2009.90",
    "abstract": "Haptic feedback can be a critical component of virtual environments used in cognitive research, rehabilitation, military training, and entertainment. A limiting factor in the innovation and the acceptance of virtual environments with haptic feedback is the time and cost required to build them. This paper presents a development environment called iAcumen that supports a new approach for programming such systems. This approach allows the developer to directly express physical equations describing the underlying dynamics. By raising the level of abstraction for the developer, we avoid many of the problems that limit the effectiveness of traditional approaches.",
    "author": [
      {
        "family": "Zhu",
        "given": "Angela Yun"
      },
      {
        "family": "Inoue",
        "given": "Jun"
      },
      {
        "family": "Peralta",
        "given": "Marisa Linnea"
      },
      {
        "family": "Taha",
        "given": "Walid"
      },
      {
        "family": "O’Malley",
        "given": "Marcia K."
      },
      {
        "family": "Powell",
        "given": "Dane"
      }
    ],
    "collection-title": "ICESS ’09",
    "container-title": "Proceedings of the 2009 international conference on embedded software and systems",
    "id": "10.1109/ICESS.2009.90",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "haptic feedback systems, simulation, virtual environments",
    "page": "482-489",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Implementing haptic feedback environments from high-level descriptions",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2157136.2157311",
    "ISBN": "9781450310987",
    "URL": "https://doi.org/10.1145/2157136.2157311",
    "abstract": "Closed labs have become a common feature in computer science education because they provide hands-on experience in a supervised setting. Microlabs extend this approach into the lecture format with very short hands-on activities in the \"middle of the lecture.\" The programming microlab approach was developed for a distributed computing course that integrated all levels of parallelism (multicore, cluster, and grid). Since that time we have developed logical microlabs where students solve conceptual problems that do not involve programming. These are integrated into a Microlab Learning Cycle. We want our microlabs to be usable with a wide variety of computing devices, including tablets. After experimenting with different development environments we have adopted the Google Web Toolkit (GWT). After presenting the current status of our activities, we discuss future directions for microlab development. This work is supported, in part, by three National Science Foundation grants.",
    "author": [
      {
        "family": "Kurtz",
        "given": "Barry L."
      },
      {
        "family": "Fenwick",
        "given": "James B."
      },
      {
        "family": "Meznar",
        "given": "Philip"
      }
    ],
    "collection-title": "SIGCSE ’12",
    "container-title": "Proceedings of the 43rd ACM technical symposium on computer science education",
    "id": "10.1145/2157136.2157311",
    "issued": {
      "date-parts": [
        [
          2012
        ]
      ]
    },
    "keyword": "active learning, automated grading, web development",
    "page": "607-612",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Developing microlabs using google web toolkit",
    "type": "paper-conference"
  },
  {
    "ISBN": "1586035304",
    "abstract": "Modern computer games show potential not just for engaging and entertaining users, but also in promoting learning. Game designers employ a range of techniques to promote long-term user engagement and motivation. These techniques are increasingly being employed in so-called serious games, games that have non-entertainment purposes such as education or training. Although such games share the goal of AIED of promoting deep learner engagement with subject matter, the techniques employed are very different. Can AIED technologies complement and enhance serious game design techniques, or does good serious game design render AIED techniques superfluous? This paper explores these questions in the context of the Tactical Language Training System (TLTS), a program that supports rapid acquisition of foreign language and cultural skills. The TLTS combines game design principles and game development tools with learner modelling, pedagogical agents, and pedagogical dramas. Learners carry out missions in a simulated game world, interacting with non-player characters. A virtual aide assists the learners if they run into difficulties, and gives performance feedback in the context of preparatory exercises. Artificial intelligence plays a key role in controlling the behaviour of the non-player characters in the game; intelligent tutoring provides supplementary scaffolding.",
    "author": [
      {
        "family": "Johnson",
        "given": "W. Lewis"
      },
      {
        "family": "Vilhjalmsson",
        "given": "Hannes"
      },
      {
        "family": "Marsella",
        "given": "Stacy"
      }
    ],
    "container-title": "Proceedings of the 2005 conference on artificial intelligence in education: Supporting learning through intelligent and socially informed technology",
    "id": "10.5555/1562524.1562569",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "306-313",
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Serious games for language learning: How much game, how much AI?",
    "title-short": "Serious games for language learning",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICETET.2011.37",
    "ISBN": "9780769545615",
    "URL": "https://doi.org/10.1109/ICETET.2011.37",
    "abstract": "Unique affect of computer and information technology development on education in engineering is that both higher education courses and product development environments can utilize high performance methods, tools, and systems. Product development relies upon sophisticated product description and simulations. At the same time, education of engineers involves teaching competences those are also applied in product modeling and simulation. It is evident, that connection of computer systems in product development and higher education could bring a real integration of academic system with field practice. A former result in computer modeling of higher education courses was analyzed by the authors regarding issues for application at the every day practice of engineering education. This paper introduces new results in possibilities for the support of higher education programs considering recent advances in higher education and engineering modeling processes. Paper starts with an outline of supports for education programs in a computer system. Following this, teaching, projects, and problem solving are discussed in education program. Next, course description, elements of higher education process, and main connections of industrial instruction are explained in a practice oriented context. Finally, integrating product modeling with course modeling is sketched and concluded.",
    "author": [
      {
        "family": "Gáti",
        "given": "Jozsef"
      },
      {
        "family": "Kártyás",
        "given": "Gyula"
      }
    ],
    "collection-title": "ICETET ’11",
    "container-title": "Proceedings of the 2011 fourth international conference on emerging trends in engineering &amp; technology",
    "id": "10.1109/ICETET.2011.37",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "keyword": "computer system assisted education, course modeling, higher education in engineering",
    "page": "61-65",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Computer system support for higher education programs in engineering",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3463274.3463806",
    "ISBN": "9781450390538",
    "URL": "https://doi.org/10.1145/3463274.3463806",
    "abstract": "Finding bugs in a commercial cyber-physical system (CPS) development tool such as Simulink is hard as its codebase contains millions of lines of code and complete formal language specifications are not available. While deep learning techniques promise to learn such language specifications from sample models, deep learning needs a large number of training data to work well. SLGPT addresses this problem by using transfer learning to leverage the powerful Generative Pre-trained Transformer 2 (GPT-2) model, which has been pre-trained on a large set of training data. SLGPT adapts GPT-2 to Simulink with both randomly generated models and models mined from open-source repositories. SLGPT produced Simulink models that are both more similar to open-source models than its closest competitor, DeepFuzzSL, and found a super-set of the Simulink development toolchain bugs found by DeepFuzzSL.",
    "author": [
      {
        "family": "Shrestha",
        "given": "Sohil Lal"
      },
      {
        "family": "Csallner",
        "given": "Christoph"
      }
    ],
    "collection-title": "EASE ’21",
    "container-title": "Proceedings of the 25th international conference on evaluation and assessment in software engineering",
    "id": "10.1145/3463274.3463806",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Cyber-physical system development, GPT-2, Simulink, deep learning, programming language modeling, tool chain bugs",
    "page": "260-265",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SLGPT: Using transfer learning to directly generate simulink model files and find bugs in the simulink toolchain",
    "title-short": "SLGPT",
    "type": "paper-conference"
  },
  {
    "DOI": "10.2307/248753",
    "ISSN": "0276-7783",
    "URL": "https://doi.org/10.2307/248753",
    "abstract": "Selecting from the many currently available systems development methodologies (SDMs) and development techniques is a difficult problem with economic, technical, and behavioral implications. A quantitative approach to the selection problem is represented.The selection model begins with a definition of a superset of functions expected of a systems development tool. Functions are then weighted, using a Delphi approach to achieve acceptable valuations among system managers. Next, each approach under consideration is evaluated with respect to each function desired. After scores are computed for each methodology, economic and qualitative aspects such as training availability and cost can be used to differentiate the highest ranked alternatives.The four-person MBA project team from the Graduate School of Management at the University of Minnesota, with the guidance from authors, applied the model to a methodology selection problem. In addition to producing a quantitative ranking of competing methodologies, the approach described furthered understanding of the functions to be performed by the methodologies being considered. It also gained acceptance, admittedly reluctant, of the recommended methodology from managers who strongly advocated their own favorites.",
    "author": [
      {
        "family": "Naumann",
        "given": "Justus D."
      },
      {
        "family": "Palvia",
        "given": "Shailendra"
      }
    ],
    "container-title": "MIS Q.",
    "id": "10.2307/248753",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1982,
          3
        ]
      ]
    },
    "keyword": "SDM, management, methodology, standards, systems development",
    "page": "39-48",
    "publisher": "Society for Information Management; The Management Information Systems Research Center",
    "publisher-place": "USA",
    "title": "A selection model for systems development tools",
    "type": "article-journal",
    "volume": "6"
  },
  {
    "DOI": "10.1007/978-3-540-85033-5_46",
    "ISBN": "9783540850328",
    "URL": "https://doi.org/10.1007/978-3-540-85033-5_46",
    "abstract": "With the development of information technologies many researchers and instructors are interested in the educational resources on the Web. All the resources are described as Learning Object which focuses on reusability and automation. Learning Object is a central notion of the majority of current researches to Web-based education, and many institutions devote themselves to research the standardization of learning object. After analyzing Learning Object’s definition and metadata the authors emphasize that the metadata alone is not enough because it is lack of semantic and reasoning capability. Semantic Web is put forward to solve the semantic problems in current Web. Ontology is the core concept and technology in this framework. In order to reuse and share learning object better, the ontology-based description of learning object is expatiated, meanwhile this paper provides a learning object ontology with the development tool Protégé. At last a shareable model in Semantic Web is mentioned.",
    "author": [
      {
        "family": "Wang",
        "given": "Xiaodan"
      },
      {
        "family": "Fang",
        "given": "Fang"
      },
      {
        "family": "Fan",
        "given": "Lei"
      }
    ],
    "collection-title": "ICWL ’08",
    "container-title": "Proceedings of the 7th international conference on advances in web based learning",
    "id": "10.1007/978-3-540-85033-5_46",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "Learning Object, Ontology, Semantic Web, share",
    "page": "468-476",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Ontology-based description of learning object",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3308557.3308666",
    "ISBN": "9781450366731",
    "URL": "https://doi.org/10.1145/3308557.3308666",
    "abstract": "In recent years, deep learning has contributed to a big step forward in artificial intelligence, so that deep learning models have been created extensively in a variety of areas. However, development of deep learning model requires high implementation skills as well as domain knowledge. Additionally, finding the best model is a process of a lot of trial-and-error for developers. To alleviate the developers’ difficulties, we have developed a deep learning model development environment called DL-Dashboard that allows developers can create new models easily and quickly by drag-and-dropping built-in layer component and can train the models by selecting one of the suggested training options without much deep learning experience. We explain design principles and implementation of DL-Dashboard system and show how developers can create and train models user-friendly on it.",
    "author": [
      {
        "family": "Park",
        "given": "Yoomi"
      },
      {
        "family": "Lim",
        "given": "Eun-Ji"
      },
      {
        "family": "Ahn",
        "given": "Shinyoung"
      },
      {
        "family": "Choi",
        "given": "Wan"
      },
      {
        "family": "Kim",
        "given": "Taewoo"
      }
    ],
    "collection-title": "IUI ’19 companion",
    "container-title": "Companion proceedings of the 24th international conference on intelligent user interfaces",
    "id": "10.1145/3308557.3308666",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "deep learning, deep learning model creation, user interface",
    "page": "73-74",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "DL-dashboard: User-friendly deep learning model development environment",
    "title-short": "DL-dashboard",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1155/2022/7703327",
    "ISSN": "1058-9244",
    "URL": "https://doi.org/10.1155/2022/7703327",
    "abstract": "The intelligent programming analysis system based on Internet has attracted more and more attention in the field of education management. The problem of how to flexibly master the application capabilities of intelligent programming and development tools, debugging and optimizing programs, and project deployment is becoming more and more serious. Based on the intelligent programming analysis method, this paper systematically introduces the research and design process of education management model and designs modules such as distributed parallel PhpDig, information analyzer, and information resource database. The system adopts client/middleware/server (C/M/S) three-tier architecture planning and design. The server-side carries the resource manager, the middleware carries the intelligent work tasks (information analyzer, resource collection agent), and the client implements user interaction and data representation solves the storage load problem of a large amount of data. The experimental results show that the semantic processing of search object attributes can improve the retrieval performance, and the retrieval rate and tolerance factor reach 87.6",
    "author": [
      {
        "family": "Chen",
        "given": "Sijing"
      },
      {
        "family": "Zhu",
        "given": "Rukui"
      },
      {
        "family": "Huang",
        "given": "Jinshun"
      },
      {
        "family": "Bin",
        "given": "Sheng"
      }
    ],
    "container-title": "Sci. Program.",
    "id": "10.1155/2022/7703327",
    "issued": {
      "date-parts": [
        [
          2022,
          1
        ]
      ]
    },
    "publisher": "Hindawi Limited",
    "publisher-place": "London, GBR",
    "title": "Construction and application of university education management model based on intelligent programming analysis method",
    "type": "article-journal",
    "volume": "2022"
  },
  {
    "DOI": "10.1145/3209635.3209643",
    "ISBN": "9781450358057",
    "URL": "https://doi.org/10.1145/3209635.3209643",
    "abstract": "The recent emergence of durable, low cost, and highly capable robots on the commercial market provides opportunity for engaging and highly motivational new curricula to teach computer programming and problem solving principles such as those typically found in a CS 0.5 course and those implementing the College Board’s CS Principles curriculum framework. This paper documents a seventeen lesson curriculum based on the Sphero SPRK+ robot, the Sphero Edu development environment, and a motivating theme based upon the 2015 movie, The Martian. Along with the curriculum itself, discussion includes an experience report with a pilot run of the curriculum with two small sections of a freshman-level introduction to computing course aligned with the College Board’s CS Principles curriculum framework. Initial results indicate great potential for highly engaging and effective pedagogy based on this approach. The results also reveal some practical challenges with implementing similar approaches based upon current and near-term technologies.",
    "author": [
      {
        "family": "Hadfield",
        "given": "Steven M."
      },
      {
        "family": "Raynor",
        "given": "Justin T."
      },
      {
        "family": "Sievers",
        "given": "Matthew D."
      }
    ],
    "collection-title": "WCCCE ’18",
    "container-title": "Proceedings of the 23rd western canadian conference on computing education",
    "id": "10.1145/3209635.3209643",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "Blockly, CS Principles, Introduction to Programming, JavaScript, Robotics, Sphero SPRK+, Theme-Based Learning Activities",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Engaging secondary and post-secondary students to learn and explore programming using a theme-based curriculum and the sphero SPRK+ robot",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/72.712157",
    "ISSN": "1045-9227",
    "URL": "https://doi.org/10.1109/72.712157",
    "abstract": "A new learning algorithm for the Simpson fuzzy min-max neural network is presented. It overcomes some undesired properties of the Simpson model. Our new algorithm improves the network performance; the classification result does not depend on the presentation order of the patterns in the training set, and at each step, the classification error in the training set cannot increase. The new neural model is particularly useful in classification problems. Tests were executed on three different classification problems: 1) with two-dimensional synthetic data; 2) with realistic data generated by a simulator to find anomalies in the cooling system of a blast furnace; and 3) with real data for industrial diagnosis. The experiments were made following some recent evaluation criteria known in the literature and by using Microsoft Visual C++ development environment on personal computers",
    "author": [
      {
        "family": "Meneganti",
        "given": "M."
      },
      {
        "family": "Saviello",
        "given": "F. S."
      },
      {
        "family": "Tagliaferri",
        "given": "R."
      }
    ],
    "container-title": "Trans. Neur. Netw.",
    "id": "10.1109/72.712157",
    "issue": "5",
    "issued": {
      "date-parts": [
        [
          1998,
          9
        ]
      ]
    },
    "page": "848-861",
    "publisher": "IEEE Press",
    "title": "Fuzzy neural networks for classification and detection of anomalies",
    "type": "article-journal",
    "volume": "9"
  },
  {
    "DOI": "10.1155/2022/3414935",
    "ISSN": "1574-017X",
    "URL": "https://doi.org/10.1155/2022/3414935",
    "abstract": "In order to solve a series of problems similar to the repetitive construction of resources and low degree of resource sharing in cruciform teaching, this paper studies the digital disarming management. Based on the in-depth analysis of the actual needs of the digital teaching resource service system and the key problems in the system, taking the resources and business process as the starting point, based on Java Web related technology, combined with the related processes of resources and business processing, this paper designs the digital teaching resource system of colleges and universities. The system has the functions of resource digitization, process management, and interaction with other platforms. The system database platform and operation platform are built; the development environment is configured; and the user login service function, data conversion service function, process management service function, and system management service function are completed. The function is tested by unit test, and the performance is tested and analyzed according to user requirements and design objectives. The system adopts Java web development technology, uses S2SH framework as the development basis, and takes Oracle database as the data storage platform through Tomcat6.0 web server for program publishing. Through system testing and analysis, the software can operate normally and achieve the expected functions and can be put into use.",
    "author": [
      {
        "family": "Feng",
        "given": "Peilu"
      },
      {
        "family": "Wu",
        "given": "Qi"
      },
      {
        "family": "Zhu",
        "given": "Fusheng"
      }
    ],
    "container-title": "Mob. Inf. Syst.",
    "id": "10.1155/2022/3414935",
    "issued": {
      "date-parts": [
        [
          2022,
          1
        ]
      ]
    },
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Digital teaching management system based on deep learning of internet of things",
    "type": "article-journal",
    "volume": "2022"
  },
  {
    "abstract": "The use of video within clinical courses at Radford University (RU) is currently limited by labor-intensive, tape-based equipment for organizing and accessing specific scenes and events. Our faculty has successfully applied Tablet PCs and Microsoft OneNote® in courses to capture and analyze instructional sessions, but these existing systems have limited capabilities. For example, OneNote currently only supports synchronous live feeds of web cameras with moderate video fidelity. However, prerecorded asynchronous sessions fed from DVD players or saved digital movie files of sessions at remote locations are all primary sources of observation data. The overall goal of this project is to design, implement, and evaluate a Tablet PC-based software application called EVA (Extended Video Application) to overcome these limitations and substantially improve the effectiveness of specific clinical learning experiences in education, counseling, and social work courses. This paper gives the background, motivation, and an overview of the project, reports on project status, describes the software development environment, and discusses the technical difficulties and issues surrounding the design and implementation components. The paper also covers future work (which includes a rigorous evaluation component), expected outcomes, and conclusions.",
    "author": [
      {
        "family": "Derrick",
        "given": "E. Joseph"
      },
      {
        "family": "Htay",
        "given": "Maung"
      },
      {
        "family": "Vaccare",
        "given": "Carmel"
      }
    ],
    "collection-title": "WBED’07",
    "container-title": "Proceedings of the sixth conference on IASTED international conference web-based education - volume 2",
    "id": "10.5555/1323159.1323205",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "assessment, mobile e-learning, software development, tablet",
    "page": "258-263",
    "publisher": "ACTA Press",
    "publisher-place": "USA",
    "title": "EVA (extended video application): Developing tablet PC software for multi-disciplinary mobile e-learning",
    "title-short": "EVA (extended video application)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/3477.740163",
    "ISSN": "1083-4419",
    "URL": "https://doi.org/10.1109/3477.740163",
    "abstract": "To extract knowledge from a set of numerical data and build up a rule-based system is an important research topic in knowledge acquisition and expert systems. In recent years, many fuzzy systems that automatically generate fuzzy rules from numerical data have been proposed. In this paper, we propose a new fuzzy learning algorithm based on the α-cuts of equivalence relations and the α-cuts of fuzzy sets to construct the membership functions of the input variables and the output variables of fuzzy rules and to induce the fuzzy rules from the numerical training data set. Based on the proposed fuzzy learning algorithm, we also implemented a program on a Pentium PC using the MATLAB development tool to deal with the Iris data classification problem. The experimental results show that the proposed fuzzy learning algorithm has a higher average classification ratio and can generate fewer rules than the existing algorithm",
    "author": [
      {
        "family": "Wu",
        "given": "Tzu-Ping"
      },
      {
        "family": "Chen",
        "given": "Shyi-Ming"
      }
    ],
    "container-title": "Trans. Sys. Man Cyber. Part B",
    "id": "10.1109/3477.740163",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1999,
          2
        ]
      ]
    },
    "page": "25-40",
    "publisher": "IEEE Press",
    "title": "A new method for constructing membership functions and fuzzy rules from training examples",
    "type": "article-journal",
    "volume": "29"
  },
  {
    "DOI": "10.1007/s10055-021-00550-1",
    "ISSN": "1359-4338",
    "URL": "https://doi.org/10.1007/s10055-021-00550-1",
    "abstract": "Artificial intelligence models can produce powerful predictive computer vision tools for healthcare. However, their development simultaneously requires computational skill as well as biomedical expertise. This barrier often impedes the wider utilization of AI in professional environments since biomedical experts often lack software development skills. We present the first development environment where a user with no prior training can build near-expert level convolutional neural network classifiers on real-world datasets. Our key contribution is a simplified environment in virtual reality where the user can build, compute, and critique a model. Through a controlled user study, we show that our software enables biomedical researchers and healthcare professionals with no AI development experience to build AI models with near-expert performance. We conclude that the potential role for AI in the biomedical domain can be realized more effectively by making its development more intuitive for non-technical domain experts using novel modes of interaction.",
    "author": [
      {
        "family": "VanHorn",
        "given": "Kevin"
      },
      {
        "family": "Çobanoğlu",
        "given": "Murat Can"
      }
    ],
    "container-title": "Virtual Real.",
    "id": "10.1007/s10055-021-00550-1",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2022,
          3
        ]
      ]
    },
    "keyword": "Deep learning, Machine learning, Neural nets, Virtual reality, Visualization",
    "page": "159-171",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Democratizing AI in biomedical image classification using virtual reality",
    "type": "article-journal",
    "volume": "26"
  },
  {
    "DOI": "10.1109/IE.2014.34",
    "ISBN": "9781479929474",
    "URL": "https://doi.org/10.1109/IE.2014.34",
    "abstract": "Smart homes, smart cars, smart classrooms are now a reality as the world becomes increasingly interconnected by ubiquitous computing technology. The next step is to interconnect such environments, however there are a number of significant barriers to advancing research in this area, most notably the lack of available environments, standards and tools etc. A possible solution is the use of simulated spaces, nevertheless as realistic as strive to make them, they are, at best, only approximations to the real spaces, with important differences such as utilising idealised rather than noisy sensor data. In this respect, an improvement to simulation is emulation, which uses specially adapted physical components to imitate real systems and environments. In this paper we present our work-in-progress towards the creation of a development tool for intelligent environments based on the interconnection of simulated, emulated and real intelligent spaces using a distributed model of mixed reality. To do so, we propose the use of physical/virtual components (xReality objects) able to be combined through a 3D graphical user interface, sharing real-time information. We present three scenarios of interconnected real and emulated spaces, used for education, achieving integration between real and virtual worlds.",
    "author": [
      {
        "family": "Rı́os",
        "given": "Anasol Peña"
      },
      {
        "family": "Callaghan",
        "given": "Vic"
      },
      {
        "family": "Gardner",
        "given": "Michael"
      },
      {
        "family": "Alhaddad",
        "given": "Mohammed J."
      }
    ],
    "collection-title": "IE ’14",
    "container-title": "Proceedings of the 2014 international conference on intelligent environments",
    "id": "10.1109/IE.2014.34",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "HCI, blended reality, hyperreality, intelligent environments, interreality, mixed reality, ubiquitous virtual reality",
    "page": "182-189",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Using mixed-reality to develop smart environments",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/98894.99124",
    "ISBN": "0897913728",
    "URL": "https://doi.org/10.1145/98894.99124",
    "abstract": "Neural networks are a popular area of research today. However, neural network algorithms have only recently proven valuable to application problems. This paper seeks to aid in the process of transferring neural network technology from research to a development environment by describing our experience in applying this technology.The application studied here is Speaker Identity Verification (SIV), which is the task of verifying a speaker’s identity by comparing the speaker’s voice pattern to a stored template.In this paper, we describe the application of the back-propagation neural network algorithm to one aspect of the SIV problem, called Residual Compression (RC). The RC problem is to extract useful features from a part of the speech signal that was not utilized by previous SIV systems. Here, we describe a neural network architecture, pre-processing algorithm, training methodology, and empirical results for this problem. We also present a few guidelines for the use of neural networks in applied settings.",
    "author": [
      {
        "family": "Pratt",
        "given": "Lorien"
      },
      {
        "family": "Cebulka",
        "given": "Kathleen D."
      },
      {
        "family": "Clitherow",
        "given": "Peter"
      }
    ],
    "collection-title": "IEA/AIE ’90",
    "container-title": "Proceedings of the 3rd international conference on industrial and engineering applications of artificial intelligence and expert systems - volume 2",
    "id": "10.1145/98894.99124",
    "issued": {
      "date-parts": [
        [
          1990
        ]
      ]
    },
    "page": "1063-1072",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Residual speech signal compression: An experiment in the practical application of neural network technology",
    "title-short": "Residual speech signal compression",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2538862.2544310",
    "ISBN": "9781450326056",
    "URL": "https://doi.org/10.1145/2538862.2544310",
    "abstract": "With the continued and alarming lack of involvement in computing among college students, attention has recently focused on engaging students at the middle and high school levels. Our \"Copper Country Programmers\" club began as a community outreach program to fill a gap left by the elimination of the computing curriculum in the local school district. In our club, university faculty and students provide curriculum, tools, and classroom tutoring for young novice programmers across the school district. Our curriculum teaches programming through a series of exercises involving HTML, BASIC, LOGO, and Processing (a graphics-oriented Java variant.) Contrary to some other approaches, we present students initially with a low level, bare bones programming model and development environment, then gradually increase the functionality and complexity. We find that students readily grasp the simple, transparent initial model, then experience first-hand the motivations for adding functionality (and complexity). Our cross-curricular programming topics include graphic design, interactive fiction, computer generated poetry, mathematical simulation, computational geometry, game physics, computer art, artificial intelligence, video game development, and critical thinking. We provide examples of our curriculum, student work, problems encountered, and how they were resolved.",
    "author": [
      {
        "family": "Ureel II",
        "given": "Leo C."
      },
      {
        "family": "Earnest",
        "given": "John"
      },
      {
        "family": "Wallace",
        "given": "Charles"
      }
    ],
    "collection-title": "SIGCSE ’14",
    "container-title": "Proceedings of the 45th ACM technical symposium on computer science education",
    "id": "10.1145/2538862.2544310",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "K-12 computer science curriculum, K-12 instruction, community outreach",
    "page": "722-723",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Copper country programmers: A novel curriculum for beginning programmers in middle and high school (abstract only)",
    "title-short": "Copper country programmers",
    "type": "paper-conference"
  },
  {
    "ISSN": "1070-986X",
    "abstract": "The development of distributed multimedia applications is supported by an increasing number of services. While such services pave the way toward sophisticated multimedia support even in distributed systems, using them still makes the task of developers quite tedious. This is because several inconsistent services have to be interfaced in order to reflect different aspects. As a way to alleviate this problem, we make the case for an encompassing framework in which all services would be offered under a unifying paradigm. First we give an overview of existing multimedia services with a focus on distribution, extracting the requirements imposed on multimedia extensions to general frameworks as a set of so-called abstractions. Known development environments for distributed applications are obvious candidates for such encompassing frameworks. We review these based on four popular paradigms: client-server/remote procedure call, object-orientation, hypermedia, and open documents. We also investigate possible multimedia extensions and discuss the \"expressive power\" of the paradigms. In conclusion, we propose steps towards an encompassing framework based on a hybrid object/hypermedia paradigm. Readers may contact Mühlhäuser at the University of Linz, Altenbergerstrasse 69, A-4040 Linz, Austria, e-mail: max@tk.uni-linz.ac.at",
    "author": [
      {
        "family": "Mühlhäuser",
        "given": "Max"
      },
      {
        "family": "Gecsei",
        "given": "Jan"
      }
    ],
    "container-title": "IEEE MultiMedia",
    "id": "10.5555/614651.614726",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          1996,
          9
        ]
      ]
    },
    "page": "48-61",
    "publisher": "IEEE Computer Society Press",
    "publisher-place": "Washington, DC, USA",
    "title": "Services, frameworks, and paradigms for distributed multimedia applications",
    "type": "article-journal",
    "volume": "3"
  },
  {
    "DOI": "10.1016/S1045-926X(06)80007-8",
    "ISSN": "1045-926X",
    "URL": "https://doi.org/10.1016/S1045-926X(06)80007-8",
    "abstract": "The current generation of data flow based visual programming systems is all too often limited in application. It is our contention that data flow visual languages, to be more widely accepted for solving a broad range of problems, need to be more general in their syntax, semantics, translation schemes, computational model, execution methods and scheduling. These capabilities should be accompanied by a development environment that facilitates information processing extensions needed by the user to solve a wide range of application-specific problems. This paper addresses these issues by describing and critiquing the Khoros system implemented by the University of New Mexico, Khoros Group. The Khoros infrastructure consists of several layers of interacting subsystems. A user interface development system (UIDS) combines a high-level user interface specification with methods of software development that are embedded in a code generation tool set. The UIDS is used to create, install and maintain the fundamental operators for cantata, the visual programming language component of Khoros.",
    "author": [
      {
        "family": "Rasure",
        "given": "John R."
      },
      {
        "family": "Williams",
        "given": "Carla S."
      }
    ],
    "container-title": "J. Vis. Lang. Comput.",
    "id": "10.1016/S1045-926X(06)80007-8",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          1991,
          9
        ]
      ]
    },
    "page": "217-246",
    "publisher": "Academic Press, Inc.",
    "publisher-place": "USA",
    "title": "An integrated data flow visual language and software development environment",
    "type": "article-journal",
    "volume": "2"
  },
  {
    "DOI": "10.1155/2021/6259995",
    "ISSN": "1939-0114",
    "URL": "https://doi.org/10.1155/2021/6259995",
    "abstract": "In order to overcome the problems of low error capture accuracy and long response time of traditional spoken French error correction algorithms, this study designed a French spoken error correction algorithm based on machine learning. Based on the construction of the French spoken pronunciation signal model, the algorithm analyzes the spectral features of French spoken pronunciation and then selects and classifies the features and captures the abnormal pronunciation signals. Based on this, the machine learning network architecture and the training process of the machine learning network are designed, and the operation structure of the algorithm, the algorithm program, the algorithm development environment, and the identification of oral errors are designed to complete the correction of oral French errors. Experimental results show that the proposed algorithm has high error capture accuracy and short response time, which prove its high efficiency and timeliness.",
    "author": [
      {
        "family": "Gao",
        "given": "Jie"
      },
      {
        "family": "Su",
        "given": "Jian"
      }
    ],
    "container-title": "Sec. and Commun. Netw.",
    "id": "10.1155/2021/6259995",
    "issued": {
      "date-parts": [
        [
          2021,
          1
        ]
      ]
    },
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "Research on machine learning-based error correction algorithm for spoken french",
    "type": "article-journal",
    "volume": "2021"
  },
  {
    "DOI": "10.1145/3407982.3408003",
    "ISBN": "9781450377683",
    "URL": "https://doi.org/10.1145/3407982.3408003",
    "abstract": "Operating on high voltage switchgears in oil plants in Russia as well as anywhere else in the world requires well-trained operative personnel. To improve the training of the workers in such plants computer-based logical simulators are developed usually. However, they are not sufficient enough in training because the trainees learn theoretically and not practically. Training specialists from different areas of industry using virtual reality environments where participants learn practically is up-to-date topic and a sphere for top-of-the-art research and development. This article examines the creation of a virtual reality training system for personnel from oil plants and represents the requirements for the training environment, the model of the system and the selection of a specific virtual reality technology and development environment. The definitions of the problem, the research and the development of the system have been entrusted to the authors of this paper by CS Construction Solutions Ltd., UK.",
    "author": [
      {
        "family": "Petkov",
        "given": "Emiliyan"
      },
      {
        "family": "Angelov",
        "given": "Vladislav"
      }
    ],
    "collection-title": "CompSysTech ’20",
    "container-title": "Proceedings of the 21st international conference on computer systems and technologies",
    "id": "10.1145/3407982.3408003",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "Industry 4.0, Virtual reality, oil, plant, switchgears, training",
    "page": "266-269",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Virtual reality training system for specialists who operate on high-voltage switchgears in an oil plant in russia",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/SSDM.2000.869796",
    "ISBN": "0769506860",
    "URL": "https://doi.org/10.1109/SSDM.2000.869796",
    "abstract": "The integration of extremely heterogeneous geo-scientific data is a challenging problem. To provide a non-redundant maintenance and cooperative utilization of data by different applications developed within the interdisciplinary geo-scientific research center at the University of Bonn we elaborated a technology based on GeoToolKit - a component-based software development tool. In the paper, we present GeoToolKit extensions required to deal with distributed heterogeneous spatial data sources. They involve metadata-level structures and methods that encourage a convenient navigation in multiple distributed data sources and smart assembling of appropriate data into local task-specific configurations.The proposed extensions can be beneficial for the development of special-purpose applications and rather general data browsers capable to deal with a wide range of geo-scientific data. In addition, they are likely to be helpful in the creation of geo-scientific warehouses and in the development of exploratory applications, which usually need the access to distributed data sources. Finally, CORBA-based architectural extensions of GeoToolKit to provide data and operation transfer are presented and evaluated with real geo-scientific applications.",
    "author": [
      {
        "family": "Balovnev",
        "given": "Oleg"
      },
      {
        "family": "Breunig",
        "given": "Martin"
      },
      {
        "family": "Cremers",
        "given": "Armin B."
      },
      {
        "family": "Shumilov",
        "given": "Serge"
      }
    ],
    "collection-title": "SSDBM ’00",
    "container-title": "Proceedings of the 12th international conference on scientific and statistical database management",
    "id": "10.1109/SSDM.2000.869796",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "page": "259",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Extending GeoToolKit to access distributed spatial data and operations",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2089155.2089157",
    "ISBN": "9781450310246",
    "URL": "https://doi.org/10.1145/2089155.2089157",
    "abstract": "It is the conventional wisdom that some aspects of programming are difficult to learn, and some aspects are error-prone even for experts. Is it possible to separate what is inherently difficult, and therefore most appropriately dealt with through education, versus what is just accidentally difficult, so a new design for a language or development environment might be able to \"fix\" the problem? And are there aspects that a designer makes difficult \"on purpose\"? For example, compare recursion, the syntax for switch statements in C, and how unification works in Prolog, respectively. It is not clear that the conventional wisdom on this topic can be trusted. For example, whereas most argue that concurrency is inherently difficult, the creators of the Alice language argue that they have found a way to make it understandable to novices. This talk will explore some HCI research on this topic, and approaches for identifying the differences.",
    "author": [
      {
        "family": "Myers",
        "given": "Brad A."
      }
    ],
    "collection-title": "PLATEAU ’11",
    "container-title": "Proceedings of the 3rd ACM SIGPLAN workshop on evaluation and usability of programming languages and tools",
    "id": "10.1145/2089155.2089157",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "keyword": "empirical studies of programmers, novice programming, usability of ides",
    "page": "1-2",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Inherent vs. Accidental vs. Intentional difficulties in programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-642-29737-3_28",
    "ISBN": "9783642297366",
    "URL": "https://doi.org/10.1007/978-3-642-29737-3_28",
    "abstract": "Despite the processor industry having more or less successfully invested already 10 years to develop better and increasingly parallel multicore architectures, both software community and educational institutions appear still to rely on the sequential computing paradigm as the primary mechanism for expressing the (very often originally inherently parallel) functionality, especially in the arena of general purpose computing. In that respect, parallel programming has remained a hobby of highly educated specialists and is still too often being considered as too difficult for the average programmer. Excuses are various: lack of education, lack of suitable easy-to-use tools, too architecture-dependent mechanisms, huge existing base of sequential legacy code, steep learning curves, and inefficient architectures. It is important for the scientific community to analyze the situation and understand whether the problem is with hardware architectures, software development tools and practices, or both. Although we would be tempted to answer this question (and actually try to do so elsewhere), there is strong need for wider academic discussion on these topics and presentation of research results in scientific workshops and conferences.",
    "author": [
      {
        "family": "Forsell",
        "given": "Martti"
      },
      {
        "family": "Träff",
        "given": "Jesper Larsson"
      }
    ],
    "collection-title": "Euro-par’11",
    "container-title": "Proceedings of the 2011 international conference on parallel processing",
    "id": "10.1007/978-3-642-29737-3_28",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "page": "245-247",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "HPPC 2010: 5th workshop on highly parallel processing on a chip",
    "title-short": "HPPC 2010",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/HICSS.2005.61",
    "ISBN": "07695226889",
    "URL": "https://doi.org/10.1109/HICSS.2005.61",
    "abstract": "This paper describes a framework for collaboration between a user and a multi-agent system to achieve adjustable autonomy. Adjustable autonomy (AA) is when the levels of autonomy of the agent system - its control over its reasoning - changes during execution due to interaction with a user or other systems. We describe a prototype agent development environment that allows users flexible on-line control over an otherwise completely autonomous agent system. AA can improve productivity during system design, allow earlier deployment, and create a more flexible system. AA can reduce the load on instructors when used in training situations, and allow the user to aid the system when faced with unforseen situations or problems. Examples are given of AA in simulated pilots for fighter aircraft. We found that the AA - the user’s ability to modify the behavior of the agents during execution, resulted in a better, more flexible system.",
    "author": [
      {
        "family": "Reed",
        "given": "N. E."
      }
    ],
    "collection-title": "HICSS ’05",
    "container-title": "Proceedings of the proceedings of the 38th annual hawaii international conference on system sciences - volume 09",
    "id": "10.1109/HICSS.2005.61",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "295.2",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "A user controlled approach to adjustable autonomy",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/TE.2005.850709",
    "ISSN": "0018-9359",
    "URL": "https://doi.org/10.1109/TE.2005.850709",
    "abstract": "A good teacher is able to customize the lesson to fit the requirements and needs of the learners he or she has in the classroom. This process becomes difficult and expensive in open and distance education, where customization means availability of similar contents, presented in diversified styles. A methodology and the tools to tackle the problem by using automated course compilation have been developed in the 3DE project (Design, Development, and Delivery-Electronic Environment for Educational Multimedia). The work on course customization showed the key role of the authoring process and the related problems. This paper summarizes the methodology and describes the development environment designed to assist authors in the creation of customized educational material. The environment seeks to help teachers/authors understand the relations among pedagogical and technical aspects and provides instructions, guidelines, and assistance for the development of learning-styles-aware material. The paper focuses on the author interface of the environment with details on the pedagogical framework, the authors’ guide, the classification guide, and the metadata tool.",
    "author": [
      {
        "family": "Del Corso",
        "given": "D."
      },
      {
        "family": "Ovcin",
        "given": "E."
      },
      {
        "family": "Morrone",
        "given": "G."
      }
    ],
    "container-title": "IEEE Trans. on Educ.",
    "id": "10.1109/TE.2005.850709",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2005,
          11
        ]
      ]
    },
    "keyword": "Authoring guide, automated course construction, educational effectiveness, interoperability, learning styles (LSs), personalized learning, reuse",
    "page": "574-579",
    "publisher": "IEEE Press",
    "title": "A teacher friendly environment to foster learner-centered customization in the development of interactive educational packages",
    "type": "article-journal",
    "volume": "48"
  },
  {
    "DOI": "10.1109/ITSC.2019.8917398",
    "URL": "https://doi.org/10.1109/ITSC.2019.8917398",
    "abstract": "Advanced sensors are a key to enable self-driving cars technology. Laser scanner sensors (LiDAR, Light Detection And Ranging) became a fundamental choice due to its long-range and robustness to low light driving conditions. The problem of designing a control software for self-driving cars is a complex task to explicitly formulate in rule-based systems, thus recent approaches rely on machine learning that can learn those rules from data. The major problem with such approaches is that the amount of training data required for generalizing a machine learning model is big, and on the other hand LiDAR data annotation is very costly compared to other car sensors. An accurate LiDAR sensor model can cope with such problem. Moreover, its value goes beyond this because existing LiDAR development, validation, and evaluation platforms and processes are very costly, and virtual testing and development environments are still immature in terms of physical properties representation.In this work we propose a novel Deep Learning-based LiDAR sensor model. This method models the sensor echos, using a Deep Neural Network to model echo pulse widths learned from real data using Polar Grid Maps (PGM). We benchmark our model performance against comprehensive real sensor data and very promising results are achieved that sets a baseline for future works.",
    "author": [
      {
        "family": "Elmadawi",
        "given": "Khaled"
      },
      {
        "family": "Abdelrazek",
        "given": "Moemen"
      },
      {
        "family": "Elsobky",
        "given": "Mohamed"
      },
      {
        "family": "Eraqi",
        "given": "Hesham M."
      },
      {
        "family": "Zahran",
        "given": "Mohamed"
      }
    ],
    "container-title": "2019 IEEE intelligent transportation systems conference (ITSC)",
    "id": "10.1109/ITSC.2019.8917398",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "page": "1619-1624",
    "publisher": "IEEE Press",
    "publisher-place": "Auckland, New Zealand",
    "title": "End-to-end sensor modeling for LiDAR point cloud",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/DSD.2006.80",
    "ISBN": "0769526098",
    "URL": "https://doi.org/10.1109/DSD.2006.80",
    "abstract": "SoC design methodology is totally dependent on the availability of reliable, easily interfaced and well supported IP cores. Complex cores such as microprocessors can be very expensive if licenced from commercial providers. Research projects, and even small companies, look for open source cores despite the problems associated with this source. The Rachael embedded processor discussed in this paper is a result of an open source initiative, supported both by a commercial design firm and a university. The processor is based on the proven SPARC architecture and was developed in Verilog with systematic methodology as used in industry. Rachael has a flexible memory architecture and is interfaced to the AMBA on chip bus. It is supported by a suite of development tools and is made available as an open source core. Rachel was extensively tested on Virtex4, an earlier version was used in a commercial chip, and a full version is to be fabricated. We discuss architectural issues and trade-offs in the design of Rachael, present its architecture, and analyse performance factors. The Verilog pre-processor developed for the project is briefly introduced. The open source project is presented and analysed from both the university and industry perspectives. Rachael runs at speed on Xilinx’s ML401 board and it can be demonstrated executing various software applications.",
    "author": [
      {
        "family": "Cowell",
        "given": "Michael"
      },
      {
        "family": "Postula",
        "given": "Adam"
      }
    ],
    "collection-title": "DSD ’06",
    "container-title": "Proceedings of the 9th EUROMICRO conference on digital system design",
    "id": "10.1109/DSD.2006.80",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "page": "415-422",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Rachael SPARC: An open source 32-bit microprocessor core for SoCs",
    "title-short": "Rachael SPARC",
    "type": "paper-conference"
  },
  {
    "ISBN": "9781586037154",
    "abstract": "Modern software engineering attacks its complexity problems by applying well-understood development principles. In particular, the systematic adoption of design patterns caused a significant improvement of software engineering and is one of the most effective remedies for what was formerly called the software crises. Design patterns and their utilization constitute an increasing body of knowledge in software engineering. Due to their regular structure, their orthogonal applicability and the availability of meaningful examples design patterns can serve as an excellent set of use cases for organizational memories, for software development tools and for e-learning environments.Patterns are defined and described on two levels [1]: by real-world examples—e.g., textual or graphical content on their principles, best practices, structure diagrams, code etc.—and by conceptual models—e.g., on categories of application problems, software solutions, deployment consequences etc. This intrinsically dualistic nature of patterns makes them good candidates for conceptual content management (CCM). In this paper we report on the application of the CCM approach to a repository for teaching and training in pattern-based software design as well as for the support of the corresponding e-learning processes.",
    "author": [
      {
        "family": "Sehring",
        "given": "Hans-Werner"
      },
      {
        "family": "Bossung",
        "given": "Sebastian"
      },
      {
        "family": "Hupe",
        "given": "Patrick"
      },
      {
        "family": "Skusa",
        "given": "Michael"
      },
      {
        "family": "Schmidt",
        "given": "Joachim W."
      }
    ],
    "container-title": "Proceedings of the 2007 conference on databases and information systems IV: Selected papers from the seventh international baltic conference DB&amp;IS’2006",
    "id": "10.5555/1565421.1565426",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "Conceptual Modeling, Content Management, Design Patterns, E-Learning",
    "page": "40-54",
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Pattern repositories for software engineering education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800225.806822",
    "ISBN": "0897911652",
    "URL": "https://doi.org/10.1145/800225.806822",
    "abstract": "Polylith is the name of a set of enhanced execution time system services along with development tools and an interfacing methodology.1 As a system, Polylith supports the reliable union of many component tools, addressing the problems of data interchange and synchronization between these tools. It facilitates reuse of code, and promotes the notion that construction of large programs should be viewed instead as orchestration of services. The Polylith is visible as a grammar in which instances of environments2 are precisely and rapidly specified; it is, through compilation and execution of assertions in that language, a medium through which many programs and tools can be united with impunity.This paper presents an overview of the Polylith architecture, along with some brief remarks on the requirements analysis leading to Project Polylith at the University of Illinois. Section 2 presents this architecture, summarizing language and data transformation issues. Simple examples are included. Section 3 introduces one particular instance of an environment specified within Polylith called Minion. It is presented as an extended example, showing how the Polylith is utilized to construct an enthusiastic assistant for mathematical problem solving. The closing section contains some evaluation of how Polylith affects the task of environment development.",
    "author": [
      {
        "family": "Purtilo",
        "given": "James"
      }
    ],
    "collection-title": "SLIPE ’85",
    "container-title": "Proceedings of the ACM SIGPLAN 85 symposium on language issues in programming environments",
    "id": "10.1145/800225.806822",
    "issued": {
      "date-parts": [
        [
          1985
        ]
      ]
    },
    "page": "12-18",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Polylith: An environment to support management of tool interfaces",
    "title-short": "Polylith",
    "type": "paper-conference"
  },
  {
    "ISBN": "0672337231",
    "abstract": "In just 24 sessions of one hour each, learn how to build powerful applications for todays hottest handheld devices: the iPhone and iPad! Using this books straightforward, step-by-step approach, youll master every skill and technology you need, from setting up your iOS development environment to building great user interfaces, sensing motion to writing multitasking applications. Each lesson builds on what youve already learned, giving you a rock-solid foundation for real-world success! Step-by-step instructions carefully walk you through the most common iOS development tasks. Quizzes and Exercises help you test your knowledge. By the Way notes present interesting information related to the discussion. Did You Know? tips show you easier ways to perform tasks. Watch Out! cautions alert you to possible problems and give you advice on how to avoid them. John Ray is currently serving as the Director of the Office of Research Information Systems at the Ohio State University. His many books include Using TCP/IP: Special Edition, Maximum Mac OS X Security, Mac OS X Unleashed, Teach Yourself Dreamweaver MX in 21 Days, and Sams Teach Yourself iOS 7 Application Development in 24 Hours. Printed in full colorfigures and code appear as they do in Xcode Covers iOS 8 and up Learn to navigate the Xcode 6.x development environment Prepare your system and iDevice for efficient development Get started quickly with Apples new language: Swift Test code using the new iOS Playground Understand the Model-View-Controller (MVC) development pattern Visually design and code interfaces using Xcode Storyboards, Segues, Exits, Image Slicing, and the iOS Object Library Use Auto Layout and Size Classes to adapt to different screen sizes and orientations Build advanced UIs with Tables, Split Views, Navigation Controllers, and more Read and write preferences and data, and create System Settings plug-ins Use the iOS media playback and recording capabilities Take photos and manipulate graphics with Core Image Sense motion, orientation, and location with the accelerometer, gyroscope, and GPS Integrate online services using Twitter, Facebook, Email, Web Views, and Apple Maps Create universal applications that run on both the iPhone and iPad Write background-aware multitasking applications Trace, debug, and monitor your applications as they run",
    "author": [
      {
        "family": "Ray",
        "given": "John"
      }
    ],
    "edition": "6th",
    "id": "10.5555/2771337",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "publisher": "Sams publishing",
    "title": "iOS 8 application development in 24 hours, sams teach yourself",
    "type": "book"
  },
  {
    "DOI": "10.1145/2664243.2664254",
    "ISBN": "9781450330053",
    "URL": "https://doi.org/10.1145/2664243.2664254",
    "abstract": "Despite the security community’s emphasis on the importance of building secure software, the number of new vulnerabilities found in our systems is increasing. In addition, vulnerabilities that have been studied for years are still commonly reported in vulnerability databases. This paper investigates a new hypothesis that software vulnerabilities are blind spots in developer’s heuristic-based decision-making processes. Heuristics are simple computational models to solve problems without considering all the information available. They are an adaptive response to our short working memory because they require less cognitive effort. Our hypothesis is that as software vulnerabilities represent corner cases that exercise unusual information flows, they tend to be left out from the repertoire of heuristics used by developers during their programming tasks.To validate this hypothesis we conducted a study with 47 developers using psychological manipulation. In this study each developer worked for approximately one hour on six vulnerable programming scenarios. The sessions progressed from providing no information about the possibility of vulnerabilities, to priming developers about unexpected results, and explicitly mentioning the existence of vulnerabilities in the code. The results show that (i) security is not a priority in software development environments, (ii) security is not part of developer’s mindset while coding, (iii) developers assume common cases for their code, (iv) security thinking requires cognitive effort, (v) security education helps, but developers can have difficulties correlating a particular learned vulnerability or security information with their current working task, and (vi) priming or explicitly cueing about vulnerabilities on-the-spot is a powerful mechanism to make developers aware about potential vulnerabilities.",
    "author": [
      {
        "family": "Oliveira",
        "given": "Daniela"
      },
      {
        "family": "Rosenthal",
        "given": "Marissa"
      },
      {
        "family": "Morin",
        "given": "Nicole"
      },
      {
        "family": "Yeh",
        "given": "Kuo-Chuan"
      },
      {
        "family": "Cappos",
        "given": "Justin"
      },
      {
        "family": "Zhuang",
        "given": "Yanyan"
      }
    ],
    "collection-title": "ACSAC ’14",
    "container-title": "Proceedings of the 30th annual computer security applications conference",
    "id": "10.1145/2664243.2664254",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "page": "296-305",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "It’s the psychology stupid: How heuristics explain software vulnerabilities and how priming can illuminate developer’s blind spots",
    "title-short": "It’s the psychology stupid",
    "type": "paper-conference"
  },
  {
    "ISBN": "0818673249",
    "abstract": "This paper discusses the initial stages of a long-term case study designed to examine the efforts of an experienced software development team in moving to a more process-driven software development environment. This team has previously produced software that has met functional, schedule, and cost criteria as specified by their customers. The software development manager, as directed by an organizational mandate, has initiated efforts to move this team into a more structured, formalism-based development and testing environment. The Capability Maturity Model (CMM) developed by the Software Engineering Institute (SEI) is being used as the model for this effort. The group dynamic and team development aspects of this effort are being carefully monitored to determine possible sources of resistance to change and to develop intervention \"just-in-time\" training sessions that can address identified problem areas, particularly those that may directly affect productivity, quality, and schedule. This paper discusses initial findings in this area and addresses them within the CMM framework.",
    "author": [
      {
        "family": "McGuire",
        "given": "Eugene G."
      }
    ],
    "collection-title": "HICSS ’96",
    "container-title": "Proceedings of the 29th hawaii international conference on system sciences volume 1: Software technology and architecture",
    "id": "10.5555/795698.798373",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "page": "713",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Initial effects of software process improvement on an experienced software development team",
    "type": "paper-conference"
  },
  {
    "ISBN": "1586036734",
    "abstract": "Software is the essential enabler for the new economy and science. It creates new markets and new directions for a more reliable, flexible, and robust society. It empowers the exploration of our world in ever more depth. However, software often falls short behind our expectations. Current software methodologies, tools, and techniques remain expensive and not yet reliable for a highly changeable and evolutionary market. Many approaches have been proven only as case-by-case oriented methods.This book presents a number of new trends and theories in the direction in which we believe software science and engineering may develop to transform the role of software and science in tomorrow’s information society.This book is an attempt to capture the essence of a new state of art in software science and its supporting technology. The book also aims at identifying the challenges such a technology has to master. It contains papers accepted at the Fifth International Conference on New Trends in software Methodology Tools, and Techniques, V, (SoMeT_06) held in Quebec, Canada, from 25th to 27th October 2006, (url: www.somet.soft.iwate-pu.ac.jp/somet_06). This workshop had brought together researchers and practitioners to share their original research results and practical development experiences in software science, and its related new challenging technology.One of the important issues addressed in this book is software security tools and techniques. Another example we challenge in this conference is, Lyee methodology as a new Japanese emerged software methodology that has been patented in several countries in Europe, Asia, and America. But it is still in its early stage of emerging as a new software style. This book and the series it continues will also contribute to elaborate on such new trends and related academic research studies and development.A major goal of this book was to gather scholars from the international research community to discuss and share research experiences on new software methodologies, and formal techniques. The book also investigated other comparable theories and practices in software science, including emerging technologies, from their computational foundations in terms of models, methodologies, and tools. These are essential for developing a variety of information systems research projects and to assess the practical impact on real-world software problems.For an outline of the past series of related events that contributed to this publication are SoMeT_02 that was held October 3–5, 2002, in Sorbonne, Paris, France. SoMeT_03 was held in Stockholm, Sweden, SoMeT_04 held in Leipzig, Germany, SoMeT_05 held in Tokyo, Japan and this publication covers SoMeT_06; held in Quebec, Canada. These events, also initiate the forthcoming SoMeT_07, to be organized in Rome, Italy in November 2007, (url: www.somet.soft.iwate-pu.ac.jp/somet_07/).This book participates to provide an opportunity for exchanging ideas and experiences in the field of software technology opening up new avenues for software development, methodologies, tools, and techniques, especially, software security and program coding diagnosis and related software maintenance techniques aspects.The Lyee framework for example, captures the essence of the innovations, controversies, challenges and possible solutions of the software industry. This world wide patented software approach was born and enriched from experience, and it is time, and again through SoMeT_06 to try to let it stimulate the academic research on software engineering attempting to close the gap so far existed between theory and practice. We believe that this book creates an opportunity for us in the software science community to think about where we are today and where we are going.The book is a collection of 28 carefully reviewed best-selected papers by the reviewing committee.This book covers the following areas:• Software engineering aspects on software security, programs diagnosis and maintenance• Static and dynamic analysis on Lyee-oriented software performance model• Software security aspects on Java mobile code, and networking• Practical artefact on software security, software validation and diagnosis• Software optimization and formal methods• Requirement engineering and requirement elicitation• Software methodologies and Lyee oriented software techniques• Automatic software generation, reuse, and legacy systems• Software quality and process assessment• Intelligent software systems and evolution• End-user requirement engineering and programming environment• Ontology and philosophical aspects on software engineering• Business software models and other kinds of software application models, based on Lyee theoryAll papers published in this book are carefully reviewed selected by the SOMET international reviewing committee. Each paper has been reviewed by three and up to four reviewers and has been revised based on the review reports. The papers were reviewed on the basis of technical soundness, relevance, originality, significance, and clarity.This book outcome is also a collective effort from all the Lyee International project collaborators and industrial supporters. We also, gratefully thank Iwate Prefectural University, University of Laval, Catena Co., ISD, Ltd, SANGIKYO co., and others for their overwhelming support, on this work. We specially, are thankful to the review committee and others who participated in the review of all submitted papers and thanks also for the hot discussion we have had on the reviews evaluation meetings that selected those contributed in book.This outcome is another milestone in mastering new challenges on software and its new promising technology, within SoMeT’s consecutive events. Also, it gives the reader new insights, inspiration and concrete material to elaborate and study this new technology.Also, at last and not least, we would like to thank and acknowledge the support of the University of Leipzig, Telematik and e-Business group for allowing us to use the Paperdyne System as a conference-supporting tool during all the phases on review transactions.The Editors",
    "container-title": "Proceedings of the 2006 conference on new trends in software methodologies, tools and techniques: Proceedings of the fifth SoMeT_06",
    "id": "10.5555/1565321.1565322",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "page": "i-xiv",
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Front matter",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3442536.3442546",
    "ISBN": "9781450388832",
    "URL": "https://doi.org/10.1145/3442536.3442546",
    "abstract": "The progressive development of information technology has provided multiple learning modes. The rich content and innovative applications available allow pupils to improve their skills through self-regulated learning (SRL), which has become an important education goal. Intelligent robots can be used in a wide range of applications, from programmed movements for learning activities, to the combination of artificial intelligence and sensor technology for human life and education. A robot’s dynamic and interesting interface is more suitable for children’s self-regulated learning. This study used a Zenbo robot as the development tool and Zenbo Scratch platform programming to develop an AI robot math quiz game for primary school students. Two elementary school math teachers, and a parent and a 5th grade primary school student were involved in the development of the game. This study used the parent’s and student’s continuous interaction with the robot to adjust the code and achieve the best human-computer interaction in robotic mathematics problem solving. Moreover, this study developed a companion robot for a math quiz game, which can be used for reviewing what has been learned in class. The robot can be used for self-regulated learning by young children to increase student learning outcome.",
    "author": [
      {
        "family": "Weng",
        "given": "Ting-Sheng"
      },
      {
        "family": "Li",
        "given": "Chien-Kuo"
      },
      {
        "family": "Hsu",
        "given": "Meng-Hui"
      }
    ],
    "collection-title": "AICCC ’20",
    "container-title": "Proceedings of the 2020 3rd artificial intelligence and cloud computing conference",
    "id": "10.1145/3442536.3442546",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "AI robot, Perceived usefulness, Perceived enjoyment, Robotic quiz games, Self-regulated learning",
    "page": "58-62",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Development of robotic quiz games for self-regulated learning of primary school children",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3626202.3637565",
    "ISBN": "9798400704185",
    "URL": "https://doi.org/10.1145/3626202.3637565",
    "abstract": "This paper introduces an FPGA-enabled framework to accelerate the automated design process for Photonic Integrated Circuit (PIC) devices. PICs are foreseen as a foundation for the next-generation semiconductors. However, the complexity of PIC design presents considerable challenges. Machine Learning (ML) techniques have shown promise in the realm of PIC design. The primary hurdle, however, is the extended training duration, solely constrained by the slow electromagnetic (EM) Finite-Difference Time-Domain (FDTD) solver. We propose a fast framework with a dedicated FPGA FDTD accelerator tailor-designed to speed up the PIC simulation. Benchmarking was carried out against commercial tools, with the single-FPGA accelerator outperforming both a multicore CPU and a GPU cluster. We taped out and evaluated the PIC devices designed through the proposed framework, and the experimental outcomes aligned. This demonstrates the full design circle, showcasing that the proposed framework enabled by FPGA breaks the current bottleneck in this domain. This study was conducted entirely on a commercial cloud platform (AWS), leveraging CPUs, FPGAs, and GPUs, with FPGA programming efficiently executed using High-Level Synthesis (HLS) and the Xilinx Runtime (XRT). The FPGA, along with its modern development tools, is seamlessly integrated into a heterogeneous computing platform, showcasing the accessible and practical nature of this approach. Our findings show the exciting possibility that ML-based physical design could be notably sped up enabled by FPGAs in a cloud-hosted heterogeneous cluster as a service.",
    "author": [
      {
        "family": "Xu",
        "given": "Zhenyu"
      },
      {
        "family": "Yu",
        "given": "Miaoxiang"
      },
      {
        "family": "Cai",
        "given": "Jillian"
      },
      {
        "family": "Gafsi",
        "given": "Saddam"
      },
      {
        "family": "Ryckman",
        "given": "Judson Douglas"
      },
      {
        "family": "Yang",
        "given": "Qing"
      },
      {
        "family": "Wei",
        "given": "Tao"
      }
    ],
    "collection-title": "FPGA ’24",
    "container-title": "Proceedings of the 2024 ACM/SIGDA international symposium on field programmable gate arrays",
    "id": "10.1145/3626202.3637565",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "cloud computing, finite difference time domain, fpga, heterogeneous computing, machine learning, photonic integrated circuits",
    "page": "119-129",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An FPGA-enabled framework for rapid automated design of photonic integrated circuits",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ESEM.2017.37",
    "ISBN": "9781509040391",
    "URL": "https://doi.org/10.1109/ESEM.2017.37",
    "abstract": "[Background] A high-functioning team is a decisive factor for a successful software development project. However building such a team is not easy. Among many issues and obstacles encountered by teams, social loafing is a common but difficult one to tackle.[Aim] We intend to construct an approach to effectively prevent social loafing behaviors in software development teams.[Method] We built one social loafing prevention approach based on existing literature and survey instruments. It has been applied in an educational context with 2nd-year computer science students working on software development projects in teams.[Results] The approach starts with increasing team members’ awareness of social loafing. Team Expectations Agreement (TEA) is then used to help the team to write down the terms that explicitly prevent social loafing. During the project, a small survey instrument is used to track regularly if the specified terms are followed by the team members. At the end of a period, the presence/absence of social loafing is assessed by the team using another short survey. How to interpret the results of the surveys is explained as part of the presented approach.[Conclusions] This approach has potential to improve teamwork skills of students, which is not adequately addressed in higher education programs. Meanwhile it can be adapted in professional software development environments to prevent social loafing and improve teamwork. The next step of our study will be using the collected data to evaluate the proposed approach, and formulating a set of recommendations to use the approach in the professional software development context.",
    "author": [
      {
        "family": "Fronza",
        "given": "Ilenia"
      },
      {
        "family": "Wang",
        "given": "Xiaofeng"
      }
    ],
    "collection-title": "ESEM ’17",
    "container-title": "Proceedings of the 11th ACM/IEEE international symposium on empirical software engineering and measurement",
    "id": "10.1109/ESEM.2017.37",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "page": "241-246",
    "publisher": "IEEE Press",
    "publisher-place": "Markham, Ontario, Canada",
    "title": "Towards an approach to prevent social loafing in software development teams",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2839509.2850566",
    "ISBN": "9781450336857",
    "URL": "https://doi.org/10.1145/2839509.2850566",
    "abstract": "The humanoid NAO robot continues to win both hearts and imaginations with its lifelike appearance and behaviors. Its consistent growth in popularity, an increasing wealth of free behaviors, and the intuitive Choregraphe development environment provide educators and developers with exceptional opportunities to motivate interest in STEM disciplines and breach impediments such as perceptions that such technology is simply too hard. In this poster, the authors discuss a variety of experimental uses of the NAO robots for K-5 STEM Outreach. Initial development and demonstrations focused on generating enthusiasm for both robotics and programming. Dancing and exercising behaviors from Notre Dame University’s F.U.N. Lab and Aldebaran Robots easily integrated into voice-controlled Choregraphe demonstration scripts. Faculty and undergraduate students directed this enthusiasm to motivate engagement in Hour of Code programming activities. The team also utilized the NAO robots in small group settings within a K-5 Response To Intervention (RTI) program where demonstrations were followed by having the children interactively experiment with the robots stimulating imagination, creativity, curiosity, and problem solving skills as well as confidence and self-esteem. Next the RTI children actually programmed the robots using a story-based methodology and the powerful while intuitive building block programming constructs of Choregraphe. The team’s on-going development efforts focus on expanding the repertoire of available behaviors to include interactive math games and foreign language educational dialogs. Results from use of these new behaviors will be presented at the SIGCSE Symposium. The team is also working to measure attitudinal, conceptual understanding, and math and language skills improvements.",
    "author": [
      {
        "family": "Hadfield",
        "given": "Steven M."
      },
      {
        "family": "Coulston",
        "given": "Christopher S."
      },
      {
        "family": "Hadfield",
        "given": "Marissa G."
      },
      {
        "family": "Warner",
        "given": "Lillian B."
      }
    ],
    "collection-title": "SIGCSE ’16",
    "container-title": "Proceedings of the 47th ACM technical symposium on computing science education",
    "id": "10.1145/2839509.2850566",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "k-5, nao, outreach, robots, rti, stem",
    "page": "697",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Adventures in k-5 STEM outreach using the NAO robot (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ISISE.2009.53",
    "ISBN": "9780769539911",
    "URL": "https://doi.org/10.1109/ISISE.2009.53",
    "abstract": "Focusing on recognizing some typical gestures based on 3-axis MEMS accelerometer to interact with an application of human-machine interactive game, the hand gesture problem is analyzed firstly, then theory basis of HMM is introduced. In order to obtain training gesture data for HMM, and also to provide a hardware basis for gesture recognition, a low cost data acquisition system hardware is researched and designed. The system can get the acceleration data of user’s gesture and transmit them wirelessly to a personal computer. In the hand gesture recognition approach, k-mean algorithms are applied to cluster and abstract the vector data from sensor. And then the quantized vectors are put into a hidden Markov model to learn and recognize user’s gestures. Finally the gesture recognition library is implemented in C# development environment, and is utilized in a human-machine interactive game application. The results show that the typical gesture emerging in the game can be identified in a high rate, and the user can experience more interest and interaction.",
    "author": [
      {
        "family": "Rao",
        "given": "Jinjun"
      },
      {
        "family": "Gao",
        "given": "Tongyue"
      },
      {
        "family": "Gong",
        "given": "Zhenbang"
      },
      {
        "family": "Jiang",
        "given": "Zhen"
      }
    ],
    "collection-title": "ISISE ’09",
    "container-title": "Proceedings of the 2009 second international symposium on information science and engineering",
    "id": "10.1109/ISISE.2009.53",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "Hidden markov model, accelerometer, gesture recognition, virtual reality",
    "page": "433-438",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Low cost hand gesture learning and recognition system based on hidden markov model",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3512290.3528700",
    "ISBN": "9781450392372",
    "URL": "https://doi.org/10.1145/3512290.3528700",
    "abstract": "GitHub Copilot, an extension for the Visual Studio Code development environment powered by the large-scale language model Codex, makes automatic program synthesis available for software developers. This model has been extensively studied in the field of deep learning, however, a comparison to genetic programming, which is also known for its performance in automatic program synthesis, has not yet been carried out. In this paper, we evaluate GitHub Copilot on standard program synthesis benchmark problems and compare the achieved results with those from the genetic programming literature. In addition, we discuss the performance of both approaches. We find that the performance of the two approaches on the benchmark problems is quite similar, however, in comparison to GitHub Copilot, the program synthesis approaches based on genetic programming are not yet mature enough to support programmers in practical software development. Genetic programming usually needs a huge amount of expensive hand-labeled training cases and takes too much time to generate solutions. Furthermore, source code generated by genetic programming approaches is often bloated and difficult to understand. For future work on program synthesis with genetic programming, we suggest researchers to focus on improving the execution time, readability, and usability.",
    "author": [
      {
        "family": "Sobania",
        "given": "Dominik"
      },
      {
        "family": "Briesch",
        "given": "Martin"
      },
      {
        "family": "Rothlauf",
        "given": "Franz"
      }
    ],
    "collection-title": "GECCO ’22",
    "container-title": "Proceedings of the genetic and evolutionary computation conference",
    "id": "10.1145/3512290.3528700",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "GitHub copilot, codex, genetic programming, large-scale language models, program synthesis, software engineering",
    "page": "1019-1027",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Choose your programming copilot: A comparison of the program synthesis performance of github copilot and genetic programming",
    "title-short": "Choose your programming copilot",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/504450.504460",
    "ISBN": "9781450373395",
    "URL": "https://doi.org/10.1145/504450.504460",
    "abstract": "The CLEO project [2], centered at Cornell University, is a large-scale high energy physics project. The goals of the project arise from an esoteric question—why is there apparently so little antimatter in the universe?—and the computational problems that arise in trying to answer this question are quite challenging.To answer this question, the CESR storage ring at Cornell is used to generate a beam of electrons directed at an equally strong beam of positrons. These two beams meet inside a detector that is embedded in a magnetic field and is equipped with sensors. The collisions of electrons and positrons generate several secondary subatomic particles. Each collision is called an event and is sensed by detecting charged particles (via the ionization they produce in a drift chamber) and neutral particles (in the case of photons, via their deposition of energy in a crystal calorimeter), as well as by other specialized detector elements. Most events are ignored, but some are recorded in what is called raw data (typically 8Kbytes per event). Offline, a second program called pass2 computes, for each event, the physical properties of the particles, such as their momenta, masses, and charges. This compute-bound program produces a new set of records describing the events (now typically 20Kbytes per event). Finally, a third program reads these events, and produces a lossily-compressed version of only certain frequently-accessed fields, written in what is called roar format (typically 2Kbytes per event).The physicists analyze this data with programs that are, for the most part, embarrassingly parallel and I/O limited. Such programs typically compute a result based on a projection of a selection of a large number of events, where the result is insensitive to the order in which the events are processed. For example, a program may construct histograms, or compute statistics, or cull the raw data for physical inspection. The projection is either the complete pass2 record or (much more often) the smaller roar record, and the selection is done in an ad-hoc manner by the program itself.Other programs are run as well. For example, a Monte Carlo simulation of the experiment is also run (called monte carlo) in order to correct the data for detector acceptance and inefficiencies, as well as testing aspects of the model used to interpret the data. This program is compute bound. Another important example is called recompress. Roughly every two years, improvements in detector calibration and reconstruction algorithms make it worthwhile to recompute more accurate pass2 data (and hence, more accurate roar data) from all of the raw data. This program is compute-bound (it currently requires 24 200-MIP workstations running flat out for three months) and so must be carefully worked into the schedule so that it does not seriously impact the ongoing operations.Making this more concrete, the current experiment generates approximately 1 terabyte of event data a year. Only recent roar data can be kept on disk; all other data must reside on tape. The data processing demands consume approximately 12,000 SPECint92 cycles a year. Improvements in the performance of CESR and the sensitivity of the detector will cause both of these values to go up by a factor of ten in the next few years, which will correspondingly increase the storage and computational needs by a factor of ten.The CLEO project prides itself on being able to do big science on a tight budget, and so the programming environment that the CLEO project provides for researchers is innovative but somewhat primitive. Jobs that access the entire data set can take days to complete. To circumvent limited access to tape, the network, or compute resources close to the central disk, physicists often do preliminary selections and projections (called skims) to create private disk data sets of events for further local analysis. Limited resources usually exact a high human price for resource and job management and ironically, can sometimes lead to inefficiencies. Given the increase in data storage, data retrieval, and computational needs, it has become clear that the CLEO physicists require a better distributed environment in which to do their work.Hence, an NSF-funded National Challenge project was started with participants from both high energy physics, distributed computing, and data storage, in order to provide a better environment for the CLEO experiment. The goals of this project, called NILE [7], are:Finally, the CLEO necessity of building on a budget carries over to NILE. There are some more expensive resources, such as ATM switches and tape silos, that it will be necessary to use. However, as far as possible we are using commodity equipment, and free or inexpensive software whenever possible. For example, one of our principal development platforms is Pentium-based PCs, interconnected with 100 Mbps Ethernet, running Linux and the GNU suite of tools.",
    "author": [
      {
        "family": "Marzullo",
        "given": "Keith"
      },
      {
        "family": "Ogg",
        "given": "Michael"
      },
      {
        "family": "Ricciardi",
        "given": "Aleta"
      },
      {
        "family": "Amoroso",
        "given": "Alessandro"
      },
      {
        "family": "Calkins",
        "given": "F. Andrew"
      },
      {
        "family": "Rothfus",
        "given": "Eric"
      }
    ],
    "collection-title": "EW 7",
    "container-title": "Proceedings of the 7th workshop on ACM SIGOPS european workshop: Systems support for worldwide applications",
    "id": "10.1145/504450.504460",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "page": "49-54",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "NILE: Wide-area computing for high energy physics",
    "title-short": "NILE",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3287324.3293709",
    "ISBN": "9781450358903",
    "URL": "https://doi.org/10.1145/3287324.3293709",
    "abstract": "This work presents a new paradigm for collaborative project-based computer science education called Online Mob Programming (OMP). OMP is adapted from the industrial practice of Mob Programming, where groups of developers work on the same problem, at the same time, in the same place. OMP was designed and implemented as a technique where a group of 4-6 students collaborate online through a structured process for solving programming tasks. In OMP, students rotate through clearly defined roles to collectively contribute towards a solution to a programming challenge. These roles require students to brainstorm potential solutions, decide on a path forward, and implement the correct course of action respectively. OMP was investigated in the context of a 6-week free online course on Cloud Computing. During the course, students participated in four intelligent conversational agent-coordinated OMP sessions. By instrumenting the online development environment, all student code revisions and chat logs were collected in addition to qualitative data from questionnaires. Analyses show evidence of success in terms of students following the structure of OMP and further investigations into differences in mob behavior based on the size, and problem outcome provide pedagogically valuable insights and a path toward building OMP into the computer science education curriculum.",
    "author": [
      {
        "family": "Sankaranarayanan",
        "given": "Sreecharan"
      }
    ],
    "collection-title": "SIGCSE ’19",
    "container-title": "Proceedings of the 50th ACM technical symposium on computer science education",
    "id": "10.1145/3287324.3293709",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "collaborative learning, computer-supported collaborative learning, mob programming, online mob programming, project-based learning",
    "page": "1296",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Online mob programming: Effective collaborative project-based learning",
    "title-short": "Online mob programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "9780549622680",
    "abstract": "Multi-cores are already available on today’s personal computers, and parallel programming is the key to utilizing their scalable performance. However, writing a fast and correct parallel program is still difficult because multiple threads run on the shared data; thus, programmers should synchronize them properly. To address this difficulty, Transactional Memory (TM) has been proposed as an alternative to conventional lock-based synchronization. TM can be implemented in a variety of ways; software TM (STM) is attractive because it runs on off-the-shelf hardware without modification, whereas hardware TM (HTM) performs much better and provides correct and predictable results. This research is built upon the Transactional Coherence and Consistency architecture (TCC), an HTM architecture developed at Stanford University. Moreover, unlike other proposals, TCC uses TM mechanisms to replace conventional MESI (Modified-Exclusive-Shared-Invalid) protocol, having all user code executes within transactions—i.e. all transactions, all the time. To develop parallel applications that fully utilize TM’s capability, a complete software development environment is necessary. The software environment includes programming languages, an operating system, and performance and functionality debugging tools. This thesis presents a software development environment, referred to as ATLAS; it addresses the challenges of the latter two issues, the operating system and the productivity tools, on the full-system prototype of the TCC architecture. Running an operating system on an HTM system faces many challenges: it requires a communication mechanism between the user thread and the operating system that does not compromise the atomicity and isolation of transactions; It also requires a mechanism to handle irrevocable operations, such as I/O, and external actions, such as interrupts. ATLAS addresses these issues by dedicating a CPU to run the operating system (OS CPU). The remaining CPUs run a proxy kernel that handles the interactions of the applications with the operating system using a separate communication channel. This thesis describes the implementation of OS functionality using this approach and demonstrates that it scales efficiently to multi-core systems with 32 processors. ATLAS builds upon TM resources to provide three functional and performance debugging tools for parallel programming. The first tool, ReplayT, provides the deterministic replay of multithreaded applications; it tracks execution at the granularity of transactions to reduce both the time and space overhead of logging thread interactions. The second tool, AVIO-TM, detects atomicity violation bugs in transactional memory programs. It extends, simplifies, and accelerates the proposed AVIO mechanism. The third tool, TAPE, is a light-weight runtime performance bottleneck monitor that identifies the performance bottlenecks of TM applications with the detailed information that is needed to optimize the applications. TAPE builds upon TM hardware that continuously monitors all memory accesses in the user code.",
    "author": [
      {
        "family": "Wee",
        "given": "Sewook"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1467771",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "note": "AAI3313683",
    "publisher": "Stanford University",
    "publisher-place": "Stanford, CA, USA",
    "title": "Atlas: Software development environment for hardware transactional memory",
    "title-short": "Atlas",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/2462476.2465611",
    "ISBN": "9781450320788",
    "URL": "https://doi.org/10.1145/2462476.2465611",
    "abstract": "In this poster we present a CS curriculum aimed at \"middle-years\" students. In the U.S., this corresponds roughly to middle school and early high-school, i.e., students aged 11-15. This MyCS curriculum provides a hands-on introduction to computer science through six distinct modules. Three programming modules use the Scratch environment to build computational sophistication and procedural intuition within an inviting development environment. Alternating with Scratch are three problem-solving modules whose activities deepen awareness and facility with computation through novel and adapted exercises. By carefully integrating novel activities with a targeted subset of the excellent resources from ECS, AP CS Principles, webdev tools, and CS unplugged, MyCS enables middle-school teachers without prior CS training to offer an 18-week course after only one week of summertime professional development. More than 25 classrooms and 900 students have participated in MyCS’s pilot years within the Pomona, CA and Lihue, HI school districts. 2013-15 will see an expansion of its workshops, academic-year classes, and program evaluation. This poster shares our development and deployment of MyCS to date, and it invites feedback from the experiences of other institutions, worldwide, in their efforts to foster adolescents’ computational identities.",
    "author": [
      {
        "family": "Dodds",
        "given": "Zachary"
      },
      {
        "family": "Erlinger",
        "given": "Michael"
      }
    ],
    "collection-title": "ITiCSE ’13",
    "container-title": "Proceedings of the 18th ACM conference on innovation and technology in computer science education",
    "id": "10.1145/2462476.2465611",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "keyword": "middle-school computer science",
    "page": "330",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "MyCS: Building a middle-years CS curriculum",
    "title-short": "MyCS",
    "type": "paper-conference"
  },
  {
    "ISBN": "9789606766428",
    "abstract": "In the recent years, software development has become larger in scale and more complicated. Furthermore, development with faster delivery and lower cost is required, thus the software development environment is becoming more and more critical. Therefore, companies are seeking high potential students in universities who have a practical sense. The information science and engineering department of Shibaura Institute of Technology provides group exercise classes that adopt a more practical approach to software development such that students can obtain the knowledge and skills necessary for software development (strictly it is a team exercise in the sense that each member of the group shares the tasks for software development). However, as the class hours assigned for learning software engineering are not sufficient, EtUDE (Environment for Ultimate software Development Exercise), the support system that learners can collectively practice at any time anywhere was developed, and introduced to the exercise classes. However, as the skills of software development differ from one student to another, the problem that some teams are not able to accomplish the assignment by the deadline often occurs. Therefore, the authors developed EtUDE/GO, which automatically generates the best plan for team formation. Optimizing team formation with this system, we can solve the problem attributable to difference in students’ software development skills. This paper discusses the system overview of EtUDE/GO as well as the consequence of applying the system.",
    "author": [
      {
        "family": "Hashiura",
        "given": "Hiroaki"
      },
      {
        "family": "Kuwabara",
        "given": "Toru"
      },
      {
        "family": "Qiu",
        "given": "Yumei"
      },
      {
        "family": "Yamashita",
        "given": "Koutarou"
      },
      {
        "family": "Ishikawa",
        "given": "Tatsuya"
      },
      {
        "family": "Shirakawa",
        "given": "Kiyomi"
      },
      {
        "family": "Komiya",
        "given": "Seiichi"
      }
    ],
    "collection-title": "SEPADS’08",
    "container-title": "Proceedings of the 7th WSEAS international conference on software engineering, parallel and distributed systems",
    "id": "10.5555/1416502.1416531",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "exercise for software development, exercises in units of groups, genetic algorithm, optimizing project team formation, web application system",
    "page": "149-157",
    "publisher": "World Scientific; Engineering Academy; Society (WSEAS)",
    "publisher-place": "Stevens Point, Wisconsin, USA",
    "title": "A system for supporting group exercise in software development with facilities to create an optimal plan of student grouping and team formation of each group",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3456887.3457496",
    "ISBN": "9781450389969",
    "URL": "https://doi.org/10.1145/3456887.3457496",
    "abstract": "Distance education based on computer has become the main part of modern education in our country, which has contributed to the popularization of higher education and the improvement of teaching quality. However, at the same time, there are still many deficiencies in the opening of the existing computer education system courseware. Therefore, this paper puts forward a research on the design of integrated courseware development environment for computer education based on online evaluation system. This paper makes a detailed analysis of the classification and selection of computer education courseware, and points out the main problems existing in the existing courseware mode. In view of these shortcomings, according to the characteristics of computer education courseware, this paper puts forward the optimization design of online evaluation system. In this paper, the development ideas and objectives of the integrated courseware system are further studied. SCORM content aggregation model is used to effectively manage the micro teaching units in the courseware. Especially after the establishment of the classroom management module, the computer distance education becomes more flexible. In the application of courseware, it can be combined according to the needs, which greatly expands the computer education department the practicability of the system. The analysis shows that the computer integrated courseware management scheme based on online evaluation system not only improves the courseware editing and demonstration ability of the computer education system, but also greatly improves the comprehensive performance of the system. The teaching effect can be evaluated in real time, so that the students’ learning efficiency is higher.",
    "author": [
      {
        "family": "Zhang",
        "given": "Rongfeng"
      }
    ],
    "collection-title": "CIPAE 2021",
    "container-title": "2021 2nd international conference on computers, information processing and advanced education",
    "id": "10.1145/3456887.3457496",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Computer Courseware, Computer Networks, Distance Education, Online Evaluation System",
    "page": "1231-1234",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design of integrated courseware development environment for computer education based on online evaluation system",
    "type": "paper-conference"
  },
  {
    "ISBN": "1847196063",
    "abstract": "Capture, automate, and reuse your business processes in a clear English language that your computer can understand. An easy-to-understand JBoss Drools business rules tutorial for non-programmers Automate your business processes such as order processing, supply management, staff activity, and more Prototype, test, and implement workflows by themselves using business rules that are simple statements written in an English-like language Discover advanced features of Drools to write clear business rules that execute quickly For confident users of Excel or other business software, this book is everything you need to learn JBoss Drools business rules and successfully automate your business. In Detail In business, a lot of actions are trigged by rules: \"Order more ice cream when the stock is below 100 units and temperature is above 25 C\", \"Approve credit card application when the credit background check is OK, past relationship with the customer is profitable, and identity is confirmed\", and so on. Traditional computer programming languages make it difficult to translate this \"natural language\" into a software program. But JBoss Rules (also known as Drools) enables anybody with basic IT skills and an understanding of the business to turn statements such as these into running computer code. This book will teach you to specify business rules using JBoss Drools, and then put them into action in your business. You will be able to create rules that trigger actions and decisions, based on data that comes from a variety of sources and departments right across your business. Regardless of the size of your business, you can make your processes more effective and manageable by adopting JBoss Rules. Banks use business rules to process your mortgage (home loan) application, and to manage the process through each step (initial indication of amount available, actual application, approval of the total according to strict rules regarding the amount of income, house value, previous repayment record, swapping title deeds, and so on). Countries such as Australia apply business rules to visa applications (when you want to go and live there)–you get points for your age, whether you have a degree or masters, your occupation, any family members in the country, and a variety of other factors. Supermarkets apply business rules to what stock they should have on their shelves and where–this depends upon analyzing factors such as how much shelf space there is, what location the supermarket is in, what people have bought the week before, the weather forecast for next week (for example, ice cream in hot weather), and what discounts the manufacturers are giving. This book shows how you can use similar rules and processes in your business or organization. It begins with a detailed, clear explanation of business rules and how JBoss Rules supports them. You will then see how to install and get to grips with the essential software required to use JBoss Rules. Once you have mastered the basic tools, you will learn how to build practical and effective of the business rule systems. The book provides clear explanations of business rule jargon. You will learn how to work with Decision Tables, Domain-Specifi c Languages (DSL)s, the Guvnor and JBoss Integrated Development Environment (IDE), workflow and much more. By the end of the book you will know exactly how to harness the power of JBoss Rules in your business. What you will learn from this book? Understand the basics of business rules and JBoss rules with minimal effortInstall the required software easily and learn to use the Guvnor, which is a user-friendly web editor that’s also powerful enough to test our rules as we write themLearn to write sophisticated rules and import the fact model into the Guvnor and then build a guided rule around it, which makes your web pages a lot clearerGain complete knowledge of what we can do with the Guvnor rule editor, and then use the JBoss IDE as an even more powerful way of writing rules, and automate processes for discounts, orders, sales, and moreKnow the structure of the rule file through the example of a shipping schedule, which will help you with your own shipping scheduleTest your rules not only in the Guvnor, but also using FIT for rule testing against requirements documents; run unit tests using JUnit for error-free rules and interruption-free servicesSpecifically, non-developers can work with Excel spreadsheets as a fact model to develop business processes without learning any other new technologyWork with DSLs (Domain-Specific Languages) and rule flow to make writing rules easy; which makes staff training quicker and your working life easierDeploy your business rules to the real world, which completes your project successfully, and combine this into a web project using the framework of your choice to provide better servicesBenefit from concepts such as truth maintenance, conflict resolution, pattern matching rules agenda, and the Rete algorithm to provide advanced and faster business systems so that staff efficiency is maximized Approach This book takes a practical approach, with step-by-step instructions. It doesn’t hesitate to talk about the technologies, but takes time to explain them (to an Excel power-user level). There is a good use of graphics and code where necessary. Who this book is written for? If you are a business analyst - somebody involved with enterprise IT but at a high level, understanding problems and planning solutions, rather than coding in-depth implementations - then this book is for you. If you are a business user who needs to write rules, or a technical person who needs to support rules, this book is for you. If you are looking for an introduction to rule engine technology, this book will satisfy your needs. If you are a business user and want to write rules using Guvnor/JBoss IDE, this book will be suitable for you. This book will also suit your need if you are a business user and want to understand what Drools can do and how it works, but would rather leave the implementation to a developer.",
    "author": [
      {
        "family": "Browne",
        "given": "Paul"
      }
    ],
    "id": "10.5555/1611309",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "JBoss drools business rules",
    "type": "book"
  },
  {
    "abstract": "The Dialogue Management Project at Virginia Tech is studying the poorly understood problem of human-computer dialogue development. This problem often leads to low usability in human-computer dialogues. The Dialogue Management Project approaches solutions to low usability in interfaces by addressing human-computer dialogue development as an integral and equal part of the total system development process. This project consists of two rather distinct, but dependent, parts. One is development of concepts for dialogue management, and the other is implementation of a dialogue management system (DMS) to evaluate these concepts. The goal of this paper is to describe our approach to the development of two of these conceptual aspects and how we oriented those toward the needs of practical implementation. The two conceptual aspects are (a) a structural, descriptive model of human-computer interaction, and (b) Techniques for representing both the behavioral (end-user”s) view and the constructional (developer”s) view of dialogue. The approach to their development was a technology transfer process that was part of a two-year university/industry research liaison between the Dialogue Management Project and IBM Federal Systems Division (FSD), now called Systems Integration Division. Part of this liaison was aimed at moving our research ideas and results into a real-world dialogue development environment. Following presentation of the technical problems and solutions, the paper concludes with a discussion of results of our liaison and by raising and addressing some questions of mutual interest that arose during our cooperative interaction.",
    "author": [
      {
        "family": "Hartson",
        "given": "H. R"
      },
      {
        "family": "Hix",
        "given": "Deborah"
      },
      {
        "family": "Kraly",
        "given": "Thomas M."
      }
    ],
    "id": "10.5555/903388",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "publisher": "Virginia Polytechnic Institute &amp; State University",
    "publisher-place": "USA",
    "title": "Developing human-computer interface models and representation techniques(dialogue management as an integral part of software engineering)",
    "type": "report"
  },
  {
    "abstract": "The development of computer based instruction (CBI) is a costly labor intensive endeavor which is considered a serious obstacle to the widespread use of CBI. Transaction shells, a CBI authoring and delivery tool, represents one attempt at finding a solution to this problem. The specific purposes of this study were to investigate: (a) The efficacy of transaction shells as an authoring environment and instructional paradigm for an instructional developer, (b) the efficacy of a transaction shell based instructional product for an instructor as a user of the development tool or owner of the instructional lesson, and (c) the efficacy of a transaction shell based instructional lesson for the student or user of that lesson. The samples for this study involved a graduate student in Instructional Technology as an instructional developer, an instructor in the School of Engineering, and users of CBI drawn from the graduate population in Instructional Technology all at Wayne State University in Detroit, Michigan.The results of the study include: (1) Transaction shells as represented in this version of ID Expert contain enactment problems that need to be addressed. (2) The transaction shell authoring approach is different from other authoring programs and the commercial version of this software should be provided with clear and concise directions. (3) The educational environment will be slow in feeling the impact of this authoring tool due to hardware requirements. (4) Transaction shells provide an effective and efficient instructional development review process. (5) The transaction shell automated instructional delivery paradigm allows the developer to concentrate on the instructional content and not the instruction. (6) Transaction shells can be used as a presentation program. (7) Transaction shells appear to be efficient and effective for instructional delivery. (8) The use of multimedia resources within transaction shells should be determined by motivational concerns identified with specific audiences or where the instructional outcomes are not being accomplished.Recommendations were made for additional research that would build on the findings of this study and implications were made for the field of instructional design and automated authoring tools.",
    "author": [
      {
        "family": "Bevill",
        "given": "Douglas A."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/921884",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "note": "AAI9530525",
    "publisher": "Wayne State University",
    "publisher-place": "USA",
    "title": "An investigation into the efficacy of transaction shells as a computer-based instructional design and delivery tool for an instructional designer, instructor, and end user",
    "type": "thesis"
  },
  {
    "ISBN": "0591326434",
    "abstract": "Process-centered environments (PCEs) are viewed by many as a way around the \"software crisis\"; they formalize development methodologies in enactable process modeling languages (PMLs) that can be \"executed\" in order to provide various assistance modes to developers. These include, e.g. maintaining consistency, monitoring compliance with and/or actually enforcing the process, automation of routine activities, and guiding developers through the process. Research has produced a variety of PCEs, each with its own PML, providing one or more assistance modes. However, no consensus has formed on such issues as the appropriate set of assistance modes, or the \"best\" software process formalism; we doubt that there is a single \"best\" PML. Thus, for a development organization wishing to move to a process-based environment, there is a problem of competing formalisms–choosing an appropriate PCE, with its associated PML.Problems can also arise in migrating to a PCE. Integrating the organization’s development tools into the PCE is generally simple, but the process also must be \"coded up\" in the PML, and the existing code \"immigrated\" into the PCE. This can present technical difficulties, but there are also serious organizational problems, notably training the developers, managers, etc., who know only the old legacy environment, to use the new PCE.We address both problems: Competing formalisms, by translating high-level PMLs into a rule-based \"process assembly language\" (PAL), and legacy environments, by means of process servers that provide process enactment facilities to an existing environment, rather than taking over top-level control, as PCEs generally do. We present A scMBER, a process engine with extensible PAL syntax and semantics tailorable to any desired assistance modes, as a kernel for process servers supporting a wide range of PMLs. New process enactment directives may be added to the syntax of the PAL, adding new assistance modes to A scMBER. The process engine is parameterized by callbacks to mediator code in order to implement any new directives and to modify the enactment behavior. A scMBER’s mediators also facilitate integration with a wide variety of environment architectures.",
    "author": [
      {
        "family": "Popovich",
        "given": "Steven S."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/924952",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "note": "AAI9723838",
    "publisher": "Columbia University",
    "publisher-place": "USA",
    "title": "An architecture for extensible workflow process servers",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3304221.3319751",
    "ISBN": "9781450368957",
    "URL": "https://doi.org/10.1145/3304221.3319751",
    "abstract": "Understanding student thinking and identifying student misconceptions are important precursors to developing high quality pedagogical materials and approaches. Prior work has used conceptual assessment surveys and task-based interviews to pursue this knowledge, typically having students evaluate existing code or predict or explain code behavior. However, features of student thinking captured under these conditions may differ from features of student thinking that occurs \"in the wild.\" We present the results of a study conducted with 10 introductory CS students at a large, engineering-focused US university. In this work, students were asked to \"Please, think aloud\" as they interacted in a development environment, attempting to reverse engineer a solution to a defined task based on a provided executable. We captured and analyzed video recordings of the screen and audio recordings of their utterances to characterize their actions, current task, the relevant CS concept involved, current problem-solving phase, and expressed level of certainty. We also took note of the nature of their uncertainties and if and how these uncertainties were resolved. We found that students showed uncertainty regardless of success at task completion. Students who were successful at the task engaged in live experimentation to address these uncertainties in their thinking and coding. However, the ability to produce a program that behaved correctly did not guarantee that the students fully grasped the underlying concepts: some students submitted erroneous code that coincidentally worked, while expressing doubts about the correctness of their implementation.",
    "author": [
      {
        "family": "Kennedy",
        "given": "Cazembe"
      },
      {
        "family": "Kraemer",
        "given": "Eileen T."
      }
    ],
    "collection-title": "ITiCSE ’19",
    "container-title": "Proceedings of the 2019 ACM conference on innovation and technology in computer science education",
    "id": "10.1145/3304221.3319751",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "computing education, cs1, cs2, introductory programming, misconceptions, pedagogical content knowledge, qualitative analysis",
    "page": "224-230",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Qualitative observations of student reasoning: Coding in the wild",
    "title-short": "Qualitative observations of student reasoning",
    "type": "paper-conference"
  },
  {
    "ISSN": "0741-2223",
    "abstract": "Autonomous robotics projects encompass the rich nature of integrated systems that includes mechanical, electrical, and computational software components. The availability of smaller and cheaper hardware components has helped make possible a new dimension in operational autonomy. This paper describes a mobile robotic platform consisting of several integrated modules including a laptop computer that serves as the main control module, microcontroller-based motion control module, a vision processing module, a sensor interface module, and a navigation module. The laptop computer module contains the main software development environment with a user interface to access and control all other modules. Programming language independence is achieved by using standard input/output computer interfaces including RS-232 serial port, USB, networking, audio input and output, and parallel port devices. However, with the same hardware technology available to all, the distinguishing factor in most cases for intelligent systems becomes the software design. The software for autonomous robots must intelligently control the hardware so that it functions in unstructured, dynamic, and uncertain environments while maintaining an autonomous adaptability. This paper describes how we introduced fuzzy logic control to one robot platform in order to solve the 2003 Intelligent Ground Vehicle Competition (IGVC) Autonomous Challenge problem. This paper also describes the introduction of hybrid software design that utilizes Fuzzy Evolutionary Artificial Neural Network techniques. In this design, rather than using a control program that is directly coded, the robot’s artificial neural net is first trained with a training data set using evolutionary optimization techniques to adjust weight values between neurons. The trained neural network with a weight average defuzzification method was able to make correct decisions to unseen vision patterns for the IGVC Autonomous Challenge. A comparison of the Lawrence Technological University robot designs and the design of the other competing schools shows that our platforms were the most affordable robot systems to use as tools for computer science and engineering education. © 2004 Wiley Periodicals, Inc.",
    "author": [
      {
        "family": "Tedder",
        "given": "Maurice"
      },
      {
        "family": "Chamulak",
        "given": "David"
      },
      {
        "family": "Chen",
        "given": "Li-Ping"
      },
      {
        "family": "Nair",
        "given": "Santosh"
      },
      {
        "family": "Shvartsman",
        "given": "Andrey"
      },
      {
        "family": "Tseng",
        "given": "I."
      },
      {
        "family": "Chung",
        "given": "Chan-Jin"
      }
    ],
    "container-title": "J. Robot. Syst.",
    "id": "10.5555/1060033.1060035",
    "issue": "8",
    "issued": {
      "date-parts": [
        [
          2004,
          8
        ]
      ]
    },
    "page": "419-428",
    "publisher": "John Wiley; Sons Ltd.",
    "publisher-place": "GBR",
    "title": "An affordable modular mobile robotic platform with fuzzy logic control and evolutionary artificial neural networks",
    "type": "article-journal",
    "volume": "21"
  },
  {
    "DOI": "10.1145/3287324.3293750",
    "ISBN": "9781450358903",
    "URL": "https://doi.org/10.1145/3287324.3293750",
    "abstract": "Pair-programming is an Agile technique in Extreme Programming (XP) where traditionally two programmers need to be collocated and work together at one workstation. Previous research has shown that pair-programming is very beneficial in software engineering education. However, learning and practicing pair-programming are mostly limited in a class where students can only learn to collaboratively program with another student in controlled or laboratory settings. Although nowadays there exist some collaborative tools, such as CodePilot, Google Colaboratory and Git, they are not specifically pair-programming-oriented. This impedes a pairing’s ability to discuss effective strategies in problem solving, to form productive or mutually learning pairs, and to predict pair compatibility. To encourage students in out-class practice of pair-programming, we present a demonstration of a novel web-based software development environment, called CodeBuddy, for remote pair-programming. CodeBuddy provides instructors and students with several features for managing laboratory classes and practicing pair-programming. Examples of CodeBuddy’s features include: coding screen mirroring between a pair, output terminal to show compiled results, face-to-face like communication channels (i.e., video calling and instant text messaging), automatic and manual role switching, code quality analysis for monitoring coding students’ progress and recommending a pair with targeted pairing goals, implicit code reviews using face detection for tracking a reviewer’s engagement, line-by-line code commenting, etc. The demonstration consists of a walkthrough of two use-case scenarios: an instructor assigns a problem-solving task and two students remotely work together in a pair using CodeBuddy on two different workstations to solve it.",
    "author": [
      {
        "family": "Leelanupab",
        "given": "Teerapong"
      },
      {
        "family": "Meephruek",
        "given": "Tiwipab"
      }
    ],
    "collection-title": "SIGCSE ’19",
    "container-title": "Proceedings of the 50th ACM technical symposium on computer science education",
    "id": "10.1145/3287324.3293750",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "agile software development, pair programming, remote collaboration and learning, software engineering",
    "page": "1290",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CodeBuddy (collaborative software development environment): In- and out-class practice for remote pair-programming with monitoring coding students’ progress",
    "title-short": "CodeBuddy (collaborative software development environment)",
    "type": "paper-conference"
  },
  {
    "ISBN": "1581137419",
    "abstract": "On behalf of the organizing committee, we welcome you to the First Conference on Computing Frontiers (CF’04). We selected Ischia as the conference site, for we felt it would create a pleasant forum for the meeting. We also wished to initiate a tradition of a comfortable and relaxing atmosphere which would be conducive to many informal discussions.The conference was created to allow the exploration of those technologies at the very edge of computing which would have the potential to substantially improve existing art. To this end, we have considered papers on theory, methods, technologies, and implementations concerned with innovations in computing paradigms, computational models, architectural paradigms, computer architectures, development environments, compilers, and operating environments.The organizing committee has strived to put together a stimulating scientific program consisting of regular papers and invited sessions on some promising and established areas of research. The technical program contains 36 papers, selected out of 57 submitted manuscripts through a careful peer review process and grouped in 13 sessions, spanning from architectures to processors, from networking to clusters, and from computational models to applications. The keynote address (\"Quantum Parallelism and the Exact Simulation of Physical Systems\") by Professor Dan Marinescu (University of Central Florida) will tackle quantum computing, one of the most promising technologies to break the performance barriers of conventional systems. Three special sessions have also been organized on \"NOMADS (Networks of Mobile Adaptive Dependable Systems)\" by Professor Miroslaw Malek (Humboldt-Universität zu Berlin), \"Memory Wall\" by Professor Mateo Valero (Universidad Politecnica de Catalunya), and \"Reconfigurable Computing\" by Professor Jürgen Becker (Universität Karlsruhe (TH)).We must emphasize that several people, all volunteers, have worked to make this Computing Frontiers conference a success. We would like to thank in particular all the members of the steering and program committees, the special sessions chairs, the publicity and publication chairs, the treasurer, the local arrangements chair, and all the authors and reviewers.Welcome to Ischia and to CF’04. We trust that you will enjoy the scientific as well the social program of the conference. Also, we hope you will consider submitting or attending Computing Frontiers next year and will tell all your colleagues what an informative and productive meeting this has been.",
    "id": "10.1145/977091",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CF ’04: Proceedings of the 1st conference on computing frontiers",
    "title-short": "CF ’04",
    "type": "book"
  },
  {
    "ISBN": "9789604742028",
    "abstract": "Language is the fundamental tool for the development of thought. It is therefore an essential tool for all the inquiry aspects in the sciences (identifying relationships between pieces of information, identifying investigation questions, formulating and verifying hypotheses, making inferences) and in the trains of thoughts leading from information to interpretation and ultimately to theory. It is thus extremely important that science students acquire sufficiently sophisticated levels of language-mastering to be able to use it for a real familiarization with the main aspects of doing science.In recent years, there is a growing concern about fast deterioration of the quality of language-mastering among the young generation, mostly as a result of the dominant use of communication technologies for which short, grammatically and logically unconnected sentences are viewed as the most suitable options. Such deterioration poses a threat to the development of science thoughts in future years, because of the risk of inadequacies in the ability to utilise the essential thought-development tool to its full power.The current presentation suggests that the development of language-mastering abilities up to the sophistication levels that are needed for the generation and communication of scientific information needs to become a relevant component of science and technology education. This requires the design of novel approaches, integrating the increasing utilization of new, computer-based, educational technologies with the development of language-mastering abilities. The design is challenging, because of the complexity of the language skills that are relevant within the sciences ? skills concerning the identification and expression of individual logical or method-related relationships (e.g., cause-effect, hypothesis-thesis, condition-consequence) and of comprehensive logical and interpretation frameworks. The presentation proposes and discusses some options, considering implementation pathways, feasibility assessments and expected impacts, on the basis of long experience with the analysis of language-related difficulties encountered by science students and of the interplays between language communication and other communications forms, like visualization.",
    "author": [
      {
        "family": "Mammino",
        "given": "Liliana"
      }
    ],
    "collection-title": "EDUCATION’10",
    "container-title": "Proceedings of the 7th WSEAS international conference on engineering education",
    "id": "10.5555/1864181.1864187",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "page": "20",
    "publisher": "World Scientific; Engineering Academy; Society (WSEAS)",
    "publisher-place": "Stevens Point, Wisconsin, USA",
    "title": "Plenary lecture 6: Language aspects in science and technology education: Novel approaches for new technologies",
    "title-short": "Plenary lecture 6",
    "type": "paper-conference"
  },
  {
    "ISBN": "1584502193",
    "abstract": "From the Publisher: Focusing on the needs of the advanced technical professional who is responsible for an entireseries of Windows NT, Windows2000 and Windows XP Professional, The Windows XP Professional Handbook is designed to be both a handy desk reference in addition to a content review for MCSE courses. This book provides readers with insights into how Microsoft’s latest enterprise-based operating system solves the connectivity and development environment challenges that system administrators and advanced users face everyday. It also focuses on how to solve the tougher issues that arise in organizations running multiple operating systems. In addition to the expanded coverage of the most challenging aspects of keeping a workgroup going, this hands-on guide also includes short case studies as sidebars, illustrating key terms and concepts from the content covered in the chapter. KEY FEATURES - Contains information on upgrading from previous operating systems and installing popular software applications on Windows XP Professional - Focuses on the needs of technical professionals responsible for a series of Windows XP systems - Acts as a complete desk reference and resource for various certification topics - Provides insights on solving everyday problems with Windows XP Professional - Includes a CD-ROM with demos of tools and utilities to evaluate leading Windows XP applications prior to purchasing them Author Biography: Louis Columbus (Orange, CA) is Senior Manager, Workstation Marketing at Gateway Inc., and has written ten other books on computer topics, three focusing on the Windows XP Professional operating system. Louis’ interests include writing articles and books on computer topics and teaching systems analysis, systems design and Windows NT and XP Professional and Server courses at a local university.",
    "author": [
      {
        "family": "Columbus",
        "given": "Louis"
      }
    ],
    "id": "10.5555/515554",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Charles River Media, Inc.",
    "publisher-place": "USA",
    "title": "The microsoft windows XP professional handbook",
    "type": "book"
  },
  {
    "DOI": "10.1023/A:1019069012307",
    "ISSN": "1386-7857",
    "URL": "https://doi.org/10.1023/A:1019069012307",
    "abstract": "Current advances in high-speed networks such as ATM and fiber-optics, and software technologies such as the JAVA programming language and WWW tools, have made network-based computing a cost-effective, high-performance distributed computing environment. Metacomputing, a special subset of network-based computing, is a well-integrated execution environment derived by combining diverse and distributed resources such as MPPs, workstations, mass storage, and databases that show a heterogeneous nature in terms of hardware, software, and organization. In this paper we present the Virtual Distributed Computing Environment (VDCE), a metacomputing environment currently being developed at Syracuse University. VDCE provides an efficient web-based approach for developing, evaluating, and visualizing large-scale distributed applications that are based on predefined task libraries on diverse platforms. The VDCE task libraries relieve end-users of tedious task implementations and also support reusability. The VDCE software architecture is described in terms of three modules: (a) the Application Editor, a user-friendly application development environment that generates the Application Flow Graph (AFG) of an application; (b) the Application Scheduler, which provides an efficient task-to-resource mapping of AFG; and (c) the VDCE Runtime System, which is responsible for running and managing application execution and for monitoring the VDCE resources. We present experimental results of an application execution on the VDCE prototype for evaluating the performance of different machine and network configurations. We also show how the VDCE can be used as a problem-solving environment on which large-scale, network-centric applications can be developed by a novice programmer rather than by an expert in low-level details of parallel programming languages.",
    "author": [
      {
        "family": "Topcuoglu",
        "given": "Haluk"
      },
      {
        "family": "Hariri",
        "given": "Salim"
      },
      {
        "family": "Kim",
        "given": "Dongmin"
      },
      {
        "family": "Kim",
        "given": "Yoonhee"
      },
      {
        "family": "Bing",
        "given": "Xue"
      },
      {
        "family": "Ye",
        "given": "Baoqing"
      },
      {
        "family": "Ra",
        "given": "Ilkyeun"
      },
      {
        "family": "Valente",
        "given": "Jon"
      }
    ],
    "container-title": "Cluster Computing",
    "id": "10.1023/A:1019069012307",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1998,
          5
        ]
      ]
    },
    "keyword": "Asynchronous Transfer Mode, Application Execution, Asynchronous Transfer Mode Network, Cluster Manager, Site Repository",
    "page": "81-93",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "The design and evaluation of a virtual distributed computing environment",
    "type": "article-journal",
    "volume": "1"
  },
  {
    "ISBN": "1441917187",
    "abstract": "As scientific research increasingly requires the efforts of globally diverse, multidisciplinary teams from different laboratories and organizations, there surfaces a need to facilitate this kind of collaborative work. These large-scale scientific initiatives, where information technology plays an important role, are termed e-Science; e-Science activities employ geographically distributed resources like high performance computing facilities, scientific instruments, databases, and high performance networks. Future Application and Middleware Technology on e-Science presents selected papers from the 2008 Korea e-Science All-Hands-Meeting (AHM 2008). Hosted by the Korea Institute of Science and Technology Information (KISTI), the Korea e-Science AHM was designed to bring together developers and users of e-Science applications and enabling information technologies from international and interdisciplinary research communities. The AHM 2008 conference served as a forum for engineers and scientists to present state-of-the-art research and product/tool developments, and to highlight related activities in all fields of e-Science. The following topics concerning e-Science are covered in this volume: e-Science applications in Physics, Astronomy, and Chemistry e-Science applications in Bio-medicine and Life science e-Science applications in Geo-science with remote sensing e-Science applications in Climates and Earth systems e-Science applications in Engineering (Aerospace, Ship, Automobile, and etc) Grid technologies (Computing, Data, VO, and etc) Collaborative science models and techniques Enabling technologies of Workflows and Web services Resource management and scheduling Problem solving environments Scientific data management Application development environments Robust and transparent middleware Programming paradigms and models Software engineering tools Community development and engagement User outreach, training, and documentation The works presented in this edited volume bring together cross-disciplinary information on e-Science in one cohesive source. This book is suitable for the professional audience composed of industry researchers and practitioners of e-Science. This volume is also suitable for advanced-level students in the field.",
    "author": [
      {
        "family": "Byeon",
        "given": "Ok-Hwan"
      },
      {
        "family": "Kwon",
        "given": "Jang Hyuk"
      },
      {
        "family": "Dunning",
        "given": "Thom"
      },
      {
        "family": "Cho",
        "given": "Kum Won"
      },
      {
        "family": "Savoy-Navarro",
        "given": "Aurore"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1708084",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "Future application and middleware technology on e-science",
    "type": "book"
  },
  {
    "ISBN": "0201619164",
    "abstract": "From the Book: PREFACE: Preface Digital signal processing techniques are now so powerful that sometimes it is extremely difficult, if not impossible, for analogue signal processing to achieve the same or closer performance. Added to this, digital signal processors are very affordable and include good development tools and support. This is sufficient to explain the growing number of areas of application for DSP, including motor drives, communications, biomedical instrumentation and automotive applications. Having dealt for some time with undergraduate and postgraduate students, researchers and digital signal processor users in general, I have found that first-time users of DSP find a barrier obstructing them in progressing from theory to the full implementation of algorithms. When it comes to implementing an algorithm many questions arise, questions such as: Which processor to use - fixed or floating point Which manufacturer to choose Which application hardware to use How many I/O interfaces are needed and how fast should they be When these questions are answered, more questions arise regarding the implementation on the specific processor and hardware selected. In this book, use of the TMS320C6000 will be justified, and the hardware and complete implementation of selected algorithms will be dealt with in detail. Material used for the teaching of undergraduate and postgraduate students, along with laboratory experiments, are used to demonstrate and simplify the transition from theory to the full implementation on the TMS320C6201 processor. This book is divided into nine chapters. Chapters2and 3 are very important and it is advisable that they are well understood before progressing onto subsequent chapters. Chapter 1 Introduction This introductory chapter provides the reader with general knowledge on general-purpose DSP processors and also provides an up-to-date TMS320 roadmap showing the evolution of Texas Instruments’ DSP chips in terms of processing power. Chapter 2 The TMS320C62xxlC67xx architecture The objective of this chapter is to provide a comprehensive description of the ’C6x architecture. This includes a detailed description of the Central Processing Unit (CPU) and program control along with an overview of the memory organisation, serial ports, boot function and internal timer. Chapter 3 Software development tools and TMS32OC6201 EVM overview This chapter is divided into three main parts. The first part describes the software development tools, the second part describes the Evaluation Module (EVM) and, finally, the third part describes the codec, and use of interrupts along with some useful programs for testing the TMS320C6201 EVM. Chapter 4 Software optimisation To introduce the need for code optimisation, this chapter starts by developing the concept of pipelining. Since the TMS320C62xx and the TMS320C67xx each have eight units, which are dedicated to different operations, and since different instructions can have different latencies, the programmer or the tools are left with the burden of scheduling the code. Backed by examples, this chapter explains the different techniques used to optimise DSP code on these processors. Chapter 5 Finite Impulse Response (FIR) filter implementation The purpose of this chapter is twofold. Primarily, it shows how to design an FIR filter and implement it on the TMS320C62xx processor, and secondly, it shows how to optimise the code as discussed in Chapter 4. This chapter discusses the interface between C and assembly, how to use intrinsics, and how to put into practice material that has been covered in the previous chapters. Chapter 6 Infinite Impulse Response (IIR) filter implementation This chapter introduces the IIR filters and describes two popular design methods, that is the bilinear and the impulse invariant methods. Step by step, this chapter shows the procedures necessary to implement typical IIR filters specified by their transfer functions. Finally, this chapter provides complete implementation of an IIR filter in C language, assembly and linear assembly, and shows how to interface C with linear assembly. Chapter 7 Adaptive filter implementation This chapter starts by introducing the need for an adaptive filter in communications. It then shows how to calculate the filter coefficients using the Mean Square Error (MSE) criterion, exposes the Least Mean Square (LMS) algorithm and, finally, shows how the LMS algorithm is implemented in both C and assembly. Chapter 8 Goertzel algorithm implementation This chapter deals with Dual Tone Multi-Frequency (DTMF) detection and provides a practical example of the Goertzel algorithm. This chapter also shows how to produce optimised code by the pen and paper method, describes linear assembly and demonstrates how to program the Direct Memory Access (DMA). Chapter 9 Implementation of the Discrete Cosine Transform This chapter starts by introducing the need for video compression to reduce the channel bandwidth requirement, then explains the Joint Photographic Experts Group (JPEG) image codec. This includes a detailed discussion and the implementation of the Discrete Cosine Transform (DCT) and Inverse Discrete Cosine Transform (IDCT) and concentrates on their optimisation. An explanation of the PC-DSP communication via the PCI bus is also provided. Software The accompanying CD includes all the programs used in this book. To help the reader in locating or viewing the files, an Index.htm file has been included. The files are in separate directories corresponding to each chapter. Some directories are further divided in sub-directories to separate different implementations. Batch files for compiling, assembling and linking these programs are included. All the files have been tested (the environment may need to be modified: see env.bat file). Software using Code Composer Studio environment is also provided. Software updates including code running on the TMS320C6211 DSK can be obtained from the Publisher. Acknowledgements As you can imagine, it is hard to produce any textbook on state-of-the-art technology, especially when the time factor is playing against you. However, with the first very encouraging comments from the five anonymous reviewers, my motivation for writing this book surged, and therefore I would like to thank them for their constructive comments. Due to the unfamiliarity with this processor, it was difficult to share ideas with other users. But with Tuan-Kiang Chiew, Kwee-Tong Heng and Michael Hart many problems were solved and many grey areas were clarified; I extend to them special thanks. I am indebted to Robert Owen, Hans Peter Blaettel, Gene Frantz, Neville Bulsara, Greg Peake, Helga and Graham Stevenson and Maria Ho of Texas Instruments for their encouragement, continuous help and support. I owe my thanks to Professor Barrie Jones, Professor David Evans, Dr. John Fothergill and Fernando Schlindwein from Leicester University for their encouragement, and Dr Anthony Brooms from Oxford University and Dr Mark Yoder from the Rose-Hulman Institute of Technology, USA, for reviewing the material. My thanks to all of my colleagues at the Department of Engineering at Bristol University and to all of our students, in particular Khaled, Fernando, Mohamed, Samir, Chris, Shirley and Julian. Also I would like to thank Cornelius Kellerhoff, European DSP Business Development Consultant, Paul Coulton, Communications Research Centre, Lancaster University, and Mariusz Jankowski, University of Southern Maine, for their valuable technical reviews. I thank my parents, family and friends for their support and encouragement. Finally, many thanks to Karen Sutherland, Julie Knight and all of the Pearson Education and Prentice Hall team who were very kind, supportive and encouraging. N. Dahnoun Naim.Dahnoun@Bristol.ac.uk",
    "author": [
      {
        "family": "Dahnoun",
        "given": "Naim"
      }
    ],
    "edition": "1st",
    "id": "10.5555/517603",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Digital signal processing implementation using the TMS320C6000 DSP platform",
    "type": "book"
  },
  {
    "DOI": "10.1109/ADCOM.2007.126",
    "ISBN": "0769530591",
    "URL": "https://doi.org/10.1109/ADCOM.2007.126",
    "abstract": "Grid computing, one of the latest buzzwords in the ICT industry, is emerging as a new paradigm for Internet-based parallel and distributing computing. It enables the sharing, selection, and aggregation of geographically distributed autonomous resources, such as computers (PCs, servers, clusters, supercomputers), databases, and scientific instruments, for solving large-scale problems in science, engineering, and commerce. It leverages existing IT infrastructure to optimize compute resources and manage data and computing workloads. The developers of Grids and Grid applications need to address numerous challenges: security, heterogeneity, dynamicity, scalability, reliability, service creation and pricing, resource discovery, resource management, application dAbsecomposition and service composition, and qualify of services. A number of projects around the world are developing technologies that help address one or more of these challenges. To address some of these challenges, the Gridbus Project at the University of Melbourne has developed grid middleware technologies that (1) enable the creation of Utility Grids, which provide economic incentive for Grid service providers for sharing resources; and (2) support rapid development and optimal deployment of eScience and eBusiness applications on enterprise and global Grids. The components of Gridbus middleware are: Grid application development environment for rapid creation of distributed applications, Grid service broker and application scheduler, Grid workflow management engine, SLA (service-level agreements) based Scheduler for clusters, Web-services based Grid market directory (GMD), Grid accounting services, Gridscape for creation of dynamic and interactive resource monitoring portals, Portlets for creation of Grid portals that support web-based management of Grid applications execution, and GridSim toolkit for performance evaluation. In addition, Gridbus also includes a widely used .NET-based enterprise Grid technology and Grid web services framework to support the integration of both Windows and Unix-class resources for Grid computing.",
    "author": [
      {
        "family": "Buyya",
        "given": "Rajkumar"
      }
    ],
    "collection-title": "ADCOM ’07",
    "container-title": "Proceedings of the 15th international conference on advanced computing and communications",
    "id": "10.1109/ADCOM.2007.126",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "page": "xxiii-xxiv",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Tutorial 1: Utility-oriented grid computing and the gridbus middleware",
    "title-short": "Tutorial 1",
    "type": "paper-conference"
  },
  {
    "ISBN": "9781450326544",
    "abstract": "\"Necessity is the mother of invention\". That premise motivated the organizers of this workshop and the program committee to bring together communities that need vast amounts of computingresources for big analytics problems and the communities that can build computing platforms to solve those problems.It is our great pleasure to welcome you to the First Workshop on Parallel Programming for Analytics Applications (PPAA). Analytics applications are scaling rapidly in terms of the size and variety of data analyzed, the complexity of models explored and tested, and the number of analytics professionals or data scientists supported concurrently. At the same time hardware systems are embracing new technologies like on-chip and off-chip accelerators, vector extensions to instruction sets, and solid state disks. New programming methodologies and run-times to support them are emerging to facilitate the development of new analytics applications, and to leverage emerging systems. This workshop provides a forum for the applications community, runtime and development environment community and systems community to exchange the outlook for progress in each of these areas and exchange ideas on how to cross leverage the progress.We especially encourage attendees to attend the keynote and invited talk presentations. These valuable and insightful talks can and will guide us to a better understanding of the future: Future Directions in Analytic Applications, Dr. Edward J. Baranoski (currently Director of the Office of Smart Collection at Intelligence Advanced Research Projects Activity (IARPA) where the focus is on dramatically improving the value of collected data from all sources.)Cognitive Computing Journey, David Nahamoo (currently at IBM Research, focusing on cognitive computing.)Graphs &amp; Networks: Computing and Analytics at Lincoln Laboratory, Robert A. Bond (currently with IBM Lincoln Labs architectures, conducting research that support graph analytics as data sets scale to million-node graphs and beyond.)High-speed Graph Analytics with the Galois System, Dr. Keshav Pingali (Professor in the Department of Computer Science at the University of Texas at Austin, research is focused on programming languages and tools for multicore and manycore processors.)",
    "id": "10.1145/2567634",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PPAA ’14: Proceedings of the first workshop on parallel programming for analytics applications",
    "title-short": "PPAA ’14",
    "type": "book"
  },
  {
    "ISBN": "1789130336",
    "abstract": "Learn how to apply TensorFlow to a wide range of deep learning and Machine Learning problems with this practical guide on training CNNs for image classification, image recognition, object detection and many computer vision challenges. Key Features Learn the fundamentals of Convolutional Neural Networks Harness Python and Tensorflow to train CNNs Build scalable deep learning models that can process millions of items Book Description Convolutional Neural Networks (CNN) are one of the most popular architectures used in computer vision apps. This book is an introduction to CNNs through solving real-world problems in deep learning while teaching you their implementation in popular Python library - TensorFlow. By the end of the book, you will be training CNNs in no time! We start with an overview of popular machine learning and deep learning models, and then get you set up with a TensorFlow development environment. This environment is the basis for implementing and training deep learning models in later chapters. Then, you will use Convolutional Neural Networks to work on problems such as image classification, object detection, and semantic segmentation. After that, you will use transfer learning to see how these models can solve other deep learning problems. You will also get a taste of implementing generative models such as autoencoders and generative adversarial networks. Later on, you will see useful tips on machine learning best practices and troubleshooting. Finally, you will learn how to apply your models on large datasets of millions of images. What you will learn Train machine learning models with TensorFlow Create systems that can evolve and scale during their life cycle Use CNNs in image recognition and classification Use TensorFlow for building deep learning models Train popular deep learning models Fine-tune a neural network to improve the quality of results with transfer learning Build TensorFlow models that can scale to large datasets and systems Who this book is for This book is for Software Engineers, Data Scientists, or Machine Learning practitioners who want to use CNNs for solving real-world problems. Knowledge of basic machine learning concepts, linear algebra and Python will help.",
    "author": [
      {
        "family": "Zafar",
        "given": "Iffat"
      },
      {
        "family": "Tzanidou",
        "given": "Giounona"
      },
      {
        "family": "Burton",
        "given": "Richard"
      },
      {
        "family": "Patel",
        "given": "Nimesh"
      },
      {
        "family": "Araujo",
        "given": "Leonardo"
      }
    ],
    "id": "10.5555/3294129",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Hands-on convolutional neural networks with TensorFlow: Solve computer vision problems with modeling in TensorFlow and python",
    "title-short": "Hands-on convolutional neural networks with TensorFlow",
    "type": "book"
  },
  {
    "ISBN": "0130652016",
    "abstract": "From the Book: Preface Data management has been a central focus of mine throughout most of my 30-plus-year career. As an architect engaged mostly in working with business managers, helping them define their project needs (Should I build, lease, expand, or what ... And how much do I need ), I needed a computer early on. I began using BASIC in 1970, on a timesharing network, to manage the data I collected and to produce reports. Thus began my involvement with the BASIC language. I have used many dialects, from the line-numbered, Beginners All-purpose Symbolic Instruction Code that came out of Dartmouth University around 1960, to the modern versions of VB and VBA. These are now among the favored languages for communicating with relational databases such as Oracle, SQL Server, and the like, and for creating content for the Internet. BASIC was so-named because, as an interpreted language, it was easy to learn by incrementally developing a program, entering a few lines of code at a time, and then testing the result. At the time, however, many professional programmers thought it to be something of a toy. Mr. Gates, on the other hand, was a strong supporter of the language, introducing three levels of BASIC with the first IBM PC in 1981. Cassette BASIC was hardwired into the machines’ ROM, and you could only save files to a cassette tape. (I never actually did that!) The disk and advanced levels were built into Microsoft’s first version of its operating system: MS-DOS 1.0. A BASIC compiler (BASCOM) was introduced shortly thereafter, which produced executable programs in .EXE format. Late in the 1980s, QuickBasic wasintroduced with the first Interactive Development Environment (IDE) for DOS. This was followed in 1991 by Visual Basic 1.0, in both DOS and Windows versions. Visual Basic (VB) continues its growth in popularity. Microsoft Word and Excel were the first components of Microsoft Office, and each had its own internal functionality for creating macros, essentially scripts that allowed certain procedures to be automated within the application. Visual Basic for Applications (VBA) was first introduced in Excel in 1993. With the addition of Access, PowerPoint, and other products to the mix, VBA now provides an object-oriented programming environment common to all the Office components. This not only allows the creation of macros within each of the applications, but macros that allow Access, for example, to actually start up and communicate with Excel. The AutoCAD World AutoCAD is and always has been a database program. Underlying its graphic interface are lists within lists that define the entities that make up your drawing. During its evolution into a fully Windows-compatible product, many new data-oriented features were added. Initially conceived as a drafting package and written by engineers, AutoCAD was designed with an accessible data structure that allows both the manipulation of its graphic entities as well as the attachment and extraction of textual and numeric data. Attribute extraction using AutoLISP was at first the only means of manipulating the data within the drawing, and this method was widely used in the DOS days of the mid-1980s, when I began using the application. The AutoCAD SQL Extension (ASE), introduced with Release 12 in the early 90s, provided a rudimentary interface to databases such as DBASE and PARADOX. AutoCAD was recast in object-oriented C++ with Release 13 and the introduction of the AutoCAD Runtime Extension (ARX). Using ARX requires a programmer capable of creating DLLs using C++, which the average AutoCAD user is not. About the same time, however, AutoCAD users began experimenting with programs written in Visual Basic 3.0 using Dynamic Data Exchange (DDE). Curiously, support for a more robust connection between VB and AutoCAD had been provided in Release 12, but was dropped in Release 13. Autodesk added support for Microsoft’s ActiveX Automation interface standard to Release 14, first allowing VBA access to AutoCAD objects. Autodesk initially released AutoCAD 2000 in the spring of 1999, fully incorporating VBA. Further enhancements focusing on Internet functionality were a feature of the 2000i release in the summer of 2000. The development environment has a look and feel identical to that of any Microsoft Office component. With this convergence, the ability to write AutoCAD macros and communicate with other VBA-enabled applications is now fully accessible to the user. Now, with the release of AutoCAD 2002, Autodesk has adopted a policy of regular releases, incorporating \"technology extensions\" in the form of incremental upgrades. The extensions added over each period of time will be incorporated into the latest modular release. Who This Book Is For AutoCAD 2002 is the flagship product of Autodesk, which, according to the company’s web page \"is the world’s leading supplier of PC design software and digital content creation.\" Since its initial release in 1982, well over two million copies of AutoCAD have been shipped. There are nearly 1000 Autodesk Training Centers worldwide, and over one million students are trained on Autodesk products each year. Eighty five percent of the companies in the Fortune 500 are Autodesk customers, and the firm’s products are available in 19 languages. There are, according to Autodesk, over 200 user groups worldwide, along with almost 3000 registered developers. There are also countless unregistered developers who have no formal relationship with Autodesk. They produce add-ons and customizations both for sale and for their own and their companies’ use. The CAD Manager who needs to convert the layers of several hundred drawings received from another consultant is a potential AutoCAD developer. The Facility Manager who needs to link drawing attributes representing occupied and available areas to an Excel spreadsheet can now use VBA to accomplish this. Automation using VBA allows the user to work on the AutoCAD side, or the Excel side, or in some other application, whichever he or she is more comfortable with. I have routinely used VBA to write SQL scripts to populate database tables, as well accessing and modifying drawings in AutoCAD. I used to do many of these things in AutoLISP, which was the only act in town for 15 years. This book is for the AutoCAD and Office user who has problems to solve. Users who are already programmers can use it to familiarize themselves with the AutoCAD object model. Users who are not programmers will be able to get started by studying the book’s examples. My paramount goal, more than just presenting the components of VBA, is to tie together the disparate elements of AutoCAD with which you must be reasonably comfortable in order to use VBA effectively. The AutoCAD documentation treats, in unrelated discussions, many of those features that need to work in concert to get a job done. Understanding the DXF file representation, for example, together with some of the basic syntax of AutoLISP as it relates to the underlying database structure, provides the keys to unlocking the AutoCAD drawing and manipulating its data. It is the purpose of this book to provide those necessary links. What’s in the Book VBA for AutoCAD 2002: Writing AutoCAD Macros is divided into three major sections: The AutoCAD VBA Environment (Chapters 1-4) Using the AutoCAD Object Model (Chapters 5-17) Communicating with Other Applications and the Internet (Chapters 18-20) There are four appendices containing additional reference material as well as some supplemental utilities and examples. Part Two, Using the AutoCAD Object Model, is by far the longest section, in which the application’s numerous collections and objects will be discussed in detail. The following outline gives you an overview of what you can expect to see in each chapter. Part One: The AutoCAD VBA Environment Chapter 1, Taking Control of AutoCAD, introduces you to some of the concepts of Automation and Microsoft’s Component Object Model (COM). In it we will talk about what we mean by object-oriented programming; its tripartite foundation of encapsulation, inheritance, and polymorphism; and define such terms as class, interface, and binding. We will look at a programming example that reads data from an Excel worksheet and creates an AutoCAD drawing with it, without either application being visible, in 30 lines of code. Finally, we will introduce a system that we will use to chart all of AutoCAD’s methods, properties, and events, categorizing them in a concise reference format that will be used throughout the book. Chapter 2, The VBA Environment, shows you how to use the Interactive Development Environment (IDE); how to create, edit, and save VBA projects; and differentiates between global and embedded projects. Chapter 3, DXF: Key to the Drawing Structure, goes into some necessary detail about DXF that will add to your understanding of the drawing database. Subclass markers, which are the reflection of AutoCAD’s internal object structure, are introduced. We will develop two small VBA projects. One lets you look at selected DXF entity data within an AutoCAD drawing (DWG) file, and the other searches for specified entities in a DXF file. At the end of the chapters we will look at two tiny procedures that do the same thing, one in VBA and one in AutoLISP. You can decide for yourself which is the more accessible of the two languages. Chapter 4, Elements of the Object Model, introduces the AutoCAD object model. We will talk a little more about Automation interfaces, but will concentrate on taking a high-level view of the collections and objects that VBA offers within AutoCAD. Part Two: Using the AutoCAD Object Model Chapter 5, Documents and the User Interface, begins our top-down examination of the object model in detail. In the first part of the chapter we will talk about file management: creating, opening, saving, closing, importing, and exporting drawings. Then we will turn our attention to the user interface, discussing how to control your display and how to handle views and viewports. Chapter 6, Collections and Objects, continues our traversal of the object model with a discussion of the Application and Document objects. We will discuss such document-related functions as layer management and then look at how to manage Collections and access the data within the Objects they contain. Chapter 7, Utility Objects, concludes our introduction of the AutoCAD object model. In this chapter we will concentrate on functions related to creating and editing drawing data, such as Selection Sets: How to select entities in the drawing in order to do something to them. The utility object includes methods for acquiring and converting the formats of data and accessing the Internet. Chapter 8, Blocks and External References, prefaces Chapters 9-11, which deal with the AutoCAD graphic objects, or entities, both two- and three-dimensional. Blocks are complete AutoCAD drawings that have been inserted into other drawings, as symbols in many instances. We discuss Attributes in this chapter, which provide one of the means by which alphanumeric data can be stored and accessed in AutoCAD drawings. External References, which are similar to blocks, exist when other drawings are not actually inserted, but references to them are created so that changes appear automatically when the referenced drawings are updated. In Chapter 8 we will create procedures to rename and redefine XRefs, as they are called, while preserving their insertion instances. Chapter 9, Entities, covers all 23 basic AutoCAD Entities exclusive of the modeled solids and dimensions. We will dwell at some length upon some of the more interesting ones such as the Multiline, seeing how it is constructed and how to create multiline styles using DXF representation. Both kinds of meshes are treated in detail. We will create a Polyface Mesh from a data table stored in a text file and a Polygon Mesh using an Excel VBA macro and a point matrix stored in a worksheet. Chapter 10, Solids, covers the 11 three-dimensional entities in the domain of AutoCAD’s solid modeler. In addition to constructing them, we will concentrate on the methods for editing them, creating compound objects using Boolean functions, making sections, and slicing. Finally, we will discuss their mass properties, such as moment of inertia, and what these properties mean. Chapter 11, Dimensions, covers the seven basic dimension types together with the Leader and Tolerance objects. We begin this chapter with a discussion of dimension styles and how to manage them. Creating and using special symbols with the tolerance object for annotation purposes is also covered. The remainder of the chapter is devoted to the dimensioning properties, which are categorized according to AutoCAD’s dimension style manager. Each property is defined, along with its corresponding system variable. Chapter 12, Editing, extends our vocabulary of methods for changing and manipulating AutoCAD objects, such as Copy, Move, and the like. We will spend some time on a subject that is often glossed over, the use of geometric transformation matrices. We will develop a procedure that uses the TransformBy method to dynamically zoom and scale a three-dimensional object. Chapter 13, Events, deals with AutoCAD’s \"inflection points,\" which occur whenever there is a change of state in the application itself, the drawing you are working on, or an entity. You can write VBA subroutines called event handlers that automatically execute whenever the event to which they are connected occurs. Chapter 14, Forms and Controls, covers the principal user interface with VBA programs. Forms are containers for dialog box controls such as command buttons, list boxes, and the like, through which the user directs the program. After introducing the standard toolbox and some tips for using it, we will spend the balance of the chapter developing a utility application to discover how to integrate the form interface with many of the entity creation and editing functions we have been discussing. The utility application, called Relative, copies or moves selected entities relative to an existing location, using a dialog box. Relative also draws lines and polylines relative to a specified start point. Chapter 15, PaperSpace and Plotting, will discuss Viewports along with the Plot Configuration and Layout objects, two alternative means of formatting drawings. PaperSpace is AutoCAD’s environment intended for setting up drawings to print. We will look at the methods for detecting plotter and media characteristics in order to produce the desired output. We will develop a plotting application called BatchPlot, which will format (in paper space) and plot multiple drawings with your desired layer settings. You specify the drawings to be printed using either Visual Basic’s common dialog box or a list contained in a text file. Chapter 16, Preferences, deals with parts of the AutoCAD object model that control characteristics of the application itself, its environment, and the means of manipulating it, rather than the drawing itself. These are of two types, preferences stored in the registry, corresponding to the tabs on the AutoCAD’s dialog box for user options, plus user options stored in the drawing that can be accessed from other applications without the use of AutoCAD itself. Chapter 17, Menus, gives you the means of altering AutoCAD’s main menu, toolbars, and other menus using VBA. Part Three: Communicating with Other Applications and the Internet Chapter 18, Extensibility, will demonstrate how you can use VBA to communicate with other applications. It covers extended entity data in detail, introducing some concepts and test data that will be used more extensively in Chapter 19’s project. This chapter also covers working in a zero document state, the VBA interface itself, and a brief section on ARX application handling. Chapter 19, The Facility Project, ties together much of the material presented throughout the book into an application that links an AutoCAD drawing to a Microsoft Access database. The facility project (FP) uses Microsoft’s Data Access Objects (DAO) object model to integrate AutoCAD with Access, in order to track area allocation in an office layout. Chapter 20, The DWF Object Model, will go beyond AutoCAD, using and give you an understanding of how to use this additional functionality in querying and displaying drawings in DWF format over the Internet. AutoCAD’s Whip! viewer, which is freely downloadable for displaying drawings in a browser, also has a VBA programming interface. We will develop an Excel-based procedure that locates a specified floor drawing and room based on a row selection in a worksheet. Appendices Appendix A, System Variables: A dictionary of the AutoCAD system variables, other than those pertaining to dimensions covered in Chapter 11. Appendix B, Enums: A listing of AutoCAD’s enumerated variables, defined integer constants used in developing VBA macros. Appendix C, Object Inheritance: A chart of AutoCAD’s COM interface hierarchy. Appendix D, DXF Reference: A selection of the basic graphical entities as they are represented in DXF format. An Excel VBA application is included that will read your DXF files and list the various sections in a conveniently readable format.",
    "author": [
      {
        "family": "Clark",
        "given": "Jeffrey E."
      }
    ],
    "id": "10.5555/515908",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "VBA for AutoCAD 2002: Writing AutoCAD macros",
    "title-short": "VBA for AutoCAD 2002",
    "type": "book"
  },
  {
    "DOI": "10.1155/2021/3256924",
    "ISSN": "1574-017X",
    "URL": "https://doi.org/10.1155/2021/3256924",
    "abstract": "In recent years, badminton has become more and more popular in national fitness programs. Amateur badminton clubs have been established all over the country, and amateur badminton events at all levels have increased significantly. Due to the lack of correct medical supervision and health guidance, many people have varying degrees of injury during sports. Therefore, it is very important to study the method of badminton movement capture and intelligent correction based on machine vision to provide safe and effective exercise plan for amateur badminton enthusiasts. This article aims to study the methods of motion capture and intelligent correction of badminton. Aiming at the shortcoming of the mean shift algorithm that it is easy to lose the target when the target is occluded or the background is disturbed, this paper combines the mean shift algorithm with the Kalman filter algorithm and proposes an improvement to the combined algorithm. The improved algorithm is added to the calculation of the average speed of the target, which can be used as the target speed when the target is occluded to predict the area where the target may appear at the next moment, and it can also be used as a judgment condition for whether the target is interfered by the background. The improved algorithm combines the macroscopic motion information of the target, can overcome the problem of target loss when the target is occluded and background interference, and improves the robustness of target tracking. Using LabVIEW development environment to write the system software of the Japanese standard tracking robot, the experiment verified the rationality and correctness of the improved target tracking algorithm and motion control method, which can meet the real-time performance of moving target tracking. Experimental results show that 83",
    "author": [
      {
        "family": "Zhang",
        "given": "Yibo"
      },
      {
        "family": "Tang",
        "given": "Jianjun"
      },
      {
        "family": "Huang",
        "given": "Hui"
      },
      {
        "family": "Tsai",
        "given": "Sang-Bing"
      }
    ],
    "container-title": "Mob. Inf. Syst.",
    "id": "10.1155/2021/3256924",
    "issued": {
      "date-parts": [
        [
          2021,
          1
        ]
      ]
    },
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Motion capture and intelligent correction method of badminton movement based on machine vision",
    "type": "article-journal",
    "volume": "2021"
  },
  {
    "abstract": "Expert system knowledge bases have traditionally been manually loaded by a knowledge engineer. The \"knowledge\" was first extracted from a expert through a series of questions and answers conducted by the knowledge engineer. Then through establishing rules and/or specific examples from the real world, this information was carefully coded and loaded into a knowledge base. This is a process that sometimes took years to complete. More recently, advances in expert system technology have addressed reducing the involvement of the knowledge engineer and providing tools for users/experts to build their own knowledge bases. Most of these expert system building tools rely heavily on the human expert not only to provide the knowledge, but also to provide the logic structure of the knowledge. The next step in the enhancement of expert system development tools is not only to reduce the time required in collecting knowledge, but additionally to structure that knowledge into a usable expert system shell format. Rather than develop \"intelligent interface\" techniques through direct dialogue with a \"human\" expert, this study addresses the development of automatic knowledge base acquisition techniques that use \"text\" as a source of knowledge.Hard copy \"text\" knowledge is readily available in many areas suitable for expert system development. Acquisition of knowledge from text has not been successful thus far, primarily because most text is not presented in a format (rules, frames, or logic) that can be directly used to load a knowledge base. Most text books, manuals, training guides, etc. are written in a conceptual presentation format. This format may be amenable to human comprehension, but it generally does not spell out the \"what-if-else\" type details required to construct an expert system knowledge base. This study proposes techniques to over-come these inherent problems.This study develops a model to illustrate the techniques of automatic knowledge base acquisition from text. Several examples are used to show the theory of the techniques. A real world application is selected, and two validation exercises are conducted to support the credibility of the model. This study identifies and illustrates new automatic acquisition techniques that may greatly enhance the speed and structure with which knowledge bases can be constructed.",
    "author": [
      {
        "family": "Harding",
        "given": "William Thomas"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/128516",
    "issued": {
      "date-parts": [
        [
          1991
        ]
      ]
    },
    "note": "UMI Order No. GAX91-14962",
    "publisher": "Virginia Commonwealth University",
    "publisher-place": "USA",
    "title": "Techniques for automatic knowledge base acquisition: Applications for expert systems",
    "title-short": "Techniques for automatic knowledge base acquisition",
    "type": "thesis"
  },
  {
    "ISBN": "9798835533800",
    "abstract": "This project described in this dissertation is being carried out for the Ministry of Social and Economic Inclusion (MIES) of Ecuador based on its current problems. The de ciencies that government entities have to help their citizens with information and paperwork has exceeded their operational capacity. The MIES currently has a Marketing and Information department that is saturated with questions through channels such as call centers, information centers in their of- ces and social networks outside their o ce hours.In recent years there has been an increase in requests for information through digital channels such as its Facebook page, since internet access to places far from the big cities has increased. This has been seen as an opportunity for improvement by creating an chatbot agent that helps citizens 24 hours a day, 7 days a week. Most of the queries can be made through a query to their internal data and this allows the operational burden of the operators to be released to carry out management processes and not just information.Many public and private companies have resorted to using chatbots to help their users with simple information tasks. They have also relied on these technological tools to create registration and management functions. Today we can use chatbots development tools and platforms such as Dialog ow that allow to create chatbots in a manageable and scalable way according to needs. Facebook has multiple connection tools that allow it to integrate safely and e ciently with its platforms such as Facebook Messenger, allowing customers to create applications that will reach the majority of citizens who have internet access.Developing a chatbot agent can be a simple and straightforward task, but in which the remaining time must be invested in training and helping the chatbot agent to understand words or idioms of language used in di erent regions of the same country. In the development of a chatbot, the training cycle is constant and allows the chatbot to increase its ability to understand the users who use them.In the tests carried out on this chatbot, it was concluded that although the use of these tools allows to release the operational load, it does not avoid the need for users to interact with natural persons, but the requirement is drastically reduced. In the tests it was also obtained that many problems can be obtained by nding a wide range of synonyms and local expressions, but correct training and constant review of the answers provided helps the chatbot to self-train and evolve its answers over time interactions.",
    "author": [
      {
        "family": "Peñaherrera",
        "given": "Esteban Eduardo Cando"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI29137972",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "note": "AAI29137972",
    "publisher": "Instituto Politecnico de Leiria (Portugal)",
    "title": "A conversational agent to assist users in public institutions of ecuador",
    "type": "thesis"
  },
  {
    "ISBN": "9798368462530",
    "abstract": "Context: Software development, especially in its initial requirements phase, is a human-centric activity and hence vulnerable to human error. Human errors are flaws in the human thought process. To ensure software quality, it is essential for practitioners to understand how to manage these human errors. Organizations often introduce changes into the requirements engineering process to either prevent human errors from occurring or to mitigate the harm caused when those errors do occur. While there are studies on human error management in other disciplines, research studies on the prevention and mitigation of human errors in software engineering and requirements engineering specifically are scarce. The current studies in software engineering do not provide strong results about the types of changes most effective in requirements engineering. Objective: The goal of this dissertation research is to structure and organize the findings on human error prevention and mitigation approaches and provide an initial evaluation of their effectiveness. To that end, I developed a taxonomy of human error prevention and mitigation strategies based on data gathered from requirements engineering professionals. Furthermore, I validated its feasibility to be broadly representative and useful in real software development processes. Method: I performed a qualitative analysis of data from two practitioner surveys on requirements engineering practices to identify and classify strategies for preventing and mitigating human errors. Then, I attempted to fit human error prevention and mitigation strategies identified in software engineering and cognitive psychology domains into the taxonomy to enhance and broaden it. Finally, I evaluated the feasibility and usefulness of the taxonomy by training senior-level undergraduate students to use the error management strategies organized in the taxonomy to handle their software development problems. Results: I organized the human error management strategies into a formal taxonomy based on whether the changes primarily affect People, Processes, or the Environment. I further organized the strategies into low-level classes inside each of these high-level categories. I found that error management strategies focused on changes in Process are more frequently used and, hence, more effective than those focused on changes in People. Conclusions: The Human Error Management taxonomy (HEMT) provides a systematic classification and organization of strategies for the prevention and mitigation of human errors in software engineering. This systematic organization provides a foundation upon which future research can build. This dissertation research provides an initial structure to the scattered error management approaches and an initial evaluation of the feasibility and usefulness of that structure. Further empirical studies are needed in more real software development environments and settings to validate and generalize the findings reported in this dissertation.",
    "author": [
      {
        "family": "Mahaju",
        "given": "Sweta"
      },
      {
        "family": "Jeff",
        "suffix": "Gray"
      },
      {
        "family": "Chris",
        "suffix": "Crawford"
      },
      {
        "family": "Randy",
        "suffix": "Smith"
      },
      {
        "family": "Gary",
        "suffix": "Bradshaw"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI29324138",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "note": "AAI29324138",
    "publisher": "The University of Alabama",
    "title": "Application of human error theories in managing human errors in software engineering",
    "type": "thesis"
  },
  {
    "ISBN": "9780123852076",
    "abstract": "A general purpose graphical modeling language used to specify, analyze, and design systems that may include hardware, software, and personnel, SysML is now being adopted by companies across a broad range of industries, including aerospace and defense, automotive, and IT system developers. This book is the bestselling, authoritative guide to SysML for systems and software engineers, providing a comprehensive and practical resource for modeling systems with SysML. Fully updated to cover newly released version 1.3, it includes a full description of the modeling language along with a quick reference guide, and shows how an organization or project can transition to model-based systems engineering using SysML, with considerations for processes, methods, tools, and training. Numerous examples to help readers understand how SysML can be used in practice, while reference material facilitates studying for the OMG Systems Modeling Professional (OCSMP) Certification Program, designed to test candidates knowledge of SysML and their ability to use models to represent real-world systems. Authoritative and comprehensive guide to understanding and implementing SysML A quick reference guide, including language descriptions and practical examples Application of model-based methodologies to solve complex system problems Guidance on transitioning to model-based systems engineering using SysML Preparation guide for OMG Certified Systems Modeling Professional (OCSMP) Table of Contents Part I Introduction Systems Engineering Overview Model-Based Systems Engineering3 SysML Language Overview SysML Language Overview Part II Language Description SysML Language Architecture Organizing the Model with Packages Modeling Structure with Blocks Modeling Constraints with Parametrics Modeling Flow-Based Behavior with Activities Modeling Message-Based Behavior with Interactions Modeling Event-Based Behavior with State Machines Modeling Functionality with Use Cases Modeling Text-Based Requirements and their Relationship to Design Modeling Cross-Cutting Relationships with Allocations Customizing SysML for Specific Domains Part III Modeling Examples Water Distiller Example Using Functional Analysis Residential Security System Example Using the Object-Oriented Systems Engineering Method Part IV Transitioning to Model-Based Systems Engineering Integrating SysML into a Systems Development Environment Deploying SysML into an Organization APPENDIXES A-1 SysML Reference Guide A-2 Cross Reference Guide to the OMG Systems Modeling Professional Certification Program (OCSMP) - NEW",
    "author": [
      {
        "family": "Friedenthal",
        "given": "Sanford"
      },
      {
        "family": "Moore",
        "given": "Alan"
      },
      {
        "family": "Steiner",
        "given": "Rick"
      }
    ],
    "edition": "2",
    "id": "10.5555/2597859",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "publisher": "Morgan Kaufmann Publishers Inc.",
    "publisher-place": "San Francisco, CA, USA",
    "title": "A practical guide to SysML: The systems modeling language",
    "title-short": "A practical guide to SysML",
    "type": "book"
  },
  {
    "ISBN": "0596526954",
    "abstract": "Well before Ajax and Microsoft’s Windows Presentation Foundation hit the scene, Macromedia offered the first method for building web pages with the responsiveness and functionality of desktop programs with its Flash-based \"Rich Internet Applications\". Now, new owner Adobe is taking Flash and its powerful capabilities beyond the Web and making it a full-fledged development environment. Rather than focus on theory, the ActionScript 3.0 Cookbook concentrates on the practical application of ActionScript, with more than 300 solutions you can use to solve a wide range of common coding dilemmas. You’ll find recipes that show you how to:Detect the user’s Flash Player version or their operating systemBuild custom classesFormat dates and currency typesWork with stringsBuild user interface componentsWork with audio and videoMake remote procedure calls using Flash Remoting and web servicesLoad, send, and search XML dataAnd much, much more ...Each code recipe presents the Problem, Solution, and Discussion of how you can use it in other ways or personalize it for your own needs, and why it works. You can quickly locate the recipe that most closely matches your situation and get the solution without reading the whole book to understand the underlying code. Solutions progress from short recipes for small problems to more complex scripts for thornier riddles, and the discussions offer a deeper analysis for resolving similar issues in the future, along with possible design choices and ramifications. You’ll even learn how to link modular ActionScript pieces together to create rock-solid solutions for Flex 2 and Flash applications.When you’re not sure how ActionScript 3.0 works or how to approach a specific programming dilemma, you can simply pick up the book, flip to the relevant recipe(s), and quickly find the solution you’re looking for.Adobe Developer Library is a co-publishing partnership between O’Reilly Media and Adobe Systems, Inc. and is designed to produce the number one information resources for developers who use Adobe technologies. Created in 2006, the Adobe Developer Library is the official source for comprehensive learning solutions to help developers create expressive and interactive web applications that can reach virtually anyone on any platform. With top-notch books and innovative online resources covering the latest in rich Internet application development, the Adobe Developer Library offers expert training and in-depth resources, straight from the source.",
    "author": [
      {
        "family": "Lott",
        "given": "Joey"
      },
      {
        "family": "Schall",
        "given": "Darron"
      },
      {
        "family": "Peters",
        "given": "Keith"
      }
    ],
    "id": "10.5555/1210154",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "publisher": "O’Reilly Media, Inc.",
    "title": "ActionScript 3.0 cookbook",
    "type": "book"
  },
  {
    "ISBN": "0769500684",
    "abstract": "This panel discusses the impact OT has made and is making on traditional software development methodologies. The scope of the panel is defined by, but not limited to, the following areas: - Object-Oriented (OO) Modeling and Design; - OO Architectures and Frameworks; - Distributed objects and web technology; - Roadmap to OT adoption, - Transition to OT; - OT and Standardization.The goal of this panel session is to study the aforementioned topics, define research areas and state-of-the-art in more detail, and to identify open problems.1. OT and software development. OO Analysis and UML are currently combined with various requirements analysis techniques, e.g., goal-oriented analysis, user centered work modeling, user interaction scenarios and business modeling. While a domain model and use-case model describe a system as a black box, a logical architecture (analysis model) describes what the system’s structure [2, 3]. Layered object architecture facilitates better design of software components.2. OO Architectures and Frameworks. Some major impacts of OT on software development practice are definition and usage of OO frameworks and design patterns to facilitate reuse of code and design. Software architecture is a conceptual model defining system components, their interfaces and how they interact between each other. Frameworks provide services and mechanisms for a set of components and can define structural relationships between components. Components vary in granularity and have value within specified environments. OMG Business Object Component Architecture serves as an architectural template for defining domain- and technology-specific architectures and frameworks.3. OT and Web Technology. Internet middleware architecture adopted a concept of \"object Web\", i.e., universal connectivity, heterogeneous distributed environments, and cross platform interoperation of both infrastructure and applications. Three major drivers: CORBA, DCOM and Enterprise JavaBeans.4. OT adoption. A successful OT adoption is normally based on a plan that includes: resources, scope, management, process, technology and training.5. OT and Standardization. UML is a standard modeling language for OO Analysis and Design. It has been widely recognized and is currently used in many areas. An OO software development process (SDP) is harder to standardize. A Unified Rational Approach which can serve as a framework for definition of OO SDP specifics to a particular project or software development environment. CORBA standards specify many services that can be used in a consistent manner across platforms. More work has to be done to standardize components.",
    "author": [
      {
        "family": "Ushakov",
        "given": "I."
      },
      {
        "family": "Coleman",
        "given": "D."
      },
      {
        "dropping-particle": "da",
        "family": "Costa",
        "given": "L."
      }
    ],
    "collection-title": "ISESS ’99",
    "container-title": "Proceedings of the 4th IEEE international symposium and forum on software engineering standards",
    "id": "10.5555/520047.854883",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "page": "245",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Object technology",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130895571",
    "author": [
      {
        "family": "Deitel",
        "given": "Harvey M."
      },
      {
        "family": "Deitel",
        "given": "Paul"
      },
      {
        "family": "Nieto",
        "given": "Tem"
      }
    ],
    "id": "10.5555/558603",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "The complete XML programming training course",
    "type": "book"
  },
  {
    "DOI": "10.1145/1805986.1806014",
    "ISBN": "9781450300452",
    "URL": "https://doi.org/10.1145/1805986.1806014",
    "abstract": "Broadband technologies are rapidly becoming integral to education, commerce, employment, community participation, health and safety Yet there remain multiple barriers to effective and affordable access by people with disabilities, elder, or those with low literacy creating an increasing digital divide. There are assistive technologies that can provide access for some. However it is not available for all disabilities, not affordable by many, and lags mainstream developments and deployments. Even when the latest AT is close to the latest IT, few people have the latest version. The cost of keeping up with mainstream technologies reduces resources available for innovation in assistive technologies and new directions in broadband technologies will require an already strapped AT industry to retool and re-architect their products. We are moving to an ICT environment with a profusion of hardware models (desktop, laptop, netbook, smartphone, tablet, set top box, game systems, players), multiple operating systems (Windows, Mac, Linux, Chrome OS, iPhone, Android, Windows Mobile, Symbian, Maemo (Nokia), Bada (Samsung), WebOS, etc.), hundreds of software applications that embed another universe of widgets, plug-ins, and players, and a networked information environment that adheres to no standard and mutates far beyond the initial conception of the Web. Our current access technologies and infrastructure cannot handle this; the assistive technologies that now exist do not address all disabilities well, particularly cognitive, language, and learning disabilities, deaf-blindness and the mixed problems faced by elders; current assistive technologies often add, rather than reduce, complexity; finally, but importantly, people are not aware of what is possible, see it as complicated, and do not have any easy way to determine that there is something that can help themA coalition of academic, industry and non-governmental organizations and individuals are coming together to promote the creation of a National Public Inclusive Infrastructure (NPII) to address these problems. The purpose is to ensure that everyone who faces accessibility barriers due to disability, literacy or aging, regardless of economic status, can access and use the Internet and all its information, communities, and services for education, employment, daily living, civic participation, health and safety.An NPII would provide key software enhancements to the physical infrastructure to allow lower cost accessibility that could be invoked on any computer, anywhere. Its key components would be a cloud based delivery system that would allow anywhere, any computer access, a personal preference system to allow systems to automatically configure themselves to users, a system of wizards to make creation of a preference profile simple even when a professional is not available, a metadata server to allow users to find accessible media or captions or descriptions for inaccessible media, a trusted source for malware free solutions, a rich development environment with common building blocks, and an awareness program to make more people aware of what is possible for them. All of the NPII components are being designed to support both commercial assistive technologies and free, built-in access features (universal design). The NPII will include a delivery system, personalization profiles and a rich development system and common modules. In addition to lowering development costs and increasing the number of solutions for different disabilities, the NPII can also enable new types of assistive technologies and services, including assistance-on-demand services that allow consumers to invoke computer or human assistance whenever and wherever they need it. The goal is a richer set of access options that it is less expensive to create and distribute and that can address the needs of a wider range of disabilities than is possible today. And a model infrastructure that can be replicated internationally and bring this wide variety of access options and the lower cost delivery system for both commercial and free access features to countries world-wide.",
    "author": [
      {
        "family": "Vanderheiden",
        "given": "Gregg"
      }
    ],
    "collection-title": "W4A ’10",
    "container-title": "Proceedings of the 2010 international cross disciplinary conference on web accessibility (W4A)",
    "id": "10.1145/1805986.1806014",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Building national public infrastructures on our way to a global inclusive infrastructure",
    "type": "paper-conference"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "The \"Program By Design\" (neé \"TeachScheme!\") curriculum has been used to great success in middle schools, high schools, community colleges, liberal-arts colleges, and research universities, and won Matthias Felleisen the two highest awards in computer science education, the ACM Karlstrom award and the SIGCSE Distinguished Educator award. The curriculum starts with a beginner-friendly IDE (DrRacket) and a simple language (a tiny subset of Scheme), emphasizing an explicit, concrete problem-solving strategy and motivating central CS and math concepts (variables, functions, composition, data types, classes, polymorphism, etc.) with graphics and animation. Using this curriculum, I routinely teach non-CS-majors to write separable-model, event-driven GUI programs involving higher-order functions and recursive traversal of linked data structures, all within their first semester. For CS majors, we then show (in a second semester) how the same concepts and strategies apply in a more difficult language like Java.",
    "author": [
      {
        "family": "Bloch",
        "given": "Stephen"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/2038836.2038854",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2011,
          12
        ]
      ]
    },
    "page": "125-126",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Program by design: Graphics-first programming without drowning in syntax",
    "title-short": "Program by design",
    "type": "article-journal",
    "volume": "27"
  },
  {
    "DOI": "10.1145/3555810",
    "ISSN": "1936-7406",
    "URL": "https://doi.org/10.1145/3555810",
    "abstract": "With the proliferation of low-cost sensors and the Internet of Things, the rate of producing data far exceeds the compute and storage capabilities of today’s infrastructure. Much of this data takes the form of time series, and in response, there has been increasing interest in the creation of time series archives in the past decade, along with the development and deployment of novel analysis methods to process the data. The general strategy has been to apply a plurality of similarity search mechanisms to various subsets and subsequences of time series data to identify repeated patterns and anomalies; however, the computational demands of these approaches renders them incompatible with today’s power-constrained embedded CPUs.To address this challenge, we present FA-LAMP, an FPGA-accelerated implementation of the Learned Approximate Matrix Profile (LAMP) algorithm, which predicts the correlation between streaming data sampled in real-time and a representative time series dataset used for training. FA-LAMP lends itself as a real-time solution for time series analysis problems such as classification. We present the implementation of FA-LAMP on both edge- and cloud-based prototypes. On the edge devices, FA-LAMP integrates accelerated computation as close as possible to IoT sensors, thereby eliminating the need to transmit and store data in the cloud for posterior analysis. On the cloud-based accelerators, FA-LAMP can execute multiple LAMP models on the same board, allowing simultaneous processing of incoming data from multiple data sources across a network.LAMP employs a Convolutional Neural Network (CNN) for prediction. This work investigates the challenges and limitations of deploying CNNs on FPGAs using the Xilinx Deep Learning Processor Unit (DPU) and the Vitis AI development environment. We expose several technical limitations of the DPU, while providing a mechanism to overcome them by attaching custom IP block accelerators to the architecture. We evaluate FA-LAMP using a low-cost Xilinx Ultra96-V2 FPGA as well as a cloud-based Xilinx Alveo U280 accelerator card and measure their performance against a prototypical LAMP deployment running on a Raspberry Pi 3, an Edge TPU, a GPU, a desktop CPU, and a server-class CPU. In the edge scenario, the Ultra96-V2 FPGA improved performance and energy consumption compared to the Raspberry Pi; in the cloud scenario, the server CPU and GPU outperformed the Alveo U280 accelerator card, while the desktop CPU achieved comparable performance; however, the Alveo card offered an order of magnitude lower energy consumption compared to the other four platforms. Our implementation is publicly available at https://github.com/aminiok1/lamp-alveo.",
    "author": [
      {
        "family": "Kalantar",
        "given": "Amin"
      },
      {
        "family": "Zimmerman",
        "given": "Zachary"
      },
      {
        "family": "Brisk",
        "given": "Philip"
      }
    ],
    "container-title": "ACM Trans. Reconfigurable Technol. Syst.",
    "id": "10.1145/3555810",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2022,
          12
        ]
      ]
    },
    "keyword": "Field-programmable gate array (FPGA), time series, Matrix Profile",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FPGA-based acceleration of time series similarity prediction: From cloud to edge",
    "title-short": "FPGA-based acceleration of time series similarity prediction",
    "type": "article-journal",
    "volume": "16"
  },
  {
    "DOI": "10.1145/3568812.3603473",
    "ISBN": "9781450399753",
    "URL": "https://doi.org/10.1145/3568812.3603473",
    "abstract": "Enrollments in university-level introductory computing courses are skyrocketing [3], but many students struggle in these courses [2]. Recent research suggests that student perceptions of the programming process may contribute to this problem. Students often have inaccurate expectations of programming that may lead them to negatively assess their abilities in response to natural programming moments [6]. For example, many students believe they are doing poorly when they use resources to look up syntax, even though this is considered good practice [7]. This is important because negative self-assessments correlate with lower self-efficacy [6], or one’s belief that they can achieve a goal [1], and students with lower self-efficacy tend to exhibit lower persistence in undergraduate computing programs [9]. In this poster, we present an initial design and evaluation of an intervention that aims to reduce overly negative self-assessments and improve self-efficacy by providing real-time feedback as students program. We created an extension to the jGRASP development environment [4] that delivers feedback messages in response to eight self-assessment moments that can be automatically detected by an expert system developed in prior work [5] (see Figure 1). Informed by recommendations from the feedback literature [8, 10], we developed six messages for each moment that aim to help students develop more accurate expectations by normalizing the moment or highlighting how it could support future growth (see Figure 2). By delivering this feedback automatically, in real-time, and in the context of the task, this intervention aims to address negative self-assessments as they occur. This approach has been successful in other domains [8, 10] and allows us to provide individual feedback at scale, which is particularly challenging as course enrollments grow [3, 11]. We conducted a formative user study with 10 CS1 and 11 CS2 students to understand how they perceived the intervention and which feedback messages they preferred, with the goal of informing future design iterations. First, participants completed a modified version of the survey from [6] to measure their self-efficacy and self-assessments; this served as a pretest. Then, they worked on a programming problem with the intervention for twenty minutes. Finally, participants completed the same survey as a posttest and we interviewed students about their reactions to the intervention as they watched a video of their session. The pretest results showed that many participants do not negatively self-assess in response to these eight programming moments, which is surprising since previous research with other populations has found that negative self-assessments are common [6]. Our preliminary analysis indicates that some participants found the messages reassuring and timely while others found them unhelpful. Participants expressed preferences for some message designs over others, and overall the feedback resonated most with participants who had more negative self-assessments or struggled more on the programming problem. Based on this feedback, we are refining the intervention and collecting data with other populations ahead of a summative evaluation to measure the intervention’s impact on self-assessments and self-efficacy.",
    "author": [
      {
        "family": "Chen",
        "given": "Melissa"
      },
      {
        "family": "O’Rourke",
        "given": "Eleanor"
      }
    ],
    "collection-title": "ICER ’23",
    "container-title": "Proceedings of the 2023 ACM conference on international computing education research - volume 2",
    "id": "10.1145/3568812.3603473",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "CS1, self-assessments, self-efficacy",
    "page": "9-10",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing a real-time intervention to address negative self-assessments while programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/FIE.2018.8658513",
    "URL": "https://doi.org/10.1109/FIE.2018.8658513",
    "abstract": "Robotics and computational thought are ideal tools for developing science, technology, engineering and mathematics (STEM) pedagogy. Throughout this paper a modular and adaptive course is presented, the main objective of which is to make known simple and economic tools of educational robotics. This course is aimed at those who want to discover the possibilities of educational robotics in the context of the introduction to robotics. Today, robotics training tools are raised with the aim of promoting innovation and motivation of students during the learning process. Robots are becoming more and more common in our daily lives; therefore, it is important to integrate robots into all levels of our society. The course is designed to work with the Scratch, Crumble and Arduino tools as STEM enhancers. Using Scratch, interactive stories, games and animations can be programmed. Scratch helps young people to acquire and improve skills such as think creatively, think systematically, and work collaboratively. Scratch is a project of MIT Media Lab’s Lifelong Kindergarten Group. It is offered free of charge. On the other hand, Crumble is an easy-to-use programmable controller. Its programming interface uses a block programming language based on Scratch that makes it easy for children from 10 years old to use it. In addition, the hardware elements associated with Crumble are very intuitive and easy to connect. Last, but not least, Arduino is an open source electronic platform based on hardware and software that is easy to use. It is a platform that incorporates a simple microcontroller and an interface development environment to create the applications to be downloaded on the board. The course offers a three-tiered journey through three levels with each of the three tools. It consists of a total of 9 modules. This course has a very practical approach. A project-based pedagogical methodology is used. Experiments are promoted, where trial and error are part of learning and self-discovery. The student learns to have more autonomy and responsibility. Knowledge is acquired in different disciplines. It develops: motor skills (scale mobility in the hands), group skills, allowing people to socialize, creative abilities, and learning in a fun way. The operational details, materials used and examples of activities for some modules are also presented with the expectation that all teachers will be able to adapt these activities in their class. In addition, results are included from several groups of students who have already completed some modules. Despite not having a large number of students, the experience provided results that may be useful for other teachers to promote a course with similar or equal content for more results. The results of this work show that it is important to combine theory and practice to include fun tasks intertwined with the challenges of applying theory to problem solving.",
    "author": [
      {
        "family": "Plaza",
        "given": "Pedro"
      },
      {
        "family": "Sancristobal",
        "given": "Elio"
      },
      {
        "family": "Carro",
        "given": "German"
      },
      {
        "family": "Castro",
        "given": "Manuel"
      },
      {
        "family": "Blazquez",
        "given": "Manuel"
      },
      {
        "family": "Garcı́a-Loro",
        "given": "Félix"
      }
    ],
    "container-title": "2018 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE.2018.8658513",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "page": "1-9",
    "publisher": "IEEE Press",
    "publisher-place": "San Jose, CA, USA",
    "title": "Multiplatform educational robotics course to introduce children in robotics",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800214.806560",
    "ISBN": "9781450378673",
    "URL": "https://doi.org/10.1145/800214.806560",
    "abstract": "Thoth is a portable real-time operating system which has been developed at the University of Waterloo. Various configurations of Thoth have been running since May 1976; it is currently running on two minicomputers with quite different architectures (Texas Instruments 990 and Data General NOVA).This research is motivated by the difficulties encountered when moving application programs from one system to another; these difficulties arise when interfacing with the hardware and support software of the target machine. The problems encountered interfacing with the new software support are usually more difficult than those of interfacing with new hardware because of the wide variety of abstract machines presented by the compilers, assemblers, loaders, file systems and operating systems of the various target machines. We have taken the approach of developing portable system software and porting it to “bare” hardware. Because the same system software is used on different hardware, the same abstract machine is available to application programs. Thus most application programs which use Thoth can be portable, if not machine independent.Most previous work on software portability has focused on problems of porting programs over different operating systems as well as hardware. To our knowledge, this is the first time an entire system has been ported. Our experience indicates that this approach is practical both in the cost of porting the system and its time and space performance.The design of Thoth strives for more than portability. A second design goal is to provide a system in which programs can be structured using many small concurrent processes. Thus we have aimed for efficient interprocess communication to make this structuring technique attractive. We have also provided safe dynamic process creation and destruction.A third design goal is that the system meet the demands of real-time applications. To meet this goal, the system guarantees that the worst-case time for response to certain external events (interrupt requests) is bounded by a small constant.A fourth design goal is that the system be adaptable to a wide range of real-time applications. A range of system configurations is possible: A stand-alone application program can use a stripped version of the Thoth kernel which supports dynamic memory allocation and interprocess communication. Such a configuration requires less than 2000 16-bit words of memory. Larger configurations can support process destruction, a device-independent input-output system, a tree-structured file system, and multiple teams of processes. (A team is a set of processes which share the same logical address space and therefore can share data.)Thoth is implemented in a high-level language called Eh (a descendant of BCPL) and a small amount of assembly language. The major job in porting the system seems to be in redesigning the code generation parts of the compiler.Since it appears impractical to design system software to be portable over all computers (even over all existing machines), we have aimed at making Thoth portable over a subset of machines. Machines in the set can be characterized by a set of properties such as: a word must be at least 16 bits in length, a pointer to a word must fit into a word, etc. Roughly, this set of machines includes most modern minicomputers. It is important that many machines which do not yet exist will be included in it.A number of application programs have been written using Thoth. In addition to software development tools, communications and real-time control programs have been written. All of these programs require few if any changes when ported to new hardware. Some of these programs have been developed by inexperienced programmers who were not planning on porting their program. Hence, it seems to take less skill to write portable software in this system than using conventional techniques. However, existing software written for other systems is incompatible with Thoth and usually difficult to port to the Thoth system.Although, at the time of this writing, we have limited experience with porting the system to new hardware, we feel that Thoth has been highly successful in terms of our original objectives. Among other things, it has partially demonstrated the feasibility of building a portable operating system for a specified class of machines.",
    "author": [
      {
        "family": "Cheriton",
        "given": "David R."
      },
      {
        "family": "Malcolm",
        "given": "Michael A."
      },
      {
        "family": "Melen",
        "given": "Lawrence S."
      },
      {
        "family": "Sager",
        "given": "Gary R."
      }
    ],
    "collection-title": "SOSP ’77",
    "container-title": "Proceedings of the sixth ACM symposium on operating systems principles",
    "id": "10.1145/800214.806560",
    "issued": {
      "date-parts": [
        [
          1977
        ]
      ]
    },
    "page": "171",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Thoth, a portable real-time operating system (extended abstract)",
    "type": "paper-conference"
  },
  {
    "ISBN": "9781267316615",
    "abstract": "The goal of state-of-the-art research in decision guidance applications is to build complex systems with predicting capability. Systems can make decisions intelligently rewarded by more desirable outcomes. Predictions are actually made based on a dynamically collected amount of information. Some models with unknown parameters in the application can be learned from the collected information and domain knowledge as well [1]. A development tool called Decision Guidance Management System (DGMS) is proposed to develop decision guidance applications. Four phases are involved in the decision guidance applications and will be repeated as needed. They are data collection, model learning, prediction, and optimization phases for decision-making [1]. This dissertation focuses on a framework, models, languages, and algorithms to integrate the machine learning functionality (regression learning) into DGMS applications as their first class citizen. A framework CoReJava (Constraint Optimization Regression in Java), which extends the Java programming language with regression learning or the ability of parameter estimation for a function, is proposed and developed. CoReJava is unique in that functional forms for regression analysis are expressed as first class citizens, that is, as Java programs, in which some parameters are not given in advance, but will be learned from learning data sets provided as input. To implement regression learning, the CoReJava compiler (a) analyzes the structure of the parameterized Java program that represent a functional form; (b) automatically generates a constraint optimization problem, in which constraint variables are the unknown parameters, and the objective function to be minimized is the sum of squares of errors with regarding to the learning set; and (c) solves the optimization problem using an external nonlinear optimization solver. The parameterized Java programs are executed as a regular Java program, with the initially unknown parameters substituted by the found optimal values. CoReJava syntax and semantics are formally defined and exemplified using a simple supply chain example. The if-then-else decision structures of the Java language are naturally adopted to represent piecewise functional forms of regression. Thus, minimization of the sum of squared errors involves an optimization problem with a search space that is exponential to the size of the learning set. A combinatorial restructuring algorithm is proposed to guarantee learning optimality and reduce the search space to be polynomial in the size of the learning set, but exponential to the number of piecewise bounds. A Heaviside restructuring algorithm, which expresses the piecewise linear regression function using a unified functional format [2], instead of multiple pieces, is proposed to decrease the searching complexity further to be polynomial in both the size of the learning set and the number of piecewise bounds, while the learning outcome will be an approximation of the optimality. An Expectation Maximization-based (EM-based) Multi-step Piecewise Surface Regression Algorithm (EMMPSR) is proposed to solve piecewise surface regression problem. The multiple steps involved are local regression on each data point of the training data set and a small set of its closest neighbors, clustering on the feature vector space formed from the local regression, regression learning for each individual surface, and classification to determine the boundaries for each individual surface [3]. An EM-based iteration process is introduced in the regression learning phase to improve the learning outcome [4]. The reassignment of a cluster identifier for every data point in the training set is determined by predictive performance of each submodel [5]. Clustering quality validity indices are applied to the scenario in which the number of piecewise surfaces is not given in advance. The Relational Database Management System (RDBMS) is extended with the piecewise regression learning capability as well. The functional forms are represented as database tables. The EMMPSR algorithm is implemented as stored procedures. A case study is undertaken to describe the decision optimization process based on the learning outcome of the EMMPSR algorithm. Evaluation of the resulting research is established by experiments and empirical analysis in comparison with those of related regression learning packages.",
    "author": [
      {
        "family": "Luo",
        "given": "Juan"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/2522400",
    "issued": {
      "date-parts": [
        [
          2012
        ]
      ]
    },
    "note": "AAI3506265",
    "publisher": "George Mason University",
    "publisher-place": "USA",
    "title": "Regression learning in decision guidance systems: Models, languages, and algorithms",
    "title-short": "Regression learning in decision guidance systems",
    "type": "thesis"
  },
  {
    "ISBN": "059164634X",
    "abstract": "Decision support system (DSS) technologies are becoming very important supporting tools for helping people in the decision-making process. DSS have been used in forestry and are evolving very rapidly as foresters are demanding more system functionality to improve forestry management operations along with development of dynamic and user-friendly software to cope with the increased demand for information. The Intermountain Forest Tree Nutrition Cooperative (IFTNC) at the University of Idaho initiated a DSS project including, as its primary functional part, a real-time expert system prototype for Central Washington that focuses on tree nutrition management. The project’s main objective was to design and develop a system methodology that involves a microcomputer program to predict Douglas-fir growth response based on fertilization treatments of 200 or 400 lb of nitrogen per acre during a six-year period. The system methodology began with the definition of the problem and ended with a preliminary design and operation of an integrated microcomputer application prototype.Nine experts on forest fertilization management issues were interviewed with the purpose to acquire heuristic knowledge they use to conduct fertilization operations and also to obtain their input on how a fertilization-supporting tool could strengthen the decision-making process. In order to reinforce the qualitative information collected from the interviews, quantitative data from different sources were also gathered i.e., data mining. For instance, the IFTNC database was a source for individual tree measurements and site characteristics. Geographic Information Systems (GIS) database related to soil parent materials and potassium level were generalized to include these parameters as input attributes in the data set. Global Positional System (GPS) was used to locate stands and input site-specific conditions.Interpretation and analysis included the interpretation of qualitative and quantitative information to look for system component functioning and then an analysis of how different components would operate under an integrated environment. To facilitate system understanding, a theoretical fertilization control system input was designed. This framework made it easy to design and operate the logic for various system module components. Also, preliminary definitions of the modeling and system architecture were studied.Modeling consisted of searching for an appropriate mathematical technique for system prediction. The system mathematical module uses a neural network approach where input/output data pairs on individual tree measurements and physical site characteristics are trained to predict Douglas-fir growth response based on 200 or 400 lb of nitrogen per acre during a six-year span. This component proved to be a quick and robust prediction technique for the prototype under development.Finally system development primarily dealt with the design and operation of the prototype itself. This system uses distinct software packages within an integrated personal computer environment using Microsoft Visual Basic as the integration development language. Besides the mathematical module, the prototype includes a visualization module implemented with MapObjects that produces maps of geographic stand location and also serves for data interpretation and analysis.The research project involved designing process that involves a feasible and rapid way of using different tools to deal with forest fertilization management operations. It uses different software components within an integrated computer development environment, resulting in a state-of-the-art fertilization prediction tool. The system supports management decisions, and helps people involved in forest fertilization design and administer fertilization prescriptions in the Intermountain Northwest.",
    "author": [
      {
        "family": "Avila",
        "given": "Roberto Antonio"
      },
      {
        "family": "Moore",
        "given": "James A."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/925703",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "note": "AAI9813712",
    "publisher": "University of Idaho",
    "publisher-place": "USA",
    "title": "Methodology and design of a decision support system to predict tree growth response from forest fertilization",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3517428.3550408",
    "ISBN": "9781450392587",
    "URL": "https://doi.org/10.1145/3517428.3550408",
    "abstract": "Students with disabilities face numerous access barriers in higher education institutions. For example, many students struggle to receive the accommodations that they legally have a right to, and many course materials and tools are inaccessible (e.g., textbooks, required software, slide decks). Consequently, students with disabilities drop out of college at a higher rate than nondisabled students. In this dissertation, I aim to improve two core areas of inaccessibility for students with disabilities. First, I will learn about the common issues that arise when three stakeholders (disabled students, professors, and people working in disability service offices) work to fulfill technology-focused accommodations (e.g., slides, IDEs, lecture videos) for a student. Through this two part survey and interview/co-design study, I will develop design recommendations around how technology can better support this process. Second, I will apply techniques like optimization and natural language processing to build tools to identify and automatically repair common accessibility issues in a ubiquitous tool for teaching across departments: slide show presentations. By conducting this work, I will contribute software tools and design recommendations that will support disabled students in obtaining an accessible education.",
    "author": [
      {
        "family": "Mack",
        "given": "Kelly"
      }
    ],
    "collection-title": "ASSETS ’22",
    "container-title": "Proceedings of the 24th international ACM SIGACCESS conference on computers and accessibility",
    "id": "10.1145/3517428.3550408",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "accessibility, accommodations, disability, higher education, slideshows",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Accessible communication and materials in higher education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3341525.3387369",
    "ISBN": "9781450368742",
    "URL": "https://doi.org/10.1145/3341525.3387369",
    "abstract": "The literature on programming education describes different problems found in courses that introduce the basic concepts of Object-Oriented Programming (OOP). Some of these problems arise from the large amounts of abstract concepts that are needed even for the simplest programs. Other difficulties are related with the concepts of class and instantiation, and the duality between classes and objects. Educators and researchers have proposed several alternatives to define a gradual path for the introduction of OOP.A group of educators from several universities in the Buenos Aires area crafted a learning path for a first course about OOP in which the concepts of class and instantiation are introduced several weeks after the beginning of the course. Gradualism is achieved in this proposal by starting with a minimal metamodel based on self-defined objects, which is progressively enlarged. Following this learning path, by the time students are introduced to classes and instantiation, they already have a good acquaintance with object definition and interaction, and are also able to quickly understand the convenience of the new concepts.The same group conceived and developed a didactically-oriented programming language along with an IDE; and produced several exercises that can be solved using the initial metamodels.In this article, we discuss which concepts and language elements can be introduced before classes and instantiation, the need for a programming language that supports the proposed learning path, and the results of its application in several universities.",
    "author": [
      {
        "family": "Passerini",
        "given": "Nicolás"
      },
      {
        "family": "Lombardi",
        "given": "Carlos"
      }
    ],
    "collection-title": "ITiCSE ’20",
    "container-title": "Proceedings of the 2020 ACM conference on innovation and technology in computer science education",
    "id": "10.1145/3341525.3387369",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "CS0, CS1, CS2, educational tools, instructional approaches",
    "page": "152-158",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Postponing the concept of class when introducing OOP",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/SMC.2018.00599",
    "URL": "https://doi.org/10.1109/SMC.2018.00599",
    "abstract": "Debugging a program is always an obstacle to programmers and learners. In particular, novice programmers waste a lot of time finding bugs, so a feedback system to support debugging is required. Although existing editors and IDEs support finding syntax errors, their functions for detecting logical errors are limited. In the present paper, we present bug detection methods for the feedback system of an online judge system which contains many programming problems and accumulates numerous lines of solution source code. The proposed method uses the solutions and a language model based on long short-term memory (LSTM) networks for bug detection. In addition, since LSTM networks have some hyperparameters, we investigate the best model for bug detection in terms of perplexity and training time. The results of experiments show that models trained by solutions can detect bugs in a compiled code based on the static structure of a program.",
    "author": [
      {
        "family": "Teshima",
        "given": "Yunosuke"
      },
      {
        "family": "Watanobe",
        "given": "Yutaka"
      }
    ],
    "container-title": "2018 IEEE international conference on systems, man, and cybernetics (SMC)",
    "id": "10.1109/SMC.2018.00599",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "page": "3541-3546",
    "publisher": "IEEE Press",
    "publisher-place": "Miyazaki, Japan",
    "title": "Bug detection based on LSTM networks and solution codes",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-319-03889-6_23",
    "ISBN": "978-3-319-03888-9",
    "URL": "https://doi.org/10.1007/978-3-319-03889-6_23",
    "abstract": "In the region of Campania in south-west Italy there is growing evidence, including a World Health Organization (WHO) study of the region, that the accumulation of waste, illegal and legal, urban and industrial, has contaminated soil, water, and the air with a range of toxic pollutants including dioxins. An effective environmental monitoring system represents an important tool for an early detection of the environmental violations. The IDES Project is a Geo-environmental Intelligence System developed by the CIRA with the contribution of universities and other government bodies and it aims at implementing an advanced software and hardware platform for image, data and document analysis in order to support law enforcement investigations. The IDES main modules are: Imagery Analysis Module to monitor land-use and anthropogenic changes; Environmental GIS Module to fuse geographical and administrative information; Epidemiological domain Module; Semantic Search Module to discover information in public sources like: Blog, Social Network, Forum, Newspapers; This paper focuses on Semantic Search Module and aims to provide the greatest support to the extraction of possible environmental crimes collecting and analyzing documents from online public sources. Unlikely people denounce criminal activity to the authorities. On the other hand many people through blogs, forums and social networks every day expose the status of land degradation. In addition, journalists often, have given the interest of the public, documenting the critical environmental issues. All this unstructured information are often lost due to the difficulty to collect and analyse. The IDES Semantic Search Module is an innovative solution for aggregating of the common uneasiness and thoughts of the people able to transform and objectify the public opinion in human sensors for safety environmental monitoring. In this paper we introduce methods and technologies used in some case studies and, finally, we report some representatives results, highlighting innovative aspects of this applied research.",
    "author": [
      {
        "family": "Gargiulo",
        "given": "Francesco"
      },
      {
        "family": "Persechino",
        "given": "G."
      },
      {
        "family": "Lega",
        "given": "M."
      },
      {
        "family": "Errico",
        "given": "A."
      }
    ],
    "container-title": "Algorithms and architectures for parallel processing: 13th international conference, ICA3PP 2013, vietri sul mare, italy, december 18-20, 2013, proceedings, part II",
    "id": "10.1007/978-3-319-03889-6_23",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "keyword": "Illegal dumping, Landfills monitoring, interoperability, Text semantic search, Information retrieval, Geographical Information Systems",
    "page": "201-208",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "IDES project: A new effective tool for safety and security in the environment",
    "title-short": "IDES project",
    "type": "paper-conference"
  },
  {
    "ISBN": "0201719746",
    "abstract": "From the Book: The chaotic testing environment A project is in panic mode and the deadline is rapidly approaching. Management starts to think about the need to test this product, having already missed some prime opportunities for improving software quality. One unfortunate programmer is assigned the task of software testing, which is often viewed as being transferred to purgatory. Needless to say, this poor hapless soul is given no guidance, and nobody in the organization is capable of providing any help. Despite the poor condition of requirements and other product documentation, the product is being built and it will be shipped. The task given to the tester is to minimize the surprises that could manifest themselves after the product is installed at customer sites. Under extreme pressure, this untrained tester is very inefficient and is at a loss how to begin. A clueless manager may even purchase testing tools, despite there being no useful tests to automate. This is the scenario that gives software testing a bad name. Software testing is a specialized discipline requiring unique skills. Software testing is not intuitive; one must learn how to do it. Naı̈ve managers erroneously think that any programmer can test software if you can program, then you can test. This is the motivation behind this book: to provide a step-by-step approach for getting started with the testing effort. Many fine books on software testing are available today. Those that do address test case design describe proven methods such as boundary value analysis, equivalence class partitioning, decision tables, syntax testing, cause-effect diagrams, data-flow methods, and other suchconcepts. Some novice testers wonder how to weed though poor specifications, before even being able to apply these methods. Many texts state that good requirements are necessary for the test effort assuming that requirements exist yet I have not seen any that explain the transition from requirements to test cases. In the chaotic software development environment, adequate requirements are rarely provided, and if they are, their completeness and correctness are questionable. In a situation when no one has analyzed the requirements adequately, the burden falls on the tester to pursue requirements issues prior to defining any tests. It is often impossible to perform thorough testing, given the tight schedules and limited resources. It is possible, however, to make intelligent choices and maximize the effectiveness of the testing effort. The goal is to learn how best to approach the testing tasks and eventually produce a workable test process for future projects. The author’s philosophy To introduce the ideas on how to begin testing, I will work through several detailed examples, each containing defective \"requirements\". By definition, good requirements are testable and unambiguous. The fact that the sample requirements are deficient does not prevent useful test activities from occurring. I use the word \"requirements\" loosely and equate it with some sort of product description. While the sample test scenarios would not be permissible in a mature software organization, the work described will help the lone tester jumpstart the testing process under duress. The goal is to show that some product information, however deficient, can be used to start the testing effort. I do not advocate working from poor requirements. Properly analyzing requirements corrects many deficiencies. Reviews and inspections have been proven to provide the most cost effective method for finding problems early in the development cycle. Many times, I have had to bite my tongue to avoid blurting out to project managers, \"The requirements are absolute garbage and there’s no way that we can begin a productive testing effort until you clean up your act.\" Actually, this phrase would contain unprintable language and be uttered under one’s breath. We have undoubtedly all shared this fantasy, and the ugly truth is that despite this valid complaint, the product delivery deadline is fast approaching. Although I do not advocate cutting corners, there are some shortcuts that will help document the testing activities. A crude list of tests is better than no list. The minimum you will have is a documented trail, though rudimentary, that records your testing effort should you need to prove or demonstrate what you did. Subsequent testing efforts will improve on this initial work, producing test documents and developing a test process that is more in line with accepted practices. Incremental changes lead to successful process improvements. Just knowing how to get started with testing is a feat in itself. The tester must understand how to transform product information into test cases; this is the book’s chief goal. Many existing books do an outstanding job of explaining software testing concepts and methods. Rather than reiterate what others have written, I make many references to their work. This book is a primer on getting started. It supplements currently available literature on software testing by providing an introduction to known software testing techniques. Intended audience This book is aimed at several types of readers: persons new to software testing who have no guidance or training; managers or mentors, who may themselves be experienced testers, seeking ideas on how to provide guidance to novice testers; experienced programmers who have been assigned testing tasks; knowledgeable testers looking for new ideas. While readers are not assumed to be knowledgeable about software testing concepts, they should be computer literate and able to use a word processor and spreadsheet. Job descriptions The general job description terms used throughout the book are as follows: Tester: The person who defines and executes tests. Developer: The person who produces the application, including the design, source code, and final product integration. Project manager: The person with authority regarding schedules and staffing. Project authority: The domain expert with authority to define and clarify the requirements. I refer to these descriptive titles without implying an organization structure or employee reporting chain. Project staffing decisions and job responsibilities vary across organizations. Depending on how the project is staffed, the tester could be either in the same or in a separate group from the developer. Other projects could require that the same person performs both development and t changing mindset in mid-project. Ideally, a trained software test engineer performs the testing activities. However, some projects simply assign the testing role to whichever person is available. The project authority can be the marketing manager, company executive, or customer support liaison, provided that this person has full authority to define the project contents. This role is necessary to prevent further chaos. Someone must be in charge of deciding which features to incorporate into a product; lack of such control is a well-known cause of problems when trying to get bad requirement definitions sorted out. Your organization may use different job titles than those listed above. The key point is to assign people to perform the necessary tasks each of which requires specialized skills. Mature and immature software development environments The examples cited in this book, with their incomplete product information, are what one could expect to find in an immature software organization. I will refrain from critiquing the work environment and from preaching about software process improvement. The reality is that many companies operate under less than ideal conditions. Despite the lack of suitable software processes, products are still being developed and shipped to customers. Testing, however minimal, can still be done. With poor requirements, the tester spends more time identifying product definition deficiencies rather than proceeding with testing-related tasks. A mature software organization displays the characteristics listed below. An immature organization often does not understand how the following points can improve product quality: provide useful requirements and product descriptions; conduct reviews and inspections; have signoffs or checkpoints before proceeding to the next step; mentor and train personnel; schedule adequate time and resources for testing; overlap testing and development activities; provide defined software development and software testing processes; enforce configuration management. Testing is a responsibility shared with the rest of the development team. The old view of testing as an afterthought design, code, and then you test has never produced good testing results. The adversarial and destructive \"developer vs tester\" mentality has often resulted from the developers’ ignorance about software testing activities more proof that testing is a unique discipline. It is often the case that a tester often knows more about programming than a developer knows about software testing. A collaborative approach between testers and developers fosters goodwill and good communication. By working closely with the testers, many developers learn more about software testing, even if all the developers see is how their knowledge about the product filters into the test documentation. Effective software testing requires co-operation among all the members of a project. Book overview Chapter 1 deals with the unfortunate \"you’re new to testing, have no idea where to start, and the product ships Friday\" nightmare. Hoping that your next project gives you more time to carry out testing activities, Chapter 2 illustrates the use of outlines, which is al analyzing requirements if no one else has done this task. Chapter 3 transforms the outline contents into test cases. Tables and spreadsheets are an integral tool used by software test engineers, and Chapter 4 shows several table formats and shortcuts for documenting test cases. Chapter 5 shows additional usages of tables. Applications built using object-oriented methods can use many of the same test design techniques outlined in the previous chapters. However, Chapter 6 describes some issues particular to testing object-oriented systems. Chapter 7 lists the challenges faced when testing web applications, although many of the strategies presented apply equally to client-server environments. No uniform software testing method exists. Each example uses a different approach for producing tests. You may wonder why one method was used in one example instead of another. The answer is simple: I selected a method based on my experience. You may very well try a different approach that will be just as successful in your testing effort. Although the examples cover different types of applications, the core software testing themes apply equally to all examples, and some concepts are reiterated among all chapters. I recommend that you read through each scenario and not dismiss the subject simply because the example does not reflect your type of application. By following the ideas and methods presented, you will have defined and documented many test cases. Chapter 8 will help you identify the most pertinent tests and thus reduce the necessary number of test cases to execute. Producing a set of test cases to execute is only part of the overall software testing picture. Chapter 9 lists other testing and quality related tasks that are necessary for producing quality software. If this is the organization’s first venture into methodical software testing, you will have established a good baseline. Although the work produced will be a vast improvement over prior chaotic efforts, it will fall short of satisfying, and conforming to, industry standards. Chapter 10 briefly describes some of the more common software engineering standards and how each affects the test case examples. Consider this a launching point for improving the testing effort.",
    "author": [
      {
        "family": "Tamres",
        "given": "Louise"
      }
    ],
    "id": "10.5555/515475",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Introducing software testing: A practical guide to getting started",
    "title-short": "Introducing software testing",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "This poster presentation summarizes the major pedagogical innovations of the TeachScheme!, ReachJava approach, reports on the results of our past faculty workshops (particularly the adoption of our approach by respected colleges, universities, and high schools), and invites visitors to a free (NSF-funded) faculty workshop in Summer 2010. Several textbooks and other instructional materials using this approach, e.g. (Bloch, 2010), (Felleisen F. F., 2008), (Felleisen F. F., 2010), (Felleisen F. F., 2001), (Sperber, 2009) will be available for examination.A first course in computer programming should not be about the current \"hot\" language in industry – which may be obsolete by the time today’s freshmen graduate – but rather about lasting, transferable concepts and practices of good programming. Yet beginning programming students spend much of their time wrestling with the language, and often mistake that as the subject of the course. The programming language distracts from the course material; on the other hand, students need a real language to write real programs that really run on real computers.We resolve this dilemma by starting in a language with simple, consistent syntax and semantics, currently a subset of Scheme (omitting I/O, assignment, sequence, higher-order functions, and local definitions). Our pedagogically-oriented IDE enforces this subset, and gives error messages appropriate to the current subset, but allows students as they outgrow each subset to advance to a larger one with a few mouse clicks. Students become comfortable with fundamental programming concepts — variables, function composition, function definition, parameter passing, data types, design for reuse and modifiability, conditionals, fields, polymorphism, self-reference and recursion, functional abstraction, event-driven programming, model/view separation, etc. — in this sheltered environment before encountering the same concepts in the more bewildering world of Java, C++, etc.Simultaneously, students are trained in a step-by-step design recipe for software development: a series of concrete questions, with concrete products at each stage:1) Identify the purpose, inputs, and outputs of the program (function, method, whatever) to be written;2) Identify (and, if necessary, define) data types relevant to the problem at hand;3) Write examples or test cases of how the program will be invoked, in legal syntax and accompanied by expected results, using the data types from step 2 as a guide;4) Write a program skeleton, the syntax to define a function with the name and parameters chosen above;5) Write an inventory of available and likely-to-be-needed expressions, based on parameter names and their data types;6) Choose and combine items from the inventory to form a complete program body (the hardest part, but in practice step 5 often does most of the work);7) Test the program by running it on the examples from step 3.We emphasize data types throughout, not only as a fundamental concept, but as an invaluable tool in coding: to every data type correspond both a natural coding pattern, which provides a rough draft of the code and helps students avoid \"blank page syndrome\", and a natural testing pattern, which provides guidance in building test suites. In particular, recursion is introduced as simply the application of already-learned coding patterns to a self-referential data type. The concrete methodology also provides a handy grading rubric that shows students that every step matters, not only the coding.For non-majors, we aim to convey important programming concepts and methodology in one language. For CS majors, the course switches from Scheme to Java late in the first semester or between first and second semesters. The Java stage is not independent, but builds on and reinforces the programming concepts and methodology already learned in Scheme, with explicit discussion of similarities, differences, and the continued applicability of the concepts and methodology. Students learn to apply the same test-driven, step-by-step design recipe in Java that they’ve been using in Scheme. The result is a student who, after a year of coursework, can approach programming problems in a principled manner (not \"hack it until it works\"), with understanding and perspective.Although we currently use Scheme as a first language and Java as a second, the approach is applicable to other languages. Whatever the language, however, we believe the first exposure to programming should be functional rather than imperative/sequential/procedural: not only do functional programs have simpler semantics, relying on the familiar model of algebraic expression evaluation rather than a load/store machine model, but it’s enormously easier to write test cases for functional programs than for stateful ones. Stateful testing, along with stateful programming, can be introduced late in the first semester after students have thoroughly internalized functional techniques.Our approach has been adopted at a number of colleges and universities, including Rice, Northeastern, the University of Chicago, Northwestern, the University of Utah, Cal. Poly San Luis Obispo, Vassar College, and the University of Delaware, as well as dozens or hundreds of high schools. We’ll be offering free (NSF-funded) one-week workshops in Summer 2010 at four locations around the U.S.",
    "author": [
      {
        "family": "Bloch",
        "given": "Stephen"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1791129.1791170",
    "issue": "6",
    "issued": {
      "date-parts": [
        [
          2010,
          6
        ]
      ]
    },
    "page": "218-220",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Teachscheme, ReachJava: Introducing object-oriented programming without drowning in syntax: Poster session",
    "title-short": "Teachscheme, ReachJava",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Programming is learned through practice, with said practice in introductory programming courses often translating to a prohibitively large number of assignments, increasing the grading workload for faculty and/or teaching assistants. In short, this is unsustainable. Several publishers and a few notable companies have provided meritable solutions, although most are plagued with problems including minimal problem sets, limited customization options, high cost, and even a disconnect with the pedagogical needs within academia. This paper presents a survey of the more popular solutions currently available, followed by a presentation of our newly-developed web application, MOCSIDE: open-source and scalable online IDE and auto-grader for computer science education.",
    "author": [
      {
        "family": "Barlow",
        "given": "Max"
      },
      {
        "family": "Cazalas",
        "given": "Ibraheem"
      },
      {
        "family": "Robinson",
        "given": "Chase"
      },
      {
        "family": "Cazalas",
        "given": "Jonathan"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/3512733.3512734",
    "issue": "5",
    "issued": {
      "date-parts": [
        [
          2021,
          10
        ]
      ]
    },
    "page": "11-20",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "MOCSIDE: An open-source and scalable online IDE and auto-grader for introductory programming courses",
    "title-short": "MOCSIDE",
    "type": "article-journal",
    "volume": "37"
  },
  {
    "DOI": "10.1145/3036686.3036691",
    "URL": "https://doi.org/10.1145/3036686.3036691",
    "abstract": "The e-Yantra robot is the basis for a highly scalable embedded systems teaching program setting up 500 embedded systems labs in Indian engineering colleges. A key strategy to encourage rapid prototyping of applications has been to encourage reuse of code using a commodity robot with a standard API along with excellent documentation and training material. An important challenge has been to teach the reasoning process from a design through to an implementation deployed on an actual machine. Model based design is key to articulating such reasoning. A further challenge is to do this in an affordable manner where most available model- based IDEs are expensive proprietary systems using languages such as Esterel and SCADE. We illustrate with a \"Valet Parking\" application how our robotic eco-system facilitates the learning of important model-based design principles taking a high-level specification of a problem down to working code and even deriving test cases in the process. A novel feature of our approach is that we carry out design-time scheduling of various (concurrent) activities by analyzing dependencies between modules and obtain purely sequential C-code implemented on a microcontroller without the need for an RTOS. This case study is an exemplar of a model-based design approach for a large class of such robotic projects.",
    "author": [
      {
        "family": "Arya",
        "given": "Kavi"
      },
      {
        "family": "Coelho",
        "given": "Blossom"
      },
      {
        "family": "Pandya",
        "given": "Shraddha"
      }
    ],
    "container-title": "SIGBED Rev.",
    "id": "10.1145/3036686.3036691",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2017,
          1
        ]
      ]
    },
    "keyword": "UML, design time scheduling, educational robot, model based design, model based testing, project based learning, state machines",
    "page": "37-43",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A model based design approach to system building using the e-yantra educational robot",
    "type": "article-journal",
    "volume": "14"
  },
  {
    "DOI": "10.1145/2828959.2828972",
    "ISBN": "9781450340205",
    "URL": "https://doi.org/10.1145/2828959.2828972",
    "abstract": "Empirical studies revealed that computer science and engineering students have difficulty in mastering concepts such as interfaces and information hiding. These concepts are central to component-based software engineering (CBSE), a challenging subject to address in a university course, given that some degree of software development complexity is necessary for effectively practicing it. This paper describes an experiment carried in an advanced programming course offered at our institution, consisting of having a collaborative course project targeting the practice of CBSE. In this collaborative project, different student teams developed parts of an IDE whose designs were tested by other teams in terms of component interoperability and extensibility. Although students were able to practice the CBSE-related concepts in approximate real settings, the necessary technical supervision from instructors might consist of a pitfall.",
    "author": [
      {
        "family": "Santos",
        "given": "André L."
      }
    ],
    "collection-title": "Koli calling ’15",
    "container-title": "Proceedings of the 15th koli calling conference on computing education research",
    "id": "10.1145/2828959.2828972",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "IDEs, collaborative learning, component-based software engineering, pedagogy",
    "page": "142-146",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Collaborative course project for practicing component-based software engineering",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3478432.3499125",
    "ISBN": "9781450390712",
    "URL": "https://doi.org/10.1145/3478432.3499125",
    "abstract": "Programming is learned through practice, with said practice in introductory programming courses often translating to a prohibitively large number of assignments, increasing the grading workload for faculty and/or teaching assistants. In short, this is unsustainable. Several publishers and a few notable companies have provided meritable auto-grading solutions, although most are plagued with problems including minimal problem sets, limited customization options, high cost, and at times even a disconnect with the pedagogical needs of academia. This poster presents our newly-developed web application, MOCSIDE, an open-source and scalable online IDE and auto-grader for computer science education. Results indicate a positive user experience from students and instructors alike, with cost savings, ease of use, and code collaboration highlighted as key features.",
    "author": [
      {
        "family": "Cazalas",
        "given": "Jonathan"
      },
      {
        "family": "Barlow",
        "given": "Max"
      },
      {
        "family": "Cazalas",
        "given": "Ibraheem"
      },
      {
        "family": "Robinson",
        "given": "Chase"
      }
    ],
    "collection-title": "SIGCSE 2022",
    "container-title": "Proceedings of the 53rd ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3478432.3499125",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "auto-grading, computer science education, cs1, cs2, online ide",
    "page": "1114",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "MOCSIDE: An open-source and scalable online IDE and auto-grader for computer science education",
    "title-short": "MOCSIDE",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130213438",
    "abstract": "From the Book: PREFACE: The day C. J. Buck Trayser of Digital Equipment Corporation suggested that I become certified to teach Microsofts Visual Basic course was a major turning point in my career. The last time I had used the BASIC programming language was when I was working on an extra-credit project while pursuing a degree in Computer Science in 1976. The program was to run on a DEC PDP-8 and had to be saved on paper tape. I was trying to write a program that played backgammon, but ran out of memory after creating routines to make an opening move from an openings book and drawing the board on a character cell terminal. Now, nearly fifteen years later, I had considered myself a seasoned C and C++ programmer, and was on a contract assigned to teach VMS programmers how to call System Services using the C programming language. If Buck had not been such a good friend and respected colleague, I may have laughed at his suggestion. But he convinced me that becoming certified to teach Visual Basic 3.0 would be a good business decision - the demand for such training was skyrocketing. I have since taken quite a liking to Visual Basic, and have used the language in developing corporate applications for many of my customers, often combining it with Visual C++. Its appeal stems from its many interesting attributes. For one, Visual Basic is amazingly easy to use, and is probably responsible for making many new programmers out of folks who were once just users. It is quite non-intimidating to approach, yet can end up challenging the most experienced programmer due to its rich feature content. It reminds me of what is printed on the box of MasterMind, a game in which one attempts to guessacolor code created by an opponent - A minute to learn, a lifetime to master. I thought of Buck again when Andrew Scoppa suggested that I write a book on developing distributed applications with Visual Basic. My affiliation with Andrews company, UCI Software Training Centers, goes back over 16 years, and my respect for him is immense. As a quality provider of developer training, I take any suggestions Andrew makes quite seriously. Of course, at the time Buck suggested I look into Visual Basic, its features were not quite rich enough to develop distributed applications. But that has changed. The Evolution of Visual Basic As a language for developing Windows dialog-based user interfaces, Visual Basic is in its original element. As a teaching language, Visual Basic is ideal for illustrating not only Windows user interface programming concepts, but topics related to modular software development, code reuse, data scope, and even object-oriented design and programming techniques. For testing COM objects developed in C++ and ATL, Visual Basic offers the quickest solution. The popularity of Visual Basic is no doubt responsible for its evolution from a graphical user interface development tool to an advanced, high-performance application development environment. Its ease of use, data access capabilities, multi-threading conformance, COM compliance, and native code generation capabilities now make it an excellent choice for the rapid development of the server-hosted business components of a distributed application. Having taught Visual Basic to developers for a number of years, I am beginning to see the language finally receive the respect it deserves. With over 20 years of software development experience and a degree in Computer Science, I feel qualified to author a book that treats Visual Basic with the same kind of respect. About This Book This is a book for serious developers of distributed applications. While it is, strictly speaking, an intermediate-level book, I expect the reader to be an experienced programmer. The main theme of this book is to get you started with the development of distributed applications using Visual Basic in the quickest way possible. I have provided complete examples of both 2-tier and 3-tier applications - these applications have thousands of lines of Visual Basic code. Complementing these complete applications are dozens of small demos that illustrate one or two important concepts. While instructions for running these demos are included in the chapters that follow, you should check the README.TXT file on the enclosed CD-ROM for additional and last-minute information regarding the use of the demos. Probably the most unusual thing about this book is that I start with a chapter on deploying multi-tiered distributed applications. This approach has worked well in the classroom when I teach my courseware, and I expect the same results in this book. Since many of the demos used in later chapters depend on the sample applications being installed, it is essential that you read the first chapter and go through the installation procedures. In Chapter 2, I discuss how to use objects from a Visual Basic application, using the sample video store objects provided with this book. Even if you are familiar with using COM objects in a Visual Basic application, you should read this chapter. The chapter may seem like a show-and-tell for an existing application, but it provides good examples of object design and documentation. In Chapter 3, I cover how to develop Win32 user interface applications that use COM objects. In addition to providing more examples of object use, the chapter is an excuse for me to introduce some advanced user interface techniques. In this chapter, you will learn how to use the Windows registry, display a splash screen, use OLE drag-and-drop, and use advanced user interface controls such as the tree view, list view, tab strip, and toolbar controls. My advanced Visual Basic students often ask to see how to use these controls and techniques in their programs. I consider Chapter 4 to be the paying your dues chapter. In earlier days, programmers had to use APIs such as the TCPIP socket API to develop distributed applications. The Windows platform SDKs and developer tools such as Visual Basic have made the creation of distributed applications much easier. If you are pressed for time, you can skip Chapter 4. As an essential and fundamental introduction to developing the middle tiers of a distributed application, Chapter 5 is required reading. This chapter introduces Activex Data Objects (ADO), showing both their programmatic use and their use through the new ADO Data Control. Additionally, the chapter explains Data Environments and how to create programs that generate reports from a database. Chapters 6, 7, and 8 are all about objects. First, I cover the use of class modules in Visual Basic, then move to their use in creating Activex Components. Finally, the internals of COM, the Component Object Model, are revealed in more detail than the typical Visual Basic developer would probably want - but more is better than less! If you are familiar with using class modules in Visual Basic, you can skip Chapter 6, but since some of the examples in Chapter 7 extend concepts presented in Chapter 6, it may be better to skim it rather than skip it. In Chapter 9, I provide all you will need to know, and then some, about creating Activex Controls in Visual Basic. Although their development and use is, strictly speaking, not required in a distributed application, it is one of the most popular and requested topics of my students. If you wish, you can skip this chapter. Interesting uses of COM are presented in Chapter 10, which covers automation fundamentals. In this chapter, youll learn how to develop Visual Basic applications that launch and control other applications. Youll also learn how to add an automation interface to your own applications so that other programs can control yours. Its a short chapter, and one of my favorite topics, so I suggest you read this one. A fundamental and hands-on introduction to DCOM, the Distributed Component Object Model, is presented in Chapter 11. Reading this chapter and performing the walkthroughs will give you a solid introduction to DCOM, as well as an appreciation for the features provided by Microsoft Transaction Server (MTS). The serious distributed application developer will want to read and understand this chapter. Based on my experience, I am quite certain that many of you purchased this book for the topic covered in Chapters 12 and 13 - using MTS. For over a year now, I have often entertained myself by seeing the reaction of students when I ask, How many of you are interested in learning about MTS Even people who have never raised their hands in public since the third grade eagerly raise one, if not both arms, often adding a vigorous circular motion. It goes without saying that youll want to read both of these chapters. One of the strongest objections to using a distributed approach to software development is the inherent difficulty in maintenance and troubleshooting - How would you debug that thing In Chapter 14, I attempt to show you that it is not that hard to maintain a distributed application. Additionally, I provide information about the often-dreaded binary compatibility features of Visual Basic. This chapter is essential reading for the serious developer. Entire books have been written on the topic covered in Chapter 15 - creating Internet interfaces using Active Server Pages (ASP). I have purposely kept this chapter light, because I never really bought into the concept of mixing a program (e.g., script) with graphic content (e.g., HTML). Certainly there are thousands of developers who love this sort of thing, and are capable of creating interesting Web pages while also providing the programming behind them. The chapter goes a bit beyond getting you started, and I would consider it to be required reading, if only because chances are the existing Web applications you now have were implemented as ASP pages. A far better approach to developing Web applications was introduced in Visual Basic 6.0, and is the subject of Chapter 16 - creating Internet IIS applications. This new approach allows an applications programmer to program applications and a graphics designer to design graphics. I highly recommend reading this chapter thoroughly. In Chapter 17, I introduce Activex Documents, which many Visual Basic developers are likely to find as appealing solutions for intranet development. While their reach is limited, due to browser compatibility, if you dont need broad reach capabilities for your intranet application, Activex Documents are at least worth a look. Wrapping up the book is Chapter 18, in which you will learn how to use the Internet Transfer and Web Browser controls. In this chapter, you will see how to embed browser capabilities directly in your Visual Basic application, and automate file transfers via FTP. Acknowledgements I have quite a list of people to thank for assistance in writing this book. First, I want to thank Buck Trayser of Digital Equipment Corporation for persuading me that learning Visual Basic would be a good thing. I must also thank Cheryl Jacobs and Tony Todd of M&amp;MMars, great customers of mine, for asking that I do a course on Visual Basic 3.0. That course turned out to be the start of a total of eight courses I developed covering Visual Basic from its fundamentals to its advanced features. Certainly this book would not have been possible without the help of Andrew Scoppa and Donna Thayer of UCI Software Training Centers in Stoneham, Massachusetts. As a senior consulting partner with UCI, I have enjoyed working with Andrew and Donna for nearly 16 years. In my opinion, they offer the best developer training anywhere. Thanks to Dave Libertone, also of UCI, for his help on this book - as a published author himself, he was a great pathfinder for me. Dave provided me with a terrific opportunity to get my feet wet as an author when I wrote a short chapter for his excellent book Windows NT Cluster Server Guidebook, also published by Prentice Hall. In addition to being a great friend, Daves technical advice is always as good as gold. Claudio Ghisolfi and Kay Connolly, also of UCI, deserve a great deal of credit for this book as well. I want to especially thank Claudio for his patience and determination in examining the demos and walkthroughs presented in this book. Thanks to the excellent instructors who have used my courseware and provided feedback on errors, omissions, and suggestions, especially Karen Gallagher and Andy Macentee. Thanks also to Art Kane and Olivia Kane of AmeriteachUCI, Chip Hillman, Ed Stepian, and Debby Stepian of the Orange County Sheriffs Office; Mary Anne Vaughn of Microsoft Corporation; Melody Glover at the Kennedy Space Center; Michael Gorman and Dominic Vergata of Avon Corporation; Rick Wallace and Vicki Kyle-Flowers of Digital Equipment Corporation; Mike Meehan of Prentice Hall; Bob Barnes of Allen-Bradley; and Jim Slate, Bruce Kepley, and Ken Kelly. Also, I want to give a very big thank you to Robin at Sir Speedy. Thanks to everyone at the Clearwater Research Group for providing the fresh academic and research environment that one needs to experiment with new technologies such as those discussed in this book. The many students I have had the pleasure of teaching have helped a great deal with their comments and suggestions. In particular, I want to thank Connie Patton and everyone at Liberty Mutual; Rich Lagasse at Mathworks; Michael Joy at Sensitech; and Daniel Bagley. Kasey, Tracy, Mary, and James, my children, deserve credit for their support. I wish to mention James in particular, a freshman at the University of Florida, for his fantastic job of data entry for the Mom-n-Pop Video Store database, and for providing me with the excellent opening paragraph of Chapter 16. Lastly, and most of all, I cannot begin to thank Patty, my wife, for her support, encouragement, faith, and companionship during the development of this book and the courses that preceded it, and for all the errands, big and small, she ran for me, and for the excellent job she has done keeping the household running while I wrote this book. Without Patty, this book would literally have not been possible, especially since she helped me through a scare in which I thought the entire book was lost on my laptop - Patty found the hidden reset button on my ThinkPad! Jim Maloney, MCSD, MCT Honorary Research Fellow, Clearwater Research Group St Petersburg, FL, November 1998",
    "author": [
      {
        "family": "Maloney",
        "given": "Jim"
      }
    ],
    "id": "10.5555/553639",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "publisher": "Prentice-Hall, Inc.",
    "publisher-place": "USA",
    "title": "Distributed COM: Application development using visual basic 6.0",
    "title-short": "Distributed COM",
    "type": "book"
  },
  {
    "DOI": "10.1145/3548771.3570193",
    "ISBN": "9781450394543",
    "URL": "https://doi.org/10.1145/3548771.3570193",
    "abstract": "Writing good software tests is difficult and not every developer’s favourite occupation. If an activity is so difficult, boring, or otherwise unattractive that people do not want to engage with it, then gamification offers a solution: By turning the activity into a fun and competitive task, participants engage, compete, and excel. In this talk, I will explore how this idea can be integrated into software testing tools (e.g. IDEs), processes (e.g. continuous integration), and education. Our experiences with gamified testing illustrate the potential of using gamification to address some of the many problems that we are facing today in software testing. There are, however, many challenges ahead, and I will outline some of the challenges and research opportunities related to gamifying software testing.",
    "author": [
      {
        "family": "Fraser",
        "given": "Gordon"
      }
    ],
    "collection-title": "Gamify 2022",
    "container-title": "Proceedings of the 1st international workshop on gamification of software development, verification, and validation",
    "id": "10.1145/3548771.3570193",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "page": "1",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Gamifying software testing (keynote)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3287324.3293867",
    "ISBN": "9781450358903",
    "URL": "https://doi.org/10.1145/3287324.3293867",
    "abstract": "Prior education research, including Computer Science, has established that students will attempt to cheat and violate academic integrity, with one of the more common forms being code plagiarism. The majority of existing tools for software plagiarism are closed source, requiring instructors to use them in a prescribed configuration and sending student code to a third-party server for analysis. At the core of this analysis is the need to perform a language-specific tokenization of the input program and then to use \"digital fingerprinting\" on the code to identify significant markers. This has required developers to write their own parser for each supported language, which is time-consuming to create and keep up-to-date, and thus a barrier to creation of these tools. Instead we bootstrap new languages into our plagiarism system by leveraging the \"Language Server Protocol\", an initiative to create open-source parsers and tokenizers for many languages (principally to be used within a range of popular IDEs). In this poster, we present our work on Lichen, the open source plagiarism detection tool that is integrated into the Submitty course management platform we use at Rensselaer Polytechnic Institute. This tool is a pipeline of modules for the specific tasks of tokenizing, fingerprinting, and then comparing the fingerprints for any number of files. Through this, a similarity score is generated for pairs of files, and these are used to help instructors determine to what extent code plagiarism has occurred.",
    "author": [
      {
        "family": "Peveler",
        "given": "Matthew"
      },
      {
        "family": "Gurjar",
        "given": "Tushar"
      },
      {
        "family": "Maicus",
        "given": "Evan"
      },
      {
        "family": "Aikens",
        "given": "Andrew"
      },
      {
        "family": "Christoforides",
        "given": "Alexander"
      },
      {
        "family": "Cutler",
        "given": "Barbara"
      }
    ],
    "collection-title": "SIGCSE ’19",
    "container-title": "Proceedings of the 50th ACM technical symposium on computer science education",
    "id": "10.1145/3287324.3293867",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "code plagiarism, lichen, plagiarism",
    "page": "1270",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Lichen: Customizable, open source plagiarism detection in submitty",
    "title-short": "Lichen",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3159450.3162207",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3162207",
    "abstract": "Parsons Problems is an effective Introductory Programming teaching tool that allows students to arrange code to form a functional program, reducing their cognitive load so they can focus on programming concepts. This demonstration shows how Parsons Problems can be used as a pedagogical strategy in a Massive Open Online Course (MOOC) for introductory programming. A MOOC is a learning platform, where compilers and IDEs have already been embedded for CS students to immerse themselves in a single learning environment. The Parsons Problems package, js-parsons, available at https://github.com/js-parsons/js-parsons has been successfully integrated into the University of Adelaide’s edX’s MOOC platform as a component that can potentially be made available for other edX platforms. The demonstration presents the educators’ interface to add new questions and receive students’ results, along with students’ perspective, including subgoals. The demonstration prototypes new feedback models when students encounter Parsons Problems errors, opening discussion up to the audience for opinions and input. This demonstration is intended for anyone wanting to know how to use Parsons Problems within MOOCs as a pedagogical approach; those seeking to incorporate MOOCs into their coursework with focused exercises; and those wanting to contribute to future Parsons Problems enhancements. Laptops are recommended, since participants will have the hands-on opportunity to evaluate the package during the demonstration.",
    "author": [
      {
        "family": "Garcia",
        "given": "Rita"
      },
      {
        "family": "Falkner",
        "given": "Katria"
      },
      {
        "family": "Vivian",
        "given": "Rebecca"
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3162207",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "introductory programming, mooc, parsons problems",
    "page": "1111",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Parsons problems usage within a MOOC pedagogy: (Abstract only)",
    "title-short": "Parsons problems usage within a MOOC pedagogy",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3328778.3372701",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3372701",
    "abstract": "Due to the increased demand for computer scientists in the, the importance to improve the retention rate of CS majors who could potentially fill such positions has been ongoing. Literature has produced many efforts for increasing the engagement of CS majors in the field while also exploring ways to improve their ability to develop the ideal skill sets for success. In such efforts, our research explores the impact of visual and/or command-line based programming editors and their ability to shape the students’ mental model as they learn to program. This abstract discusses a \"think-aloud\" protocol assessment that was conducted on two entry level programming courses at a university in the United States during the 2018-2019 school year. The objective of this assessment was to determine whether Repl.IT, a web-based IDE, and Cygwin/Nano Editor, a command line-based tool, impacted student performance while being used for programming. Our preliminary results showed that 41",
    "author": [
      {
        "family": "Cooper",
        "given": "Saraah"
      },
      {
        "family": "Clinkscale",
        "given": "Ben"
      },
      {
        "family": "Williams",
        "given": "Briana"
      },
      {
        "family": "Lewis",
        "given": "Myles"
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3372701",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "cs-majors, programming-editors, verbal-protocol-assessment",
    "page": "1422",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring the impact of exposing CS majors to programming concepts using IDE programming vs. Non-IDE programming in the classroom",
    "type": "paper-conference"
  },
  {
    "DOI": "10.14778/3554821.3554836",
    "ISSN": "2150-8097",
    "URL": "https://doi.org/10.14778/3554821.3554836",
    "abstract": "Blueprint is a declarative domain-specific language for document extraction. Users describe document layout using spatial, textual, semantic, and numerical fuzzy constraints, and the language runtime extracts the field-value mappings that best satisfy the constraints in a given document.We used Blueprint to develop several document extraction solutions in a commercial setting. This approach to the extraction problem proved powerful. Concise Blueprint programs were able to generate good accuracy on a broad set of use cases. However, a major goal of our work was to build a system that non-experts, and in particular non-engineers, could use effectively, and we found that writing declarative fuzzy constraint-based extraction programs was not intuitive for many users: a large up-front learning investment was required to be effective, and debugging was often challenging.To address these issues, we developed a no-code IDE for Blueprint, called Studio, as well as program synthesis functionality for automatically generating Blueprint programs from training data, which could be created by labeling document samples in our IDE. Overall, the IDE significantly improved the Blueprint development experience and the results users were able to achieve.In this paper, we discuss the design, implementation, and deployment of Blueprint and Studio. We compare our system with a state-of-the-art deep-learning based extraction tool and show that our system can achieve comparable accuracy results, with comparable development time, for appropriately-chosen use cases, while providing better interpretability and debuggability.",
    "author": [
      {
        "family": "Mishchenko",
        "given": "Andrey"
      },
      {
        "family": "Danco",
        "given": "Dominique"
      },
      {
        "family": "Jindal",
        "given": "Abhilash"
      },
      {
        "family": "Blue",
        "given": "Adrian"
      }
    ],
    "container-title": "Proc. VLDB Endow.",
    "id": "10.14778/3554821.3554836",
    "issue": "12",
    "issued": {
      "date-parts": [
        [
          2022,
          8
        ]
      ]
    },
    "page": "3459-3471",
    "publisher": "VLDB Endowment",
    "title": "Blueprint: A constraint-solving approach for document extraction",
    "title-short": "Blueprint",
    "type": "article-journal",
    "volume": "15"
  },
  {
    "DOI": "10.1145/7902.214916",
    "ISSN": "0001-0782",
    "URL": "https://doi.org/10.1145/7902.214916",
    "abstract": "The articles presented in our Special Issue on parallel processing on the supercomputing scale reflect, to some extent, splits in the community developing these machines. There are several schools of thought on how best to implement parallel processing at both the hard- and software levels. Controversy exists over the wisdom of aiming for general- or special-purpose parallel machines, and what architectures, networks, and granularities would serve these best. The efficiency of processing elements that are loosely or tightly coupled is still in question. And, in the software amphitheatre, there is debate over whether new languages should be written from scratch, whether old languages should be modified into parallel processing dialogues, or whether investments in old, sequential programs should be leveraged by recompiling them into parallel programs.These issues were readily apparent at this year’s International Conference on Parallel Processing (ICPP), as they have been during the 15 years since the annual conference first met. Few expect resolutions to these questions within the next 15 years, which is not to say that these subfields are not progressing rapidly; quite the contrary. As we now see, an outpouring of recent commercial unveilings of both super and supermini parallel processors represents the expected potpourri of design philosophies.Related to the general- versus special-purpose issue is the direct, applications-oriented question: What do parallel processor architects expect their machines to be used for? And, taking this a step further, what would they like to see next-generation machines, with one hundred times more speed and memory, do? I asked ICPP attendees and other computer scientists these questions. Many answered straightforwardly that they see simulation as the main application now and in the future. Others deflected the question. Said one such architect quite flatly, \"I just build the things. You’d be better off asking users.\" Yes and no; I wanted to know what was on architects’ minds. Why were their imaginations so dry? But then others plunged in quite daringly, answering at a completely different level as reported below. Perhaps the range of all responses reflects differences in priorities that are to be expected in a young field in flux. Some of their thoughts convey that they are somewhat overwhelmed by new choices and freedoms. It seems that the advent of parallelism may be more than just the beginning of a new era within computer science. \"Historically, computer scientists have been unable to predict many of the uses of faster machines,\" says DARPA/Information Science Technology Office Program Manager Stephen H. Kaisler, \"because each such machine opens up new regimes of computing to explore.\" Indeed, parallel computing itself—not just its promise of improved speed—is all at once exposing new, unforeseen possibilities: a wide vista of architectures, languages, and operating systems. \"To date, we’ve been playing around with a very limited range of these, but now many novel, promising combinations are within our grasp,\" says George Adams, a research scientist at the Research Institute for Advanced Computer Science who is studying parallel processors for NASA Ames Research Center. Until recently, the technology was not advanced enough to create a machine with large numbers of processing elements, for example. Today, says Adams, cheap chips and improved communications permit running new permutations of languages and operating systems on such machines. These combinations were never before testable.According to Adams, the balance between CPU capability and memory should be of prime concern for next-generation parallel processors and supercomputers, which he predicts are on a collision course and will become one and the same. Scientists at Ames are most often limited not by CPU speed, he says, but by memory size. Because data space for problems involving simulation of physical systems cannot be held entirely in memory, portions must reside on disk. This causes wall-clock problem solution time to \"suffer drastically,\" says Adams. Since disk access is typically 100,000 times slower than memory access, users prefer not to wait for a value to be retrieved. Instead, they often recalculate values even if hundreds of mathematical operations are involved. So, if a parallel supercomputer with two orders of magnitude more CPU speed and memory suddenly appeared, \"these scientists would likely cheer,\" says Adams. \"Then they would ask for (still) more memory.\"For Paul Castleman, president and CEO of BBN Advanced Computers, there is really no reason to limit CPU and memory increases for the next generation of general-purpose parallel processors to two orders of magnitude: \"That’s thinking relatively conservatively\" for the next decade, he says. \"We have in the works a prototype processor that is 1000 times faster than today’s, and we are beginning work on configurations that are tens of thousands times faster.\" But a product’s usability is the final determinant, says Castleman, \"not the macho of how many more MIPS you can get . . . not whether you’ve souped up your sports car to run that much faster, but whether it feels comfortable to use.\" The solution is in the software development environment, which is why DEC and IBM have done so well, he says. Consequently, BBN Advanced Computers is now putting most of its effort into software tools for both scientific and nonscientific users. Graphics, for example, can further a user’s understanding of many simultaneous processes—each using information from a common database—with graphs of processing elements’ [PEs’) results. An economist may watch one PE number crunching dollars flowing into consumption and another PE measuring capital accumulation: or a physical plant operator may observe calculations of pressure that is causing a tank to overflow while another PE handles variables affecting a chemical reaction. Besides being an aid to users, if graphics tools are also provided, each user’s applications programmer would employ these utilities to generate the necessary aggregate graphics.But DARPA’s Kaisler says that, in exploiting the first wave of commercially available parallel processors, little effort has been expended toward using these machines for research and development in computer science. \"What is needed is a new effort, a new push to open up new avenues of algorithm development,\" he says, \"beginning from first principles about what constitutes an algorithm and how to map it to the computational model provided by a specific parallel processor.\"The impact of commercial unveilings draws different if not diametrically opposed conclusions, however. A cautionary note about \"hardware revelations\" comes from David Gelernter, associate professor of computer science at Yale University. Hardware designers thus stricken will build machines from \"the bottom up\" that no one will know how to program, he says. Already, a dozen models have a dozen different low-level parallel programming systems. Moreover, Gelernter bemoans the fact that \"machine-independent methods for parallel programming have been slow to emerge, and that consequently programmers have been forced to accommodate themselves to the machines rather than vice versa.\" He proposes that researchers imagine new kinds of programs before they imagine new kinds of machines. Once again the computer science equivalent of the age-old chicken-before-the-egg question arises. How far can hard- and software developments proceed independently? When should they be combined? Parallelism seems to bring these matters to the surface with particular urgency.The first article in our Special Issue is \"Data Parallel Algorithms,\" by W. Daniel Hillis and Guy L. Steele, Jr. These authors, from Thinking Machines Corporation, discuss algorithms and a new programming style for fine-grained single instruction multiple data (SIMD) parallel processors like the Connection Machine®. They cite examples such as parsing and finding the ends of linked lists—problems that they had assumed were inherently sequential—as milestones in their transition from \"serial to parallel thinkers.\"The next article, \"Advanced Compiler Optimizations for Supercomputers,\" is by David A. Padua and Michael J. Wolfe, of the University of Illinois and Kuck and Associates, respectively. They represent those who believe sequential algorithms should be recompiled to accommodate vector, concurrent, and multiprocessor architectures. In a discussion of data dependence testing in loops, they show how parallelism in sequential codes for operations, statements, and iterations can be automatically detected for vector supercomputers. Further, they discuss improving data dependence graphs and optimizing code for parallel computers.In a more theoretical vein, Robert Thomas and Randall Rettberg of BBN Advanced Computers discuss contention, or \"hot spots,\" the phenomenon that some have predicted might cripple certain parallel processors. In their article, \"Contention Is No Obstacle to Shared-Memory Multiprocessing,\" the authors describe engineering approaches to controlling the backup of data in networks and switches. Besides reporting specific methods used to control contention, they offer benchmarks on their own machine, the Butterfly™.Two applications-oriented articles complete the set. \"Toward Memory-Based Reasoning,\" by Craig Stanfill and David Waltz, suggests that memory of specific events, rather than of rules like those used in expert systems, is the right foundation for intelligent machines. In \"Parallel Free-Text Search on the Connection Machine System,\" Craig Stanfill and Brewster Kahle harness unique properties of massive parallelism to implement a successful document-retrieval search paradigm. They use simple queries and relevance feedback techniques to produce intriguing results on a Reuters news database of 16,000 stories.",
    "author": [
      {
        "family": "Frenkel",
        "given": "Karen A."
      }
    ],
    "container-title": "Commun. ACM",
    "id": "10.1145/7902.214916",
    "issue": "12",
    "issued": {
      "date-parts": [
        [
          1986,
          12
        ]
      ]
    },
    "page": "1168-1169",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Special issue on parallelism",
    "type": "article-journal",
    "volume": "29"
  },
  {
    "DOI": "10.1016/j.jvlc.2014.10.017",
    "ISSN": "1045-926X",
    "URL": "https://doi.org/10.1016/j.jvlc.2014.10.017",
    "abstract": "This paper proposes a technique, called smell-driven performance analysis (SDPA), which automatically provides situated explanations within a visual dataflow language IDE to help end-user programmers to overcome performance problems without leaving the visual dataflow paradigm. An experiment showed SDPA increased end-user programmers’ success rates at finding performance problems and decreased the time required for finding solutions. Another study, based on using SDPA to analyze a corpus of example end-user programs, revealed that it is usually accurate at identifying performance problems. Based on these results, we conclude that SDPA provides a reliable basis for helping end-user programmers to troubleshoot performance problems, as well as a potential foundation for future work aimed at training users and at aiding code reuse. Smell-driven performance analysis (SDPA) finds dataflow performance problems.SDPA provides situated explanations within the visual dataflow language.We present an extended form of the technique that incorporates runtime profiling.In a user study, participants could more easily diagnose performance problems.A second study confirmed that profiling improves accuracy.",
    "author": [
      {
        "family": "Chambers",
        "given": "Christopher"
      },
      {
        "family": "Scaffidi",
        "given": "Christopher"
      }
    ],
    "container-title": "J. Vis. Lang. Comput.",
    "id": "10.1016/j.jvlc.2014.10.017",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2015,
          2
        ]
      ]
    },
    "keyword": "End-user programming, Performance, Visual language",
    "page": "1-14",
    "publisher": "Academic Press, Inc.",
    "publisher-place": "USA",
    "title": "Utility and accuracy of smell-driven performance analysis for end-user programmers",
    "type": "article-journal",
    "volume": "26"
  },
  {
    "DOI": "10.1109/IECON.2019.8927573",
    "URL": "https://doi.org/10.1109/IECON.2019.8927573",
    "abstract": "The implementation of stand-alone applications enclosing artificial neural networks (ANNs) running on low-cost platforms tends to be prohibitive, primarily due to the demand for (very) large computational resources. This paper proposes a very effective method to solve this kind of problem. We rely on the existing approach of first configuring and training the ANN on a platform offering the necessary computing power, memory, and appropriate software tools, and then implementing the ANN model on the host platform. In our method, the code for the ANN model is automatically generated and integrated into the final application. The MATLAB environment, running on a PC, plays the roles of both a training platform and a code generator. The Arduino IDE is used for automatic code integration, while Arduino development boards provide the host for the stand-alone application. Some experimental tests confirm the proper operation of our approach. Quite a large ANN can be simulated on low-cost Arduino boards: Uno can accommodate an architecture with 315 parameters (83",
    "author": [
      {
        "family": "Oltean",
        "given": "Gabriel"
      },
      {
        "family": "Oltean",
        "given": "Victor"
      },
      {
        "family": "Balea",
        "given": "Horea Alin"
      }
    ],
    "container-title": "IECON 2019 - 45th annual conference of the IEEE industrial electronics society",
    "id": "10.1109/IECON.2019.8927573",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "page": "138-143",
    "publisher": "IEEE Press",
    "publisher-place": "Lisbon, Portugal",
    "title": "Method for rapid development of arduino-based applications enclosing ANN",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-030-90235-3_32",
    "ISBN": "978-3-030-90234-6",
    "URL": "https://doi.org/10.1007/978-3-030-90235-3_32",
    "abstract": "In recent years, more and more countries have included programming as one of the subjects in the national education curriculum. However, comparatively less attention has been paid to reviewing the methodologies and tools, according to our observations. This paper aims to review methods and tools that have been applied in higher education levels and identify the most effective one to be applied in teaching and learning programming in high schools. The possible methods to be applied in high schools are highly dependent on the education landscape of the country itself. Therefore, the methods proposed in this paper are identified by considering education issues in Malaysia such as language of communication, digital divide and schools’ teaching and learning time. We conducted an interview with the teachers and students to identify the real problems of teaching and learning programming in Malaysia public secondary schools. From the interview and extensive review of literature, possible model elements have been identified. We found that teaching and learning programming at high school level should incorporate the following main features; incorporating computational thinking, IDE-centric learning, relation to life-example, reiterative method and spaced exercise, effective questioning, support multi-language and self-study. However, all of these recommendations should be studied for their effectiveness by conducting a detail testing. Thus, we conducted an expert evaluation by using a learning management system (LMS) that we created specifically to represent our suggested model components. The findings gathered from the expert evaluation confirms on the needs to give high priority to the following model components; reiterative and chunking, effective questioning, designing instructional materials, followed by adaptive learning, language and self-study. The components identified during the research process that are worthwhile to continue to prove their level of efficiency are AI, support think-pair, competition-based, gamification, mobile friendly and low usage of system resources (small memory footprint or RAM usage and low CPU usage). It is hoped that our model can be adopted by public secondary schools in Malaysia to produce the best tools or methods for teaching programming. Finally, we discuss the implications of our findings and suggest future research directions that could develop a more holistic understanding of this pedagogical technique.",
    "author": [
      {
        "family": "Mohamed Salleh",
        "given": "Faridah Hani"
      },
      {
        "family": "Dewi",
        "given": "Deshinta Arrova"
      },
      {
        "family": "Liyana",
        "given": "Nurul Azlin"
      },
      {
        "family": "Md Nasir",
        "given": "Naziffa Raha"
      }
    ],
    "container-title": "Advances in visual informatics: 7th international visual informatics conference, IVIC 2021, kajang, malaysia, november 23–25, 2021, proceedings",
    "id": "10.1007/978-3-030-90235-3_32",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Programming, Secondary schools",
    "page": "362-373",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "A model for teaching and learning programming subjects in public secondary schools of malaysia",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.advengsoft.2022.103292",
    "ISSN": "0965-9978",
    "URL": "https://doi.org/10.1016/j.advengsoft.2022.103292",
    "author": [
      {
        "family": "Brindha Merin",
        "given": "J"
      },
      {
        "family": "Aisha Banu",
        "given": "W"
      }
    ],
    "container-title": "Adv. Eng. Softw.",
    "id": "10.1016/j.advengsoft.2022.103292",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2022,
          12
        ]
      ]
    },
    "keyword": "Web Service Description Language (WSDL), Hadoop Distributed File System (HDFS), Hybrid Artificial Deep Learning Neural Network (HADLNN), Cat swarm Optimization (CSO) and Modified K-means (MK-means)",
    "publisher": "Elsevier Science Ltd.",
    "publisher-place": "GBR",
    "title": "An efficient web service annotation for domain classification and information retrieval systems using HADLNN classifier",
    "type": "article-journal",
    "volume": "174"
  },
  {
    "DOI": "10.1145/3287324.3293851",
    "ISBN": "9781450358903",
    "URL": "https://doi.org/10.1145/3287324.3293851",
    "abstract": "With large class sizes and instructors who may not be equipped to assist struggling students, many students abandon the field, deeming it to be too difficult and not for them. Consistent, constructive, supportive feedback through a Tutoring Companion can scaffold the learning process for students. This poster describes a reasoning model, using neural networks techniques, for a tutoring companion embedded into the Eclipse IDE. The companion provides support for students in a first-year university Java programming course. The companion collects data from students’ events and programming assignments, analyzes it for relevant trends, and estimates each student’s situation. The input data for the neural network comes from areas with which beginning computer science students often struggle, such as the presence of important keywords and the amount of time spent in a state with errors. Then, it determines the feedback to be provided for students to overcome a detected challenging situation, providing both hints on how to fix the problem with the code, as well as encouragement to help keep students motivated and learning. The effectiveness of the approach is examined among first-year computer science students through the completion of recursion and control flow programming assignments. The students complete surveys regarding their learning experience to assist in evaluating the companion’s pedagogical effectiveness, which is discussed with an emphasis on the value of feedback provided.",
    "author": [
      {
        "family": "Day",
        "given": "Melissa"
      },
      {
        "family": "Gonzalez-Sanchez",
        "given": "Javier"
      }
    ],
    "collection-title": "SIGCSE ’19",
    "container-title": "Proceedings of the 50th ACM technical symposium on computer science education",
    "id": "10.1145/3287324.3293851",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "computer science education, eclipse ide, neural networks, programming tutoring, teaching programming, tutoring companion",
    "page": "1268",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A neural network model for a tutoring companion supporting students in a programming with java course",
    "type": "paper-conference"
  },
  {
    "ISBN": "1788473698",
    "abstract": "Key Features Leverage specific features of Kotlin to ease Android application developmentAn illustrative guide that will help you write code based Kotlin language to build robust Android applicationsFilled with various practical examples build amazing Android project using Kotlin so you can easily apply your knowledge to real world scenarios Book Description Kotlin is a programming language intended to be a better Java, and it’s designed to be usable and readable across large teams with different levels of knowledge. As a language, it helps developers build amazing Android applications in an easy and effective way. This book begins by giving you a strong grasp of Kotlins features in the context of Android development and its APIs. Moving on, youll take steps toward building stunning applications for Android. The book will show you how to set up the environment, and the difficulty level will grow steadily with the applications covered in the upcoming chapters. Later on, the book will introduce you to the Android Studio IDE, which plays an integral role in Android development. Well use Kotlins basic programming concepts such as functions, lambdas, properties, object-oriented code, safety aspects, type parameterization, testing, and concurrency, which will guide you through writing Kotlin code into production. Well also show you how to integrate Kotlin into any existing Android project. What you will learn Understand the basics of Android development with KotlinGet to know the key concepts in Android development See how to create modern mobile applications for the Android platform Adjust your applications look and feel Know how to persist and share application databaseWork with Services and other concurrency mechanisms Write effective tests Migrate an existing Java-based project to Kotlin About the Author Milo Vasi is a software engineer, author, and open source enthusiast. He holds a bachelor’s degree in the programming of computer graphics and a master’s degree in the field of Android programming; both degrees were gained at Singidunum University. He published his first book, Fundamental Kotlin, in October 2016, thus achieving his dream of becoming an author. He’s currently employed at the Robert Bosch company, where he’s working on SDKs for the auto-industry. When he is not working on new books, Milo works on his open source projects.",
    "author": [
      {
        "family": "Vasic",
        "given": "Milos"
      }
    ],
    "id": "10.5555/3202541",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Mastering android development with kotlin: Deep dive into the world of android to create robust applications with kotlin",
    "title-short": "Mastering android development with kotlin",
    "type": "book"
  },
  {
    "DOI": "10.1109/TCBB.2022.3168676",
    "ISSN": "1545-5963",
    "URL": "https://doi.org/10.1109/TCBB.2022.3168676",
    "abstract": "Protein secondary structure (SS) prediction is a classic problem of computational biology and is widely used in structural characterization and to infer homology. While most SS predictors have been trained on thousands of sequences, a previous approach had developed a compact model of training proteins that used a &lt;bold&gt;C&lt;/bold&gt;-&lt;bold&gt;A&lt;/bold&gt;lpha, C-&lt;bold&gt;B&lt;/bold&gt;eta &lt;bold&gt;S&lt;/bold&gt;ide Chain (&lt;bold&gt;CABS&lt;/bold&gt;)-algorithm derived energy based feature representation. Here, the previous approach is extended to Deep Belief Networks (DBN). Deep learning methods are notorious for requiring large datasets and there is a wide consensus that training deep models from scratch on small datasets, works poorly. By contrast, we demonstrate a simple DBN architecture containing a single hidden layer, trained only on the CB513 dataset. Testing on an independent set of G Switch proteins improved the Q&lt;inline-formula&gt;&lt;tex-math notation=\"LaTeX\"&gt;$_{3}$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:msub&gt;&lt;mml:mrow/&gt;&lt;mml:mn&gt;3&lt;/mml:mn&gt;&lt;/mml:msub&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=\"rashid-ieq1-3168676.gif\"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; score of the previous compact model by almost 3",
    "author": [
      {
        "family": "Rashid",
        "given": "Shamima"
      },
      {
        "family": "Sundaram",
        "given": "Suresh"
      },
      {
        "family": "Kwoh",
        "given": "Chee Keong"
      }
    ],
    "container-title": "IEEE/ACM Trans. Comput. Biol. Bioinformatics",
    "id": "10.1109/TCBB.2022.3168676",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2022,
          4
        ]
      ]
    },
    "page": "955-966",
    "publisher": "IEEE Computer Society Press",
    "publisher-place": "Washington, DC, USA",
    "title": "Empirical study of protein feature representation on deep belief networks trained with small data for secondary structure prediction",
    "type": "article-journal",
    "volume": "20"
  },
  {
    "ISBN": "1787129055",
    "abstract": "Key FeaturesDevelop strategies to speed up your R codeTackle programming problems and explore both functional and object-oriented programming techniquesLearn how to address the core problems of programming in R with the most popular R packages for common tasksBook DescriptionR is a powerful tool for statistics, graphics, and statistical programming. It is used by tens of thousands of people daily to perform serious statistical analyses. It is a free, open source system whose implementation is the collective accomplishment of many intelligent, hard-working people. There are more than 2,000 available add-ons, and R is a serious rival to all commercial statistical packages. The objective of this book is to show how to work with different programming aspects of R. The emerging R developers and data science could have very good programming knowledge but might have limited understanding about R syntax and semantics. Our book will be a platform develop practical solution out of real world problem in scalable fashion and with very good understanding. You will work with various versions of R libraries that are essential for scalable data science solutions. You will learn to work with Input / Output issues when working with relatively larger dataset. At the end of this book readers will also learn how to work with databases from within R and also what and how meta programming helps in developing applications. What you will learn Install R and its various IDE for a given platform along with installing libraries from different repositories and version control Learn about basic data structures in R and how to work with them Write customized R functions and handle recursions, exceptions in R environments Create the data processing task as a step by step computer program and execute using dplyr Extract and process unstructured text data Interact with database management system to develop statistical applications Formulate and implement parallel processing in RAbout the Author Jaynal Abedin is currently doing research as a PhD student at Unit for Biomedical Data Analytics (BDA) of INSIGHT at the National University of Ireland Galway. His research work is focused on the sports science and sports medicine area in a targeted project with ORRECO –an Irish startup company that provides evidence-based advice to individual athletes through biomarker and GPS data. Before joining INSIGHT as a PhD student he was leading a team of statisticians at an international public health research organization (icddr,b). His primary role there was to develop internal statistical capabilities for researchers who come from various disciplines. He was involved in designing and delivering statistical training to the researchers. He has a bachelors and masters degree in statistics, and he has written two books in R programming: Data Manipulation with R and R Graphs Cookbook (Second Edition) with Packt. His current research interests are predictive modeling to predict probable injury of an athlete and scoring extremeness of multivariate data to get an early signal of an anomaly. Moreover, he has an excellent reputation as a freelance R programmer and statistician in an online platform such as upwork.",
    "author": [
      {
        "family": "Abedin",
        "given": "Jaynal"
      }
    ],
    "id": "10.5555/3181138",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Modern r programming cookbook: Recipes to simplify your statistical applications",
    "title-short": "Modern r programming cookbook",
    "type": "book"
  },
  {
    "abstract": "Word Sense Disambiguation (WSD) is the process of resolving the meaning of a word unambiguously in a given natural language context. Within the scope of this thesis, it is the process of marking text with explicit sense labels. What constitutes a sense is a subject of great debate. An appealing perspective, aims to define senses in terms of their multilingual correspondences, an idea explored by several researchers, Dyvik (1998), Ide (1999), Resnik &amp; Yarowsky (1999), and Chugur, Gonzalo &amp; Verdejo (2002) but to date it has not been given any practical demonstration. This thesis is an empirical validation of these ideas of characterizing word meaning using cross-linguistic correspondences. The idea is that word meaning or word sense is quantifiable as much as it is uniquely translated in some language or set of languages. Consequently, we address the problem of WSD from a multilingual perspective; we expand the notion of context to encompass multilingual evidence. We devise a new approach to resolve word sense ambiguity in natural language, using a source of information that was never exploited on a large scale for WSD before. The core of the work presented builds on exploiting word correspondences across languages for sense distinction. In essence, it is a practical and functional implementation of a basic idea common to research interest in defining word meanings in cross-linguistic terms. We devise an algorithm, SALAAM for Sense Assignment Leveraging Alignment And Multilinguality, that empirically investigates the feasibility and the validity of utilizing translations for WSD. SALAAM is an unsupervised approach for word sense tagging of large amounts of text given a parallel corpus—texts in translation—and a sense inventory for one of the languages in the corpus. Using SALAAM, we obtain large amounts of sense annotated data in both languages of the parallel corpus, simultaneously. The quality of the tagging is rigorously evaluated for both languages of the corpora. The automatic unsupervised tagged data produced by SALAAM is further utilized to bootstrap a supervised learning WSD system, in essence, combining supervised and unsupervised approaches in an intelligent way to alleviate the resources acquisition bottleneck for supervised methods. Essentially, SALAAM is extended as an unsupervised approach for WSD within a learning framework; in many of the cases of the words disambiguated, SALAAM coupled with the machine learning system rivals the performance of a canonical supervised WSD system that relies on human tagged data for training. Realizing the fundamental role of similarity for SALAAM, we investigate different dimensions of semantic similarity as it applies to verbs since they are relatively more complex than nouns, which are the focus of the previous evaluations. We design a human judgment experiment to obtain human ratings on verbs’ semantic similarity. The obtained human ratings are cast as a reference point for comparing different automated similarity measures that crucially rely on various sources of information. Finally, a cognitively salient model integrating human judgments in SALAAM is proposed as a means of improving its performance on sense disambiguation for verbs in particular and other word types in general.",
    "author": [
      {
        "family": "Diab",
        "given": "Mona Talat"
      },
      {
        "family": "Resnik",
        "given": "Philip"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/997603",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "note": "AAI3115805",
    "publisher": "University of Maryland at College Park",
    "publisher-place": "USA",
    "title": "Word sense disambiguation within a multilingual framework",
    "type": "thesis"
  },
  {
    "ISBN": "0072191724",
    "abstract": "From the Book: Introduction Who Will Enjoy This You will, if you want to create attractive, feature-packed, and easy-to-use Web sites with FrontPage. Because of its Microsoft Office-like interface, FrontPage is a very accessible Web design tool. But beneath the surface, youll find powerful features that allow you to edit pictures, generate JavaScripts, and collect input data-features not available in any other Web design package. My goal with this book is to make those features accessible to both brand new Web designers, as well as veteran FrontPage designers who would like to add advanced features to their sites. Ive been teaching folks like yourself to use FrontPage for five years now. Ive written Microsoft authorized books on how to pass the Microsoft FrontPage MCSD exam (and Ive passed the Microsoft FrontPage Certified Professional exam myself). But Ive also taught people FrontPage who have never created a Web site before. Perhaps most importantly, I use FrontPage almost every day to create Web sites. Ive learned through trial and error the best ways to create Web sites with FrontPage, and also the best ways to learn FrontPage. Beginning level, intermediate, and many advanced FrontPage designers will all find important resources in this book. Many chapters approach concepts like tables, frames, and input forms on different levels. At first, new FrontPage users might want to try the more basic step-by-step sections early in the chapter, while more advanced developers will push the envelope using all the features covered in a chapter. And, this book is much more than a book. The accompanying CD-ROM, which is discussed in detail in the remainder of this introduction, has more than an hour of videos with demonstrations, tips, and candid advice. FrontPage 2002 Virtual Classroom CD This CD contains an exciting new kind of video-based instruction to help you learn FrontPage faster. We believe this learning tool is a unique development in the area of computer-based training. The author actually talks to you, right from your computer screen, demonstrating topics he wrote about in the book. Moving screencams and slides accompany the presentation, reinforcing what youre learning. The technology and design of the presentation were developed by Brainsville.com. The content on the CD-ROM was developed by OsborneMcGraw-Hill, David Karlins, and Brainsville.com. Patents (pending), copyright, and trademark protections apply to this technology and the name Brainsville.com. To ensure that the lessons play as smoothly as possible, please read the following directions for usage of the CD-ROM. Getting Started The CD-ROM is optimized to run under Windows 9598MENT2000 using the QuickTime player version 5 (or greater), from Apple. This CD-ROM is not designed to run on a Mac. If you dont have the QuickTime 5 player installed, you must install it either by downloading it from the Internet at http:www. quicktime.com, or running the Setup program from the CD-ROM. If you install from the Web, its fine to use the free version of the QuickTime player. You dont need to purchase the full version. To install the QuickTime player from the CD-ROM on a Windows PC: 1. Insert the CD-ROM in the drive. 2. Use Explorer or My Computer to browse to the CD-ROM. 3. Open the QuickTime folder. 4. Double-click the setup program there. 5. Follow the setup instructions on screen. Running the CD in Windows 9598MENT2000 Minimum Requirements: QuickTime 5 player Pentium II P300 (or equivalent) 64MB of RAM 8X CD-ROM Windows 95, Windows 98, Windows 2000, Windows ME, or Windows NT 4.0 with at least Service Pack 4 16-bit sound card and speakers FrontPage 2002 Virtual Classroom CD-ROM can run directly from the CD (see the following for running it from the hard drive for better performance if necessary) and should start automatically when you insert the CD in the drive. If the program does not start automatically, your system might not be set up to automatically detect CDs. To change this, you can do the following: 1. Choose Settings I Control Panel, and click the System icon. 2. Click the Device Manager tab in the System Properties dialog box. 3. Double-click the Disk drives icon and locate your CD-ROM drive. 4. Double-click the CD-ROM drive icon, and then click the Settings tab in the CD-ROM Properties dialog box. Make sure the Auto Insert Notification box is checked. This specifies that Windows will be notified when you insert a compact disc into the drive. If you dont care about the auto-start setting for your CD-ROM, and dont mind the manual approach, you can start the lessons manually. Heres how: 1. Insert the CD-ROM. 2. Double-click the My Computer icon on your Windows desktop. 3. Open the CD-ROM folder. 4. Double-click the startnow.exe icon in the folder. 5. Follow the instructions on screen to start. When the program autostarts, youll see a small window in the middle of your screen with an image of the book; click that image to launch the QuickTime player and start the lessons. The QuickTime player window should open and the Virtual Classroom introduction should begin running. On some computers, after the lesson loads you must click the Play button to begin. The Play button is the big round button with an arrow on it at the bottom center of the QuickTime player window. It looks like the play button on a VCR. You can click the links in the lower-left region of the QuickTime window to jump to a given lesson. The author will explain how to use the interface. The QuickTime player will completely fill a screen that is running at 800 x 600 resolution. (This is the minimum resolution required to play the lessons.) For screens with higher resolution, you can adjust the position of the player on screen, as you like. If you are online, you can click the Brainsville.com logo under the index marks to jump directly to the Brainsville.com Web site for information about additional video lessons from Brainsville.com. (See the description in the back of this book about the Web Design CD Extra for more details.) Improving PlayBack Your Virtual Classroom CD-ROM employs some cutting-edge technologies, requiring that your computer be pretty fast to run the lessons smoothly. Many variables determine a computers video performance, so we cant give you specific requirements for running the lessons. CPU speed, internal bus speed, amount of RAM, CD-ROM drive transfer rate, video display performance, CD-ROM cache settings and other variables will determine how well the lessons play. Our advice is to simply try the CD. The disk has been tested on laptops and desktops of various speeds, and in general, youll need at least a Pentium II-class computer running in excess of 300Mhz for decent performance. (If youre doing serious Web-design work, its likely your machine is at least this fast.) Close Other Programs For best performance, make sure you are not running other programs in the background while viewing the CD-based lessons. Rendering the video onscreen takes a lot of computing power, and background programs such as automatic e-mail checking, Web-site updating, or Active Desktop applets (such as scrolling stock tickers) can tax the CPU to the point of slowing the videos. Adjust the Screen Color Depth to Speed Up Performance Its possible that the authors lips will be out of synch with his voice, just like Web-based videos often look. There are a couple solutions: Lowering the color depth to 16-bit color makes a world of difference with many computers, laptops included. Rarely do people need 24-bit or 32-bit color for their work anyway, and it makes scrolling your screen (in any program) that much slower when running in those higher color depths. Try this: 1. Right-click the desktop and choose Properties. 2. Click the Settings tab. 3. In the Colors section, open the drop-down list box and choose a lower setting. If you are currently running at 24-bit (True Color) color, for example, try 16-bit (High Color). Dont use 256 colors, because video will appear very funky if you do. 4. OK the box. With most computers these days, you dont have to restart the computer after making this change. The video should run more smoothly now, because your computers CPU doesnt have to work as hard to paint the video pictures on your screen. If adjusting the color depth didnt help the synch problem, see the following section about copying the CDs files to your hard disk. When lessons are playing youre likely to not interact with the keyboard or mouse. Because of this, your computer screen might blank, and in some cases (such as with laptops) the computer might even go into a standby mode. Youll want to prevent these annoyances by turning off your screen saver and checking the power options settings to ensure they dont kick in while youre viewing the lessons. You make settings for both of these parameters from the Control Panel. 1. Open Control Panel, choose Display, and click the Screen Saver tab. Choose None for the screen saver. 2. Open Control Panel, choose Power Management, and set System Standby, Turn off Monitor, and Turn off Hard Disks to Never. Then click Save As and save this power setting as Brainsville Courses. You can return your power settings to their previous state, if you like, after you are finished viewing the lessons. just use the Power Schemes drop-down list and choose one of the factorysupplied settings, such as HomeOffice Desk. Copy the CD Files to the Hard Disk to Speed Up Performance The CD-ROM drive will whir quite a bit when running the lessons from the CD. If your computer or CD-ROM drive is a bit slow, its possible the authors lips will be out of synch with his voice, just like Web-based videos often look. The video might freeze or slow down occasionally, though the audio will typically keep going along just fine. If you dont like the CD constantly whirring, or you are annoyed by outof-synch video, you might be able to solve either or both problems by copying the CD-ROMs contents to your hard disk and running the lessons from there. To move CD content to your hard disk: 1. Using My Computer or Explorer, check to see that you have at least 650M free space on your hard disk. 2. Create a new folder on your hard disk (the name doesnt matter) and copy all the contents of the CD-ROM to the new folder. (You must preserve the subfolder names and folder organization as it is on the CD-ROM). 3. Start the program by opening the new folder and double-clicking the file startnow.exe. This will automatically start the lessons and run them from the hard disk. 4. (Optional) For convenience, you can create a shortcut to the startnow.exe file and place it on your desktop. You will then be able to start the program by clicking the shortcut. Update Your QuickTime Player The QuickTime software is updated frequently and posted on the Apple QuickTime Web site ( ). You can update your software by clicking Update Existing Software, from the Help menu in the QuickTime player. We strongly suggest you do this from time to time. Make Sure Your CD-Rom Drive is Set for Optimum Performance CD-ROM drives on IBM PCs can be set to transfer data using the DMA (Direct Memory Access) mode, assuming the drive supports this faster mode. If you are experiencing slow performance and out-of-synch problems, check this setting. These steps are for Windows 98 and Windows ME: 1. Choose Control Panel I System. 2. Click the Device Manager tab. 3. Click the plus (+) sign to the left of the CD-ROM drive. 4. Right-click the CD-ROM drive. 5. Choose Properties. 6. Click the Settings tab. 7. Look to see if the DMA check box is turned on (has a check mark in it). If selected, this increases the CD-ROM drive access speed. Some drives do not support this option. If the DMA check box remains selected after you restart Windows, this option is supported by the device. In Windows 2000, the approach is a little different. You access the drives settings via Device Manager as above, but click IDEATAPI Controllers. Right-click the IDE channel that your CD-ROM drive is on, choose Properties, and make the settings as appropriate. (Choose the device number, 0 or 1, and check the settings.) Typically its set to DMA If Available, which is fine. Its not recommended that you change these settings unless you know what you are doing! TroubleShooting This section offers solutions to common problems. Check for much more information about the QuickTime player, which is the software the Virtual Classroom CD uses to play. The CD Will Not Run If you have followed the instructions above and the program will not work, you might have a defective drive or CD. Be sure the CD is inserted properly in the drive. Test the drive with other CDs to see if they run. The ScreenCam Movie In! A Lesson Tangs If the author continues to talk, but the accompanying screencam seems to be stuck, just click the lesson index in the lower-left region of the QuickTime window to begin your specific lesson again. If this doesnt help, close the QuickTime window; then start the Virtual Classroom CD again. Volume Is Too Low or Totally Silent 1. Check your system volume first. Click the speaker icon next to the clock, in the lower-right corner of the screen. A little slider pops up. Adjust the slider, and make sure the Mute check box is not checked. 2. Next, if you have external speakers on your computer, make sure your speakers are turned on, plugged in, wired up properly, and the volume control on the speakers themselves is turned up. 3. Note that the QuickTime player also has a volume control setting. The setting is a slider control in the lower-left of the QuickTime player window. 4. The next place to look if youre still having trouble is in the Windows volume controls. Double-click the speaker next to the clock and it will bring up the Windows Volume Control sliders. Make sure the slider for Wave is not muted, and make sure its positioned near the top. For Technical Support Phone Hudson Software at (800) 217-0059 Visit Visit",
    "author": [
      {
        "family": "Karlins",
        "given": "David"
      }
    ],
    "id": "10.5555/580423",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "McGraw-Hill Professional",
    "title": "FrontPage 2002 virtual classroom",
    "type": "book"
  },
  {
    "DOI": "10.1007/978-3-319-92049-8_49",
    "ISBN": "978-3-319-92048-1",
    "URL": "https://doi.org/10.1007/978-3-319-92049-8_49",
    "abstract": "Research on the use of interactive media as learning tools for children with cognitive impairments has focused mainly on employing predesigned content, rather than constructing new content. Visual programming tools could potentially provide cognitively impaired children with a platform that can enable them to create their own interactive media. However, very little is known about the accessibility of the tools. This study uses a novel approach to evaluate the accessibility of Scratch (a visual programming tool) for children with cognitive impairments by employing a Grounded Theory research method. The study was conducted with 9 participants: 2 special education teachers and 7 cognitively impaired children over a period of ten weeks. The children’s usage of Scratch was documented through screen capturing. In addition, semi structured interviews were conducted with the two teachers. Grounded Theory based analysis was performed using QSR NVivo, which led to the identification of: accessibility issues; causal conditions; contexts; strategies employed to tackle issues; and consequences. Thus, the findings of this research contribute to existing knowledge on the accessibility of visual programming tools and elucidate the experience of cognitively impaired children while using the tools.",
    "author": [
      {
        "family": "Zubair",
        "given": "Misbahu S."
      },
      {
        "family": "Brown",
        "given": "David"
      },
      {
        "family": "Hughes-Roberts",
        "given": "Thomas"
      },
      {
        "family": "Bates",
        "given": "Matthew"
      }
    ],
    "container-title": "Universal access in human-computer interaction. Methods, technologies, and users: 12th international conference, UAHCI 2018, held as part of HCI international 2018, las vegas, NV, USA, july 15-20, 2018, proceedings, part i",
    "id": "10.1007/978-3-319-92049-8_49",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "Grounded Theory, Scratch, Cognitive impairments, Visual programming, Accessibility",
    "page": "660-676",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Evaluating the accessibility of scratch for children with cognitive impairments",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3629296.3629297",
    "ISBN": "9798400709111",
    "URL": "https://doi.org/10.1145/3629296.3629297",
    "abstract": "In recent years, numerous approaches to automated feedback have been presented in the field of programming education. Often, these methods deliver feedback through standalone web-based environments or educational programming environments. However, only few works have explored how such feedback can be provided within Integrated Development Environments (IDEs). We propose MINDFIX, an approach for integrating alternative feedback mechanisms for addressing programming language misconceptions about Java into the Eclipse IDE. These mechanisms include textual hints, code examples, and a personalized pedagogical agent. A laboratory experiment was conducted to investigate their impact on novice programmers in higher education. The results show that MINDFIX addresses missing feedback mechanisms and features. Additionally, there are initial insights that our feedback addresses programming language misconceptions while being perceived as useful and comprehensible. Our findings also suggest that novice programmers with low self-efficacy expectations perceive pedagogical agents as more motivating, useful, and less disruptive compared to their peers.",
    "author": [
      {
        "family": "Fischer",
        "given": "Björn"
      },
      {
        "family": "Birk",
        "given": "Fabian"
      },
      {
        "family": "Iwer",
        "given": "Eva-Maria"
      },
      {
        "family": "Panitz",
        "given": "Sven Eric"
      },
      {
        "family": "Dörner",
        "given": "Ralf"
      }
    ],
    "collection-title": "ICETC ’23",
    "container-title": "Proceedings of the 15th international conference on education technology and computers",
    "id": "10.1145/3629296.3629297",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "affective computing, example-based feedback, intelligent tutoring system, pedagogical agent, programming environment",
    "page": "1-8",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Addressing misconceptions in introductory programming: Automated feedback in integrated development environments",
    "title-short": "Addressing misconceptions in introductory programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "0818606207",
    "abstract": "A primary goal of Software Engineering is to improve the process of software development. It is being recognised that recent integrated programming environments have made significant progress towards this aim. This paper describes new operations, suitable for such environments, which are applicable in a much wider scope of programming, termed here as programming in the all. Development of software in this new scope is carried out incrementally in program fragments of various types, called fragtypes. Fragtypes range from a simple Expression type to a complete Subsystem type, and therefore are suited to the development of non-trivial software. The proposed operations on fragtypes have been incorporated in the design of the programming environment MUPE-2 for Modula-2, which is currently under development at McGill University.",
    "author": [
      {
        "family": "Madhavji",
        "given": "Nazim H."
      }
    ],
    "collection-title": "ICSE ’85",
    "container-title": "Proceedings of the 8th international conference on software engineering",
    "id": "10.5555/319568.319572",
    "issued": {
      "date-parts": [
        [
          1985
        ]
      ]
    },
    "page": "15-25",
    "publisher": "IEEE Computer Society Press",
    "publisher-place": "Washington, DC, USA",
    "title": "Operations for programming in the all",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/268084.268167",
    "ISBN": "0897918894",
    "URL": "https://doi.org/10.1145/268084.268167",
    "abstract": "The parallel programming community has long recognized the need for a simple programming environment offering interprocess communication between heterogeneous systems. As the Parallel Virtual Machine environment, PVM, has emerged to meet this goal, an increasing number of educational institutions are choosing PVM to support their teaching of parallel and distributed computing using networks of workstations. However, it is often the nature of PVM’s design and implementation that can severely limit its success in a teaching environment. This paper first motivates and then describes improvements to the PVM environment which increase both robustness and efficiency in an educational setting.",
    "author": [
      {
        "family": "McDonald",
        "given": "Chris"
      },
      {
        "family": "Kazemi",
        "given": "Kamran"
      }
    ],
    "collection-title": "SIGCSE ’97",
    "container-title": "Proceedings of the twenty-eighth SIGCSE technical symposium on computer science education",
    "id": "10.1145/268084.268167",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "page": "219-223",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Improving the PVM teaching environment",
    "type": "paper-conference"
  },
  {
    "ISBN": "9781450322959",
    "abstract": "It is our great pleasure to welcome you to the proceedings of the PROMOTO’14. The 2nd Workshop on Programming with Mobile and Touch (PROMOTO’14) was held in Portland, OR on October 22, 2014, in conjunction with SPLASH/OOPSLA 2014. The goals of the workshop were to discuss the issues surrounding touch and mobile programming and to plan future directions.Workshop Overview Today, easy-to-use mobile devices like smartphones and tablets are becoming more prevalent than traditional PCs and laptops. New programming languages are emerging to enable programmers to develop software easily, leveraging the exciting advances in existing hardware, and providing abstractions that fit the capabilities of target platforms with multiple sensors, touch and cloud capabilities. PROMOTO’14 brought together researchers who have been exploring new programming paradigms, embracing the new realities of always connected, touch-enabled mobile devices. Specific areas of interest were the technical aspects of cross-platform computing, cloud computing, social applications, and education.Submissions for this event were invited in the general area of mobile and touch-oriented programming languages and programming environments, and teaching of programming for mobile devices. Topics of interest included: Mobile and touch-oriented programming languagesProgramming languages using innovative input mechanismsProgramming environments on or for mobile devicesTeaching of programming on or for mobile devicesProgramming tools such as debuggers on or for mobiles devicesLibraries and programming frameworks that simplify programming for mobile devicesThe workshop received 11 submissions from all over the world. Each paper was reviewed by three members of the program committee and 6 were chosen for presentation as full papers, short papers or tool demos. We also had three additional stimulating sessions: A keynote on \"Programming gadgets with gadgets\" presented by Jonathan de Halleux of Microsoft Research.A group hands-on session, were participants were challenged to create an app in an hour, and compare results.A lively panel on \"Mobile Computing and Education\"The Keynote The keynote by de Halleux son \"Programming gadgets with gadgets\", not reported on elsewhere, was a lively presentation with an array of gadgets on display. Hardware 2.0 is upon us: cheap micro-controller boards like Arduino have gained massive adoption in recent years. Paired with 3D printers, cheap sensors and actuators, Hardware 2.0 allows anyone to prototype the next hot gadget. And yet, the maker will have to learn a soup of software language and framework to build a connected IoC solution: C++ for the micro controller code, HTML + javascript for the client, some backend language and a communication layer to interact with the devices. In this keynote, de Halleux showed a unified approach for compilation of web server code, rich client and embedded firmware under a simple mobile friendly language and IDE.",
    "id": "10.1145/2688471",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PROMOTO ’14: Proceedings of the 2nd workshop on programming for mobile &amp; touch",
    "title-short": "PROMOTO ’14",
    "type": "book"
  },
  {
    "DOI": "10.1145/2811681.2811683",
    "ISBN": "9781450337960",
    "URL": "https://doi.org/10.1145/2811681.2811683",
    "abstract": "The PrimeGame is an established mathematical programming game that has been used successfully in undergraduate computer science teaching since 2003. To meet the increasing demand for innovative programming tools in undergraduate tertiary and secondary education, we have created SoGaCo, a novel platform to deliver the PrimeGame and similar games to a wide audience via standard web browsers. SoGaCo is designed to have a very low total cost of ownership. This is achieved by enabling teachers to provision a customised collaborative development environment on commodity cloud computing infrastructure. Amongst the unique features of the platform are its social networking features and support for polyglot programming.In this paper, we describe the requirements for this system, its design and implementation. We focus on how the scalability and security challenges of an open web-based development environment are addressed. This includes a discussion of the sandboxing and verification techniques we have developed in order to safeguard server-side code execution on the Java Virtual Machine.",
    "author": [
      {
        "family": "Dietrich",
        "given": "Jens"
      },
      {
        "family": "Tandler",
        "given": "Johannes"
      },
      {
        "family": "Sui",
        "given": "Li"
      },
      {
        "family": "Meyer",
        "given": "Manfred"
      }
    ],
    "collection-title": "ASWEC ’ 15 vol. II",
    "container-title": "Proceedings of the ASWEC 2015 24th australasian software engineering conference",
    "id": "10.1145/2811681.2811683",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "page": "8-12",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The PrimeGame revolutions: A cloud-based collaborative environment for teaching introductory programming",
    "title-short": "The PrimeGame revolutions",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1593105.1593135",
    "ISBN": "9781605581057",
    "URL": "https://doi.org/10.1145/1593105.1593135",
    "abstract": "In this paper we describe a novel concept for teaching introductory Java programming to post-secondary students in their first year of higher education. The concept includes labs and a capstone project all linked together and all utilizing the Java-based Greenfoot programming environment. The concept is designed with two goals in mind: to improve the students experience in their first computer programming course by making it more entertaining; and to increase retention in the diploma or degree programs by peaking the student’s interest early in their studies. This is accomplished through a Going to the Moon scenario we have designed and implemented into the Greenfoot programming environment.",
    "author": [
      {
        "family": "Gallant",
        "given": "Randy J."
      },
      {
        "family": "Mahmoud",
        "given": "Qusay H."
      }
    ],
    "collection-title": "ACM-SE 46",
    "container-title": "Proceedings of the 46th annual southeast regional conference on XX",
    "id": "10.1145/1593105.1593135",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "simple data types, programming for fun, programming environments, Moon Scenario, Greenfoot",
    "page": "118-121",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using greenfoot and a moon scenario to teach java programming in CS1",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s10664-020-09895-8",
    "ISSN": "1382-3256",
    "URL": "https://doi.org/10.1007/s10664-020-09895-8",
    "author": [
      {
        "family": "Santos",
        "given": "Adrian"
      },
      {
        "family": "Vegas",
        "given": "Sira"
      },
      {
        "family": "Dieste",
        "given": "Oscar"
      },
      {
        "family": "Uyaguari",
        "given": "Fernando"
      },
      {
        "family": "Tosun",
        "given": "Ayşe"
      },
      {
        "family": "Fucci",
        "given": "Davide"
      },
      {
        "family": "Turhan",
        "given": "Burak"
      },
      {
        "family": "Scanniello",
        "given": "Giuseppe"
      },
      {
        "family": "Romano",
        "given": "Simone"
      },
      {
        "family": "Karac",
        "given": "Itir"
      },
      {
        "family": "Kuhrmann",
        "given": "Marco"
      },
      {
        "family": "Mandić",
        "given": "Vladimir"
      },
      {
        "family": "Ramač",
        "given": "Robert"
      },
      {
        "family": "Pfahl",
        "given": "Dietmar"
      },
      {
        "family": "Engblom",
        "given": "Christian"
      },
      {
        "family": "Kyykka",
        "given": "Jarno"
      },
      {
        "family": "Rungi",
        "given": "Kerli"
      },
      {
        "family": "Palomeque",
        "given": "Carolina"
      },
      {
        "family": "Spisak",
        "given": "Jaroslav"
      },
      {
        "family": "Oivo",
        "given": "Markku"
      },
      {
        "family": "Juristo",
        "given": "Natalia"
      }
    ],
    "container-title": "Empirical Softw. Engg.",
    "id": "10.1007/s10664-020-09895-8",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2021,
          5
        ]
      ]
    },
    "keyword": "Quality, Academia, Industry, Test-driven development, Family of experiments",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "A family of experiments on test-driven development",
    "type": "article-journal",
    "volume": "26"
  },
  {
    "abstract": "Every year thousands of specialized CAD/CAM applications programs are developed to meet the needs of industry, education and research. The international 3-D graphics standard, PHIGS, has proven to be very useful in the creation of custom CAD/CAM software. Although PHIGS+ promises to deliver some geometric modeling procedures, not nearly enough is being done to support the writing of CAD/CAM software. CAD/CAM applications programmers should have available a standardized high level applications programming environment which supports the creation of device-dependent and portable design and manufacturing software.In this dissertation, one approach towards the establishment of a CAD/CAM programming standard has been presented. This programming environment is called CADMADE–Computer-Aided Design and Manufacturing Applications Development Environment. CADMADE includes not only graphics programming support, but also high level procedures to support the creation of geometric modeling, mechanical design, manufacturing, expert systems and user interface software. The requirements of CADMADE have been created. CADMADE consists of five environments: the User Interface Environment (UIE), the Design and Modeling Environment (DME), the Virtual Manufacturing Environment (VME), the Expert Consultation Environment (ECE) and the PHIGS+ Environment. The User Interface Environment has been designed in great detail. A prototype of the User Interface Environment has been created using PHIGS. Examples of applications programs which use the prototype User Interface Environment are presented. The Design and Modeling Environment has also been designed. A new set of logical input/output devices has been created for the Design and Modeling Environment. The requirements of the Expert Consultation Environment and some new concepts in expert system consultation are discussed.",
    "author": [
      {
        "family": "Jayaram",
        "given": "S."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/75966",
    "issued": {
      "date-parts": [
        [
          1989
        ]
      ]
    },
    "note": "UMI order no: GAX89-21155",
    "publisher": "Virginia Polytechnic Institute &amp; State University",
    "publisher-place": "USA",
    "title": "CADMADE: An approach towards a device-independent standard for CAD/CAM software development",
    "title-short": "CADMADE",
    "type": "thesis"
  },
  {
    "DOI": "10.1109/DASC.2014.41",
    "ISBN": "9781479950799",
    "URL": "https://doi.org/10.1109/DASC.2014.41",
    "abstract": "C is a popular programming language because of high portability and simple syntax. As a result, it is the first course for most of university students who major in computer, electronics, and electrical engineering and so on. To obtain a good learning achievement, students usually need to put their effort and time on programming as much as possible. Therefore, a ubiquitous integrated development environment is helpful for students to practice programming anytime and anywhere. To achieve this goal, we develop a novel integrated development environment called Ubi-C for C programming based on Clang and LLVM in this paper. Using this IDE, users can directly write, compile, execute and debug their C programs on Android-based smart phones or tablets. Moreover, this IDE provides the API of multimedia programming, and integrates with cloud services such as Dropbox for storing user programs and data. Consequently, users can easily develop multimedia applications by using C on mobile devices, and can switch their working environments between mobile devices and fixed computers with the support of Dropbox.",
    "author": [
      {
        "family": "Liang",
        "given": "Tyng Yeu"
      },
      {
        "family": "Li",
        "given": "Hung Fu"
      },
      {
        "family": "Chen",
        "given": "Yu Chih"
      }
    ],
    "collection-title": "DASC ’14",
    "container-title": "Proceedings of the 2014 IEEE 12th international conference on dependable, autonomic and secure computing",
    "id": "10.1109/DASC.2014.41",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "mobile devices, LLVM, Clang, C programming, Android",
    "page": "184-189",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "A ubiquitous integrated development environment for c programming on mobile devices",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1609/aimag.v7i1.531",
    "ISSN": "0738-4602",
    "URL": "https://doi.org/10.1609/aimag.v7i1.531",
    "abstract": "The Advanced Computational Methods Center (ACMC), established at the University of Georgia in 1984, supports several research projects in artificial intelligence. The primary goal of AI research at ACMC is the design and installation of a logic‐programming environment with advanced natural language processing and knowledge‐acquisition capabilities on the university’s highly parallel CYBERPLUS system from Control Data Corporation. This article briefly describes current research projects in artificial intelligence at ACMC.",
    "author": [
      {
        "family": "Nute",
        "given": "Donald"
      },
      {
        "family": "Covington",
        "given": "Michael"
      },
      {
        "family": "Rankin",
        "given": "Terry"
      }
    ],
    "container-title": "AI Mag.",
    "id": "10.1609/aimag.v7i1.531",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1986,
          3
        ]
      ]
    },
    "page": "74-76",
    "publisher": "American Association for Artificial Intelligence",
    "publisher-place": "USA",
    "title": "The advanced computational methods center, university of georgia",
    "type": "article-journal",
    "volume": "7"
  },
  {
    "DOI": "10.1145/70593.70599",
    "ISSN": "0097-8418",
    "URL": "https://doi.org/10.1145/70593.70599",
    "abstract": "Properly done, introductory computer science courses have great potential, both for preparing future computing professionals and for the broad goals of general education. Yet the performance all too often lags well behind the promise. Poor grades, high failure and drop out rates are all too common at both the collegiate and pre-collegiate levels. However the advent of seamless programming environments based on structure editing provides us with an opportunity to change the situation in fundamental ways. Initial studies show dramatic differences between students who do and do not use a structure editor based environment.",
    "author": [
      {
        "family": "Goldenson",
        "given": "D. R."
      }
    ],
    "container-title": "SIGCSE Bull.",
    "id": "10.1145/70593.70599",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          1989,
          9
        ]
      ]
    },
    "page": "26-29",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The impact of structured editing on introductory computer science education: The results so far",
    "title-short": "The impact of structured editing on introductory computer science education",
    "type": "article-journal",
    "volume": "21"
  },
  {
    "DOI": "10.1145/1045283.1045333",
    "ISSN": "0163-5719",
    "URL": "https://doi.org/10.1145/1045283.1045333",
    "abstract": "The Natural Language Graphics Project (NLG) at The Ohio State University is concerned with natural language programming in an interactive graphics environment. Natural interaction between men depends on a combination of both graphical and linguistic modes of communication [1]. The goals of the project are to study the relationships between graphical and linguistic processing in a programming environment. To achieve these goals, associated practical and theoretical issues in man-machine interaction, computer graphics, computational linguistics, and knowledge representation will be investigated.",
    "author": [
      {
        "family": "Brown",
        "given": "D. C."
      },
      {
        "family": "Buttelmann",
        "given": "H. W."
      },
      {
        "family": "Chandrasekaran",
        "given": "B."
      },
      {
        "family": "Kwasny",
        "given": "S. C."
      },
      {
        "family": "Sondheimer",
        "given": "N. K."
      }
    ],
    "container-title": "SIGART Bull.",
    "id": "10.1145/1045283.1045333",
    "issue": "61",
    "issued": {
      "date-parts": [
        [
          1977,
          2
        ]
      ]
    },
    "page": "57-58",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Natural language graphics",
    "type": "article-journal"
  },
  {
    "DOI": "10.1145/3408877.3439625",
    "ISBN": "9781450380621",
    "URL": "https://doi.org/10.1145/3408877.3439625",
    "abstract": "Debugging has been an expanding topic in K-12 computer science (CS) education research. However, few studies have focused on in-depth analysis of elementary students’ debugging in block-based visual programming environments. Thus, using the video analysis technique, this basic interpretive qualitative study aimed to explore what debugging behaviors students exhibited and how these debugging behaviors mapped with an existing K-8 debugging learning trajectory (LT). Findings revealed five types of debugging behaviors and four primary challenges. These debugging behaviors mapped to five consensus goals in the K-8 debugging learning trajectory. Future research will focus on students’ efficiency in using debugging strategies and understanding of debugging.",
    "author": [
      {
        "family": "Yan",
        "given": "Wei"
      },
      {
        "family": "Israel",
        "given": "Maya"
      },
      {
        "family": "Luo",
        "given": "Feiya"
      },
      {
        "family": "Liu",
        "given": "Ruohan"
      }
    ],
    "collection-title": "SIGCSE ’21",
    "container-title": "Proceedings of the 52nd ACM technical symposium on computer science education",
    "id": "10.1145/3408877.3439625",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "puzzle-based programming, learning trajectories, debugging",
    "page": "1308",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring elementary students’ debugging behaviors in puzzle-based programming: A learning trajectory approach",
    "title-short": "Exploring elementary students’ debugging behaviors in puzzle-based programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3545947.3576265",
    "ISBN": "9781450394338",
    "URL": "https://doi.org/10.1145/3545947.3576265",
    "abstract": "Training tools targeting robust AI are still in their infancy. We present Maestro, an effective open-source game-based platform for robust AI training in higher education, which includes counter- measures and prevention of AI vulnerabilities. Maestro provides goal-based scenarios (GBSs) where students are exposed to challenging life-inspired assignments in a competitive programming environment. The assessment of Maestro showed that its leader-board, a key gamification element, has been crucial for effective student learning. Students who felt the acquisition of new skills in robust AI tended to appreciate highly Maestro and scored highly on material consolidation, curiosity and maestry in robust AI.",
    "author": [
      {
        "family": "Geleta",
        "given": "Margarita"
      },
      {
        "family": "Xu",
        "given": "Jiacen"
      },
      {
        "family": "Loya",
        "given": "Manikanta"
      },
      {
        "family": "Wang",
        "given": "Junlin"
      },
      {
        "family": "Singh",
        "given": "Sameer"
      },
      {
        "family": "Li",
        "given": "Zhou"
      },
      {
        "family": "Gago-Masague",
        "given": "Sergio"
      }
    ],
    "collection-title": "SIGCSE 2023",
    "container-title": "Proceedings of the 54th ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3545947.3576265",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "robust ai, leaderboard, gamification, education, adversarial ai",
    "page": "1318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design factors of maestro: A serious game for robust AI education",
    "title-short": "Design factors of maestro",
    "type": "paper-conference"
  },
  {
    "abstract": "This paper describes a domain-independent implementation of explanation-based generalization (EBG) within a logic-programming environment. Explanation is interleaved with generalization, so that as the training instance is proven to be a positive example of the goal concept, the generalization is simultaneously created. All aspects of the EBG task are viewed in logic, which provides a clear semantics for EBG, and allows its integration into the logic-programming system. In this light operationally becomes a property requiring explicit reasoning. Additionally, viewing EBG in logic clarifies the relation of learning search-control to EBG, and suggests solutions for dealing with imperfect domain theories.",
    "author": [
      {
        "family": "Hirsh",
        "given": "Haym"
      }
    ],
    "collection-title": "IJCAI’87",
    "container-title": "Proceedings of the 10th international joint conference on artificial intelligence - volume 1",
    "id": "10.5555/1625015.1625060",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "page": "221-227",
    "publisher": "Morgan Kaufmann Publishers Inc.",
    "publisher-place": "San Francisco, CA, USA",
    "title": "Explanation-based generalization in a logic-programming environment",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2485760.2485785",
    "ISBN": "9781450319188",
    "URL": "https://doi.org/10.1145/2485760.2485785",
    "abstract": "ScratchJr is a graphical programming language based on Scratch and redesigned for the unique developmental and learning needs of children in kindergarten to second grade. The creation of ScratchJr addresses the relative lack of powerful technologies for digital creation and computer programming in early childhood education. ScratchJr will provide software for children to create interactive, animated stories as well as curricula and online resources to support adoption by educators. This paper describes the goals and challenges of creating a developmentally appropriate programming tool for children ages 5-7 and presents the path from guiding principles and studies with young children to current ScratchJr designs and plans for future work.",
    "author": [
      {
        "family": "Flannery",
        "given": "Louise P."
      },
      {
        "family": "Silverman",
        "given": "Brian"
      },
      {
        "family": "Kazakoff",
        "given": "Elizabeth R."
      },
      {
        "family": "Bers",
        "given": "Marina Umaschi"
      },
      {
        "family": "Bontá",
        "given": "Paula"
      },
      {
        "family": "Resnick",
        "given": "Mitchel"
      }
    ],
    "collection-title": "IDC ’13",
    "container-title": "Proceedings of the 12th international conference on interaction design and children",
    "id": "10.1145/2485760.2485785",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "keyword": "graphical programming, education, early childhood, STEM",
    "page": "1-10",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing ScratchJr: Support for early childhood learning through computer programming",
    "title-short": "Designing ScratchJr",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1121802.1121809",
    "URL": "https://doi.org/10.1145/1121802.1121809",
    "abstract": "We are carrying out a development of a whole system for processing solar images in a high performance parallel system. The main objective is to create the initial conditions for studying and forecasting the solar explosions in real time. Due to the high computational costs involved in the processing, visualization and analysis of a great amount of solar images, a high performance computer system becomes necessary to carry out the forecast of solar explosions. As a joint effort between the Department of Computer Science at Federal University of São Carlos (UFSCar), the Astrophysics Division (DAS) and Associated Laboratory for Computing and Applied Mathematics (LAC) at National Institute for Space Research - INPE, a high performance parallel system was developed with capacity to support realistic applications, involving a reasonable amount of parallel processing. The forecast of solar explosions is important as they may cause serious perturbations in terrestrial communication systems. A significant limitation for the development of parallel real-time systems is the lack of adequate programming tools, mainly for supporting the final stages of the development life cycle. This work presents a development environment, called Visual Environment for the Development of Parallel Real-Time Programs, that supports the design and implementation of parallel real-time applications executed with the support of a parallel kernel. This paper shows how this Environment was used to carry out the 3D Reconstruction of Solar Images.",
    "author": [
      {
        "family": "Morón",
        "given": "Célio E."
      },
      {
        "family": "Faria",
        "given": "Lilian N."
      },
      {
        "family": "Mascarenhas",
        "given": "Nelson D. A."
      },
      {
        "family": "Saito",
        "given": "José H."
      },
      {
        "family": "Rosa",
        "given": "Reinaldo R."
      },
      {
        "family": "Sawant",
        "given": "Hanumant S."
      }
    ],
    "container-title": "SIGBED Rev.",
    "id": "10.1145/1121802.1121809",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2005,
          7
        ]
      ]
    },
    "page": "30-35",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Visual environment for high performance real-time 3D reconstruction",
    "type": "article-journal",
    "volume": "2"
  },
  {
    "DOI": "10.1145/1099203.1099229",
    "ISBN": "1595932232",
    "URL": "https://doi.org/10.1145/1099203.1099229",
    "abstract": "Learning computer programming in a modern university course is rarely an individual activity; however, IDEs used in introductory programming classes do not support collaboration at a level appropriate for novices. The goal of our research is to make it easier for first-year students to experience working in a team in their programming assignments. Based on our previous work developing and evaluating IDEs for novice programmers, we have identified two main areas of required functionality: 1) features for code sharing and coordination; and 2) features to support communication. We have extended an existing teaching-oriented integrated development environment (called Gild) with features to support code sharing and coordination. We report on a preliminary study in which pairs of students used a prototype of our collaborative IDE to work on a programming assignment. The goals of this study were to evaluate the effectiveness and usability of the new features and to determine requirements for future communication support.",
    "author": [
      {
        "family": "Čubranić",
        "given": "Davor"
      },
      {
        "family": "Storey",
        "given": "Margaret Anne D."
      }
    ],
    "collection-title": "GROUP ’05",
    "container-title": "Proceedings of the 2005 ACM international conference on supporting group work",
    "id": "10.1145/1099203.1099229",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "keyword": "teaching programming, gild",
    "page": "136-139",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Collaboration support for novice team programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3341525.3394000",
    "ISBN": "9781450368742",
    "URL": "https://doi.org/10.1145/3341525.3394000",
    "abstract": "In computer programming education, showing the application of programming in reality has become a common way to introduce it to young learners. However, we have limited knowledge of how best to utilize smart objects and environments to foster the learners’ programming skills and develop a positive attitude towards programming. My research focuses on filling this gap by presenting an educational block-based programming tool that brings together the hot topic of smart environments and the visual programming paradigm. The end goal is empirically investigating the impacts of state-of-the-art smart technologies together with block-based programming on the learners’ programming skills and attitudes towards programming in non-formal learning environments.",
    "author": [
      {
        "family": "Seraj",
        "given": "Mazyar"
      }
    ],
    "collection-title": "ITiCSE ’20",
    "container-title": "Proceedings of the 2020 ACM conference on innovation and technology in computer science education",
    "id": "10.1145/3341525.3394000",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "young learners, smart homes, programming skills, experiment, block-based programming, attitudes towards programming",
    "page": "569-570",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Impacts of block-based programming on young learners’ programming skills and attitudes in the context of smart environments",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1275620.1275625",
    "ISBN": "9781450347358",
    "URL": "https://doi.org/10.1145/1275620.1275625",
    "abstract": "At Northeastern University we are building a number of courses upon a common embedded systems platform. The goal is to reduce the learning curve associated with new architectures and programming environments. The platform selected is based on the Analog Devices Blackfin digital signal processor.In this paper we discuss our recent experience developing anew undergraduate embedded systems lab. Students learn to utilize the embedded DSP platform to address a number of different applications, including controller design, RS-232 communication, encryption, and image processing. This platform provides a rich design exploration sandbox replete with programming and simulation tools. We describe our use of this platform in our Microprocessor-based Design Laboratory and discuss how this platform can be used in a range of classes.",
    "author": [
      {
        "family": "Benjamin",
        "given": "Michael"
      },
      {
        "family": "Kaeli",
        "given": "David"
      },
      {
        "family": "Platcow",
        "given": "Richard"
      }
    ],
    "collection-title": "WCAE ’06",
    "container-title": "Proceedings of the 2006 workshop on computer architecture education: Held in conjunction with the 33rd international symposium on computer architecture",
    "id": "10.1145/1275620.1275625",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "page": "2-es",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Experiences with the blackfin architecture in an embedded systems lab",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800225.806824",
    "ISBN": "0897911652",
    "URL": "https://doi.org/10.1145/800225.806824",
    "abstract": "The programming system generator developed at the Technical University of Darmstadt generates sophisticated interactive programming environments from formal language definitions. From a formal, entirely non-procedural definition of the language’s syntax, context conditions and denotational semantics, it produces a hybrid editor, an interpreter and a library system. The editor allows both structure editing and text editing, guaranteeing immediate recognition of syntactic and semantic errors. The generator has been used to generate environments for PASCAL, MODULA-2 and the formal language definition language itself. A brief description of the generated environments and the definition language is given, and our experiences with formal language definitions are discussed from the language definer’s point of view as well as from the programmer’s point of view using the generated environments.",
    "author": [
      {
        "family": "Bahlke",
        "given": "Rolf"
      },
      {
        "family": "Snelting",
        "given": "Gregor"
      }
    ],
    "collection-title": "SLIPE ’85",
    "container-title": "Proceedings of the ACM SIGPLAN 85 symposium on language issues in programming environments",
    "id": "10.1145/800225.806824",
    "issued": {
      "date-parts": [
        [
          1985
        ]
      ]
    },
    "page": "28-33",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The PSG - programming system generator",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/6465.6489",
    "ISSN": "0164-0925",
    "URL": "https://doi.org/10.1145/6465.6489",
    "abstract": "In spite of substantial progress in the theory of interprocedural data flow analysis, few practical compiling systems can afford to apply it to produce more efficient object programs. To perform interprocedural analysis, a compiler needs not only the source code of the module being compiled, but also information about the side effects of every procedure in the program containing that module, even separately compiled procedures. In a conventional batch compiler system, the increase in compilation time required to gather this information would make the whole process impractical. In an integrated programming environment, however, other tools can cooperate with the compiler to compute the necessary interprocedural information incrementally. as the program is being developed, decreasing both the overall cost of the analysis and the cost of individual compilations.A central goal of the Rn project at Rice University is to construct a prototype software development environment that is designed to build whole programs, rather than just individual modules. It employs interprocedural analysis and optimization to produce high-quality machine code for whole programs. This paper presents an overview of the methods used by the environment to accomplish this task and discusses the impact of these methods on the various environment components. The responsibilities of each component of the environment for the preparation and use of interprocedural information are presented in detail.",
    "author": [
      {
        "family": "Cooper",
        "given": "Keith D."
      },
      {
        "family": "Kennedy",
        "given": "Ken"
      },
      {
        "family": "Torczon",
        "given": "Linda"
      }
    ],
    "container-title": "ACM Trans. Program. Lang. Syst.",
    "id": "10.1145/6465.6489",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1986,
          8
        ]
      ]
    },
    "page": "491-523",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The impact of interprocedural analysis and optimization in the rn programming environment",
    "type": "article-journal",
    "volume": "8"
  },
  {
    "DOI": "10.1145/1176617.1176635",
    "ISBN": "159593491X",
    "URL": "https://doi.org/10.1145/1176617.1176635",
    "abstract": "The Eclipse platform (http://www.eclipse.org) is designed for building integrated development environments (IDEs) for object-oriented application development. Building on the success of the Eclipse Technology eXchange workshops at OOPSLA 2003, 2004, and 2005, we invite original papers that describe potential new uses of Eclipse and how the core Eclipse technology can be leveraged, improved and/or extended for research and teaching projects. Accepted papers will be presented at the workshop. Due to the popularity of this workshop in the past, this year’s ETX will be a 1.5 day event. Workshop topics include (but are not limited to) the use of Eclipse for: IDEs, supporting the software development process, debugging or testing, design requirements/specification, modeling environments or frameworks, aspect-oriented programming, program analysis and transformation, such as for refactoring, optimization, or obfuscation, computer-based learning, software engineering education, teaching foundations of object-oriented programming courseware, teaching an introductory undergraduate programming course, web service applications, rich client application.",
    "author": [
      {
        "family": "Burke",
        "given": "Michael G."
      },
      {
        "family": "Morris",
        "given": "Cheryl"
      },
      {
        "family": "Orso",
        "given": "Alessandro"
      },
      {
        "family": "Robillard",
        "given": "Martin"
      }
    ],
    "collection-title": "OOPSLA ’06",
    "container-title": "Companion to the 21st ACM SIGPLAN symposium on object-oriented programming systems, languages, and applications",
    "id": "10.1145/1176617.1176635",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "page": "619",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Eclipse technology eXchange (ETX) workshop",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1238844.1238853",
    "ISBN": "9781595937667",
    "URL": "https://doi.org/10.1145/1238844.1238853",
    "abstract": "The years 1985 through 1995 saw the birth and development of the language Self, starting from its design by the authors at Xerox PARC, through first implementations by Ungar and his graduate students at Stanford University, and then with a larger team formed when the authors joined Sun Microsystems Laboratories in 1991. Self was designed to help programmers become more productive and creative by giving them a simple, pure, and powerful language, an implementation that combined ease of use with high performance, a user interface that off-loaded cognitive burden, and a programming environment that captured the malleability of a physical world of live objects. Accomplishing these goals required innovation in several areas: a simple yet powerful prototype-based object model for mainstream programming, many compilation techniques including customization, splitting, type prediction, polymorphic inline caches, adaptive optimization, and dynamic deoptimization, the application of cartoon animation to enhance the legibility of a dynamic graphical interface, an object-centered programming environment, and a user-interface construction framework that embodied a uniform use-mention distinction. Over the years, the project has published many papers and released four major versions of Self.Although the Self project ended in 1995, its implementation, animation, user interface toolkit architecture, and even its prototype object model impact computer science today (2006). Java virtual machines for desktop and laptop computers have adopted Self’s implementation techniques, many user interfaces incorporate cartoon animation, several popular systems have adopted similar interface frameworks, and the prototype object model can be found in some of today’s languages, including JavaScript. Nevertheless, the vision we tried to capture in the unified whole has yet to be achieved.",
    "author": [
      {
        "family": "Ungar",
        "given": "David"
      },
      {
        "family": "Smith",
        "given": "Randall B."
      }
    ],
    "collection-title": "HOPL III",
    "container-title": "Proceedings of the third ACM SIGPLAN conference on history of programming languages",
    "id": "10.1145/1238844.1238853",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "virtual machine, prototype-based programming language, programming environment, object-oriented language, morphic, history of programming languages, exploratory programming, dynamic optimization, dynamic language, cartoon animation, adaptive optimization, Self",
    "page": "9-1-9-50",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Self",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1227310.1227388",
    "ISBN": "1595933611",
    "URL": "https://doi.org/10.1145/1227310.1227388",
    "abstract": "Scratch is a \"media-rich programming environment\" recently developed by MIT’s Media Lab that \"lets you create your own animations, games, and interactive art.\" Although Scratch is intended to \"enhance the development of technological fluency [among youths] at after-school centers in economically disadvantaged communities,\" we find rarkable potential in this programming environment for higher education as well.We propose Scratch as a first language for first-time programmers in introductory courses, for majors and non-majors alike. Scratch allows students to program with a mouse: programmatic constructs are represented as puzzle pieces that only fit together if \"syntactically\" appropriate. We argue that this environment allows students not only to master programmatic constructs before syntax but also to focus on probls of logic before syntax. We view Scratch as a gateway to languages like Java.To validate our proposal, we recently deployed Scratch for the first time in higher education via harvard Summer School’s Computer Science S-1: Great Ideas in Computer Science, the summertime version of a course at harvard College. Our goal was not to improve scores but instead to improve first-time programmers’ experiences. We ultimately transitioned to Java, but we first introduced programming itself via Scratch. We present in this paper the results of our trial.We find that, not only did Scratch excite students at a critical time (i.e.,, their first foray into computer science), it also familiarized the inexperienced among th with fundamentals of programming without the distraction of syntax. Moreover, when asked via surveys at term’s end to reflect on how their initial experience with Scratch affected their subsequent experience with Java, most students (76",
    "author": [
      {
        "family": "Malan",
        "given": "David J."
      },
      {
        "family": "Leitner",
        "given": "Henry H."
      }
    ],
    "collection-title": "SIGCSE ’07",
    "container-title": "Proceedings of the 38th SIGCSE technical symposium on computer science education",
    "id": "10.1145/1227310.1227388",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "scratch, programming, languages, Java",
    "page": "223-227",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Scratch for budding computer scientists",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICCIMA.2005.29",
    "ISBN": "0769523587",
    "URL": "https://doi.org/10.1109/ICCIMA.2005.29",
    "abstract": "Computational Intelligence (CI) based model approaches, realized by Fuzzy Control models (FC) or models with Artificial Neural Networks (NN), are used as alternativ concepts to classical approaches. In university education or further training are on the one hand models necessary which represent the technical system transparent and easy cognizable and on the other hand a programming tool is required that supports an easy development process. That includes tools to verify the results and tuning the system with graphic functions under real time conditions. A Fuzzy Control Design Tool (FHFCE-Tool) and four technical modells will be presented. The methodical and didactical objective in the utilization of this teaching models is to develop solution strategies in CI applications, for example Fuzzy Controller, special to analyse different algorithms of inference or defuzzyfication and to verify and tune those systems.",
    "author": [
      {
        "family": "Kramer",
        "given": "Klaus-Dietrich"
      },
      {
        "family": "Blankenberg",
        "given": "Christian"
      }
    ],
    "collection-title": "ICCIMA ’05",
    "container-title": "Proceedings of the sixth international conference on computational intelligence and multimedia applications",
    "id": "10.1109/ICCIMA.2005.29",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "335-336",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Fuzzy control design tool to apply in FC teaching models",
    "type": "paper-conference"
  },
  {
    "ISBN": "3540441808",
    "abstract": "In recent years, many theoretically I/O-efficient algorithms and data structures have been developed. The TPIE project at Duke University was started to investigate the practical importance of these theoretical results. The goal of this ongoing project is to provide a portable, extensible, flexible, and easy to use C++ programming environment for efficiently implementing I/O-algorithms and data structures. The TPIE library has been developed in two phases. The first phase focused on supporting algorithms with a sequential I/O pattern, while the recently developed second phase has focused on supporting on-line I/O-efficient data structures, which exhibit a more random I/O pattern. This paper describes the design and implementation of the second phase of TPIE.",
    "author": [
      {
        "family": "Arge",
        "given": "Lars"
      },
      {
        "family": "Procopiuc",
        "given": "Octavian"
      },
      {
        "family": "Vitter",
        "given": "Jeffrey Scott"
      }
    ],
    "collection-title": "ESA ’02",
    "container-title": "Proceedings of the 10th annual european symposium on algorithms",
    "id": "10.5555/647912.740668",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "page": "88-100",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Implementing i/o-efficient data structures using TPIE",
    "type": "paper-conference"
  },
  {
    "abstract": "In the Fall of 1992, the graduate Operating Systems class at Carnegie Mellon University implemented the necessary components to provide applications with a programmable interface to a mobile palmtop computer. The goal of the project was to expose project members to the area of mobile computing through \"shock immersion.\" Over the course of two months, students designed and implemented the infrastructure for a simple mobile computing environment for low-end palmtop machines. This programming environment was used to develop a suite of mobile applications such as a mailer, graphical locator map, the game tetris, and a scheme interpreter that allowed functions to be remotely executed on the palmtop. In this paper, we describe the results of the course project and the lessons learned.",
    "author": [
      {
        "family": "Watson",
        "given": "Terri"
      },
      {
        "family": "Bershad",
        "given": "Brian N."
      }
    ],
    "collection-title": "MLCS",
    "container-title": "Mobile &amp; location-independent computing symposium on mobile &amp; location-independent computing symposium",
    "id": "10.5555/1287073.1287083",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "page": "10",
    "publisher": "USENIX Association",
    "publisher-place": "USA",
    "title": "Local area mobile computing on stock hardware and mostly stock software",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1155/ASP.2005.1005",
    "ISSN": "1110-8657",
    "URL": "https://doi.org/10.1155/ASP.2005.1005",
    "abstract": "SKiPPER is a Skeleton-based Parallel Programming EnviRonment being developed since 1996 and running at LASMEA Laboratory, the Blaise-Pascal University, France. The main goal of the project was to demonstrate the applicability of skeleton-based parallel programming techniques to the fast prototyping of reactive vision applications. This paper deals with the special features embedded in the latest version of the project: algorithmic skeleton nesting capabilities and a fully dynamic operating model. Throughout the case study of a complete and realistic image processing application, in which we have pointed out the requirement for skeleton nesting, we are presenting the operating model of this feature. The work described here is one of the few reported experiments showing the application of skeleton nesting facilities for the parallelisation of a realistic application, especially in the area of image processing. The image processing application we have chosen is a 3D face-tracking algorithm from appearance.",
    "author": [
      {
        "family": "Coudarcher",
        "given": "Rémi"
      },
      {
        "family": "Duculty",
        "given": "Florent"
      },
      {
        "family": "Serot",
        "given": "Jocelyn"
      },
      {
        "family": "Jurie",
        "given": "Frédéric"
      },
      {
        "family": "Derutin",
        "given": "Jean-Pierre"
      },
      {
        "family": "Dhome",
        "given": "Michel"
      }
    ],
    "container-title": "EURASIP J. Adv. Signal Process",
    "id": "10.1155/ASP.2005.1005",
    "issued": {
      "date-parts": [
        [
          2005,
          1
        ]
      ]
    },
    "keyword": "parallel programming, nesting, image processing, algorithmic skeleton, 3D face tracking",
    "page": "1005-1023",
    "publisher": "Hindawi Limited",
    "publisher-place": "London, GBR",
    "title": "Managing algorithmic skeleton nesting requirements in realistic image processing applications: The case of the SKiPPER-II parallel programming environment’s operating model",
    "title-short": "Managing algorithmic skeleton nesting requirements in realistic image processing applications",
    "type": "article-journal",
    "volume": "2005"
  },
  {
    "DOI": "10.1145/3567512.3567527",
    "ISBN": "9781450399197",
    "URL": "https://doi.org/10.1145/3567512.3567527",
    "abstract": "Exploratory programming is a software development style in which code is a medium for prototyping ideas and solutions, and in which even the end-goal can evolve over time. Exploratory programming is valuable in various contexts such as programming education, data science, and end-user programming. However, there is a lack of appropriate tooling and language design principles to support exploratory programming. This paper presents a host language- and object language-independent protocol for exploratory programming akin to the Language Server Protocol. The protocol serves as a basis to develop novel (or extend existing) programming environments for exploratory programming such as computational notebooks and command-line REPLs. An architecture is presented on top of which prototype environments can be developed with relative ease, because existing (language) components can be reused. Our prototypes demonstrate that the proposed protocol is sufficiently expressive to support exploratory programming scenarios as encountered in literature within the software engineering, human-computer interaction and data science domains.",
    "author": [
      {
        "dropping-particle": "van",
        "family": "Binsbergen",
        "given": "L. Thomas"
      },
      {
        "family": "Frölich",
        "given": "Damian"
      },
      {
        "family": "Verano Merino",
        "given": "Mauricio"
      },
      {
        "family": "Lai",
        "given": "Joey"
      },
      {
        "family": "Jeanjean",
        "given": "Pierre"
      },
      {
        "dropping-particle": "van der",
        "family": "Storm",
        "given": "Tijs"
      },
      {
        "family": "Combemale",
        "given": "Benoit"
      },
      {
        "family": "Barais",
        "given": "Olivier"
      }
    ],
    "collection-title": "SLE 2022",
    "container-title": "Proceedings of the 15th ACM SIGPLAN international conference on software language engineering",
    "id": "10.1145/3567512.3567527",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "protocol, notebooks, interpreters, REPLs, IDEs, Exploratory programming",
    "page": "175-188",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A language-parametric approach to exploratory programming environments",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2538862.2544312",
    "ISBN": "9781450326056",
    "URL": "https://doi.org/10.1145/2538862.2544312",
    "abstract": "Studio K is a game design curriculum constructed to provide middle school students an engaging entry into computer science and programming. Developed at the University of Wisconsin-Madison, the program employs Microsoft’s 3D programming environment, Kodu, in tandem with support and analytic tools for facilitators, and an online community that provides players with a support system. These key features are bolstered with incorporation of telemetry data gathered through design sessions that are used to improve site functioning, curriculum relevancy, and administrative tools. This program is applied across contexts, with applications in formal classrooms, informal extracurricular clubs or camps, and alternative learning environments such as library systems or home schools. Studio K provides a well-supported, unique entry into computer science in which programming knowledge becomes a tool that supports learners’ goals in designing and developing games.",
    "author": [
      {
        "family": "Anton",
        "given": "Gabriella"
      },
      {
        "family": "Berland",
        "given": "Matthew"
      }
    ],
    "collection-title": "SIGCSE ’14",
    "container-title": "Proceedings of the 45th ACM technical symposium on computer science education",
    "id": "10.1145/2538862.2544312",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "game design, computer science education",
    "page": "723",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Studio k: A game development environment designed for gains in computational thinking (abstract only)",
    "title-short": "Studio k",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1384271.1384341",
    "ISBN": "9781605580784",
    "URL": "https://doi.org/10.1145/1384271.1384341",
    "abstract": "Ever growing expectations from students, university management and other stakeholders make course preparation increasingly time-consuming. Setting up a course from scratch requires producing many supporting documents such as syllabi, schedules, and course web sites listing the concepts being taught. This can be a considerable effort, taking time away from tasks with a more immediate pedagogical value, such as answering student questions and refining the concepts themselves.The TrucStudio course development framework supports a systematic approach to these necessary but arduous tasks. TrucStudio is organized like a modern programming environment, but its elements of discourse, rather than software modules, are units of knowledge such as notions, Trucs and clusters.In addition to course development, applications of TrucStudio include checking sound coverage of topics and comparing courses on an objective basis. This presentation focuses on two novel features of TrucStudio: version management of knowledge units and course information; and generation of output documents in various formats from knowledge units and other material managed by TrucStudio.",
    "author": [
      {
        "family": "Pedroni",
        "given": "Michela"
      },
      {
        "family": "Oriol",
        "given": "Manuel"
      },
      {
        "family": "Meyer",
        "given": "Bertrand"
      },
      {
        "family": "Albonico",
        "given": "Enrico"
      },
      {
        "family": "Angerer",
        "given": "Lukas"
      }
    ],
    "collection-title": "ITiCSE ’08",
    "container-title": "Proceedings of the 13th annual conference on innovation and technology in computer science education",
    "id": "10.1145/1384271.1384341",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "versioning, output generation, knowledge modeling, curriculum design, course design",
    "page": "260-264",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Course management with TrucStudio",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2808580.2808628",
    "ISBN": "9781450334426",
    "URL": "https://doi.org/10.1145/2808580.2808628",
    "abstract": "One of the basic requirements in education is to prepare students for participation in an information society in which knowledge will be the most important resource for development. Computer-Supported Collaborative Learning is one of the most promising approaches to enhance the learning process with the help of information and communication technology. At the same time, advances in technology and mobile devices in the last decade have increased the number of educational institutions adopting mobile tools in the learning process. This paper describes the design and implementation of a protocol for a collaborative mobile application. TITIBOTS Colab is a programming environment for kids between 4 and 6 years old. During the implementation of TITIBOTS Colab, while creating a working version of the protocol, our team found that all messages defined in the design worked properly in order to provide the communication rules for the client and server applications.",
    "author": [
      {
        "family": "Ramı́rez-Benavides",
        "given": "Kryscia"
      },
      {
        "family": "Garcı́a",
        "given": "Franklin"
      },
      {
        "family": "Guerrero",
        "given": "Luis A."
      }
    ],
    "collection-title": "TEEM ’15",
    "container-title": "Proceedings of the 3rd international conference on technological ecosystems for enhancing multiculturality",
    "id": "10.1145/2808580.2808628",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "robotics, protocol architecture, programming learning, mobile devices, early childhood education, collaborative work",
    "page": "317-324",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Creating a protocol for collaborative mobile applications for kids between 4 and 6 years old",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2839509.2844598",
    "ISBN": "9781450336857",
    "URL": "https://doi.org/10.1145/2839509.2844598",
    "abstract": "Computer Science Education Week activities, featuring online? programming tools embedded with tutorials, report large participation numbers. However, to truly broaden participation, activities need to be made accessible in international contexts. In 2014, Tecnológico de Monterrey and Instituto de Innovación y Transferencia de Tecnologı́a de Nuevo León, modified the Scalable Game Design CS Ed Week activity to include a Mexican feasibility pilot study. The goal of the pilot was to broaden participation in Computer Science in Mexico by creating interest and demand in further activities, including launching of 2015 Mexico CS Ed Week. This paper reviews the initial results of this 2014 pilot, including the discussion of the unique challenges faced in this context, and examines efforts to make this activity more accessible and successful. In addition to pilot data highlighting future activity improvements, initial retention results show that despite challenges, Mexican students were able to effectively use the modified activity to create games on par with U.S. students.",
    "author": [
      {
        "family": "Escherle",
        "given": "Nora A."
      },
      {
        "family": "Ramirez-Ramirez",
        "given": "Silvia I."
      },
      {
        "family": "Basawapatna",
        "given": "Ashok R."
      },
      {
        "family": "Assaf",
        "given": "Dorit"
      },
      {
        "family": "Repenning",
        "given": "Alexander"
      },
      {
        "family": "Maiello",
        "given": "Carmine"
      },
      {
        "family": "Endo",
        "given": "Yasko Ch."
      },
      {
        "family": "Nolazco-Flores",
        "given": "Juan A."
      }
    ],
    "collection-title": "SIGCSE ’16",
    "container-title": "Proceedings of the 47th ACM technical symposium on computing science education",
    "id": "10.1145/2839509.2844598",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "international research, globalization of programming activities., experience report, computer science education week, computer science education in mexico, computer science education, broadening participation",
    "page": "431-436",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Piloting computer science education week in mexico",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ISCSCT.2008.146",
    "ISBN": "9780769534985",
    "URL": "https://doi.org/10.1109/ISCSCT.2008.146",
    "abstract": "Utilize the programming environment at present, it’s effortless for us to design intuitionistic visual program. It only implements the visualization of programming ending. The process of programming is not fully visualization and it’s not visual programming language in its true sense. According to the related research on visual programming languages in the past, the language is designed for special area or education, which is of pertinence and ordinary. If the programming language is made up of a series of graphic expressions it’s under the name of visual programming language. So the goal of our research is to construct a kind of visual programming language which is propitious to program in graphic components, is convenient for comprehension to programmers and nonprogrammer and the most important is it can reduce error rate which is caused by former textual input and recede the workload in the course of lexical analysis and semantic parsing.",
    "author": [
      {
        "family": "Xiajiong",
        "given": "Shen"
      },
      {
        "family": "Ge",
        "given": "Wang"
      },
      {
        "family": "Jun",
        "given": "Gu"
      },
      {
        "family": "Xinfa",
        "given": "Dong"
      }
    ],
    "collection-title": "ISCSCT ’08",
    "container-title": "Proceedings of the 2008 international symposium on computer science and computational technology - volume 01",
    "id": "10.1109/ISCSCT.2008.146",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "visualization, visual programming language, error",
    "page": "280-283",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "A novel visual programming method designed for error rate reduction",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3545945.3569736",
    "ISBN": "9781450394314",
    "URL": "https://doi.org/10.1145/3545945.3569736",
    "abstract": "If computer science programs face a challenge of convincing students that programming is fun and achievable, they have nothing on mathematics departments who face societal beliefs that math is hard and scary. Several movements in computer science education have focused on broadening participation within computer science and across disciplines. The \"CS + X\" efforts have focused on helping computer science integrate into other disciplines. The \"CS For All\" movement has highlighted the importance of providing high quality computing education for all students. Simultaneously, there is increasing attention to the need to provide general education alternatives to college algebra. This paper describes a course designed to combine these goals: a course that uses programming to introduce students to functions, patterns, and spatial and computational thinking in order to meet quantitative reasoning goals set by the university. The course initially used Bricklayer as the programming environment, then transitioned to Processing. Students were successful in writing programs that created art, demonstrated mastery of quantitative literacy, and had improved attitudes following the course. This project suggests that in addition to the creation of introductory computer science classes, courses which embed computer science into disciplinary requirements can be a successful pathway to expand opportunities for students to learn computing.",
    "author": [
      {
        "family": "Friend",
        "given": "Michelle"
      },
      {
        "family": "Swift",
        "given": "Andrew W."
      },
      {
        "family": "Love",
        "given": "Betty"
      },
      {
        "family": "Winter",
        "given": "Victor"
      }
    ],
    "collection-title": "SIGCSE 2023",
    "container-title": "Proceedings of the 54th ACM technical symposium on computer science education v. 1",
    "id": "10.1145/3545945.3569736",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "cs+x, interdisciplinary, mathematics",
    "page": "256-262",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A wolf in lamb’s clothing: Computer science in a mathematics course",
    "title-short": "A wolf in lamb’s clothing",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2047594.2047649",
    "ISBN": "9781450310178",
    "URL": "https://doi.org/10.1145/2047594.2047649",
    "abstract": "Programming constitutes one of the core competencies demanded of any IT education. However, some students within certain specializations of this diverse discipline are inclined to question the need for programming. The use of a visual programming environment in the development of interactive multimedia applications can serve the dual purposes of getting students excited about programming and giving them the core knowledge they need. The visual language Max/MSP/Jitter (\"Max\"), geared toward music, audio, and video application programming, is introduced as an excellent vehicle toward achieving this goal. The foundational constructs of Max are introduced in a series of example programs dealing with music applications. Some details of an undergraduate IT course called \"Interactive Music System Technology\" that utilizes Max are presented. Overall, the use of Max in the undergraduate IT curriculum can enhance the student’s experience (both in multimedia and in IT in general) and promote better programming skills.",
    "author": [
      {
        "family": "Manzo",
        "given": "V. J."
      },
      {
        "family": "Halper",
        "given": "Matthew"
      },
      {
        "family": "Halper",
        "given": "Michael"
      }
    ],
    "collection-title": "SIGITE ’11",
    "container-title": "Proceedings of the 2011 conference on information technology education",
    "id": "10.1145/2047594.2047649",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "keyword": "visual programming language, multimedia, digital audio, computer music, Max/MSP/Jitter, IT programming",
    "page": "203-208",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Multimedia-based visual programming promoting core competencies in IT education",
    "type": "paper-conference"
  },
  {
    "abstract": "Implementations of em Explanation-Based Generalization (EBG) within a logic-programming environment, as e.g. the well-known PROLOG-EBG algorithm, are able to generalize the proof of a goal from a em definite (i.e. Horn clause) domain theory. However, it is a fact that practical applications frequently require the enhanced expressiveness of em negations in rule bodies. Specifically, this is the case for the domain of game playing, where traditional EBG has turned out to be inadequate. In this paper we present an approach which extends EBG to this more general setting; it is described in the form of a transformation system, and comprises Siqueira and Puget”s method of em Explanation-Based Generalization of Failures for definite programs. For the case that both domain theory and training example are represented as em allowed normal programs, we prove that the derived clause satisfies the standard requirements for EBG, namely em operationality, em sufficiency, and em correctness. Furthermore, a meta-interpreter implementation of the transformation system is provided.",
    "author": [
      {
        "family": "Schroedl",
        "given": "Stefan"
      }
    ],
    "id": "10.5555/896309",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "publisher": "Albert-Ludwigs University at Freiburg",
    "title": "An extension of explanation-based generalization to negation as failure",
    "type": "report"
  },
  {
    "DOI": "10.1145/3397617.3397833",
    "ISBN": "9781450380201",
    "URL": "https://doi.org/10.1145/3397617.3397833",
    "abstract": "Over the last few years, researchers, teachers, parents, volunteers, and even IT companies have joined efforts to develop coding activities for children in K-12 education. These efforts include technological tools and programming environments as well as activities descriptions. Kodeløypa is a coding activity offered by NTNU, which focuses on engaging teens in creative programming. In this paper, we report about the design and implementation of an empirical investigation with 13 teachers who attended Kodeløypa as associated school teachers of the pupils from their respective schools. In this study, we have addressed the following research question: What are the teachers’ understandings of coding activities for teens outside the schools? The goal of this study was to identify various factors that will help us to acquire knowledge on this important kind of stakeholders, and improve the design and implementation of Kodeløypa and other similar efforts. We have conducted a thematic analysis with the data and we expect the results of this study will help teachers and researchers to design and organize computer science learning activities more efficiently and collaboratively.",
    "author": [
      {
        "family": "Quayyum",
        "given": "Farzana"
      },
      {
        "family": "Bueie",
        "given": "Jonas"
      },
      {
        "family": "Vidal",
        "given": "Juan Carlos Torrado"
      },
      {
        "family": "Jaccheri",
        "given": "Letizia"
      }
    ],
    "collection-title": "IDC ’20",
    "container-title": "Proceedings of the 2020 ACM interaction design and children conference: Extended abstracts",
    "id": "10.1145/3397617.3397833",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "teenagers, programming for teens, kodeløypa, computational thinking, coding activities",
    "page": "187-192",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Understanding coding activities for teens: A focus on school teachers’ perspectives",
    "title-short": "Understanding coding activities for teens",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1384271.1384289",
    "ISBN": "9781605580784",
    "URL": "https://doi.org/10.1145/1384271.1384289",
    "abstract": "The complexity and resource requirements of professional IDEs mean that they are unsuitable for use in intermediate level programming courses. Jenuity is an efficient development environment for the Java programming language. Efficiency is essential as students often have outdated hardware unable to run mainstream development environments. This is of particular relevance in the context of a developing country. Jenuity provides advanced features usually associated with more resource intensive tools. It provides a simple and intuitive interface, which is well suited to intermediate level programming courses. Jenuity has been used successfully in the teaching of these courses at the authors’ institution since 2004. The requirements, development and optimisation of this tool are discussed. Techniques used to optimise Jenuity for low specification student hardware, some of which are novel, are presented. Experiences using Jenuity in a university environment are also reported. The efficiency of Jenuity is also demonstrated by means of a comparison to mainstream development environments.",
    "author": [
      {
        "dropping-particle": "van",
        "family": "Tonder",
        "given": "Martin"
      },
      {
        "family": "Naude",
        "given": "Kevin"
      },
      {
        "family": "Cilliers",
        "given": "Charmain"
      }
    ],
    "collection-title": "ITiCSE ’08",
    "container-title": "Proceedings of the 13th annual conference on innovation and technology in computer science education",
    "id": "10.1145/1384271.1384289",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "visual interface builder, jenuity, intermediate level programming, integrated development environment, cs2",
    "page": "58-62",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Jenuity: A lightweight development environment for intermediate level programming courses",
    "title-short": "Jenuity",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s00146-021-01328-4",
    "ISSN": "0951-5666",
    "URL": "https://doi.org/10.1007/s00146-021-01328-4",
    "abstract": "It is generally agreed that one origin of machine bias is resulting from characteristics within the dataset on which the algorithms are trained, i.e., the data does not warrant a generalized inference. We, however, hypothesize that a different “mechanism” may also be responsible for machine bias, namely that biases may originate from (i) the programmers’ cultural background, including education or line of work, or (ii) the contextual programming environment, including software requirements or developer tools. Combining an experimental and comparative design, we study the effects of cultural and contextual metaphors, and test whether each of these are “transferred” from the programmer to the program, thus constituting a machine bias. Our results show that (i) cultural metaphors influence the programmer’s choices and (ii) contextual metaphors induced through priming can be used to moderate or exacerbate the effects of the cultural metaphors. Our studies are purposely performed with users of varying educational backgrounds and programming skills stretching from novice to proficient.",
    "author": [
      {
        "family": "Johansen",
        "given": "Johanna"
      },
      {
        "family": "Pedersen",
        "given": "Tore"
      },
      {
        "family": "Johansen",
        "given": "Christian"
      }
    ],
    "container-title": "AI Soc.",
    "id": "10.1007/s00146-021-01328-4",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2022,
          12
        ]
      ]
    },
    "keyword": "Randomized controlled trial, Priming, Metaphors, Cultural background, AI, Programmers, Biases",
    "page": "1659-1683",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Studying human-to-computer bias transference",
    "type": "article-journal",
    "volume": "38"
  },
  {
    "DOI": "10.1145/122050.122057",
    "ISSN": "0163-5808",
    "URL": "https://doi.org/10.1145/122050.122057",
    "abstract": "Altaı̈r is a five year project which began in September of 1986. Its goal is to design an implement a next generation database system. The five year project was divided in two phases: a three year prototyping phase and a two year phase devoted for one part to the development of a product from the prototype and for the other part to a new research effort.The three year phase ended by the demonstration of the V1 prototype of the O2 object-oriented database system which has been distributed for experimentation to more than 40 universities and about 13 industrial partners.The contribution of the Altaı̈r group to the database research community has been mainly in three areas: data model and database languages, object stores, and programming environments. Furthermore, all these efforts have been integrated in a consistent way into the V1 prototype. The results of this research and development effort are being summarized in a book [BDK91] which is a commented collection of papers, most of them already published in the proceedings of a number of internationally recognized conferences. We briefly survey in the following the O2 activities.",
    "author": [
      {
        "family": "Richard",
        "given": "Philippe"
      }
    ],
    "container-title": "SIGMOD Rec.",
    "id": "10.1145/122050.122057",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1991,
          2
        ]
      ]
    },
    "page": "53-59",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Research at altaı̈r",
    "type": "article-journal",
    "volume": "20"
  },
  {
    "DOI": "10.1145/6465.20890",
    "ISSN": "0164-0925",
    "URL": "https://doi.org/10.1145/6465.20890",
    "abstract": "The PSG programming system generator developed at the Technical University of Darmstadt produces interactive, language-specific programming environments from formal language definitions. All language-dependent parts of the environment are generated from an entirely nonprocedural specification of the language’s syntax, context conditions, and dynamic semantics. The generated environment consists of a language-based editor, supporting systematic program development by named program fragments, an interpreter, and a fragment library system. The major component of the environment is a full-screen editor, which allows both structure and text editing. In structure mode the editor guarantees prevention of both syntactic and semantic errors, whereas in textual mode it guarantees their immediate recognition. PSG editors employ a novel algorithm for incremental semantic analysis which is based on unification. The algorithm will immediately detect semantic errors even in incomplete program fragments. The dynamic semantics of the language are defined in denotational style using a functional language based on the lambda calculus. Program fragments are compiled to terms of the functional language which are executed by an interpreter. The PSG generator has been used to produce environments for Pascal, ALGOL 60, MODULA-2, and the formal language definition language itself.",
    "author": [
      {
        "family": "Bahlke",
        "given": "Rolf"
      },
      {
        "family": "Snelting",
        "given": "Gregor"
      }
    ],
    "container-title": "ACM Trans. Program. Lang. Syst.",
    "id": "10.1145/6465.20890",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1986,
          8
        ]
      ]
    },
    "page": "547-576",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The PSG system: From formal language definitions to interactive programming environments",
    "title-short": "The PSG system",
    "type": "article-journal",
    "volume": "8"
  },
  {
    "DOI": "10.1016/S0167-8191(02)00189-8",
    "ISSN": "0167-8191",
    "URL": "https://doi.org/10.1016/S0167-8191(02)00189-8",
    "abstract": "This paper is a general overview of the SKIPPER project, run at Blaise Pascal University between 1996 and 2002. The main goal of the SKIPPER project was to demonstrate the applicability of skeleton-based parallel programming techniques to the fast prototyping of reactive vision applications. This proiect has produced several versions of a full-fledged integrated parallel programming environment (PPE). These PPEs have been used to implement realistic vision applications, such as road following or vehicle tracking for assisted driving, on embedded parallel platforms embarked on semi-autonomous vehicles. All versions of SKIPPER share a common front-end and repertoire of skeletons–presented in previous papers–but differ in the techniques used for implementing skeletons. This paper focuses on these implementation issues, by making a comparative survey, according to a set of four criteria (efficiency, expressivity, portability, predictability), of these implementation techniques. It also gives an account of the lessons we have learned, both when dealing with these implementation issues and when using the resulting tools for prototyping vision applications.",
    "author": [
      {
        "family": "Sérot",
        "given": "Jocelyn"
      },
      {
        "family": "Ginhac",
        "given": "Dominique"
      }
    ],
    "container-title": "Parallel Comput.",
    "id": "10.1016/S0167-8191(02)00189-8",
    "issue": "12",
    "issued": {
      "date-parts": [
        [
          2002,
          12
        ]
      ]
    },
    "keyword": "parallelism, fast prototyping, data-flow, computer vision, Skeleton",
    "page": "1685-1708",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Skeletons for parallel image processing: An overview of the SKIPPER project",
    "title-short": "Skeletons for parallel image processing",
    "type": "article-journal",
    "volume": "28"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "The demand for computer scientists is expected to continue to increase irrespective of the current state of the economy. Unfortunately, the supply is not expected to match the demand as the number of computer science majors has decreased substantially since the year 2000. As a result, universities and colleges are attempting to identify new ways to attract and retain prospective students into the field of computer science in order to increase the number of majors. In this paper we describe our approach to increase participation and retention through the use of PREOP (Providing Robotic Experiences through Object-Based Programming), an approach that combines the Alice interface and robots for a CS1 Laboratory. PREOP is an interactive 3D animation programming environment, that allows students to program real robots using a drag-and-drop, syntax-free interface. The goal is to foster student motivation and increase student understanding of the fundamental concepts within the first-year curriculum. Initial results indicate that the students in the PREOP Lab who are eligible for CS2 are more likely to rate their skills and knowledge above average than the students in the non-PREOP Labs, and more likely to be registered for the CS2 course than the students in the non-PREOP Labs.",
    "author": [
      {
        "family": "Wellman",
        "given": "Briana Lowe"
      },
      {
        "family": "Anderson",
        "given": "Monica"
      },
      {
        "family": "Vrbsky",
        "given": "Susan V."
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1629036.1629063",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2009,
          12
        ]
      ]
    },
    "page": "167-175",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "PREOP as a tool to increase student retention in CS",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "ISBN": "0818676175",
    "abstract": "Video-on-demand (VOD) systems can support multiple concurrent video accesses with guaranteed user-controlled quality of service (QoS). The growth of VOD systems is driven by the increasing need for distributed multimedia applications such as company training, distance learning, telemedicine, and home entertainment. We propose and demonstrate an ATM-based (asynchronous transfer mode) VOD system (including VOD servers, clients and connection networks) based on a Macintosh platform. ATM is a promising network standard which may satisfy various requirements of VOD systems. In this VOD system, time-based data are encoded and decoded using the MPEG (Moving Picture Experts Group) standard. Issues related to VOD system design, including the multimedia programming environment, the required system modification to support remote MPEG playback, ATM networking, process scheduling, and buffer management for both VOD servers and clients, are discussed and analyzed based on the Macintosh platform. A prototype VOD system is used to explore the design issues proposed. The Macintosh platform provided an efficient and jitter-free VOD system supporting MPEG movie playback through ATM networks.",
    "author": [
      {
        "family": "Lin",
        "given": "Mengjou"
      },
      {
        "family": "Singer",
        "given": "D."
      }
    ],
    "collection-title": "LCN ’96",
    "container-title": "Proceedings of the 21st annual IEEE conference on local computer networks",
    "id": "10.5555/788012.788356",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "keyword": "video on demand system, telemedicine, remote MPEG playback, process scheduling, network standard, multimedia programming environment, home entertainment, distributed multimedia applications, distance learning, connection networks, company training, buffer management, asynchronous transfer mode, VOD systems, VOD system design, VOD servers, Moving Picture Experts Group, Macintosh platform, MPEG standard, MPEG movie playback, ATM networks, ATM networking",
    "page": "59",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "An experimental ATM-based video-on-demand system on a macintosh platform",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICST.2010.19",
    "ISBN": "9780769539904",
    "URL": "https://doi.org/10.1109/ICST.2010.19",
    "abstract": "The modularity and customer centric approach of use cases make them the preferred methods for requirement elicitation, especially in iterative software development processes as in agile programming. Numerous guidelines exist for use case style and content, but enforcing compliance to such guidelines in the industry currently requires specialized training and a strongly managed requirement elicitation process. However, often due to aggressive development schedules, organizations shy away from such extensive processes and end up capturing use cases in an ad-hoc fashion with little guidance. This results in poor quality use cases that are seldom fit for any downstream software activities. We have developed an approach for automated and “edittime”inspection of use cases based on the construction and analysis of models of use cases. Our models contain linguistic properties of the use case text along with the functional properties of the system under discussion. In this paper, we present a suite of model analysis techniques that leverage such models to validate uses cases simultaneously for their style and content. Such model analysis techniques can be combined with a robust NLP techniques to develop integrated development environments for use case authoring, as we do in Text2Test.When used in an industrial setting, Text2Test resulted in better compliance of use cases, in enhanced productivity",
    "author": [
      {
        "family": "Sinha",
        "given": "Avik"
      },
      {
        "family": "Jr.",
        "given": "Stanley M. Sutton"
      },
      {
        "family": "Paradkar",
        "given": "Amit"
      }
    ],
    "collection-title": "ICST ’10",
    "container-title": "Proceedings of the 2010 third international conference on software testing, verification and validation",
    "id": "10.1109/ICST.2010.19",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "Use Cases, Text2Test, Testing, Requirements, Automated Inspection, Analysis",
    "page": "155-164",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Text2Test: Automated inspection of natural language use cases",
    "title-short": "Text2Test",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1609/aaai.v37i13.26878",
    "ISBN": "978-1-57735-880-0",
    "URL": "https://doi.org/10.1609/aaai.v37i13.26878",
    "abstract": "Although the prevention of AI vulnerabilities is critical to preserve the safety and privacy of users and businesses, educational tools for robust AI are still underdeveloped worldwide. We present the design, implementation, and assessment of Maestro. Maestro is an effective open-source game-based platform that contributes to the advancement of robust AI education. Maestro provides goal-based scenarios where college students are exposed to challenging life-inspired assignments in a competitive programming environment. We assessed Maestro’s influence on students’ engagement, motivation, and learning success in robust AI. This work also provides insights into the design features of online learning tools that promote active learning opportunities in the robust AI domain. We analyzed the reflection responses (measured with Likert scales) of 147 undergraduate students using Maestro in two quarterly college courses in AI. According to the results, students who felt the acquisition of new skills in robust AI tended to appreciate highly Maestro and scored highly on material consolidation, curiosity, and maestry in robust AI. Moreover, the leaderboard, our key gamification element in Maestro, has effectively contributed to students’ engagement and learning. Results also indicate that Maestro can be effectively adapted to any course length and depth without losing its educational quality.",
    "author": [
      {
        "family": "Geleta",
        "given": "Margarita"
      },
      {
        "family": "Xu",
        "given": "Jiacen"
      },
      {
        "family": "Loya",
        "given": "Manikanta"
      },
      {
        "family": "Wang",
        "given": "Junlin"
      },
      {
        "family": "Singh",
        "given": "Sameer"
      },
      {
        "family": "Li",
        "given": "Zhou"
      },
      {
        "family": "Gago-Masague",
        "given": "Sergio"
      }
    ],
    "collection-title": "AAAI’23/IAAI’23/EAAI’23",
    "container-title": "Proceedings of the thirty-seventh AAAI conference on artificial intelligence and thirty-fifth conference on innovative applications of artificial intelligence and thirteenth symposium on educational advances in artificial intelligence",
    "id": "10.1609/aaai.v37i13.26878",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "publisher": "AAAI Press",
    "title": "Maestro: A gamified platform for teaching AI robustness",
    "title-short": "Maestro",
    "type": "paper-conference"
  },
  {
    "ISBN": "0789472880",
    "abstract": "From the Publisher:World-renowned for its digital expertise, Dorling Kindersley shares its know-how in a series of user-friendly visual guides to all the computer skills you’ll ever need. Master state-of-the-art computer skills quickly and confidently with the Essential Computers series. These clear and concise step-by-step visual guides are designed to help beginners acquire all the techniques necessary to use today’s information technology, from word processing to desktop publishing to setting up e-commerce and researching on the Internet. Enhancing Your Website helps you master the basic skills to tailor your website to your needs, and includes: Identifying your requirements, Assessing website design and effectiveness, Examining websites for inspiration, Understanding HTML, Viewing website source code, Importing source code, Achieving browser compatibility, Discovering other programming tools, such as Perl, and JavaScript, and Integrating your site into the web. Author Biography: Ann Light and Des Watson are both members of staff at the School of Cognitive and Computing Sciences at the University of Sussex, England. Ann Light is researching into factors affecting website effectiveness, and Des Watson is a senior lecturer in software systems, working primarily in the field of high-level language implementation.",
    "author": [
      {
        "family": "Light",
        "given": "Ann"
      },
      {
        "family": "Publishing",
        "given": "Dorling Kindersley"
      }
    ],
    "id": "10.5555/558225",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "DK Publishing, Inc.",
    "title": "Essential computers: Enhancing your website",
    "title-short": "Essential computers",
    "type": "book"
  },
  {
    "DOI": "10.1145/3159450.3162299",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3162299",
    "abstract": "Montana is home to a large American Indian population and a rich history. The Indian Education for All (IEFA) Act, passed in 1999, reinforces the educational goals stated in Montana’s 1972 Constitution that \"every Montanan, whether Indian or non-Indian, be encouraged to learn about the distinct and unique heritage of American Indians in a culturally responsive manner.\" IEFA requires that American Indian education be integrated into \"the education of each Montana citizen,\" making Montana the only state to mandate Indian education by law. We propose an integration of CS concepts into existing content standards using the IEFA curricula. To make these concepts approachable, we utilize Alice, a drag-and-drop programming environment. This software allows students to animate stories while learning programming techniques in a user-friendly way. Furthermore, Alice 2 allows customized models; in particular, we can create models specific to American Indian culture. In this poster, we present an overview of the Storytelling project and preliminary results, an example lesson plan, evaluation techniques, and a description of the 3D model creation process. With these lesson plans and customized models, we strive to broaden participation of students from rural and American Indian communities in CS and related fields.",
    "author": [
      {
        "family": "Micka",
        "given": "Samuel Adam"
      },
      {
        "family": "Fasy",
        "given": "Brittany Terese"
      },
      {
        "family": "Hancock",
        "given": "Stacey A."
      },
      {
        "family": "Madubuko",
        "given": "Jachiike C."
      },
      {
        "family": "Theobold",
        "given": "Allison Shay"
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3162299",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "middle school education, computational thinking, Indian education for all",
    "page": "1098",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "American indian storytelling with alice: (Abstract only)",
    "title-short": "American indian storytelling with alice",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1411260.1411264",
    "ISBN": "9781605580685",
    "URL": "https://doi.org/10.1145/1411260.1411264",
    "abstract": "For the past five years, the University of Oklahoma has used the ACL2 theorem prover for a year-long sequence on software engineering. The goal of the course is to introduce students to functional programming with \"Applicative Common Lisp\" (ACL) and to expose them to defect recognition at all levels, including unit testing, randomized testing of conjectures, and formal theorem proving in \"a Computational Logic\" (ACL2).Following Page’s example, Northeastern University has experimented with the introduction of ACL2 into the freshman curriculum for the past two years. Northeastern’s goal is to supplement an introductory course on functional program design with a course on logic and theorem proving that integrates the topic with programming projects.This paper reports on our joint project’s progress. On the technical side, the paper presents the Scheme-based integrated development environment, its run-time environment for functional GUI programming, and its support for different forms of testing. On the experience side, the paper summarizes the introduction of these tools into the courses, the reaction of industrial observers of Oklahoma’s software engineering course, and the feedback from a first outreach workshop.",
    "author": [
      {
        "family": "Page",
        "given": "Rex"
      },
      {
        "family": "Eastlund",
        "given": "Carl"
      },
      {
        "family": "Felleisen",
        "given": "Matthias"
      }
    ],
    "collection-title": "FDPE ’08",
    "container-title": "Proceedings of the 2008 international workshop on functional and declarative programming in education",
    "id": "10.1145/1411260.1411264",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "test-driven development, predicate-based testing, mechanical logic, formal methods, drscheme, dracula",
    "page": "21-30",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Functional programming and theorem proving for undergraduates: A progress report",
    "title-short": "Functional programming and theorem proving for undergraduates",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3428029.3428059",
    "ISBN": "9781450389211",
    "URL": "https://doi.org/10.1145/3428029.3428059",
    "abstract": "The Covid-19 pandemic has offered new challenges and opportunities for teaching and research. It has forced constraints on in-person gathering of researchers, teachers, and students, and conversely, has also opened doors to creative instructional design. This paper describes a novel approach to designing an online, synchronous teacher professional development (PD) and curriculum co-design experience. It shares our work in bringing together high school teachers and researchers in four US states. The teachers participated in a 3-week summer PD on ideas of Distributed Computing and how to teach this advanced topic to high school students using NetsBlox, an extension of the Snap! block-based programming environment. The goal of the PD was to prepare teachers to engage in collaborative co-design of a 9-week curricular module for use in classrooms and schools. Between their own training and the co-design process, teachers co-taught a group of high school students enrolled in a remote summer internship at a university in North Carolina to pilot the learned units and leverage ideas from their teaching experience for subsequent curricular co-design. Formative and summative feedback from teachers suggest that this PD model was successful in meeting desired outcomes. Our generalizable FIRST principles—Flexibility, Innovativeness, Responsiveness (and Respect), Supports, and Teamwork (collaboration)—that helped make this unique PD successful, can help guide future CS teacher PD designs.",
    "author": [
      {
        "family": "Grover",
        "given": "Shuchi"
      },
      {
        "family": "Cateté",
        "given": "Veronica"
      },
      {
        "family": "Barnes",
        "given": "Tiffany"
      },
      {
        "family": "Hill",
        "given": "Marnie"
      },
      {
        "family": "Ledeczi",
        "given": "Akos"
      },
      {
        "family": "Broll",
        "given": "Brian"
      }
    ],
    "collection-title": "Koli calling ’20",
    "container-title": "Proceedings of the 20th koli calling international conference on computing education research",
    "id": "10.1145/3428029.3428059",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FIRST principles to design for online, synchronous high school CS teacher training and curriculum co-design",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-031-16681-5_20",
    "ISBN": "978-3-031-16680-8",
    "URL": "https://doi.org/10.1007/978-3-031-16681-5_20",
    "abstract": "The European Erasmus+ project ARC – Automated Reasoning in the Class aims at improving the academic education in disciplines related to Computational Logic by using Automated Reasoning tools. We present the technical aspects of the tools as well as our education experiments, which took place mostly in virtual lectures due to the COVID pandemics. Our education goals are: to support the virtual interaction between teacher and students in the absence of the blackboard, to explain the basic Computational Logic algorithms, to study their implementation in certain programming environments, to reveal the main relationships between logic and programming, and to develop the proof skills of the students. For the introductory lectures we use some programs in C and in Mathematica in order to illustrate normal forms, resolution, and DPLL (Davis-Putnam-Logemann-Loveland) with its Chaff version, as well as an implementation of sequent calculus in the Theorema system. Furthermore we developed special tools for SAT (propositional satisfiability), some based on the original methods from the partners, including complex tools for SMT (Satisfiability Modulo Theories) that allow the illustration of various solving approaches. An SMT related approach is natural-style proving in Elementary Analysis, for which we developed and interesting set of practical heuristics. For more advanced lectures on rewrite systems we use the Coq programming and proving environment, in order on one hand to demonstrate programming in functional style and on the other hand to prove properties of programs. Other advanced approaches used in some lectures are the deduction based synthesis of algorithms and the techniques for program transformation.",
    "author": [
      {
        "family": "Drămnesc",
        "given": "Isabela"
      },
      {
        "family": "Ábrahám",
        "given": "Erika"
      },
      {
        "family": "Jebelean",
        "given": "Tudor"
      },
      {
        "family": "Kusper",
        "given": "Gábor"
      },
      {
        "family": "Stratulat",
        "given": "Sorin"
      }
    ],
    "container-title": "Intelligent computer mathematics: 15th international conference, CICM 2022, tbilisi, georgia, september 19–23, 2022, proceedings",
    "id": "10.1007/978-3-031-16681-5_20",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "Computer aided teaching, Computational logic, Automated reasoning",
    "page": "287-304",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Experiments with&nbsp;automated reasoning in&nbsp;the&nbsp;class",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/62402.62434",
    "ISBN": "0897912837",
    "URL": "https://doi.org/10.1145/62402.62434",
    "abstract": "XVision is a software system for image processing research, education and applications. Xyvision utilizes the X Window System Version 11, which provides a network transparent windowing environment and software portability. Xyvision is designed to facilitate: data and algorithm exchange of new computer vision/image processing techniques,image processing training and education,development of turn key vision solutions for various application areas (automation, medicine, biology, astronomy, etc).XVision is a comprehensive system because it supports generation of new programs (extendibility), and integration, maintenance, modification and documentation of existing programs; and it includes: three user interfaces; a menuing system, a quick command line interface that can be customized and a standardized UNIX‡-like command line interface. A visual programming language, xvglyph, is under development.tutorials, manual pages, experiments, automated demonstrations and other supplemental documentation.an image processing library written in C,interactive image display and enhancement, image editing and creation, 2D, 3D, and contour plotting, and data creation/display via user specified functions.The Xyvision project started in February of 1987 with its first release in August of 1987. This paper describes the second version which incorporates changes suggested by many of the users (over 30 different institutions) of Xyvision Version 1.0 [1]. One of the most important design goals of the Xyvision project is to provide for easy growth and extendibility. This has been accomplished by clearly defining software levels, software systems and their standard interfaces, and by providing programming tools and a variety of user interfaces for the Xyvision user/maintainer.",
    "author": [
      {
        "family": "Teran",
        "given": "Marcelo"
      },
      {
        "family": "Rasure",
        "given": "John"
      },
      {
        "family": "Argiro",
        "given": "Danielle"
      },
      {
        "family": "Hallett",
        "given": "Stephanie"
      },
      {
        "family": "Neher",
        "given": "Ron"
      },
      {
        "family": "Young",
        "given": "Mark"
      },
      {
        "family": "Wilson",
        "given": "Scott"
      }
    ],
    "collection-title": "UIST ’88",
    "container-title": "Proceedings of the 1st annual ACM SIGGRAPH symposium on user interface software",
    "id": "10.1145/62402.62434",
    "issued": {
      "date-parts": [
        [
          1988
        ]
      ]
    },
    "page": "203-210",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "XVISION: A comprehensive software system for image processing research, education, and applications",
    "title-short": "XVISION",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/280495.280502",
    "ISSN": "1094-3641",
    "URL": "https://doi.org/10.1145/280495.280502",
    "abstract": "This paper describes a software resource that is being developed as part of the graduation requirement for the Master in Software Engineering degree at the University of Scranton. This project evolved from a series of experiments that were performed in undergraduate and graduate courses at the University. A basic editor was developed as part of an undergraduate course in rapid prototyping. Several students used that project as the basis for undergraduate Senior Projects. All undergraduates are required to complete a project as a degree requirement. This basic editor was handed over to a graduate course in Software Generation and Maintenance and used as the starting point for the construction of various software project management features. The system was constructed to support Ada source code development. However, the system could be readily modified to support source code management in other languages, notably C++. This paper describes the construction of resources that encourage the use of reusable software. Subsequent sections describe the overall framework of the system and selected details that carry out features that make reuse attractive. The system is called ReUSE (the Reuse University of Scranton Environment).ReUSE is an Ada programming environment which facilitates and promotes code reuse by individual developers or teams of developers. It provides centralized storage of project files, a package browser, automatic function and procedure call creation, a compiler interface, interactive error processing, multiple simultaneous editors, standard windows tools (menus, toolbars, etc.), and other features to help the developer write and reuse Ada code efficiently.ReUSE was developed in Microsoft Visual Basic 4.0 (32-bit) for the Windows 95 / NT operating systems.",
    "author": [
      {
        "family": "Battaglia",
        "given": "David"
      },
      {
        "family": "Burke",
        "given": "Austin"
      },
      {
        "family": "Beidler",
        "given": "John"
      }
    ],
    "container-title": "Ada Lett.",
    "id": "10.1145/280495.280502",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          1998,
          2
        ]
      ]
    },
    "page": "78-85",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An ADA reuse support system for windows 95/NT",
    "type": "article-journal",
    "volume": "XVIII"
  },
  {
    "DOI": "10.1145/2795122.2795126",
    "ISBN": "9781450337175",
    "URL": "https://doi.org/10.1145/2795122.2795126",
    "abstract": "As computer architecture integrates multiple concepts such as microarchitecture, design, the hardware-software interface, compilers, and operating systems, there is an always increasing need to develop new methods for learning and exploring the field. Parallelism in computer systems is a key focus in computer architecture and some core parallel concepts include Amdahl’s law, efficiency, and overhead. While there are a number of ways to examine these topics in traditional lectures and assignments, a unique way is to leverage Python-based programming environments that allow students to independently explore concepts and their governing parameters.This paper presents the highlights of PyCompArch Python module developed using the IPython Notebook environment to help the study of concepts in computer architecture. Python is a widely used general-purpose, high-level programming language, but traditionally the language does not play a leading role in the education of computer architecture. IPython Notebooks allow developers to interactively run Python code cells and to construct Python codes that execute on remote servers that eliminate any system requirements of the individual. In this way, the environment supports web-based remote \"in the cloud\" code development that can be modified during lectures or in homework assignments. The PyCompArch module supports a number of ways to help individuals learn concepts of parallelism related to computer architecture as well as explore experiments in computer performance and control. For example, PyCompArch supports the evaluation of performance of real-world benchmarks such as Open Computer Vision (OpenCV) and dynamic frequency scaling (DFS) in Raspberry Pi systems. Overall, the PyCompArch supports student learning and development of experiments in computer architecture.",
    "author": [
      {
        "family": "Connors",
        "given": "Dan"
      },
      {
        "family": "Dunn",
        "given": "Kyle"
      },
      {
        "family": "Bueter",
        "given": "Ryan"
      }
    ],
    "collection-title": "WCAE ’15",
    "container-title": "Proceedings of the workshop on computer architecture education",
    "id": "10.1145/2795122.2795126",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PyCompArch: Python-based modules for exploring computer architecture concepts",
    "title-short": "PyCompArch",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/iTAG.2014.15",
    "ISBN": "9781479967957",
    "URL": "https://doi.org/10.1109/iTAG.2014.15",
    "abstract": "Computing in schools has gained momentum in the last two years resulting in GCSEs in Computing and teachers looking to up skill from Digital Literacy (ICT). For many students the subject of computer science concerns software code but writing code can be challenging, due to specific requirements on syntax and spelling with new ways of thinking required. Not only do many undergraduate students lack these ways of thinking, but there is a general misrepresentation of computing in education. Were computing taught as a more serious subject like science and mathematics, public understanding of the complexities of computer systems would increase, enabling those not directly involved with IT make better informed decisions and avoid incidents such as over budget and underperforming systems. We present our exploration into teaching a variety of computing skills, most significantly \"computational thinking\", to secondary-school age children through three very different engagements. First, we discuss Print craft, in which participants learn about computer-aided design and additive manufacturing by designing and building a miniature world from scratch using the popular open-world game Mine craft and 3D printers. Second, we look at how students can get a new perspective on familiar technology with a workshop using App Inventor, a graphical Android programming environment. Finally, we look at an ongoing after school robotics club where participants face a number of challenges of their own making as they design and create a variety of robots using a number of common tools such as Scratch and Arduino.",
    "author": [
      {
        "family": "Roscoe",
        "given": "Jonathan Francis"
      },
      {
        "family": "Fearn",
        "given": "Stephen"
      },
      {
        "family": "Posey",
        "given": "Emma"
      }
    ],
    "collection-title": "ITAG ’14",
    "container-title": "Proceedings of the 2014 international conference on interactive technologies and games",
    "id": "10.1109/iTAG.2014.15",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "technology, games, e ducation, computational thinking, STEM",
    "page": "9-12",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Teaching computational thinking by playing games and building robots",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/FIE.2011.6143100",
    "ISBN": "9781612844688",
    "URL": "https://doi.org/10.1109/FIE.2011.6143100",
    "abstract": "Experiential education provides valuable learning opportunities for students in the computing disciplines. Assigning students to work on real-world projects is often seen as a way for students to practice what they have learned in the classroom. While a desirable goal, logistics often make it difficult to provide these types of experiences. However, it is vitally important for students to be exposed to and experiment with tools used in commercial software development environments. This paper provides a descriptive overview of the development and implementation of a professional software development environment used to support computer science capstone programming projects. To date, the environment has been used to support work on a National Science Foundation funded database courseware project that includes over 100 interactive software modules. The environment was built using a collection of open-source applications that provide version control, task assignment and tracking, collaborative team tools, bug tracking, and project documentation management. This project has created a venue for providing consistent high quality real-world types of experiences for students completing their capstone requirement.",
    "author": [
      {
        "family": "Murray",
        "given": "Meg Coffin"
      }
    ],
    "collection-title": "FIE ’11",
    "container-title": "Proceedings of the 2011 frontiers in education conference",
    "id": "10.1109/FIE.2011.6143100",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "page": "S4F-1-1-S4F-3",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Work in progress – creating a professional software development environment to support capstone programming projects",
    "type": "paper-conference"
  },
  {
    "ISBN": "3540755411",
    "abstract": "Distributed software projects are becoming increasingly commonplace in industry. Yet, software engineering education rarely graduates students with the necessary skills and hands-on experience that are particular to off-shore software development projects. Three key areas in successful offshore software development projects are well documented in the literature as communication, knowledge management, as well as project and process management. This paper maps tasks within each of these three areas to functions that have to be provided by remote collaboration platforms and tools that distributed projects rely on. A case-study of an off-shore requirements engineering class experience between a Master course of Polytechnic University of Puerto Rico and a customer in a Swiss financial institution shows a correlation between areas of learning by the students and functionalities covered with the tools used in the classroom. The paper identifies additional tools, developed by the authors, which will provide additional functionalities in the deficient areas to increase the learning and preparation of the students for off-shore software development projects.",
    "author": [
      {
        "family": "Berkling",
        "given": "Kay"
      },
      {
        "family": "Geisser",
        "given": "Michael"
      },
      {
        "family": "Hildenbrand",
        "given": "Tobias"
      },
      {
        "family": "Rothlauf",
        "given": "Franz"
      }
    ],
    "collection-title": "SEAFOOD’07",
    "container-title": "Proceedings of the 1st international conference on software engineering approaches for offshore and outsourced development",
    "id": "10.5555/1778650.1778651",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "traceability, software engineering education, requirements engineering, offshore software development, distributed and global software development, development tools, collaborative software development",
    "page": "1-18",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Offshore software development: Transferring research findings into the classroom",
    "title-short": "Offshore software development",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130852473",
    "author": [
      {
        "family": "Deitel",
        "given": "Harvey M."
      },
      {
        "family": "Deitel",
        "given": "Paul J."
      }
    ],
    "edition": "3rd",
    "id": "10.5555/554971",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "The complete java 2 training course with book",
    "type": "book"
  },
  {
    "ISBN": "0493274650",
    "abstract": "As computers are widely used and computer-programming gets increasingly complicated, computer users and programmers demand more convenient human-computer interfaces and programming tools. Motivated by facilitating computer programming and human-computer interaction, this project explores teaching a computer to react properly to external stimuli through natural human-computer interaction. The long-term goal of the project is to program a computer as we teach an infant, and to enable the computer to interact with us like a human and perform jobs accordingly. The project uses a multisensory mobile robot as the interface for natural human-computer interaction. We develop a computational efficient scheme that facilitates the robot to learn spoken language online, and react properly to learned speech commands. Compared to the existing speech recognizers, our system does not use text or other symbolic information to represent speech, thus is not restricted by the limitations that a speech-to-text mechanism may inherently have. Due to this fact, our system can learn speech online in any language. This learning flexibility is not achieved by state-of-the-art speech recognizers. The thesis reports the design and implementation of our scheme for spoken language acquisition. In the thesis, we discuss the available resources and possible pitfalls for the robot project: we discuss the speech communication techniques that can be or cannot be used in our project; we choose the classifiers that are suitable to our project; and we also present a humancomputer interaction model and the robot training strategies. Based on these analyses and discussions, we develop our learning scheme that can learn online from both labeled and unlabeled data. The learning scheme is based on successive refinement of the decision boundary.",
    "author": [
      {
        "family": "Liu",
        "given": "Qiong"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/933807",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "note": "AAI3017152",
    "publisher": "University of Illinois at Urbana-Champaign",
    "publisher-place": "USA",
    "title": "Interactive and incremental learning via a multisensory mobile robot",
    "type": "thesis"
  },
  {
    "DOI": "10.1007/978-3-642-25283-9_1",
    "ISBN": "9783642252822",
    "URL": "https://doi.org/10.1007/978-3-642-25283-9_1",
    "abstract": "Trusted Software Stacks (TSS) are the interfaces between applications and Trusted Platform Modules (TPMs). In order to avoid wrong usage of the stacks which could lead to security holes, they should provide an easy-to-use interface for developers. Moreover, they should be designed in a flexible way to adapt to new requirements resulting from specification or algorithm changes. However, the currently specified TSS interface is highly complex and requires a vast amount of training effort for developers to get familiar with it. Moreover, existing stacks are monolithic blocks of software - they either support the full range of TPM functions which makes them large or they support a customized subset of features which reduces their scope of use. In this paper, we propose a novel design for a Trusted Software Stack (TSS) that can be integrated into existing security frameworks. Instead of designing a new application programming interface (API), our stack uses the APIs from well known and established frameworks, allowing developers that are not familiar with Trusted Computing (TC) to easily adapt to this new technology. Furthermore, our stack supports multiple TPMs, dynamic component loading and Over-The-Air updates that allow the stack to support customized sets of features even after it has been deployed in the field. Moreover, the stack provides built-in support for user authentication and TPM access control. Our prototype stack is developed for the .NET programming environment, thereby eliminating common implementation faults like buffer overflows. Due to the managed nature of the .NET runtime environment, it is portable between different operating systems and can be used on desktop systems as well as on embedded systems without the need for recompiling it for the specific target architecture.",
    "author": [
      {
        "family": "Reiter",
        "given": "Andreas"
      },
      {
        "family": "Neubauer",
        "given": "Georg"
      },
      {
        "family": "Kapfenberger",
        "given": "Michael"
      },
      {
        "family": "Winter",
        "given": "Johannes"
      },
      {
        "family": "Dietrich",
        "given": "Kurt"
      }
    ],
    "collection-title": "INTRUST’10",
    "container-title": "Proceedings of the second international conference on trusted systems",
    "id": "10.1007/978-3-642-25283-9_1",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "trusted computing, TSS, TPM, .NET",
    "page": "1-25",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Seamless integration of trusted computing into standard cryptographic frameworks",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3576123.3576134",
    "ISBN": "9781450399418",
    "URL": "https://doi.org/10.1145/3576123.3576134",
    "abstract": "The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.",
    "author": [
      {
        "family": "Finnie-Ansley",
        "given": "James"
      },
      {
        "family": "Denny",
        "given": "Paul"
      },
      {
        "family": "Luxton-Reilly",
        "given": "Andrew"
      },
      {
        "family": "Santos",
        "given": "Eddie Antonio"
      },
      {
        "family": "Prather",
        "given": "James"
      },
      {
        "family": "Becker",
        "given": "Brett A."
      }
    ],
    "collection-title": "ACE ’23",
    "container-title": "Proceedings of the 25th australasian computing education conference",
    "id": "10.1145/3576123.3576134",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "AI, AlphaCode, CS1, CS2, Codex, DeepMind, GPT-3, GitHub, OpenAI, academic integrity, algorithms, artificial intelligence, code generation, copilot, data structures, deep learning, introductory programming, machine learning, neural networks, novice programming",
    "page": "97-104",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "My AI wants to know if this will be on the exam: Testing OpenAI’s codex on CS2 programming exercises",
    "title-short": "My AI wants to know if this will be on the exam",
    "type": "paper-conference"
  },
  {
    "abstract": "The bilingual-bicultural perspective in deaf education advocates the use of American Sign Language (ASL) as the language of classroom instruction and introduces English in print form only (a visually accessible form) to deaf students. Research into the effectiveness of the bilingual-bicultural perspective is now increasing, but teacher preparation programs were not introducing their students to this approach until very recently. Therefore, schools that choose to use this perspective will need to educate their teachers about Deaf culture, ensure that teachers are fluent users of ASL, and demonstrate how ASL and English can be used effectively in the classroom in order to achieve the goal of bilingual-bicultural development in their students. To meet these needs, a multimedia, bilingual professional development tool was created for pre-service and in-service educators of the deaf that explains and demonstrates teaching practices that can be used to promote ASL and English language development in deaf students. The instructional tool utilizes digital video, embedded in a website-like interface, to present information in live motion ASL next to English text that communicates the same information. Preliminary findings with a pilot version of the tool indicated that Deaf teachers and hearing teachers are uniquely impacted by the tool and may use similar technology in a variety of ways in the classroom environment; it was evident from the initial inquiry that further investigation was needed into the role of this and similar instructional tools. Therefore, the research study aims to determine how one bilingual, multimedia instructional tool can impact educators of the deaf differently with respect to its personal, cultural, and instructional value, depending on the educational setting the teachers work in and their personal hearing status. Surveys and focus group discussions were used to collect the data needed to answer the research questions. Final analyses will make connections between the bilingual education literature, the educational technology literature, and historical and current issues in deaf education.",
    "author": [
      {
        "family": "DiGello",
        "given": "Elizabeth A."
      }
    ],
    "collection-title": "ICLS ’04",
    "container-title": "Proceedings of the 6th international conference on learning sciences",
    "id": "10.5555/1149126.1149274",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "page": "650",
    "publisher": "International Society of the Learning Sciences",
    "publisher-place": "Santa Monica, California",
    "title": "Understanding the social and instructional meaning of a multimedia, bilingual instructional tool for educators of the deaf",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/MS.2020.3045817",
    "ISSN": "0740-7459",
    "URL": "https://doi.org/10.1109/MS.2020.3045817",
    "abstract": "This special issue of IEEE Software focuses on diversity and inclusion in software development, presenting research results and best practices for making the field equitable for all. It is well documented that the industry does not provide evenhanded participation conditions. Research has shown that implicit gender biases significantly impact hiring decisions,&lt;sup&gt;1&lt;/sup&gt; women disengage faster than men,&lt;sup&gt;2&lt;/sup&gt; Palestinian tech entrepreneurs do not have access to Internet-based distribution and payment platforms,&lt;sup&gt;3&lt;/sup&gt; software developers with a visual impairment lack tools to navigate code editors,&lt;sup&gt;4,5&lt;/sup&gt; and women are sometimes less likely to get their code accepted.&lt;sup&gt;6&lt;/sup&gt; Tools, processes, products, and education are not inclusive. Dimensions such as geography, gender, socioeconomic politics, age, ethnicity, and disability shape who can participate in creating technology.",
    "author": [
      {
        "family": "Albusays",
        "given": "Khaled"
      },
      {
        "family": "Bjorn",
        "given": "Pernille"
      },
      {
        "family": "Dabbish",
        "given": "Laura"
      },
      {
        "family": "Ford",
        "given": "Denae"
      },
      {
        "family": "Murphy-Hill",
        "given": "Emerson"
      },
      {
        "family": "Serebrenik",
        "given": "Alexander"
      },
      {
        "family": "Storey",
        "given": "Margaret-Anne"
      }
    ],
    "container-title": "IEEE Softw.",
    "id": "10.1109/MS.2020.3045817",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2021,
          3
        ]
      ]
    },
    "page": "19-25",
    "publisher": "IEEE Computer Society Press",
    "publisher-place": "Washington, DC, USA",
    "title": "The diversity crisis in software development",
    "type": "article-journal",
    "volume": "38"
  },
  {
    "ISBN": "9798835558124",
    "abstract": "The demand for graduates in Science, Technology, Engineering, and Mathematics (STEM) areas is currently quite visible. Thus, educational curricula are being adjusted. In schools, subjects are being introduced to develop more logical techniques and reasoning, the so-called Computational Thinking (CT).The original version of Tactode is a tangible block programming system aimed at children. It focuses on multi-target programming (robots, simulations, or high-level language programs) by creating behaviors/programs with tangible pieces that fit like a puzzle. Then a picture is taken of the set of grouped pieces, and it is introduced into the Tactode system application so that the program can be compiled (transposed) into the target application. If a user desires, the Tactode application also allows the program’s creation by assembling the parts in the application but with many limitations.Tactode allows the compilation of the program for some physical platforms, but manufacturers’ applications are required to run the program, and no debug information at all in the Tactode app. These additional steps cause a low-quality User Experience (UX) in the child, making learning difficult.O Scratch is a visual and block programming tool, top-rated in education and used by several schools. However, it lacks support to allow multi-target programming, especially of physical robotic agents.Scratch’s popularity and previous studies show that the best is incorporating Tactode into the Scratch ecosystem, making it more attractive and promoting better educational goals.This dissertation’s broad goal was to obtain a programming language for physical or virtual multi-targets. The solution was to merge Tactode’s features with the Scratch tool, replacing Tactode’s application with Scratch itself. A Tactode extension was created for Scratch to add the Tactode functionalities to Scratch. Moreover, a Tactode Link application was developed, which establishes Scratch’s connection with external platforms and allows the program’s execution directly on the chosen platform. The platform of choice was a miniature robot R FL of the PRO (Portuguese Robotics Open) of open software and hardware developed at FEUP.This solution allows children to improve the UX of the Tactode system so that they can complete the whole process from the creation of the program to the execution by the external target. The acquired usability raised children’s interest and improved learning in several areas of the STEM spectrum, including robotics and CT. Validation of the system was done by performing a set of test challenges and then by experimentation by students solving some challenges.",
    "author": [
      {
        "dropping-particle": "da",
        "family": "Costa Pinho",
        "given": "César Alexandre"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI29140217",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "note": "AAI29140217",
    "publisher": "Universidade do Porto (Portugal)",
    "title": "Tactode programming for robotics and other targets",
    "type": "thesis"
  },
  {
    "ISBN": "012381541X",
    "abstract": "Revolutionary tools are emerging from research labs that enable all computer users to customize and automate their use of the Web without learning how to program. No Code Required takes cutting edge material from academic and industry leaders - the people creating these tools – and presents the research, development, application, and impact of a variety of new and emerging systems. *The first book since Web 2.0 that covers the latest research, development, and systems emerging from HCI research labs on end user programming tools *Featuring contributions from the creators of Adobe s Zoetrope and Intel s Mash Maker, discussing test results, implementation, feedback, and ways forward in this booming area *Companion Web site features video demonstrations of each system (http://www.elsevierdirect.com/v2/companion.jsp ISBN=9780123815415) Table of Contents Introduction End User Programming on the Web Allen Cypher (IBM) Why We Customize the Web Robert Miller (MIT) I. End User Programming Languages for the Web Sloppy Programming Greg Little (MIT) Mixing the reactive with the personal: Opportunities for end user programming in Personal information management (system) Max Van Kleek (MIT) Going beyond PBD: A Play-by-Play and Mixed-initiative Approach (system) Hyuckchul Jung (Institute for Human and Machine Cognition) Rewriting the Web with Chickenfoot (system) Robert Miller (MIT) A Goal-Oriented Web Browser (system) Alexander Faaborg (Mozilla) II. Systems and Applications Clip, Connect, Clone: Combining Application Elements to Build Custom Interfaces for Information Access (system) Jun Fujima (Hokkaido) Mash Maker (system) Robert Ennals (Intel) Collaborative scripting on the web (system) Tessa Lau (IBM) Programming by a Sample: Rapidly Creating Web Applications with d.mix (system) Bj rn Hartmann (Stanford) Highlight: End User Mobilization of Existing Web Sites (system) Jeffrey Nichols (IBM) Subjunctive Interfaces for the Web Aran Lunzer (University of Copenhagen) From Web Summaries to Search Templates: Automation for Personal Web Content (system) Mira Dontcheva (Adobe Systems) Access to the Temporal Web Through Zoetrope (system) Eytan Adar (University of Washington) Enabling End Users to Independently Build Accessibility into the Web Jeffrey Bigham (University of Washington) Social Accessibility: A Collaborative Approach For Improving Web Accessibility (system) Yevgen Borodin (Stony Brook) III. Data Management and Interoperability A World Wider than the Web: End User Programming Across Multiple Domains (system) Will Haines (SRI) Knowing What You’re Talking About: Natural Language Programming of a Multi-Player Online Game (system) Henry Lieberman (MIT) IV. User Studies Mashups for Web-Active End Users Nan Zang (Penn State) Mashed layers and muddled models: debugging mashup applications M. Cameron Jones (Yahoo!) Reuse in the world of end-user programmers Christopher Scaffidi (CMU) Using Web Search to Write Programs Joel Brandt (Stanford)",
    "author": [
      {
        "family": "Cypher",
        "given": "Allen"
      },
      {
        "family": "Dontcheva",
        "given": "Mira"
      },
      {
        "family": "Lau",
        "given": "Tessa"
      },
      {
        "family": "Nichols",
        "given": "Jeffrey"
      }
    ],
    "id": "10.5555/1805911",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "publisher": "Morgan Kaufmann Publishers Inc.",
    "publisher-place": "San Francisco, CA, USA",
    "title": "No code required: Giving users tools to transform the web",
    "title-short": "No code required",
    "type": "book"
  },
  {
    "DOI": "10.1145/3568812.3603483",
    "ISBN": "9781450399753",
    "URL": "https://doi.org/10.1145/3568812.3603483",
    "abstract": "Motivation. We have created a modular project-based learning curriculum, Computer Science Frontiers (CSF) [1, 8], for secondary students in attempts to increase the persistence of computer science (CS) students in higher education. The CSF course is divided into four different modules (Distributed Computing, Internet of Things, Artificial Intelligence, and Software Engineering), each centered around a topic typically introduced to students only in higher education. Using the block-based programming environment NetsBlox [4], students are able to access various Application Programming Interfaces related to their interests [2, 3]. The goal of this course is to increase student interest in CS during high school - when first career choices occur [7] - in hopes they will persist in CS during their undergraduate studies. Research question. The research question for this study was: How does the Computer Science Frontiers course affect student attitudes towards computer science?Research Methods. We conducted over 20 interviews with students throughout a CSF pilot course that took place over the 2022-2023 school year. Interviews were conducted with at least five students at the end of every module. Two researchers have conducted thematic analysis with student responses from the first two modules [5]: Distributed Computing (DC) and Internet of Things (IoT). First, the two researchers developed a norm by tagging one interview together [6]. Next, the researchers independently coded the rest of the interviews for each module. After completing a single module’s interviews, the researchers met to rectify any discrepancies. Finally, the tags were grouped together based on common themes. Through this process, we found a total of seven themes. Results. The themes found through thematic analysis include: computer science, attitudes towards course, student wants, student struggles, attitudes towards projects, collaboration, and student progression. As a result of this study, we have identified different needs for secondary students with varying background in CS when studying more advanced CS topics, such as IoT. For example, a need of students who have less prior CS knowledge than others may be to review programming concepts in order to be successful in the course. We have also identified a positive change in student’s attitudes towards computer science after the first two modules. These insights provide the CS education community with ways to engage students with concepts that they have not been exposed to and how to increase their interest in CS. Implications. The CSF curriculum is currently online, and is available to computer science instructors. Each module is separated into eight to nine units which are accompanied by activities and teaching guides. This curriculum provides educators with materials and activities to introduce students to more advanced CS topics, either through individual modules or as an entire course. In future research, we plan to use CSF in an outreach program and implement the course in two secondary classrooms in the 2023-2024 school year.",
    "author": [
      {
        "family": "Brock",
        "given": "Janet"
      },
      {
        "family": "Gransbury",
        "given": "Isabella"
      },
      {
        "family": "Cateté",
        "given": "Veronica"
      },
      {
        "family": "Barnes",
        "given": "Tiffany"
      },
      {
        "family": "Grover",
        "given": "Shuchi"
      },
      {
        "family": "Ledeczi",
        "given": "Akos"
      }
    ],
    "collection-title": "ICER ’23",
    "container-title": "Proceedings of the 2023 ACM conference on international computing education research - volume 2",
    "id": "10.1145/3568812.3603483",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "socially relevant examples, secondary, project-based learning, education research, collaborative learning environment, block-based learning",
    "page": "24-25",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Student attitudes during the pilot of the computer science frontiers course",
    "type": "paper-conference"
  },
  {
    "ISBN": "0735712549",
    "abstract": "From the Publisher: Inside Flash MX employs a comprehensive and comparatively advanced approach for designers and developers, addressing the emerging fact that Flash is both a designer’s tool and a programming environment. Other \"large\" books are either more introductory or suffer from a lack of consistency and cohesiveness due to being written by several unassociated authors. Working professionals-designers, developers, and those who do both-who need a comprehensive, non-introductory tutorial reference. This is the largest growth area in the Flash market: NOT simply designers, but those familiar with the technology who use it as front end tool and as a programming tool as well. Fig Leaf’s Creative Media Department has designed and developed engaging web-based media for some of the most recognized companies and organizations in the country. Author Biography: Fig Leaf’s Creative Media Department has designed and developed engaging web-based media for some of the most recognized companies and organizations in the country. Fig Leaf offers creative services from a talented team of award winning graphic artists, programmers, writers, and instructional technologists who consistently build next- generation solutions for our clients. Using a blend of creative talent, experience and technical know-how, we are able to take our client’s web media to a new level that balances form, flow and function. Members of the Creative Media team speak regularly at tradeshows, user groups, and design conferences to inform others about the tools, technologies, and processes that they successfully employ. Jody Keating is the Assistant Director of Interactive Media at Fig Leaf, where she makes the Interactive Media programmers and designers play nice together. Jody is a Macromedia Certified Professional (MCP) and has taught Macromedia Authorized classes for Flash, Generator, UltraDev, Dreamweaver, Fireworks, and CourseBuilder. In addition to her duties at Fig Leaf, Jody is the Program Coordinator for the Washington Area Macromedia Organization (WAMMO). Jody is also a Cold Fusion developer and is having way too much fun playing with integrating Flash and ColdFusion. She has an undergraduate degree in Anthropology from the George Washington University and has done graduate work in Geobiology. When Jody’s not writing or managing, she’s racing sailboats, kayaking, or rowing on the Chesapeake Bay. Tom Pizer is a partner and the Vice President of Creative Media for Fig Leaf Software. He is responsible for Fig Leaf’s creative vision and the success of the client web sites and interactives that Fig Leaf creates. During his career, he has written course material on computer-based design and collaborated on industry-related books. His work has been featured in leading industry magazines and been written up in online trade sites. Tom is the current president of the Washington, DC area Macromedia User’s Group (WAMMO). During his tenure as president, he has forged strong ties with Macromedia and their Product Directors, programmers, sales staff, and training managers for the full suite of Macromedia’s web tools.When Branden Hall is not working with computers (rarely), he enjoys the great outdoors: camping, hiking, biking, and climbing. As an Eagle Scout, these playtime pursuits come as naturally to him as programming, which is what Branden is doing much of the rest of the time. Branden is known for developing cutting edge ActionScript techniques. At Fig Leaf Software, he is the Senior Interactive Developer and a Macromedia Instructor. His work at Fig Leaf, combined with Branden’s prominence on his Flash ActionScript mailing list, FlashCoders, and his participation in many other lists, conferences, and user groups have spawned speculation that Branden Hall cannot possibly be just one man. Amusing though the thought of a host of Branden clones running around may be, his wife Patricia Hall guarantees us all that there is, indeed, only one. Tracey Sheeley is the Assistant Director of Creative Services at Fig Leaf, and is one of the original \"Figs\". While creating many online presences for clients, she has eagerly watched Flash evolve into the indispensable program it is today. Tracey has a BA in Studio Art earned at the University of Maryland. Spanning three states throughout her life, she grew up in Maryland, works in Washington, DC, and now lives in Virginia. Chris Smith is an instructor and designer at Fig Leaf. He also teaches Flash, Dreamweaver, and Fireworks at the Corcoran School of Fine Arts in Washington, DC. Chris graduated in 1995 with a BFA from the University of Southern California. While earning his degree, he worked at Activision, Inc. and contracted an incurable interest in computer game graphics and animation that has dominated his creative pursuits ever since. Thirty years before the mast, he lives in Alexandria, VA. Kevin Towes is a Co-Founder and Chief Technical Officer of Pangaea NewMedia Inc. in Toronto, Canada. His experience ranges from traditional film, photography, and sound to 3D animation and database and software development, culminating in the integration of all of these disciplines. Kevin’s rich mix of visual and technical knowledge has been a leading force in Pangaea’s success. A leader in the ColdFusion community for the past three years, Kevin is the founder of the Toronto Cold Fusion Users Group, one of the largest CF groups in the world. He is a certified ColdFusion Developer and has led his team at Pangaea to achieve much success with Macromedia Products. Matthew David has been developing Internet solutions for over seven years and has serviced many Fortune 500 companies. His books include Flash MX Magic (New Riders) and contributions to Flash 5 Magic, Flash 5: Visual Design, Web Development Bible, Inside Dreamweaver 4, and the Dreamweaver Bible. He is currently working on chapters for three new books. Matthew also contributes regularly to Devx.com, Element K Journal’s Macromedia Solution, and Inside Project Management magazines, as well as web sites such as Macromedia.com, SitePoint.com, and UDZone.com. His own web site is http://www.matthewdavid.ws. Guy Rish is an independent consultant. He carries developer and instructor certifications from Macromedia and Rational, and in the last few years he has concentrated on applying object-oriented methodologies to web development. When not consulting or training, he does technical writing and editing for various publishers. In recent years he has taken up a traveling habit with his wife, with the end goal of seeing it all. Patricia Lee Hall is both a ColdFusion developer and Allaire Certified Instructor. Patti has degrees in English and French. She has also pursued higher education in Public Relations. She has a cat named Reese. Doug Clarke has a background in illustration, 3D motion graphics, and sound design, and he likes to use his multi-disciplinary background to push the envelope of interactive animation. \"I’m never ever really satisfied with my work, but I do enjoy the process of creating and combining different mediums within Flash. Drawing is the foundation for all my work, which in turn is based on keen observation.\" His work has been featured in various publications including USAToday, Richmond Times Dispatch, and the Virginian Pilot. When he’s not working in Flash, Doug enjoys illustration and painting. Doug is also an avid surfer and spends his off time with his family and friends in Virginia Beach. He holds a Bachelor of Fine Arts degree, graduating Magna Cum Laude of Virginia Commonwealth University. You can find Doug’s current work at http://www.liquidmethod.com. Christopher Hayes has been using Flash since Flash 3 and enjoys creating bleeding-edge design. Chris received his Master’s degree in Computer Art from Savannah College of Art and Design and his Bachelor’s degree in Fine Arts from Xavier University of Louisiana. Chris (aka P the Wicked) is also an emcee/music producer and enjoys the true hip hop culture. Chris believes that his best work ever is the next one.",
    "author": [
      {
        "family": "Keating",
        "given": "Jody"
      },
      {
        "family": "Software",
        "given": "Fig Leaf"
      }
    ],
    "edition": "2nd",
    "id": "10.5555/582699",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "New Riders Publishing",
    "publisher-place": "USA",
    "title": "Inside flash MX",
    "type": "book"
  },
  {
    "DOI": "10.1002/spe.2471",
    "ISSN": "0038-0644",
    "URL": "https://doi.org/10.1002/spe.2471",
    "abstract": "In recent years, software development environments have changed from being driven by professional developers to being driven by technical end users. One of the key issues in end-user-driven software development environments is how to guarantee the quality of the software artifacts. Measuring the quality of developed software requires the correct specification of a quality range the software is expected to meet. However, technical end users are non-professionals in engineering techniques for software requirements, and training a developer to be an expert in requirements engineering in a short period of time is difficult. This paper proposes a new software development life cycle based on reutilizing previously evaluated software requirements assets from completed projects. End-User Requirements Engineering with Collaborative Animation, a tool that was developed to support the proposed software development life cycle, is described and demonstrated by application to three projects. The results from real cases are used as the basis for a discussion on the efficiency enhancement of requirements work, an increased rate of reusing legacy software requirements assets, and an improvement in the technical end user’s individual competency level using the End-User Requirements Engineering with Collaborative Animation. Copyright © 2017 John Wiley &amp; Sons, Ltd.",
    "author": [
      {
        "family": "Kim",
        "given": "Neunghoe"
      },
      {
        "family": "Park",
        "given": "Soojin"
      },
      {
        "family": "Jeong",
        "given": "Dongwon"
      },
      {
        "family": "Hwang",
        "given": "Mansoo"
      },
      {
        "family": "Park",
        "given": "Sooyong"
      },
      {
        "family": "In",
        "given": "Hoh Peter"
      }
    ],
    "container-title": "Softw. Pract. Exper.",
    "id": "10.1002/spe.2471",
    "issue": "7",
    "issued": {
      "date-parts": [
        [
          2017,
          7
        ]
      ]
    },
    "keyword": "software reuse, requirements engineering, end-user software engineering",
    "page": "1001-1012",
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "EURECA: End-user requirements engineering with collaborative animation",
    "title-short": "EURECA",
    "type": "article-journal",
    "volume": "47"
  },
  {
    "DOI": "10.1145/3305275.3305330",
    "ISBN": "9781450365703",
    "URL": "https://doi.org/10.1145/3305275.3305330",
    "abstract": "In recent years, information technology has achieved rapid development and has been widely used in many fields. With the continuous improvement of the level of higher education and the scale of education in China, colleges and universities have paid more and more attention to the use of information technology in education management. Many universities have carried out research work on education management systems based on big data. It summarizes the related theories of big data, analyzes the importance of big data, and puts forward effective solutions according to the application status of big data in college education management system. In the overall system architecture, database security, system requirements, After detailed requirements analysis of system functions and other aspects, a system solution combining flexibility, openness and applicability was developed. For the domestic educational management systems, most of them are based on C/S or B/S single mode, they are difficult to meet the system solution requirements proposed in this paper. The system developed in this paper proposes a combination of C/S and B/S modes. Oracle and PL/SQL are used as the back-end database. The front-end development tools use Delphi2009, ASP.net, PL/SQL Developer and auxiliary software Dreamweaver5.0.",
    "author": [
      {
        "family": "Ou",
        "given": "Xiu-ying"
      }
    ],
    "collection-title": "ISBDAI ’18",
    "container-title": "Proceedings of the international symposium on big data and artificial intelligence",
    "id": "10.1145/3305275.3305330",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "management system, impact countermeasures, college education, C/S and B/S, Big data",
    "page": "275-280",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Research on university education management system based on big data",
    "type": "paper-conference"
  },
  {
    "ISBN": "0818681055",
    "abstract": "Many means for organizing software measures have been developed over the years. The Army has found that the larger the organization, the higher in the hierarchy the requirement for software measurement needs to be stated. The reason for this stems from the growing diversity of developers in larger organizations. Small organizations that have a well defined process for developing software, or a common set of software development tools, can require that specific data elements be collected, or specific measurements be taken. If larger organizations attempting to impose such specific requirements on developers are likely to meet some resistance, a tight policy does not allow for variation in development processes and development tools. With software development centers building air defense systems in Huntsville, Alabama; command and control systems in Monmouth, New Jersey; logistics systems in Petersburg, Virginia; personnel systems in Fairfax, Virginia; communications systems in Sierra Vista, Arizona; aviation systems in St. Louis, Missouri, armor systems in Picatinny, New Jersey and Detroit Michigan, and engineering systems at various locations throughout the US, the Army must have a policy for software measurement that puts in place flexible reporting requirements, yet provides training and support tailored to the needs of specific programs.",
    "author": [
      {
        "family": "Lucero",
        "given": "Don Scott"
      }
    ],
    "collection-title": "COMPSAC ’97",
    "container-title": "Proceedings of the 21st international computer software and applications conference",
    "id": "10.5555/645979.675853",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "keyword": "software measures, software measurement, software development tools, software development centers, small organizations, personnel systems, military computing, logistics systems, larger organizations, engineering systems, command and control systems, aviation systems, armor systems, air defense systems, US Army operational test/evaluation command, US Army",
    "page": "589-590",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Software measurement in the u.s. army",
    "type": "paper-conference"
  },
  {
    "ISBN": "0769504213",
    "abstract": "In this paper, the author discusses the role of automatic software development tools in graduate software engineering courses. The basic requirements for such tools, from the industry perspective, are presented, followed by the selection of tools meeting a comprehensive set of criteria in four process-related dimensions: internal, vertical, horizontal, and diagonal. Typical software development projects for student teams used in the Software Engineering Program at the University of Central Florida are presented, involving the following four software tools: SES/workbench, ObjecTime Developer, iLogix Rhapsody, and Gensym G2.",
    "author": [
      {
        "family": "Zalewski",
        "given": "Janusz"
      }
    ],
    "collection-title": "CSEET ’00",
    "container-title": "Proceedings of the 13th conference on software engineering education &amp; training",
    "id": "10.5555/794188.794299",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "page": "200",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Automatic development tools in software engineering courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-031-09342-5_45",
    "ISBN": "978-3-031-09341-8",
    "URL": "https://doi.org/10.1007/978-3-031-09342-5_45",
    "abstract": "It is challenging for programmers to build a mobile health app that is rich in AI features, and near impossible for non-technical users such as domain experts and patients. However, it is exactly these users that possess the domain knowledge and experience on how to best manage health conditions, and how AI features can help achieve that goal. End-user development environments, such as MIT Punya, can help lay users to better collaborate on mobile health apps; and even open the door for these users, given some training, to prototype their own mobile health apps. As a subfield of AI, Semantic Web technology can help with integrating online data sources with patient health data, and reasoning over the integrated data to issue smart health recommendations.",
    "author": [
      {
        "family": "Patton",
        "given": "Evan"
      },
      {
        "family": "Van Woensel",
        "given": "William"
      },
      {
        "family": "Seneviratne",
        "given": "Oshani"
      },
      {
        "family": "Loseto",
        "given": "Giuseppe"
      },
      {
        "family": "Scioscia",
        "given": "Floriano"
      },
      {
        "family": "Kagal",
        "given": "Lalana"
      }
    ],
    "container-title": "Artificial intelligence in medicine: 20th international conference on artificial intelligence in medicine, AIME 2022, halifax, NS, canada, june 14–17, 2022, proceedings",
    "id": "10.1007/978-3-031-09342-5_45",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "Semantic web, Diabetes management, Patient apps",
    "page": "431-435",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Development of AI-enabled apps by patients and domain experts using the punya platform: A case study for diabetes",
    "title-short": "Development of AI-enabled apps by patients and domain experts using the punya platform",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1066129.1066130",
    "ISBN": "9781450377980",
    "URL": "https://doi.org/10.1145/1066129.1066130",
    "abstract": "Object-oriented software development is a subject area difficult to teach, especially to beginners. They face a lot of abstraction and (from a beginners point of view) isolated topics, such as the syntax and semantics of a programming language, the functionality of a software development environment and basic object-oriented concepts. Although many professionals in education believe in the \"object first\" approach as the best method of introducing object-oriented concepts, there is no common agreement on how to start such courses. Current study programs often begin by teaching a programming language, instead of focusing on the basics of object-oriented concepts.In the last years a learning environment was developed based on a visual programming language to abstract away from details. It assists teaching step-by-step object-oriented concepts and the syntax and semantics of a programming language in secondary schools and first year university courses. Our goal is to port this learning environment to the widely used IDE Eclipse.",
    "author": [
      {
        "family": "Meyer",
        "given": "Matthias"
      },
      {
        "family": "Wendehals",
        "given": "Lothar"
      }
    ],
    "collection-title": "Eclipse ’04",
    "container-title": "Proceedings of the 2004 OOPSLA workshop on eclipse technology EXchange",
    "id": "10.1145/1066129.1066130",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "page": "1-5",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Teaching object-oriented concepts with eclipse",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/VLHCC.2010.28",
    "ISBN": "9780769542065",
    "URL": "https://doi.org/10.1109/VLHCC.2010.28",
    "abstract": "We report an empirical study of nonprogrammers who built a database-centered web application using an end-user web development tool. Half of the users spent time planning their project by creating a concept map before starting the programming; across planning conditions, half of the users were males and half female. Participants who did concept mapping or who were male were more attracted to database programming; however planning did not affect feelings of success and in general females felt more successful than males. We discuss the implications of these findings for work on gender and for future EUP tools and training.",
    "author": [
      {
        "family": "Rosson",
        "given": "Mary Beth"
      },
      {
        "family": "Sinha",
        "given": "Hansa"
      },
      {
        "family": "Edor",
        "given": "Tisha"
      }
    ],
    "collection-title": "VLHCC ’10",
    "container-title": "Proceedings of the 2010 IEEE symposium on visual languages and human-centric computing",
    "id": "10.1109/VLHCC.2010.28",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "web development, Gender HCI, End-user programming",
    "page": "141-148",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Design planning in end-user web development: Gender, feature exploration and feelings of success",
    "title-short": "Design planning in end-user web development",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3549179.3549181",
    "ISBN": "9781450396080",
    "URL": "https://doi.org/10.1145/3549179.3549181",
    "abstract": "Q-learning is a kind of reinforcement learning, having a wide range of applications varying in different fields. However, in some circumstances like robot control which has shorter training time requirement, Q-learning algorithm implemented on GPU or CPU may not meet the requirement. In this paper, we proposed a novel serial acceleration architecture for Q-learning algorithm and implemented the architecture on xczu7ev-ffvc1156 FPGA using Vivado 2019.1 development environment. As a result, the resource consumption is reduced by about 50",
    "author": [
      {
        "family": "Liu",
        "given": "Xiaojuan"
      },
      {
        "family": "Diao",
        "given": "Jietao"
      },
      {
        "family": "Li",
        "given": "Nan"
      }
    ],
    "collection-title": "PRIS ’22",
    "container-title": "Proceedings of the 2022 international conference on pattern recognition and intelligent systems",
    "id": "10.1145/3549179.3549181",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "acceleration, Q-learning, FPGA",
    "page": "8-13",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "FPGA hardware implementation of q-learning algorithm with low resource consumption",
    "type": "paper-conference"
  },
  {
    "abstract": "THE SPRING PROJECT AT THE UNIVERSITY OF MASSACHUSETTS IS A RESEARCH AND DEVELOPMENT EFFORT AIMED AT STUDYING “NEXT GENERATION”’ TIME-CRITICAL SYS- TEMS. IN ADDITION TO BEING FAST AND PREDICTABLE, THESE SYSTEMS WILL HAVE TO BE FLEXIBLE, ADAPTIVE, AND RELIABLE. THESE REQUIREMENTS ARISE FROM THE FACT THAT FUTURE SYSTEMS WILL BE LARGE AND COMPLEX AND WILL OPERATE IN ENVIRONMENTS THAT ARE DYNAMIC, DISTRIBUTED, AND FAULT-INDUCING. IN ORDER TO ACHIEVE ITS GOALS, THE SPRING PROJECT TAKES A SYNERGISTIC APPROACH INVOLVING THE DEVELOPMENT OF SCHEDULING ALGORITHMS, OPERATING SYSTEM SUPPORT, DISTRIBUTED SYSTEM ARCHITECTURE, AND APPLICATION DEVELOPMENT TOOLS. IN ADDITION, THE FOLLOWING TOPICS ARE ALSO BEING INVESTIGATED AS PART OF THE PROJECT: TRANSACTION MANAGEMENT IN REAL-TIME DATABASES, SUPPORT FOR REAL-TIME APPLICATIONS INVOLVING ARTIFICIAL INTELLIGENCE, AND FORMAL APPROACHES TO THE SPECIFICATION AND VERIFICATION OF REAL-TIME SYSTEMS. THIS REPORT SUMMARIZES THE CURRENT STATUS OF THE PROJECT.",
    "author": [
      {
        "family": "Ramamritham",
        "given": "Krithi"
      },
      {
        "family": "Stankovic",
        "given": "John A."
      }
    ],
    "id": "10.5555/896825",
    "issued": {
      "date-parts": [
        [
          1989
        ]
      ]
    },
    "publisher": "University of Massachusetts",
    "publisher-place": "USA",
    "title": "Overview of the spring project",
    "type": "report"
  },
  {
    "DOI": "10.4018/joeuc.2011100105",
    "ISSN": "1546-2234",
    "URL": "https://doi.org/10.4018/joeuc.2011100105",
    "abstract": "The development of scientific software is usually carried out by a scientist who has little professional training as a software developer. Concerns exist that such development produces low-quality products, leading to low-quality science. These concerns have led to recommendations and the imposition of software engineering development processes and standards on the scientists. This paper utilizes different frameworks to investigate and map characteristics of the scientific software development environment to the assumptions made in plan-driven software development methods and agile software development methods. This mapping exposes a mismatch between the needs and goals of scientific software development and the assumptions and goals of well-known software engineering development processes.",
    "author": [
      {
        "family": "Kelly",
        "given": "Diane"
      }
    ],
    "container-title": "J. Organ. End User Comput.",
    "id": "10.4018/joeuc.2011100105",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2011,
          10
        ]
      ]
    },
    "keyword": "Software Development Process, Scientific Software Development, Scientific Software, Professional End-User Developer, Extreme Programming",
    "page": "64-79",
    "publisher": "IGI Global",
    "publisher-place": "USA",
    "title": "An analysis of process characteristics for developing scientific software",
    "type": "article-journal",
    "volume": "23"
  },
  {
    "ISBN": "1930708424",
    "abstract": "A decision support system (DSS) was constructed to assist the academic advising staff of a college of business. The microcomputer-based system identifies any remaining unsatisfied degree program requirements, selects courses in which the student can enroll and then prioritizes them. Advisors are then able to spend time on more substantive or developmental advising issues, such as choice of electives, career options and life career goals. Using this system, a student with a minimum of computer knowledge can obtain an optimized course listing without the assistance of a human advisor in less than five minutes.A high-end spreadsheet (i.e., DSS generator) permits a workable and effective academic advising DSS. The database is the most significant part of this DSS. And, since the modeling component is difficult to separate from the structure of the data itself, a database management system might be a better choice as the DSS generator. This platform would provide a more flexible user interface as well as superior data handling capability but at some sacrifice in cost and implementation time.A recent development in the management of university and college organizations is the integrated software system, known also as enterprise resource planning (ERP) software. This integrated administrative software for higher education (e.g., CMDS [Computer Management Development Services]), operating on various hardware platforms, provides student advising data for a variety of prototyping and application development tools, such as Powersoft’s Infomaker and Microsoft’s Access.",
    "author": [
      {
        "family": "Le Blanc",
        "given": "Louis A."
      },
      {
        "family": "Rucks",
        "given": "Conway T."
      },
      {
        "family": "Murray",
        "given": "W. Scott"
      }
    ],
    "container-title": "Advanced topics in end user computing",
    "id": "10.5555/770484.770501",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "page": "263-284",
    "publisher": "IGI Global",
    "publisher-place": "USA",
    "title": "A decision support system for prescriptive academic advising",
    "type": "chapter"
  },
  {
    "DOI": "10.1109/43.31543",
    "ISSN": "0278-0070",
    "URL": "https://doi.org/10.1109/43.31543",
    "abstract": "A description is given of CHORD, a semiconductor device simulation development tool created at the University of Waterloo. CHORD is written as several small independent programs which use a centralized database facility and is specifically designed to allow the simple creation, development, and testing of new simulation models and algorithms. Communication between programs is implemented by using a byte-stream process. This allows transfer of information between individual programs running on different machines. CHORD is a general environment in that its models can incorporate any set of user-defined variables of equations. This is illustrated by the development of contact boundary conditions incorporating external circuit elements and circuit-level device models using the modified nodal formulation. Several examples of both steady-state and transient simulations are presented",
    "author": [
      {
        "family": "McMacken",
        "given": "J. R. F."
      },
      {
        "family": "Chamberlain",
        "given": "S. G."
      }
    ],
    "container-title": "Trans. Comp.-Aided Des. Integ. Cir. Sys.",
    "id": "10.1109/43.31543",
    "issue": "8",
    "issued": {
      "date-parts": [
        [
          2006,
          11
        ]
      ]
    },
    "page": "826-836",
    "publisher": "IEEE Press",
    "title": "CHORD: A modular semiconductor device simulation development tool incorporating external network models",
    "title-short": "CHORD",
    "type": "article-journal",
    "volume": "8"
  },
  {
    "DOI": "10.1109/MS.2011.72",
    "ISSN": "0740-7459",
    "URL": "https://doi.org/10.1109/MS.2011.72",
    "abstract": "Our growing ability to swiftly put together sophisticated software affords us the luxury to listen to our customers, to try out new things, to make mistakes, to redesign as we move along—in short to be agile. On the technological front, the main driving forces are powerful operating systems, the widespread availability database management systems, a wide selection of libraries, interoperability standards, versatile programming languages, ample processing power, and sophisticated development tools. On the environment front, agility is driven by specialized education, informal management structures, Web access, open source software, shifting user expectations, and the ubiquitous availability of IT infrastructures. Where agility drivers are present, we must adjust our development processes, demand more from our software suppliers, and develop in-house capacity to organically grow applications and services that will delight and even captivate our users and customers.",
    "author": [
      {
        "family": "Spinellis",
        "given": "Diomidis"
      }
    ],
    "container-title": "IEEE Softw.",
    "id": "10.1109/MS.2011.72",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2011,
          7
        ]
      ]
    },
    "keyword": "software management practices, agility",
    "page": "96",
    "publisher": "IEEE Computer Society Press",
    "publisher-place": "Washington, DC, USA",
    "title": "Agility drivers",
    "type": "article-journal",
    "volume": "28"
  },
  {
    "DOI": "10.1145/190650.190655",
    "ISSN": "0097-8418",
    "URL": "https://doi.org/10.1145/190650.190655",
    "abstract": "Much of the design and development for new computing systems in the 1990’s is being done in a networked computing environment with distributed goals. So why do so many 4-year college computer science departments still not teach \"Distributed computing systems\" in their undergraduate curriculum? The reasons are varied, but one main one is the belief that such a course requires expensive hardware and the very latest software development tools. This article demonstrates how a course for undergraduates in distributed computing can be successful at giving the students the concepts and principles, while enabling them to create such an application to experience the distributed environment, and do it all on a limited budget. The principles are highlighted along with a practical design and development component, which can give seniors a way to tie together many of the principles and applications of previous courses.",
    "author": [
      {
        "family": "Stewart",
        "given": "Carolee"
      }
    ],
    "container-title": "SIGCSE Bull.",
    "id": "10.1145/190650.190655",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1994,
          12
        ]
      ]
    },
    "page": "17-20",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Distributed systems in the undergraduate curriculum",
    "type": "article-journal",
    "volume": "26"
  },
  {
    "DOI": "10.1145/1315580.1315604",
    "ISBN": "9781595938763",
    "URL": "https://doi.org/10.1145/1315580.1315604",
    "abstract": "Hibachi is an open source (EPL), standard, extensible, vendor-neutral Eclipse Ada development environment. Hibachi is currently in the project proposal phase (see http://www.eclipse.org/projects/dev_process/development_process.php, which involves gathering a viable developer/tester/user community around the project and IP rights to any code contributions. When these pieces are in place, the project can be approved by the Eclipse Management Organization (EMO) and begin producing high quality releases available to end users, as well as third party integrators.As Hibachi project lead, Mr. Grosman has been in touch with the major active Ada development environment vendors (ACT, Aonix, DDC-I, GHS) and they have all expressed interest and a desire to commit resources to making Hibachi a success. In addition, gnuada development team members have also expressed support for Hibachi and a willingness to participate. Mr. Grosman is also in contact with several Universities who will be contributing engineering effort as part of their curricula (master theses), as well as some major industrial partners who are large scale users of Ada and who have expressed interest in contributing development and/or financial resources. Aonix has offered to contribute the source for its Eclipse plugin, AonixADT as a code base for Hibachi. AonixADT currently supports ObjectAda as well as GNAT/gnuada development. Contributions of existing code from other sources are also a possibility depending on the willingness of other potential contributors. Because of these factors, and the encouragement of the Hibachi project mentor Doug Schaefer, CDT project lead, Mr. Grosman has every expectation that the Hibachi proposal will be accepted and that we will be able to produce a plugin with features as outlined in the Hibachi Proposal-http://www.eclipse.org/proposals/adt/. The development plan outlined in the Hibachi proposal indicates that a first useable release of Hibachi will be available in time for SIGAda in November.",
    "author": [
      {
        "family": "Grosman",
        "given": "Tom"
      }
    ],
    "collection-title": "SIGAda ’07",
    "container-title": "Proceedings of the 2007 ACM international conference on SIGAda annual international conference",
    "id": "10.1145/1315580.1315604",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "software, safety, reliability, languages, high integrity, eclipse, development environment, ada",
    "page": "99",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Hibachi: The eclipse ada development toolset",
    "title-short": "Hibachi",
    "type": "paper-conference"
  },
  {
    "ISBN": "0769519962",
    "abstract": "A large and growing variety of tools can support allkinds of UML modeling aspects: from model creation toadvanced round-trip engineering of UML models and code.However, such tools aim at supporting specific life-cyclephases, but they often do not meet basic requirements arisingin heterogeneous environments, UML education, earlylife-cycle phases, or agile processes: hassle-free tool deployment,support for fast model sketching, and flexiblegraphic export features.This paper presents the freely available modeling toolUMLet we designed to specifically address these basic issues.It is a flyweight Java application that can easily bedeployed in various development environments; it featuresan intuitive and pop-up-free user interface, while still providingoutput to common high-quality publishing formats.Thus, the tool UMLet provides an effective way to teachUML and to create and share UML sketches, especiallyin agile environments and during early life-cycle phases.Its user interface supports intuitive and exploratory modeling,its architecture makes distribution and deploymentcost-efficient in heterogeneous environments.",
    "author": [
      {
        "family": "Auer",
        "given": "M."
      },
      {
        "family": "Tschurtschenthaler",
        "given": "T."
      },
      {
        "family": "Biffl",
        "given": "S."
      }
    ],
    "collection-title": "EUROMICRO ’03",
    "container-title": "Proceedings of the 29th conference on EUROMICRO",
    "id": "10.5555/942796.943259",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "page": "267",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "A flyweight UML modelling tool for software development in heterogeneous environments",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/98894.98888",
    "ISBN": "0897913728",
    "URL": "https://doi.org/10.1145/98894.98888",
    "abstract": "There is a great potential for exploiting computer assisted tutoring in industrial training situations and in formal educational environments. This paper discusses our research in developing the concept of an Intelligent Authoring/Instructional System(IA/IS) that can be used as an intelligent courseware development environment as well as an intelligent tutoring system. The goal of our research is to integrate the contributions of the content expert, the instructional design expert, and the course-ware developer into one system that will be used by both authors and students. We discuss how artificial intelligence techniques associated with case-based planning can improve the management of the instructional interaction between the Instructional System and the student.",
    "author": [
      {
        "family": "Kerner",
        "given": "Janet T."
      },
      {
        "family": "Freedman",
        "given": "Roy S."
      }
    ],
    "collection-title": "IEA/AIE ’90",
    "container-title": "Proceedings of the 3rd international conference on industrial and engineering applications of artificial intelligence and expert systems - volume 2",
    "id": "10.1145/98894.98888",
    "issued": {
      "date-parts": [
        [
          1990
        ]
      ]
    },
    "page": "890-897",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Developing intelligent tutoring systems with a hypermedia object-based intelligent educator (HOBIE)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/DEXA.2008.89",
    "ISBN": "9780769532998",
    "URL": "https://doi.org/10.1109/DEXA.2008.89",
    "abstract": "This paper gives brief overview of Selbo 2 – development environment for creating SCORM compatible electronic content. Selbo 2 uses intelligent editors (combination of component and agent) to manipulate learning content and aid content developer during content creation. Ontologies provide developers with predefined resources covering specific domain that can be used directly in the content. Selbo 2 also utilizes education templates that define pedagogical goals and agents to govern them. Furthermore, the environment employs schemes for adapting itself to its user and for collaborating with the learning management system (LMS).Although Selbo 2 is designed primarily for electronic education, it can also be used in Virtual Engineering. Different teams, working on the same project, can prepare e-lectures that give overview of their current progress, using terms and concepts from the same ontology. These lectures can be shared among teams and used as initial teaching materials for new project members.",
    "author": [
      {
        "family": "Stoyanov",
        "given": "S."
      },
      {
        "family": "Mitev",
        "given": "D."
      },
      {
        "family": "Minov",
        "given": "I."
      },
      {
        "family": "Glushkova",
        "given": "T."
      }
    ],
    "collection-title": "DEXA ’08",
    "container-title": "Proceedings of the 2008 19th international conference on database and expert systems application",
    "id": "10.1109/DEXA.2008.89",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "ontology, e-lesson, agent",
    "page": "100-104",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "eLearning development environment for software engineering selbo 2",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/AHS.2008.53",
    "ISBN": "9780769531663",
    "URL": "https://doi.org/10.1109/AHS.2008.53",
    "abstract": "This paper presents a system level framework for System-on-Chip (SoC) based embedded devices that may include adaptive and reconfigurable elements. Current development support and debugging solutions are highly dependant on off-line post-mortem style inspection, and even those that utilise tracing for real-time and schedule-critical systems rely on external development tools and environments. This new framework introduces an AI-lead infrastructure that has the potential to reduce much of the development effort while complementing existing debugging circuits. Specifically this paper investigates how to use a Kohonen self-organising map (SOM) as a classifier, and shows a preliminary investigation into how to determine the quality of a map after training. This classifier is a first step in diagnosing failure, degradation and anomalies (i.e. provides condition monitoring) in an embedded system from a system level point of view, and in the larger task of self-diagnosis of an embedded system.",
    "author": [
      {
        "family": "Sartain",
        "given": "P."
      },
      {
        "family": "Hopkins",
        "given": "A. B. T."
      },
      {
        "family": "McDonald-Mair",
        "given": "K. D."
      },
      {
        "family": "Howells",
        "given": "W. G. J."
      }
    ],
    "collection-title": "AHS ’08",
    "container-title": "Proceedings of the 2008 NASA/ESA conference on adaptive hardware and systems",
    "id": "10.1109/AHS.2008.53",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "System-on-Chip, Kohonen self-organising map, system level debugging, SOM classifier, novelty filter",
    "page": "417-423",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "A framework for self-diagnosis and condition monitoring for embedded systems using a SOM-based classifier",
    "type": "paper-conference"
  },
  {
    "abstract": "ARCADIA IS A RESEARCH PROJECT AIMED AT THE DISCOVERY AND DEVELOPMENT OF BOTH ARCHITECTURAL PRINCIPLES AND SOFTWARE TOOLS FOR SOFTWARE DEVELOPMENT ENVIRONMENTS. THE PRINCIPLES ARE INTENDED TO ENABLE THE CONSTRUCTION OF ENVIRONMENTS THAT ARE BOTH INTEGRATED AND EXTENSIBLE, WHILE THE TOOLS ARE INTENDED TO SUPPORT THE DESCRIPTION AND ANALYSIS OF SOFTWARE SYSTEMS THROUGHOUT THEIR LIFETIMES, FROM INITIAL CONCEPTION THROUGH MAINTENANCE. A MAJOR GOAL OF THE ARCADIA PROJECT IS TO CREATE A RESEARCH PLATFORM THAT CAN BE USED TO BUILD ARCADIA-1, A FIRST PROTOTYPE OF THE SORT OF NEXT-GENERA- TION ENVIRONMENT THAT WE BELIEVE CAN BETTER SUPPORT THE DEVELOPMENT AND MAINTENANCE OF LARGE, COMPLEX SOFTWARE SYSTEMS. THE ARCADIA PROJECT IS ORGANIZED AS A CONSORTIUM OF ACADEMIC AND INDUS- TRIAL RESEARCHERS. THE PRINCIPAL MEMBERS ARE FROM THE UNIVERSITY OF CALI- FORNIA AT IRVINE, THE UNIVERSITY OF COLORADO AT BOULDER, THE UNIVERSITY OF MASSACHUSETTS AT AMHERST, STANFORD UNIVERSITY, INCREMENTAL SYSTEMS CORPOR- ATION, TRW, AND THE AEROSPACE CORPORATION. IN ADDITION TO THEIR RESEARCH CONTRIBUTION, THE INDUSTRIAL MEMBERS ARE EXPECTED TO ACT AS CONDUITS OF THE TECHNOLOGY THAT EMERGES FROM THE ARCADIA PROJECT. THIS PAPER PROVIDES A BRIEF OVERVIEW OF THE RESEARCH DIRECTIONS BEING EXPLORED BY MEMBERS OF THE ARCADIA PROJECT IN THE AREAS OF ARCHITECTURAL PRINCIPLES AND SOFTWARE TOOLS, AND DESCRIBES OUR PLANS FOR ARCADIA-1.",
    "author": [
      {
        "family": "Wolf",
        "given": "Alexander L."
      }
    ],
    "id": "10.5555/897034",
    "issued": {
      "date-parts": [
        [
          1986
        ]
      ]
    },
    "publisher": "University of Massachusetts",
    "publisher-place": "USA",
    "title": "An overview of arcadia",
    "type": "report"
  },
  {
    "abstract": "The Federal Aviation Administration (FAA) is developing the Cybersecurity Test and Evaluation Facility (CyTF) for the FAA Air Transportation System as it transitions to the Next Generation Air Transportation System (NextGen). This paper describes the goals, capabilities, architecture, current implementation, initial experience, lessons learned and future implementation of the CyTF. The FAA Air Transportation System is an attractive cybersecurity threat target and the FAA must proactively and continually adjust its cybersecurity capabilities to match the changing cybersecurity threat landscape. The CyTF is providing an adaptable cybersecurity research and development environment independent of the operational system to satisfy research, test and evaluation needs. The CyTF has a number of complex requirements: testing cybersecurity tools and technologies prior to their integration into the Air Transportation System, the evaluation of individual FAA Air Transportation subsystems security, security of end-to-end services involving multiple subsystems, procedures to respond and recover from a cybersecurity event and cybersecurity training of the FAA workforce. One of the major lessons learned, described in the paper, has been how to address some aspects of the CyTF’s complex requirements",
    "author": [
      {
        "family": "Ingegneri",
        "given": "David"
      },
      {
        "family": "Timoteo",
        "given": "Dominic"
      },
      {
        "family": "Hyle",
        "given": "Patrick"
      },
      {
        "family": "Parraga",
        "given": "Fidel"
      },
      {
        "family": "Reyes",
        "given": "Alex"
      }
    ],
    "collection-title": "CSET’16",
    "container-title": "Proceedings of the 9th USENIX conference on cyber security experimentation and test",
    "id": "10.5555/3241067.3241072",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "page": "5",
    "publisher": "USENIX Association",
    "publisher-place": "USA",
    "title": "A cybersecurity test and evaluation facility for the next generation air transportation system (nextgen)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/IROS40897.2019.8967798",
    "URL": "https://doi.org/10.1109/IROS40897.2019.8967798",
    "abstract": "Duckiepond is an education and research development environment that includes software systems, educational materials, and of a fleet of autonomous surface vehicles Duckieboat. Duckieboats are designed to be easily reproducible with parts from a 3D printer and other commercially available parts, with flexible software that leverages several open source packages. The Duckiepond environment is modeled after Duckietown and AI Driving Olympics environments: Duckieboats rely only on one monocular camera, IMU, and GPS, and perform all ML processing using onboard embedded computers. Duckiepond coordinates commonly used middlewares (ROS and MOOS) and containerized software packages in Docker, making it easy to deploy. The combination of learning-based methods together with classic methods enables important maritime missions: track and trail, navigation, and coordinate among Duckieboats to avoid collisions. Duckieboats have been operating in a man-made lake, reservoir and river environments. All software, hardware, and educational materials are openly available (https://robotx-nctu.github.io/duckiepond), with the goal of supporting research and education communities across related domains.",
    "author": [
      {
        "family": "Lin",
        "given": "Ni-Ching"
      },
      {
        "family": "Benjamin",
        "given": "Michael"
      },
      {
        "family": "Chen",
        "given": "Chi-Fang"
      },
      {
        "family": "Wang",
        "given": "Hsueh-Cheng"
      },
      {
        "family": "Hsiao",
        "given": "Yu-Chieh"
      },
      {
        "family": "Huang",
        "given": "Yi-Wei"
      },
      {
        "family": "Hung",
        "given": "Ching-Tung"
      },
      {
        "family": "Chuang",
        "given": "Tzu-Kuan"
      },
      {
        "family": "Chen",
        "given": "Pin-Wei"
      },
      {
        "family": "Huang",
        "given": "Jui-Te"
      },
      {
        "family": "Hsu",
        "given": "Chao-Chun"
      },
      {
        "family": "Censi",
        "given": "Andrea"
      }
    ],
    "container-title": "2019 IEEE/RSJ international conference on intelligent robots and systems (IROS)",
    "id": "10.1109/IROS40897.2019.8967798",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "page": "7219-7226",
    "publisher": "IEEE Press",
    "publisher-place": "Macau, China",
    "title": "Duckiepond: An open education and research environment for a fleet of autonomous maritime vehicles",
    "title-short": "Duckiepond",
    "type": "paper-conference"
  },
  {
    "ISBN": "0780330226",
    "abstract": "Software based products are an ever increasing portion of industrial output. However few engineers who produce software have had formal training in the specification, design, implementation, documentation, and maintenance of large software systems. In addition, few have had training in software engineering management and development tools and processes. KSU has implemented a Master of Software Engineering degree program which provides an opportunity for new engineering graduates and practicing engineers to learn state of the art software engineering analysis and processes. The purpose is to provide students a foundation in the software engineering \"life cycle\", software measurement, software management, software specification, and software validation and verification. In addition to the core courses on software methodology, students are required to take courses in an application area which is reliant on software development. This involves faculty from many engineering and science disciplines who teach these courses and supervise the development of the student’s software \"portfolio\" in the designated engineering or science area. The goal is to integrate the software engineering process into traditional engineering processes.",
    "author": [
      {
        "family": "Gustafson",
        "given": "D."
      },
      {
        "family": "Hankley",
        "given": "B."
      },
      {
        "family": "Wallentine",
        "given": "V."
      }
    ],
    "collection-title": "FIE ’95",
    "container-title": "Proceedings of the frontiers in education conference on 1995. Proceedings., 1995 vol 1. - volume 01",
    "id": "10.5555/1253522.1253586",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "page": "2b1.5-2b1.8vol.1",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "The master of software engineering degree: An integrative engineering discipline",
    "title-short": "The master of software engineering degree",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2591062.2591165",
    "ISBN": "9781450327688",
    "URL": "https://doi.org/10.1145/2591062.2591165",
    "abstract": "A well-trained software engineering workforce is a key to success in a highly competitive environment. Changing tools and technologies, along with a rapidly changing development environment, make it incumbent on organizations to invest in training. In this paper, we describe our experience in deploying an online training program in a globally distributed organization. We write about the reasons behind ABB’s Software Development Improvement Program (SDIP), the requirements we established upfront, the people, processes and technologies we used, the promotion of SDIP, and metrics for measuring success. Finally, we share and describe results and lessons learned that could be applied to many organizations with similar issues. The goal of this paper is to provide a set of replicable best practices for initiating a software training program in a multi-national organization. The first SDIP online course was offered in June 2012. Since then, we have had more than 10,000 enrollments from employees in 54 countries. Today, our training library contains 89 e-learning, 17 webinar, video and virtual lab courses, and we have delivered more than 180 hosted webinars. Following each class, we ask students to evaluate the class. Ninety-eight percent are satisfied with the classes.",
    "author": [
      {
        "family": "Hudepohl",
        "given": "John"
      },
      {
        "family": "Dubey",
        "given": "Alpana"
      },
      {
        "family": "Moisy",
        "given": "Sylvie"
      },
      {
        "family": "Thompson",
        "given": "Jessica"
      },
      {
        "family": "Niederer",
        "given": "Hans-Martin"
      }
    ],
    "collection-title": "ICSE companion 2014",
    "container-title": "Companion proceedings of the 36th international conference on software engineering",
    "id": "10.1145/2591062.2591165",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "webinars, web-based training platform, virtual labs, e-learnings, Training in distributed organizations",
    "page": "301-310",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Deploying an online software engineering education program in a globally distributed organization",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1878537.1878588",
    "ISBN": "9781450300698",
    "URL": "https://doi.org/10.1145/1878537.1878588",
    "abstract": "The increase in fidelity found in the latest generation of video game platforms has garnered interest from many different arenas. Up to now, the primary objective of these games has been to simulate the real world within the gaming environment. Thus it was only natural that some would begin using video games in place of specially developed simulators as a means of providing training. Some argue that the advancement of training programs based on video game platforms has not advanced as much as hoped for. The prospect of utilizing video game platforms as the basis for training systems remains a tempting one, though, in light of today’s financial climate.To attain these goals, advanced game development tools should enhance already existing functionality within existing game engines, aiming for high quality sound and visual effects, realistic dynamics, appropriate responses and well maintained timing. In this effort we propose modifications to already existing game functionalities of a training module to bring about effective and dynamic simulations involving the use of unused functionalities of the existing game engine. We emphasize how the promoted changes mold the existing training module effectively to create highly realistic and interactive training environments for the Combat Life Savers of the US Army.",
    "author": [
      {
        "family": "Kuskuntla",
        "given": "Radha"
      },
      {
        "family": "Imsand",
        "given": "Eric S."
      },
      {
        "family": "Hamilton",
        "given": "J. A. \"Drew\""
      }
    ],
    "collection-title": "SpringSim ’10",
    "container-title": "Proceedings of the 2010 spring simulation multiconference",
    "id": "10.1145/1878537.1878588",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "training, combat medic, Unreal Engine 3, America’s Army",
    "publisher": "Society for Computer Simulation International",
    "publisher-place": "San Diego, CA, USA",
    "title": "Enhanced expert field medical training simulations and their effect on the modern combat life saver training procedures",
    "type": "paper-conference"
  },
  {
    "ISBN": "0769509037",
    "abstract": "Workflow can be understood as the automation of a business process in the total or partial meaning, when documents or activities are passed from one participant to another. The goal is that actions start according to a set of rules and behaviors. The objective of this article isto introduce the workflow technology and to present a new technique to model workflow systems. This technique is defined as an improvement of the Triggers Model, validated by Stef Joosten. It’s formed by a method to specify activities and by a set of graphic elementsinherent to the main concepts of workflow. As validation, this technique is used to model the Case Study to Approve Research Projects at the University at Santa Cruz do SUB. This modeling applies to the implementation of a prototype on Lotus Notes 4.6, The purpose of the improvement is to introduce aspects of the specification of the project that were not contemplated, through a sequence of stages aimed at the creation of a more efficient model, improving the implementation of a workflow system regardless of the development tool usedand making it easier.",
    "author": [
      {
        "family": "Thorn",
        "given": "LucinCia Heloisa"
      },
      {
        "family": "Scheidt",
        "given": "Neiva"
      },
      {
        "family": "Molz",
        "given": "Kurt Werner"
      }
    ],
    "collection-title": "SMT ’00",
    "container-title": "Proceedings of the international conference on software methods and tools (SMT’00)",
    "id": "10.5555/555920.830376",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "keyword": "modeling, concepts, business process, Workflow",
    "page": "223",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "A first report on a new technique to model workflow systems",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-031-20102-8_38",
    "ISBN": "978-3-031-20101-1",
    "URL": "https://doi.org/10.1007/978-3-031-20102-8_38",
    "abstract": "Semantic segmentation algorithms are the cornerstone of the autonomous driving algorithm. The implementation of these algorithms requires a lot of data. However, due to the complex and changeable production environment, the differences in image style, illumination and weather conditions not only significantly degrade the performance of network models under development environment data, but also cause costly data annotation. This paper proposes a dilation-corrosion soft label smoothing strategy. This strategy utilizes the existing self-supervised learning soft label generation strategy and overcomes the premise assumption defect of the fine-grained adversarial model on the target domain model. Our strategy evaluates its effectiveness on the domain adaptation task of GTA5 → Cityscapes. At the same time, we reduce the amount of source domain data by half and the number of domain classification training iterations by half, the resulting in the comprehensive evaluation index is 1.5",
    "author": [
      {
        "family": "Li",
        "given": "Kangshun"
      },
      {
        "family": "Wang",
        "given": "Yi"
      },
      {
        "family": "Feng",
        "given": "Tian"
      },
      {
        "family": "Jalil",
        "given": "Hassan"
      },
      {
        "family": "Nie",
        "given": "Huabei"
      }
    ],
    "container-title": "Machine learning for cyber security: 4th international conference, ML4CS 2022, guangzhou, china, december 2–4, 2022, proceedings, part III",
    "id": "10.1007/978-3-031-20102-8_38",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "Soft label smoothing, Self-supervised learning, Domain adaptive learning, Semantic segmentation",
    "page": "499-506",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Morphology-based soft label smoothing strategy for fine-grained domain adaptationming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1002/aaai.12145",
    "ISSN": "0738-4602",
    "URL": "https://doi.org/10.1002/aaai.12145",
    "abstract": "This paper highlights the overall endeavors of the NSF AI Institute for Future Edge Networks and Distributed Intelligence (AI‐EDGE) to create a research, education, knowledge transfer, and workforce development environment for developing technological leadership in next‐generation edge networks (6G and beyond) and artificial intelligence (AI). The research objectives of AI‐EDGE are twofold: “AI for Networks” and “Networks for AI.” The former develops new foundational AI techniques to revolutionize technologies for next‐generation edge networks, while the latter develops advanced networking techniques to enhance distributed and interconnected AI capabilities at edge devices. These research investigations are conducted across eight symbiotic thrust areas that work together to address the main challenges towards those goals. Such a synergistic approach ensures a virtuous research cycle so that advances in one area will accelerate advances in the other, thereby paving the way for a new generation of networks that are not only intelligent but also efficient, secure, self‐healing, and capable of solving large‐scale distributed AI challenges. This paper also outlines the institute’s endeavors in education and workforce development, as well as broadening participation and enforcing&nbsp;collaboration.",
    "author": [
      {
        "family": "Ju",
        "given": "Peizhong"
      },
      {
        "family": "Li",
        "given": "Chengzhang"
      },
      {
        "family": "Liang",
        "given": "Yingbin"
      },
      {
        "family": "Shroff",
        "given": "Ness"
      }
    ],
    "container-title": "AI Mag.",
    "id": "10.1002/aaai.12145",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2024,
          2
        ]
      ]
    },
    "page": "29-34",
    "publisher": "American Association for Artificial Intelligence",
    "publisher-place": "USA",
    "title": "AI‐EDGE: An NSF AI institute for future edge networks and distributed intelligence",
    "title-short": "AI‐EDGE",
    "type": "article-journal",
    "volume": "45"
  },
  {
    "ISSN": "1550-4646",
    "abstract": "This paper explores requirements application authoring tools should satisfy for the development of cultural applications tailored for deployment on Personal Digital Assistants (PDAs) and mobile phones. The paper reviews the use of mobile technologies in the context of cultural organizations and tourism. It identifies and evaluates the development and design facilities provided by state-of-the-art multimedia application development tools for PDAs and mobile phones: Macromedia Flash Lite, Navipocket and Java 2 Micro Edition. It describes the way these tools have been used in the implementation phase of two projects that have been developed at the Cultural Heritage Management Lab (CHMLab), at the Department of Cultural Technology and Communication, University of the Aegean. These projects focus on the use of PDAs and mobile phones for providing cultural and tourist information, keeping the visitors’ interest and attention, as well as promoting various cultural organizations’ and tourist facilities. Based on these two case studies the paper extracts a set of PDA and mobile phone application requirements. The paper concludes with a set of suggestions related to the way application authoring tools should be exploited in order to gratify application and designer needs for developing operational and profitable cultural and tourist applications.",
    "author": [
      {
        "family": "Economou",
        "given": "Daphne"
      },
      {
        "family": "Gavalas",
        "given": "Damianos"
      },
      {
        "family": "Kenteris",
        "given": "Michael"
      },
      {
        "family": "Micha",
        "given": "Katy"
      }
    ],
    "container-title": "J. Mob. Multimed.",
    "id": "10.5555/2010532.2010538",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2007,
          3
        ]
      ]
    },
    "keyword": "requirements, development platforms, cultural and tourist multimedia applications, application authoring tools, Navipocket, J2ME",
    "page": "65-87",
    "publisher": "Rinton Press, Incorporated",
    "publisher-place": "Paramus, NJ",
    "title": "Multimedia applications for handheld devices: Analysis of requirements for development platforms and application authoring tools",
    "title-short": "Multimedia applications for handheld devices",
    "type": "article-journal",
    "volume": "3"
  },
  {
    "DOI": "10.1155/2021/8357488",
    "ISSN": "1530-8669",
    "URL": "https://doi.org/10.1155/2021/8357488",
    "abstract": "This study takes the digital campus construction planning of the high school as an example and determines the requirements of the postgraduate management information system under the digital campus environment through the analysis of the overall framework and technology of the digital campus. Combining the current situation of computer technology, network technology, and the actual situation of our university, the current mainstream B/S three-layer architecture is adopted, the web adopts the current popular Java Server Pages technology, and the struts framework connects to the Oracle backend database through the Java Database Connectivity interface to design the browser-side and server-side programs. The struts framework connects to the Oracle backend database through the Java Database Connectivity interface to design browser-side and server-side programs. The functional model and data flow model of the system were established through a detailed and effective analysis of the entire workflow of postgraduate students’ training management during their school years. Then, the system analysis, design, and drawing of the swim lane diagram and data business flow diagram were carried out. The system was designed in detail in terms of system architecture, development tools, functional modules, and database design, and the core module of training program making in postgraduate training management was highlighted as an example to discuss the principles and methods in the construction of departmental business systems and informatization under the digital campus environment, and a flexible and efficient postgraduate management information system was realized. It standardizes the construction of data standardization in universities; does a good job of standardizing and normalizing information; improves the accuracy, validity, and real-time production of data collection and the real and safe unified management of historical data; and provides scientific and reasonable data support for the leadership to make relevant decisions.",
    "author": [
      {
        "family": "Ma",
        "given": "Jing"
      },
      {
        "family": "Feng",
        "given": "Bo"
      },
      {
        "family": "Zhang",
        "given": "Yuanpeng"
      }
    ],
    "container-title": "Wirel. Commun. Mob. Comput.",
    "id": "10.1155/2021/8357488",
    "issued": {
      "date-parts": [
        [
          2021,
          1
        ]
      ]
    },
    "publisher": "John Wiley; Sons Ltd.",
    "publisher-place": "GBR",
    "title": "Integrated design of graduate education information system of universities in digital campus environment",
    "type": "article-journal",
    "volume": "2021"
  },
  {
    "ISBN": "9781467330763",
    "abstract": "Computational Science and Engineering (CSE) software supports a wide variety of domains including nuclear physics, crash simulation, satellite data processing, fluid dynamics, climate modeling, bioinformatics, and vehicle development. The increases importance of CSE software motivates the need to identify and understand appropriate software engineering (SE) practices for CSE. Because of the uniqueness of the CSE domain, existing SE tools and techniques developed for the business/IT community are often not efficient or effective. Appropriate SE solutions must account for the salient characteristics of the CSE development environment. SE community members must interact with CSE community members to understand this domain and to identify effective SE practices tailored to CSEs needs. This workshop facilitates that collaboration by bringing together members of the CSE and SE communities to share perspectives and present findings from research and practice relevant to CSE software and CSE SE education. A significant portion of the workshop is devoted to focused interaction among the participants with the goal of generating a research agenda to improve tools, techniques, and experimental methods for CSE software engineering.",
    "author": [
      {
        "family": "Carver",
        "given": "Jeffrey C."
      },
      {
        "family": "Epperly",
        "given": "Tom"
      },
      {
        "family": "Hochstein",
        "given": "Lorin"
      },
      {
        "family": "Maxville",
        "given": "Valerie"
      },
      {
        "family": "Pfahl",
        "given": "Dietmar"
      },
      {
        "family": "Sillito",
        "given": "Jonathan"
      }
    ],
    "collection-title": "ICSE ’13",
    "container-title": "Proceedings of the 2013 international conference on software engineering",
    "id": "10.5555/2486788.2487077",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "page": "1547-1548",
    "publisher": "IEEE Press",
    "publisher-place": "San Francisco, CA, USA",
    "title": "5th international workshop on software engineering for computational science and engineering (SE-CSE 2013)",
    "type": "paper-conference"
  },
  {
    "abstract": "Cardiovascular rehabilitation is an interdisciplinary medical care program which includes patient specific exercise therapy, stress management, psychological counseling, aggressive dietary lipid management and extensive patient education to modify lifestyle factors which place the heart at risk. This research investigates the development of an intelligent clinical database/knowledge base system to assist in the management of the cardiovascular rehabilitation patient. Utilizing development tools for the database and knowledge base implementation, the prototype system maintains a rehabilitation clinical database and provides a rule-based system for automated therapy planning and risk monitoring.The extensive database contains over 400 variables in over 20 clinical specialties, fulfilling daily rehabilitation requirements in addition to supporting long-term, epidemiological studies. The database is designed utilizing an object-oriented paradigm; the software consists of new and modified classes added to a standard Smalltalk environment. The knowledge base retrieves parameter values from the database into a forward-chaining rule structure. Additional Smalltalk methods were added to accomplish an interface between the database and knowledge base.The system was evaluated by analyzing patient records provided by the rehabilitation clinic, completing risk analysis and reviewing the therapy plan for each patient. Risk categorizations and therapy plan deficiencies produced by the system agreed with the staff’s recommendations.",
    "author": [
      {
        "family": "Ryder",
        "given": "Robert Michael"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/143498",
    "issued": {
      "date-parts": [
        [
          1992
        ]
      ]
    },
    "note": "UMI Order No. GAX92-33366",
    "publisher": "Clemson University",
    "publisher-place": "USA",
    "title": "An object-oriented, knowledge-based system for cardiovascular rehabilitation",
    "type": "thesis"
  },
  {
    "DOI": "10.1134/S1054661821030020",
    "ISSN": "1054-6618",
    "URL": "https://doi.org/10.1134/S1054661821030020",
    "author": [
      {
        "family": "Andriyanov",
        "given": "N. A."
      }
    ],
    "container-title": "Pattern Recognit. Image Anal.",
    "id": "10.1134/S1054661821030020",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2021,
          7
        ]
      ]
    },
    "keyword": "driver monitoring system, pattern recognition, human condition monitoring, convolutional neural networks, Open Source Computer Vision Library, Haar cascades, eye extraction",
    "page": "489-495",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Application of computer vision systems for monitoring the condition of drivers based on facial image analysis",
    "type": "article-journal",
    "volume": "31"
  },
  {
    "abstract": "The purpose of this Research and Development study was to develop and evaluate Web-IEP, a Web-based Individual Education Plan (IEP) development tool, which uses artificial intelligence for decision-making based on the theories of Piaget, Vygotsky, Kohlberg, Bloom, and Erikson; and to generate Mager and Gronlund style objectives for students in special education. The software provides support to multidisciplinary teams whose charge it is to develop IEPs, which will be accessible on the Web, so that students, parents, teachers, and advocacy groups will have access to the software. The software provides assistance to novice teachers developing IEPs. The system is consistent with special education regulations, ensures IEP compliance and helps teachers develop IEP objectives. The research and development study followed a procedure based on the Systems Approach Model of Educational Research and Development (R&amp;D) method. The participants in the formative evaluations provided comments, suggestions, and criticisms, which led to the development of Web-IEP. The results of the evaluations indicated the Web-IEP fulfilled its development objectives. The results of the evaluation indicated that several schools in a regional education center could use Web-IEP to produce an IEP, IEP data would be easy to transfer from school to school, and could be shared.**This dissertation is compound (contains both a paper copy and a CD as part of the dissertation). The CD requires the following system requirements: Microsoft Office; Windows MediaPlayer or RealPlayer.",
    "author": [
      {
        "family": "Cox",
        "given": "Stephen Michael"
      },
      {
        "family": "Mcgrath",
        "given": "Diane"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/979046",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "note": "AAI3096691",
    "publisher": "Kansas State University",
    "publisher-place": "USA",
    "title": "Web-based individual education plan software: Research and development",
    "title-short": "Web-based individual education plan software",
    "type": "thesis"
  },
  {
    "ISBN": "9264077391",
    "abstract": "Information communication technologies (ICTs) are crucial to reducing poverty, improving access to health and education services and creating new sources of income and employment for the poor. Being able to access and use ICTs has become a major factor in driving competitiveness, economic growth and social development. In the last decade, ICTs, particularly mobile phones, have also opened up new channels for the free flow of ideas and opinions, thereby promoting democracy and human rights. The OECD and infoDev joined forces at a workshop on 10-11 September 2009 to examine some of the main challenges in reducing the discrepancies in access to ICTs and use of ICTs between developing countries. The workshop discussed best practices for more coherent and collaborative approaches in support of poverty reduction and meeting the Millennium Development Goals. There is much work to be done on improving policy coherence and there is a need to engage more actively with partner countries. Making the most of ICTs requires that they are seen as part of innovation for development, rather than just another development tool. This publication examines access to ICTs, as a precondition to their use; broadband Internet access and governments’ role in making it available; developments in mobile payments; ICT security issues; ICTs for improving environmental performance; and the relative priority of ICTs in education. For more information The OECD/infoDev workshop on ICTs for Development: www.oecd.org/ICT/4D OECD work on Policy Coherence for Development: www.oecd.org/development/policycoherence infoDev: www.infoDev.org Table of Content : Acronyms and Abbreviations Executive Summary Chapter 1. Why ICTS Matter for Development Chapter 2. Where Next for ICTs and International Development? Chapter 3. How the Developing World may Participate in the Global Internet Economy - Innovation Driven by Competition Chapter 4. What Role Should Governments Play in Broadband Development? Chapter 5. Regulatory Issues around Mobile Banking Chapter 6. ICTs and the Environment in Developing Countries - Opportunities and Developments Chapter 7. Policy Coherence in ICTs for Education - Examples from South Asia",
    "author": [
      {
        "dropping-particle": "for",
        "family": "Economic Co-operation",
        "given": "OECD Organisation"
      },
      {
        "family": "Development"
      }
    ],
    "id": "10.5555/1841541",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "publisher": "OECD",
    "title": "The development dimension ICTs for development: Improving policy coherence",
    "title-short": "The development dimension ICTs for development",
    "type": "book"
  },
  {
    "abstract": "HPC software is developed and used in a wide variety of scientific domains including nuclear physics, computational chemistry, crash simulation, satellite data processing, fluid dynamics, climate modeling, bioinformatics, and vehicle development. The increase in the importance of this software motivates the need to identify and understand appropriate software engineering (SE) practices for HPC architectures. Because of the variety of the scientific domains addressed using HPC, existing SE tools and techniques developed for the business/IT community are often not efficient or effective. Appropriate SE solutions must account for the salient characteristics of the HPC, research-oriented development environment. This situation creates a need for members of the SE community to interact with members of the scientific and HPC communities to address this need. This workshop facilitates that collaboration by bringing together members of the SE, the scientific, and the HPC communities to share perspectives and present findings relevant to research, practice, and education. A significant portion of the workshop is devoted to focused interaction among the participants with the goal of generating a research agenda to improve tools, techniques, and experimental methods regarding SE for HPC science.",
    "author": [
      {
        "family": "Carver",
        "given": "Jeffrey C."
      },
      {
        "family": "Hong",
        "given": "Neil Chue"
      },
      {
        "family": "Ciancarini",
        "given": "Paolo"
      }
    ],
    "collection-title": "ICSE ’15",
    "container-title": "Proceedings of the 37th international conference on software engineering - volume 2",
    "id": "10.5555/2819009.2819251",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "software engineering, high performance computing, computational science, computational engineering",
    "page": "1003-1004",
    "publisher": "IEEE Press",
    "publisher-place": "Florence, Italy",
    "title": "SE4HPCS’15: The 2015 international workshop on software engineering for high performance computing in science",
    "title-short": "SE4HPCS’15",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1002/cpe.3154",
    "ISSN": "1532-0626",
    "URL": "https://doi.org/10.1002/cpe.3154",
    "abstract": "For real-time and embedded systems, limiting the consumption of time and memory resources is often an important part of the requirements. Being able to predict bounds on the consumption of such resources during the development process of the code can be of great value. In this paper, we focus mainly on memory-related bounds. Recent research results have advanced the state of the art of resource consumption analysis. In this paper, we present a toolset that makes it possible to apply these research results in practice for real-time systems enabling JAVA developers to analyse symbolic loop bounds, symbolic bounds on heap size and both symbolic and numeric bounds on stack size. We describe which theoretical additions were needed in order to achieve this. We give an overview of the capabilities of the RESANA Radboud University Nijmegen, The Netherlands toolset that is the result of this effort. The toolset can not only perform generally applicable analyses, but it also contains a part of the analysis that is dedicated to the developers’ real-time virtual machine, such that the results apply directly to the actual development environment that is used in practice. Copyright © 2013 John Wiley &amp; Sons, Ltd.",
    "author": [
      {
        "family": "Kersten",
        "given": "Rody W. J."
      },
      {
        "family": "Gastel",
        "given": "Bernard E."
      },
      {
        "family": "Shkaravska",
        "given": "Olha"
      },
      {
        "family": "Montenegro",
        "given": "Manuel"
      },
      {
        "family": "Eekelen",
        "given": "Marko C. J. D."
      }
    ],
    "container-title": "Concurr. Comput. : Pract. Exper.",
    "id": "10.1002/cpe.3154",
    "issue": "14",
    "issued": {
      "date-parts": [
        [
          2014,
          9
        ]
      ]
    },
    "keyword": "stack bounds, resource analysis, ranking function, polynomial interpolation, loop bounds, heap bounds",
    "page": "2432-2455",
    "publisher": "John Wiley; Sons Ltd.",
    "publisher-place": "GBR",
    "title": "ResAna: A resource analysis toolset for real-time JAVA",
    "title-short": "ResAna",
    "type": "article-journal",
    "volume": "26"
  },
  {
    "ISBN": "1484220986",
    "abstract": "Learn how to create good requirements when designing hardware and software systems. While this book emphasizes writing traditional shall statements, it also provides guidance on use case design and creating user stories in support of agile methodologies. The book surveys modeling techniques and various tools that support requirements collection and analysis. Youll learn to manage requirements, including discussions of document types and digital approaches using spreadsheets, generic databases, and dedicated requirements tools. Good, clear examples are presented, many related to real-world work the author has done during his career. Requirements Writing for System Engineeringantages of different requirements approaches and implement them correctly as your needs evolve. Unlike most requirements books,Requirements Writing for System Engineeringteaches writing both hardware and software requirements because many projects include both areas. To exemplify this approach, two example projects are developed throughout the book, one focusing on hardware and the other on software. This book Presents many techniques for capturing requirements. Demonstrates gap analysis to find missing requirements. Shows how to address both software and hardware, as most projects involve both. Provides extensive examples of shall statements, user stories, and use cases. Explains how to supplement or replace traditional requirement statements with user stories and use cases that work well in agile development environments What You Will LearnUnderstand the 14 techniques for capturing all requirements.Address software and hardware needs; because most projects involve both.Ensure all statements meet the 16 attributes of a good requirement.Differentiate the 19 different functional types of requirement, and the 31 non-functional types.Write requirements properly based on extensive examples of good shall statements, user stories, and use cases.Employ modeling techniques to mitigate the imprecision of words.AudienceWriting Requirements teaches you to write requirements the correct way. It is targeted at the requirements engineer who wants to improve and master his craft. This is also an excellent book from which to teach requirements engineering at the university level. Government organizations at all levels, from Federal to local levels, can use this book to ensure they begin all development projects correctly. As well, contractor companies supporting government development are also excellent audiences for this book.",
    "author": [
      {
        "family": "Koelsch",
        "given": "George"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3031651",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Apress",
    "publisher-place": "USA",
    "title": "Requirements writing for system engineering",
    "type": "book"
  },
  {
    "DOI": "10.1145/3540250.3558965",
    "ISBN": "9781450394130",
    "URL": "https://doi.org/10.1145/3540250.3558965",
    "abstract": "Code generation aims to generate a code snippet automatically from natural language descriptions. Generally, the mainstream code generation methods rely on a large amount of paired training data, including both the natural language description and the code. However, in some domain-specific scenarios, building such a large paired corpus for code generation is difficult because there is no directly available pairing data, and a lot of effort is required to manually write the code descriptions to construct a high-quality training dataset. Due to the limited training data, the generation model cannot be well trained and is likely to be overfitting, making the model’s performance unsatisfactory for real-world use. To this end, in this paper, we propose a task augmentation method that incorporates domain knowledge into code generation models through auxiliary tasks and a Subtoken-TranX model by extending the original TranX model to support subtoken-level code generation. To verify our proposed approach, we collect a real-world code generation dataset and conduct experiments on it. Our experimental results demonstrate that the subtoken-level TranX model outperforms the original TranX model and the Transformer model on our dataset, and the exact match accuracy of Subtoken-TranX improves significantly by 12.75",
    "author": [
      {
        "family": "Shen",
        "given": "Sijie"
      },
      {
        "family": "Zhu",
        "given": "Xiang"
      },
      {
        "family": "Dong",
        "given": "Yihong"
      },
      {
        "family": "Guo",
        "given": "Qizhi"
      },
      {
        "family": "Zhen",
        "given": "Yankun"
      },
      {
        "family": "Li",
        "given": "Ge"
      }
    ],
    "collection-title": "ESEC/FSE 2022",
    "container-title": "Proceedings of the 30th ACM joint european software engineering conference and symposium on the foundations of software engineering",
    "id": "10.1145/3540250.3558965",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "Task Augmentation, Domain Knowledge, Code Generation",
    "page": "1533-1543",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Incorporating domain knowledge through task augmentation for front-end JavaScript code generation",
    "type": "paper-conference"
  },
  {
    "ISBN": "9780494637883",
    "abstract": "Driven by the technical demand of the offshore oil and gas industry in Atlantic Canada, a joint venture among several Atlantic Canadian universities, and local and national companies was established in order to advance wireless systems technology in the oil and gas industry, and to assess the feasibility of an intelligent control and asset management system built on a wireless sensor network. As part of this research project, our team at the University of New Brunswick (UNB) is developing an intelligent control and asset management system (ICAM system) to manage the massive information flow from offshore oil rigs. The objective of this PhD thesis is to design the ICAM system architecture, to analyze its multi-faceted requirements, and to verify and validate its performance and logical behavior in normal and abnormal process situations. The conceptual model of the ICAM system was defined along with its architecture, functional description and general logical behavior. A development plan to design such a complex system and the appropriate development tools were decided. The artificial intelligence (AI) requirements of the system were analyzed in terms of knowledge representation and processing, and the appropriate AI paradigm. The communication requirements were also analyzed after conducting a thorough review of middleware (i.e., communications) technologies. The structure, implementation and deployment of the system agents were defined based on the suggested system requirements.A simple prototype of the ICAM system was designed in terms of the middleware layer, the intelligent supervisory agent of the system, and the reactive agents of the system prototype. The verification and validation of the system were demonstrated, where several scenarios were applied to the system to analyze its performance in real time and its logical behavior. The oil production facility simulation model, upon which the system’s verification and validation have been demonstrated, was developed. A system performance analysis was conducted to detect any computational bottlenecks. Although the system prototype design has limitations, simulation results have demonstrated an effective system logical behavior and performance in real time.",
    "author": [
      {
        "family": "Sayda",
        "given": "Atalla F."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1970710",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "note": "AAINR63788",
    "publisher": "University of New Brunswick",
    "publisher-place": "CAN",
    "title": "Intelligent control and asset management of oil and gas production facilities",
    "type": "thesis"
  },
  {
    "ISBN": "0789739380",
    "abstract": "DVD includes: 7+ HOURS OF VIDEO INSTRUCTION 50 TIPS &amp; TECHNIQUES SKILLS YOU CAN LEARN IN Fifteen MINUTES OR LESS In Excel VBA and Macros with MrExcel, renowned Excel instructor and author Bill Jelen (MrExcel) teaches all the skills youll need to automate virtually any routine task with Excel and build powerful Excel macros! This package brings together nearly eight hours hours of personalized, expert video training: 50 quick, practical video lessons that demonstrate all the skills youll need to successfully use both the Excel macro recorder and the Visual Basic for Applications development environment. Youll learn one step at a time, at your own paceusing hands-on examples that reflect realistic challenges and showcase Excels remarkable capabilities. Along the way, Jelen will take you from the absolute basics through PivotTables and data filtering. Excel VBA and Macros with MrExcel delivers the power of the best classroom training at a small fraction of the cost. If you dont have time to read a huge book on Excel macros and scripting, this is exactly what youve been searching for! For all serious Excel users: managers, financial pros, entrepreneurs, marketers, analysts, and more. Looking for a better way to master todays rapidly changing technologies? Want expert help, but dont have the time or energy to read a book? Cant find classroom training worth the money? Discover LiveLessons: self-paced, personal video instruction from the worlds leading technology experts. LiveLessons are video courses, on DVD with a book supplement, that are organized into bite-sized, self-contained sessionsyoull learn key skills in as little as fifteen minutes! Each lesson begins with well-defined learning objectives and ends with comprehensive summaries, which help you track your progress. Follow along as your trainer shows you how to make the most of Excels macro recorder and its powerful VBA development environment! Bill Jelen is called MrExcel for a reason! Nobody knows more about Excel macros and scriptingand nobody knows more about teaching these skills to working professionals! Thought youd never write your own Excel macros and programs? Think again! You willand you can start in just minutes! Bill Jelen, known worldwide as MrExcel, presents live Excel seminars across the United States and appears in over 800 podcast episodes. His 20 Excel books include Special Edition Using Excel 2007 and VBA and Macros for Microsoft Excel. His website, MrExcel.com, answers 30,000 Excel questions per year. System Requirements OS: Windows 98, 2000, XP, and Windows Vista; Mac OS X; versions of Linux with the Flash 8 Player or later. Multimedia: DVD drive, an 1024x768 or higher display, and a sound card with speakers. Computer: 500MHz or higher, 128MB RAM or more Microsoft Office Spreadsheets/Desktop Applications $49.99 USA /$59.99 CAN / 31.99 U.K. mylivelessons.com informit.com/que",
    "author": [
      {
        "family": "Jelen",
        "given": "Bill"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1611277",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Que Publishing Company",
    "title": "Excel VBA and macros with MrExcel",
    "type": "book"
  },
  {
    "DOI": "10.1145/186281.186296",
    "ISBN": "0897916522",
    "URL": "https://doi.org/10.1145/186281.186296",
    "abstract": "The present study was conducted as exploratory research to understand the activities and beliefs of IS and line managers, with regard to the management of information technology (IT). Semi-structured interviews were conducted with 25 managers in seven firms to understand their current initiatives, future vision, and the factors driving change. Managers from three different positions from each company were interviewed—a senior IS manager, an IS application development manager, and a line manager. The results showed that there were a variety of different initiatives underway—with the most common ones being rapid prototyping, an emphasis on purchasing packages, business reengineering, and building IT infrastructure. Beyond these few commonalities, different firms were adopting a variety of changes to their IS organization structure, working relationships with users and outside vendors, system development tools and methodologies, and their training and other human resource policies.Similarly, a broad range of factors were cited as driving changes in IT management practice—with these clustering into four major sets of drivers: business cost pressures, business service pressures, IS service pressures, and technology-push factors. Few respondents were able to articulate a vision for the IS organization of the future, beyond describing their expectations for the initiatives currently underway. Of those respondents who provided such a vision, few described the steps required to achieve the transition. These findings are analyzed in terms of a management framework derived from Harold Leavitt and discussed in light of other recent research on IS management. Questions for follow-up research are suggested.",
    "author": [
      {
        "family": "Gallivan",
        "given": "Michael J."
      }
    ],
    "collection-title": "SIGCPR ’94",
    "container-title": "Proceedings of the 1994 computer personnel research conference on reinventing IS : Managing information technology in changing organizations: Managing information technology in changing organizations",
    "id": "10.1145/186281.186296",
    "issued": {
      "date-parts": [
        [
          1994
        ]
      ]
    },
    "page": "65-77",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Changes in the management of the information systems organization: An exploratory study",
    "title-short": "Changes in the management of the information systems organization",
    "type": "paper-conference"
  },
  {
    "ISBN": "0735609675",
    "abstract": "From the Publisher: This official Microsoft training kit delivers comprehensive preparation for MCP Exam 70-152–an elective exam on the Microsoft Certified Solution Developer (MCSD) track. Through a self-paced system of lessons and hands-on labs, students learn how to analyze, design, build, and implement Web-based solutions using Microsoft Visual InterDev version 6.0. The training helps build competency in 12 critical skill areas defined by the MCSD program: analyzing business requirements, defining technical architecture, developing the conceptual and logical design, designing a user interface and user services, deriving the physical design, establishing the development environment, creating user services, creating data services, testing, deployment, and Web site management. Self-assessment questions and complete model application on CD-ROM supplement and extend the learning experience. By the end of the course, students have applied real-world development skills to the creation of a full-featured data-driven Web application–and they’re ready for the MCP exam! Self-paced study and preparation for Exam 70-152–an elective credit for MCSD certification Provides proven, self-paced training for developing Web solutions using Microsoft Visual InterDev 6.0 Supports skills transfer and certification exam preparation in a single kit DV-DLT Fundamentals Includes sample questions to help assess learner progress Provides a self-study, learner-driven alternative to expensive classroom training CD-ROM contains hands-on lab exercises, demos, and complete model application for a total learning solution",
    "author": [
      {
        "family": "Corporation",
        "given": "Microsoft"
      }
    ],
    "id": "10.5555/519071",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "Microsoft Press",
    "publisher-place": "USA",
    "title": "Web applications with microsoft visual interdev 6.0 MCSD training kit: For exam 70-152 with cdrom",
    "title-short": "Web applications with microsoft visual interdev 6.0 MCSD training kit",
    "type": "book"
  },
  {
    "DOI": "10.1145/186281.186299",
    "ISBN": "0897916522",
    "URL": "https://doi.org/10.1145/186281.186299",
    "abstract": "This paper explores the potential of using multiple software requirements specification methods for elicitation of concepts in the development of university courseware based on the multimedia and hypermedia technology. At universities, the use of hypermedia and multimedia technology is perceived as one of the most efficient ways to enhance student access to information and improve learning interaction in the undergraduate computer science course. Such an approach will guarantee high level quality teaching whilst permitting significant reduction in lecturer-student contact hours. The process which plays the critical role in such a development environment is the concepts acquisition and requirements specification, collectively called requirements engineering.The hypermedia design and programming development process shows some peculiarities which make them different from the “classic” development activities. The main areas of interest include the user requirements engineering and removing ambiguity of natural language from software requirements specifications. There is a need to devise an integrated set of specification notations which would cater for the irregularities introduced by the differences in media while supporting commonly used development activities.In this case study, we assume a typical interactive multimedia development process in a teaching environment. The objective is to assess the role of prototyping and to establish the main characteristics of the formal requirements specification notation(s) as a means for achieving a more efficient utilisation of complex computing technologies. The horizontal design partitioning concept is used to establish clear demarcation lines between the development process phases. The vertical design partitioning is used to reduce complexity of the design by enforcing predictable structural patterns and presentation logic components. This approach allows deployment of the multiple specification notations in the design and implementation process.The paper is organized as follows: Firstly, we discuss the key characteristics of the hypermedia design process. In section two, the role of prototyping is critically evaluated. Section three provides our view of concepts acquisition and requirements management process. Remaining sections of this case study depict our proposed conceptual model for hypermedia based courseware development process.",
    "author": [
      {
        "family": "Dospisil",
        "given": "Jana"
      },
      {
        "family": "Polgar",
        "given": "Tony"
      }
    ],
    "collection-title": "SIGCPR ’94",
    "container-title": "Proceedings of the 1994 computer personnel research conference on reinventing IS : Managing information technology in changing organizations: Managing information technology in changing organizations",
    "id": "10.1145/186281.186299",
    "issued": {
      "date-parts": [
        [
          1994
        ]
      ]
    },
    "page": "97-104",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Conceptual modelling in the hypermedia development process",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2961111.2962615",
    "ISBN": "9781450344272",
    "URL": "https://doi.org/10.1145/2961111.2962615",
    "abstract": "Context: Most widely used cost models use source lines of code (SLOC) as the software size input measure, due to its quantifiability and high correlation with effort. Estimating the SLOC of a project is very difficult in early stages of the software lifecycle, especially for software maintenance tasks. Depending on the reuse model being used, one would need to size the existing code that needs modifications and the size of the changes being made in SLOC. Functional size measures, such as Function Points (FPs) and the Software Non-functional Assessment Process (SNAP), have been developed to improve the ability to estimate project size early in the lifecycle for both development and maintenance projects. While FPs represent software size by functions; SNAP complements FPs by sizing non-functional requirements, such as data operations and interface design. Goal: SNAP complements Function Points by sizing non-functional requirements, such as data operations and interface design. Through an empirical analysis, the authors want to determine whether SNAP might be an effective software size measure individually or in conjunction with FPs to improve effort estimation accuracy. Method: The empirical analysis will be run on Unified Code Count (UCC)’s dataset, a software tool maintained by University of Southern California (USC). Results: The analyses found that separating projects adding new functions from those modifying existing functions resulted in improved estimation models using SNAP. The effort estimation model for projects modifying functions in UCC had high prediction accuracy statistics, but less impressive results for projects adding existing functions to UCC. The effort estimation accuracy were satisfactory when using SNAP in conjunction with FPs for both groups of projects. Conclusions: SNAP, indeed, complements FPs in terms of the requirements that are considered and sized. Both size metrics should be treated as individual metrics, but can be used together for acceptably accurate cost models in UCC’s development environment.",
    "author": [
      {
        "family": "Hira",
        "given": "Anandi"
      },
      {
        "family": "Boehm",
        "given": "Barry"
      }
    ],
    "collection-title": "ESEM ’16",
    "container-title": "Proceedings of the 10th ACM/IEEE international symposium on empirical software engineering and measurement",
    "id": "10.1145/2961111.2962615",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "Software Non-Functional Assessment Process, Software Maintenance, SNAP, Project Management, Local Calibration, Function Point Analysis, Effort Estimation, Cost Estimation",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using software non-functional assessment process to complement function points for software maintenance",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1155/2022/5248308",
    "ISSN": "1530-8669",
    "URL": "https://doi.org/10.1155/2022/5248308",
    "abstract": "Machine learning methods such as Adaptive Network-Based Fuzzy Inference System (ANFIS) have been widely employed in intelligent urban storm water disaster warning for the purpose of smart city. However, there exists lack of research proposed for applying ANFIS and mobile application (App) to reach the purpose of smart city. In order to accomplish the goal, the study integrates ANFIS and Qt Framework to develop a Typhoon Rainfall Forecasting System to real-time typhoon rainfall forecast via a mobile device. The Service is first built by applying cluster analysis to typhoon data (Tamsui Weather Station of Taiwan) during June 1967 and November 2020 to classify the data into four groups and then applying the ANFIS to construct the Service with data in each group. The fuzzy rule of ANFIS is established by grid partition method. Both the Service and App employ Qt Framework as the cross-operating development tool, and the App is transformed to a smart mobile device App of different platforms. The simulated results show the following: (1) Taking the example of typhoon Nakri in group 1, the lowest root mean square error (7.898 mm) and the lowest computation time (178 sec) were obtained for training with 1000 steps and three membership functions. (2) Using the optimal parameters of the typhoon belonging to that group can obtain better prediction results. The developed typhoon rainfall forecasting system App in the supplementary information demonstrates that the user can use the smart mobile device for real-time typhoon forecasting at the most three hours ahead easily.",
    "author": [
      {
        "family": "Lin",
        "given": "Shiu-Shin"
      },
      {
        "family": "Zhu",
        "given": "Kai-Yang"
      },
      {
        "family": "Wang",
        "given": "Jun-Yuan"
      },
      {
        "family": "Liao",
        "given": "Ying-Po"
      },
      {
        "family": "Hrovat",
        "given": "Andrej"
      }
    ],
    "container-title": "Wirel. Commun. Mob. Comput.",
    "id": "10.1155/2022/5248308",
    "issued": {
      "date-parts": [
        [
          2022,
          1
        ]
      ]
    },
    "publisher": "John Wiley; Sons Ltd.",
    "publisher-place": "GBR",
    "title": "Integrating ANFIS and qt framework to develop a mobile-based typhoon rainfall forecasting system",
    "type": "article-journal",
    "volume": "2022"
  },
  {
    "ISBN": "9781538627914",
    "abstract": "This is a time of great growth at the intersection of Software Engineering (SE) and scientific software, in academia, industry, and research labs. Software is developed and used in a wide variety of scientific domains including nuclear physics, computational chemistry, satellite data processing, fluid dynamics, climate modeling, bioinformatics, vehicle development, population modeling and social simulation, sensor networks, drug discovery, and digital humanities. Despite its importance, the development of scientific software historically has attracted less attention from the software engineering community than other subdomains have. The increase in the importance of this software motivates the need to identify and understand appropriate SE practices for its development. Because of the variety and complexity of the scientific domains addressed software, existing SE tools and techniques developed for the business/IT community are often not efficient or effective. Appropriate SE solutions must account for the salient characteristics of the research-oriented development environment. This situation creates a need for members of the SE community to interact with members of the scientific software community to address this need. This workshop facilitates that collaboration by bringing together members of the SE and scientific software communities to share perspectives and present findings relevant to research, practice, and education. A significant portion of the workshop is devoted to focused interaction among the participants with the goal of generating a research agenda to improve tools, techniques, and experimental methods regarding SE for science.",
    "id": "10.5555/3105494",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "publisher": "IEEE Press",
    "publisher-place": "Buenos Aires, Argentina",
    "title": "SE4Science ’17: Proceedings of the 12th international workshop on software engineering for science",
    "title-short": "SE4Science ’17",
    "type": "book"
  },
  {
    "ISBN": "0599608951",
    "abstract": "Educational medical information system development tools have emerged as one of the most important computer applications for health care providers. The research goal of this study of educational medical information system tools is to improve the performance of health care decision making by integrating professional medical care and computer information systems. Health care organizations are concerned with both quality products and cost-effective development processes. Our reference model approach allows us to apply software reuse technology to decrease development time in bringing new software products to the market. Software engineering processes may include the process of reusing common requirements. At the conceptual level a software reuse reference model is itself a domain independent reusable structure comprised of one or more generic, generalized activities that serve to represent a generic, generalized software engineering process. Our reuse reference model derived medical information system evaluation focused on education for headache patients. This particular medical information system was effectively and efficiently derived using a software reuse reference model to generate a domain model of common requirements in headache patient education. Then, from this general domain model, a specific migraine headache domain model was derived. This in turn showed how a full line of Patient Headache Care Education System (PHCES) products could be developed. The resulting domain model derived products should significantly improve the effectiveness and efficiency of the PHCES information systems by leveraging software development reuse. This dissertation has two major steps. The first step is to develop an effective patient care education system (PCES) for headaches. The second step is to expand the PHCES customer base by increasing efficiency in the process of developing effective PHCES with variations. Use of the software reuse reference model promises to: (1)&nbsp;increase software product quality, (2)&nbsp;decrease software production effort and time, (3)&nbsp;decrease time to bring products to market, and (4)&nbsp;reduce initial up front investment by the developer. The approach to our research had three parts: (1)&nbsp;a literature survey of the headache domain, the patient care education systems (PCES) and the domain software engineering concepts. (2)&nbsp;research and development of a reusable PCES domain model with expansion capabilities, using a software reuse reference model approach. (3)&nbsp;research and development of a prototype patient headache education information system derived from the domain model, demonstrating the reusability features of our PCES object framework in the reference model. Contributions from this research include: (i)&nbsp;Reference Model of PCESs, (ii)&nbsp;PCES domain model, (iii)&nbsp;Prototype derivation from the PCES domain model for different types of headaches with variations and, (iv)&nbsp;Validation of the prototype.",
    "author": [
      {
        "family": "Khatri",
        "given": "Anil"
      },
      {
        "family": "Rine",
        "given": "David"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/930480",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "note": "AAI9957629",
    "publisher": "George Mason University",
    "publisher-place": "USA",
    "title": "Validation of patient headache care education systems developed from a software reuse reference model",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/291712.295792",
    "ISSN": "1094-3641",
    "URL": "https://doi.org/10.1145/291712.295792",
    "abstract": "The idea that representing something visually can help us understand it has long been promoted in common practice and in the literature [1,2,3,4,5,6]. Indeed, \"a picture is worth a thousand words\" has become a standard cliché in our culture. In the case of software, however, one must take great care that it is the correct thousand words that are being conveyed [5]. Nonetheless, appropriate visualizations of software can be quite beneficial to programmers, especially when faced with program comprehension tasks. Such tasks exist throughout the software life cycle (e.g., formal technical reviews, debugging, verification, reverse engineering) and in the classroom (e.g., students reading examples from the text or examples from the professor).The GRASP (Graphical Representations of Algorithms, Structures, and Processes) research project at Auburn University seeks to develop tools and techniques for the effective use of graphical representations and visualizations of software. The overall goal of this research is to increase the efficiency of programmer comprehension and understanding of source code, and thereby decrease overall software cost. As an integral part of the research project, the GRASP software engineering tool has been developed as a continuously evolving prototype. The emphasis of the tool to this point has been on visualizing program structure and complexity via the automatic generation of Control Structure Diagrams (CSDs) and Complexity Profile Graphs (CPGs) from Ada source code [7]. The current release of GRASP provides generation of CSDs and CPGs together with other program comprehension aids such as syntax coloring, typographical enhancements, and source code folding [8]. When coupled with an appropriate compilation system such as GNAT, GRASP becomes an integrated graphical development environment for Ada 95, allowing users to edit, visualize, pretty-print, compile, link, execute and debug Ada software.The GRASP prototype for Ada was first made available to the public in January 1996. Since that time, thousands of copies of GRASP have been downloaded via anonymous file transfer protocol (FTP) and the World Wide Web (WWW) from educational, government, military and commercial sites, both in the United States and abroad. When it was released to the public, GRASP was also made available to users of the Auburn University College of Engineering computer network. GRASP is now used extensively throughout the computer science and engineering curriculum at Auburn University, in approximately three to five courses per quarter.",
    "author": [
      {
        "family": "Hendrix",
        "given": "T. Dean"
      },
      {
        "family": "Cross",
        "given": "James H."
      },
      {
        "family": "Teate",
        "given": "Joe C."
      },
      {
        "family": "Barowski",
        "given": "Larry A."
      },
      {
        "family": "Mathias",
        "given": "Karl S."
      }
    ],
    "container-title": "Ada Lett.",
    "id": "10.1145/291712.295792",
    "issue": "5",
    "issued": {
      "date-parts": [
        [
          1998,
          9
        ]
      ]
    },
    "page": "51-56",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Assessing GRASP utilization through instrumentation",
    "type": "article-journal",
    "volume": "XVIII"
  },
  {
    "ISBN": "076453601X",
    "abstract": "From the Publisher: Welcome to the only guidebook series that takes a visual approach to professional-level computer topics. Open the book and you’ll discover step-by-step screen shots that demonstrate over 100 key C# programming tasks, including: Employing class inheritance Including event-handling methods Authoring a component Working with strings Declaring abstract properties Adding Web forms and controls Adding multidimensional arrays Processing XML comments Creating workgroup-enabled applications Managing the integrated debugger Extra Apply It Apply It and Extra sidebars highlight useful tips High-resolution screen shots demonstrate each task Succinct explanations walk you through step by step Two-page lessons break big topics into bite-sized modules .NET development tools on CD-ROM! TextPad and Antechinus C# Editor shareware Trial versions of VMWare Workstation and MineC#sweeper Plus all sample code and an e-version of the book System requirements: PC running Windows 98 or later. See the What’s on the CD-ROM appendix for details and complete system requirements. Author Biography: Eric Butow has used Intel-compatible computers since 1984 and is currently training for his A+ certification in computer systems and an MCSE (Microsoft Certified Systems Engineer) in Windows NT 4.02000. Eric has used Windows NT since version 3.1 was introduced in 1994 through the current release candidate of Windows 2000. Eric is a technical editor for IDG Books, and has edited seven books covering Windows 98 and several Linux distributions. In real life, Eric is a contract technical writer. He was the Editor-in-Chief for Sacramento PC Users Group Newletter Sacra Blue for two years, and remains a contributing editor. Tommy Ryan has his MCT, MCSE, and MCP + Internet and is a technical project consultant. He has worked on projects for Ryder, the Salvation Army, Ceridian, Ernst &amp; Young, and Dow Chemical. Tommy is an author for ASPToday.com. He is also the co-author of C#: Your visual blueprint for building .NET applications.",
    "author": [
      {
        "family": "Butow",
        "given": "Eric"
      },
      {
        "family": "Ryan",
        "given": "Tommy"
      }
    ],
    "id": "10.5555/559355",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "C#: Your visual blueprint for building .net applications",
    "title-short": "C#",
    "type": "book"
  },
  {
    "DOI": "10.1145/3352740.3352755",
    "ISBN": "9781450372053",
    "URL": "https://doi.org/10.1145/3352740.3352755",
    "abstract": "In the age of Internet+, the integration of information technology and vocational English course teaching is bound to bring about the reformation of ESP teaching. On the basis of introducing the main idea of \"flipped classroom\" teaching model reform in tourism English course, this paper mainly discusses the development and application of online tourism English teaching platform including the designing goals, framework, modules, and database design of the platform. It has been found that the tourism English teaching platform designed in this paper can offer effective learning scaffolding to college students majoring in tourism and tourism practitioners, meeting their needs of learning and practicing at anytime and anywhere. At the same time, teachers can handle the learning progress and quality of students so as to realize the \"flipped classroom\" teaching model of tourism English course.Under the background of the development of digital technology, CG (Compute Graphics) digital painting is an artistic form of expression that closely combines painting art with digital technology. CG painting digitally transforms two-dimensional or three-dimensional graphics into digital graphics by means of mathematical algorithms. Painting works can be widely used in animation, film and television, games, visual communication design and other fields. The main purpose of the design and development of teaching system is to construct a teaching support system that can meet the requirements. This research takes Python as the development environment, adopts the four-tier software framework of object-oriented program design, including application-level knowledge point modeling, communication-level curriculum application management, resource-level management design, user-level UI design and other modules.The core issues to be solved include the establishment of teaching environment, the presentation and editing of knowledge point framework modeling, the establishment of pre-basic skills and learning objectives, and then the establishment of the teaching department. The application of the system has been tentatively studied. Finally, five indicators, including student experience, learning process satisfaction, teaching effect evaluation, teaching time-consuming comparison and teaching effect, are selected to verify the effectiveness of teaching supported by the experimental teaching system of CG digital painting course. The experimental results show the superiority of the experimental teaching system proposed in this paper.",
    "author": [
      {
        "family": "Duan",
        "given": "Wei"
      },
      {
        "family": "Chen",
        "given": "Haiyan"
      }
    ],
    "collection-title": "EBDIT 2019",
    "container-title": "Proceedings of the 2019 3rd international workshop on education, big data and information technology",
    "id": "10.1145/3352740.3352755",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "Tourism English, The development of online teaching platform, \"Flipped classroom\" teaching model",
    "page": "87-92",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Development and application of online tourism english teaching platform",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130092258",
    "abstract": "From the Book: Preface This IBM Redbook provides detailed information on how to develop Webapplications for IBM WebSphere Application Server Version 4 using a variety ofapplication development tools. The target audience for this book includes team leaders and developers who aresetting up a new J2EE development project using WebSphere Application Serverand related tools. It also includes developers with experience of earlier versionsof the WebSphere product, who are looking to migrate to the Version 4environment. This book is split into four parts, starting with an introduction, which is followed byparts presenting topics relating to the high-level development activities ofanalysis and design, code, and unit test. A common theme running through allparts of the book is the use of tooling and automation to improve productivity andstreamline the development process. In Part 1 we introduce the WebSphere programming model, the application development tools, and the example application we use in our discussions. In Part 2 we cover the analysis and design process, from requirements modeling through object modeling and code generation to the usage of frameworks. In Part 3 we cover coding and building an application using the Java 2 Software Development Kit, WebSphere Studio Version 4, and VisualAge for Java Version 4. We touch on Software Configuration Management using Rational ClearCase and provide coding guidelines for WebSphere applications. We also cover coding using frameworks, such as Jakarta Struts and WebSphere Business Components. In Part 4 we cover application testing from simple unit testing through application assemand deployment to debugging and tracing. We also investigate how unit testing can be automated using JUnit. In our examples we often refer to the PiggyBank application. This is a verysimple J2EE application we created to help illustrate the use of the tools,concepts and principles we describe throughout the book. The team that wrote this redbook This redbook was produced by a team of specialists from around the worldworking at the International Technical Support Organization, San Jose Center. Ueli Wahli is a Consultant IT Specialist at the IBM International TechnicalSupport Organization in San Jose, California. Before joining the ITSO 17 yearsago, Ueli worked in technical support at IBM Switzerland. He writes extensivelyand teaches IBM classes worldwide on application development, objecttechnology, VisualAge products, data dictionaries, and library management. Ueliholds a degree in Mathematics from the Swiss Federal Institute of Technology. Alex Matthews is a Consulting IT Specialist in the IBM Software Business,based in London, United Kingdom (UK). He has spent the last two and a halfyears providing post-sales services to customers who have purchasedWebSphere products and related tools. Alex has seven years experience buildingdistributed systems using a variety of middleware products. He holds a degree inComputing Science from Aston University, Birmingham, UK. Paula Coll Lapido works as an IT Specialist in the e-business Innovation Centerat Madrid, Spain. Her current area of expertise focuses on developing e-businessapplications using the WebSphere platform. She has been working at IBM forone year and a half. She holds a degree in Physics from the ComplutenseUniversity of Madrid. Jean-Pierre Norguet is an IT Specialist, Team Leader and Coach in the IBMe-business department in Belgium. He has been working at IBM for three years.His areas of expertise include the entire application development life cycle. Heholds a 5-year Engineering degree in Computer Science from the UniversiteLibre de Bruxelles and a Socrates European master’s degree from the EcoleCentrale Paris. Special notice This publication is intended to help application analysts and developers to createWeb applications for WebSphere Application Server using a variety of applicationdevelopment and test tools. The information in this publication is not intended asthe specification of any programming interfaces that are provided by WebSphereApplication Server. See the PUBLICATIONS section of the IBM ProgrammingAnnouncement for WebSphere Application Server for more information aboutwhat publications are considered to be product documentation. Comments welcome Your comments are important to us! We want our IBM Redbooks to be as helpful as possible. Send us yourcomments about this or other Redbooks in one of the following ways: Use the online Contact us review redbook form found at:ibm.com/redbooks Send your comments in an Internet note to:redbook@us.ibm.com Mail your comments to the address on page ii.",
    "author": [
      {
        "family": "Wahli",
        "given": "Ueli"
      },
      {
        "family": "Matthews",
        "given": "Alex"
      },
      {
        "family": "Lapido",
        "given": "Paula"
      },
      {
        "family": "Norguet",
        "given": "Jean-Pierre"
      }
    ],
    "id": "10.5555/560371",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Websphere version 4 application development handbook",
    "type": "book"
  },
  {
    "ISBN": "9781124445656",
    "abstract": "Resource constrained microcontrollers with as little as several hundred bytes of RAM and a few dozen megahertz of processing power are the most prevalent computing devices on earth. Microcontrollers and the many application components that interface to them, such as sensors, actuators, transceivers and displays are now cheap and readily available. Once costly development tools are now downloadable from the Internet and usable for free. Interest in application development using resource constrained microcontrollers has expanded beyond embedded system engineers to a broad audience of those that include artists, designers, students and product developers in all sectors of industry and fields of research. Developing application software for resource constrained systems is a complex process. The lack of microcontroller resources preclude the use of modern high-level programming languages and operating systems. Modern development practices that support uniform software development across hardware platforms are virtually nonexistent. Additionally, device manufacturers adhere to customer lock-in business practices making compatibility between vendor tools hard to come by and transitions between vendor technologies costly and time consuming. The focus of this dissertation is to support the development of software for resource constrained microcontroller-based systems by an audience with a broad range of technical skills. Our goal is to support uniform development for a diversity of application categories on heterogeneous hardware. Specifically, we design, implement and evaluate a new high-level programming language called Em with constructs and support for modularity, abstraction, software reuse, portability and reconfigurability for differing application requirements, hardware configurations, and quantities of runtime resources. For additional application development support we design, implement in Em, and evaluate a hardware abstraction layer and model for runtime concurrency.Our empirical results indicate that high-level language constructs can effectively be used in a resource constrained environment and achieve at least equivalent resource utilization compared to C and other related systems. We show through a demonstration and evaluation of real applications how we can support modern software development practices for authoring reusable, configurable, portable software for a diversity of hardware platforms. A hardware abstraction layer and a runtime model for concurrency provide additional support for development by, respectively, providing uniform interfaces to hardware functionality and relieving developers from individually implementing concurrency mechanisms. Finally, we conduct a user study with university students showing how non-embedded systems experts and people with generally less technical expertise can successfully learn and develop non-trivial applications with Em.",
    "author": [
      {
        "family": "Amar",
        "given": "Amichi"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/2049172",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "note": "AAI3439403",
    "publisher": "University of California at Santa Barbara",
    "publisher-place": "USA",
    "title": "Support for resource constrained microcontroller programming by a broad developer community",
    "type": "thesis"
  },
  {
    "DOI": "10.1109/HPCMP-UGC.2010.31",
    "ISBN": "9780769543925",
    "URL": "https://doi.org/10.1109/HPCMP-UGC.2010.31",
    "abstract": "The increasing computational requirements of today’s software systems have led researchers to investigate ways of accelerating military and scientific computing applications. Contemporary field programmable gate arrays (FPGAs) are now equipped with multimillion gate logic fabrics, faster clock rates, reasonably large on-chip memory, and fast I/O resources for off-chip communication. The use of FPGAs as reconfigurable computational units complementing a fixed computational device such as a general-purpose processor (GPP) is the basic idea behind what are known as high performance reconfigurable computers (HPRCs). These exciting architectures allow development of reconfigurable processors that target the computationally intensive parts of a given application. Ideally, one should use a high-level language (HLL) rather than a hardware description language (HDL) to implement HPRC-based applications. However, in order to accelerate some applications, an HDL must be used to design computational kernels. The HPRC used in the joint research project between the U.S. Army Engineer Research and Development Center DoD Supercomputing Resource Center (ERDC DSRC) and Jackson State University (JSU) employs the SRC Computers’ Carte development environment. Carte allows application development using a conventional HLL, an HLL-to-HDL compiler, and custom-built VHDL-based kernels (\"user macros\" in SRC parlance). Currently, the off-the-shelf Carte mechanism for incorporating user macros does not directly support the common case of a multiple file VHDL hierarchy. This research explores a novel approach that allows multiple file VHDL kernels to be mapped onto the SRC-7 HPRC. The approach facilitates the development of FPGA-based elements via a hybrid technique that uses the Carte HLL-to-HDL compiler in conjunction with multiple file VHDL-based user macros. This paper describes the use of this novel approach to map a parameterized, parallelized, and pipelined FPGA-based sparse matrix vector multiply kernel onto an SRC-7 HPRC. The HPRC-based version runs nearly four times faster than the software-only version.",
    "author": [
      {
        "family": "Morris",
        "given": "Gerald R."
      },
      {
        "family": "Abed",
        "given": "Khalid H."
      }
    ],
    "collection-title": "HPCMP-UGC ’10",
    "container-title": "Proceedings of the 2010 DoD high performance computing modernization program users group conference",
    "id": "10.1109/HPCMP-UGC.2010.31",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "sparse matrix, reconfigurable computer, VHDL, FPGA",
    "page": "524-533",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Mapping hierarchical multiple file VHDL kernels onto an SRC-7 high performance reconfigurable computer",
    "type": "paper-conference"
  },
  {
    "ISBN": "0672330210",
    "abstract": "Application Development with Microsoft Access 2007 Live Lessons Microsoft Access/Databases For Access power users, programmers, and anyone who wants to master Access 2007 development fast. In Application Development with Access 2007, renowned Access developer, trainer, and author Alison Balter teaches all the skills you need to build professional-quality Access 2007 applications. This package brings together more than twelve hours of personalized, expert video training: 100+ quick, practical video lessons that demonstrate all the skills you need to build virtually any Access application. Youll learn one step at a time, at your own paceusing hands-on examples that reflect realistic development challenges and showcase Access 2007s remarkable capabilities. Application Development with Access 2007 delivers the power of the best classroom training at a small fraction of the cost. If you dont have time to read a huge book on Access development, this is exactly what youve been searching for! Looking for a better way to master todays rapidly changing programming technologies? Want expert help, but dont have the time or energy to read a book? Cant find classroom training worth the money? Discover LiveLessons: self-paced, personal video instruction from the worlds leading technology experts. LiveLessons are video courses, on DVD with a book supplement, that are organized into bite-sized, self-contained sessionsyoull learn key skills in as little as fifteen minutes! Each lesson begins with well-defined learning objectives and ends with comprehensive summaries, which help you track your progress. Follow along as your instructor shows how to get results in todays top development environments: including Microsofts Visual Studio and eclipse.orgs Eclipse. We are reaching more and more for video alternatives because they make sense! The imprints of Pearson Technology Group are the most trusted source of quality technology books, and they will be the brands we turn to for visual learning. Leo J. Hauguel, Information Security Analyst 5 Wells Fargo Services Company Alison Balter, one of the worlds most experienced Access developers and trainers, has created Access applications ranging from small end-user projects to enterprise-wide systems. Her thirteen books on Access include Alison Balters Mastering Microsoft Office Access 2007 Development. System Requirements Operating System: Windows 98, 2000, XP, or Vista; Mac OS X; versions of Linux with the Flash 8 Player or later Multimedia: DVD drive, an 800x600 or higher display, and sound card with speakers Computer: 500MHz or higher, 128MB RAM or more $69.99 U.S. /$76.99 CANADA / 44.99 Net UK",
    "author": [
      {
        "family": "Balter",
        "given": "Alison"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1524104",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "SAMS",
    "publisher-place": "USA",
    "title": "Application development with microsoft access 2007",
    "type": "book"
  },
  {
    "ISBN": "9780549322313",
    "abstract": "Interactive software systems have both functional and user interface components. User interface design and development requires specialized usability engineering (UE) knowledge, training, and experience in topics such as psychology, cognition, specialized design guidelines, and task analysis. The design and development of a functional core requires specialized software engineering (SE) knowledge, training, and experience in topics such as algorithms, data structures, software architectures, calling structures, and database management. Given that the user interface and the functional core are two closely coupled components of an interactive software system, with each constraining the design of the other, there is a need for the SE and UE life cycles to be connected to support communication among roles between the two development life cycles. Additionally, there is a corresponding need for appropriate computer science curricula to train the SE and UE roles about the connections between the two processes.In this dissertation, we connected the SE and UE life cycles by creating the Ripple project development environment which fosters communication between the SE and UE roles and by creating a graduate-level cross-pollinated SE-UE joint course offering, with student teams spanning the two classes, to educate students about the intricacies of interactive-software development. Using this joint course we simulated different conditions of interactive-software development (i.e. with different types of project constraints and role playing) and assigned different teams to these conditions. As part of semester-long class projects these teams developed prototype systems for a real client using their assigned development condition. Two of the total of eight teams in this study used the Ripple framework.As part of this experimental course offering, various instruments were employed throughout the semester to assess the effectiveness of a framework like Ripple and to investigate candidate factors that impact the quality of product and process of interactive-software systems. The study highlighted the importance of communication among the SE and UE roles and exemplified the need for the two roles to respect each other and to have the willingness to work with one another. Also, there appears to exist an inherent conflict of interest when the same people play both UE and SE roles as they seem to choose user interface features that are easy to implement and not necessarily easy to use by system’s target users. Regarding pedagogy, students in this study indicated that this joint SE-UE course was more useful in learning about interactive-software development and that it provided a better learning experience than traditional SE-only or UE-only courses.",
    "author": [
      {
        "family": "Pyla",
        "given": "Pardha S."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1368745",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "note": "AAI3288673",
    "publisher": "Virginia Polytechnic Institute &amp; State University",
    "publisher-place": "USA",
    "title": "Connecting the usability and software engineering life cycles through a communication-fostering software development framework and cross-pollinated computer science courses",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/1509239.1509241",
    "ISBN": "9781605584423",
    "URL": "https://doi.org/10.1145/1509239.1509241",
    "abstract": "Modern software projects are of large scale, often involving years of development, tens of thousands of days of work effort, and millions of lines of code. This complexity is aggravated by the fact that development is often distributed over several geographic locations, as dictated by cost considerations, the availability of domain specialists, legal requirements, and other factors. Despite advances in development tools and techniques, software initiatives have lagged behind in utilizing novel software engineering methods and techniques effectively to reduce the complexity of large-scale software. The results can be seen in Corporate and Government IT budgets - based on Accenture and Industry research, IT cost overruns are still commonplace, and the cost to \"keep the lights on\" for fragile legacy applications typically consumes up to 60",
    "author": [
      {
        "family": "Daugherty",
        "given": "Paul R."
      }
    ],
    "collection-title": "AOSD ’09",
    "container-title": "Proceedings of the 8th ACM international conference on aspect-oriented software development",
    "id": "10.1145/1509239.1509241",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "soa, aop",
    "page": "1-2",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The future of software architectures for large-scalebusiness solutions: Modularity, scalability, andseparation of concerns",
    "title-short": "The future of software architectures for large-scalebusiness solutions",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130204315",
    "author": [
      {
        "family": "Baker",
        "given": "Art"
      },
      {
        "family": "Lozano",
        "given": "Jerry"
      }
    ],
    "edition": "Second",
    "id": "10.5555/1405668",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "Prentice Hall Press",
    "publisher-place": "USA",
    "title": "Windows® 2000 device driver book: A guide for programmers, second edition, the",
    "title-short": "Windows® 2000 device driver book",
    "type": "book"
  },
  {
    "ISBN": "0131448528",
    "abstract": "“A good book for people who deal with SAP systems for a living. I haven’t read another book like this. It’s technical but it’s also an entertaining read. A pleasant departure from the norm.” -David C. Gilliland, Senior Consultant, SAP America, Inc. “Clearly, this book could be used as an excellent development tool and could help a company like mine perfect performance tuning steps and standards.” -Dennis Prince, SAP Development/Support Specialist, Hewlett-Packard “SAP optimization is one of those subjects that developers struggle to find time for and managers don’t know is necessary. Presenting the value of the process up front serves to give the developer ammunition to win time for optimization and the manager an education in the value and necessity of optimization. Even if the manager types don’t read past chapter 3, George’s job is done. They should be convinced that someone technical in their IT department needs to be reading this book. Anderson explains the value, then the core technology, and then when we’re all on the same page, the process. To me, that was very helpful.” -Crew Reynolds, Software Development Manager, Daydots “This book features good discussion on performance tuning the mySAP suite that no other books have so far. This is the perfect book for SAP Stress Test Project Managers, SAP Stress Test Project Teams, SAP Basis Administrators, Oracle DBAs, Unix Administrators managing SAP systems, and project implementation teams. Those who stress test their systems well with the help of this book will have significant returns.” -Sanjoy Rath, SAP ConsultantDrive maximum performance and value from your SAP investment!In this book, a leading expert on SAP performance walks through every facet of tuning and optimizing mySAP Solutions, and the technology layers underpinning these solutions, to maximize performance and value. George W. Anderson covers the entire testing and tuning process: planning, staffing, developing, testing, executing, validating, evaluating...and acting on what you’ve learned.Anderson offers unparalleled guidance with regard to predicting the impact of system changes-from new hardware to updated NetWeaver-enabled business processes. Along the way, he shows how to make the most of countless optimization and monitoring tools-from free and low-cost technology stack-based utilities to comprehensive, automated SAP testing suites. His vendor-neutral, unbiased coverage includes: Quantifying concrete performance requirements-even for complex, cross-application business processes Testing and monitoring daily system loads, month-end or seasonal business peaks, key transactions, and complex multi-system business processes Conducting comprehensive server, SAN/disk subsystem, and database testing Managing the testing process, leveraging proven best practices and techniques Analyzing, verifying, and quantifying SAP availability, scalability, and TCORegardless of the technology infrastructure underpinning your SAP solutions, if you’re responsible for deploying, managing, maintaining, refreshing, upgrading, or supporting SAP technologies, you need this book-now.",
    "author": [
      {
        "family": "Anderson",
        "given": "George W."
      }
    ],
    "id": "10.5555/993932",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "mySAP tool bag for performance tuning and stress testing",
    "type": "book"
  },
  {
    "abstract": "Welcome to CASCON ’93 – Working Together. The theme of this year’s conference is very appropriate, especially given today’s business and economic environment. As an increasing number of businesses and organizations are faced with tough cost-cutting decisions, it is more important than ever to look for ways to utilize our resources more effectively – leveraging our skills, knowledge and expertise by working together.The IBM Centre for Advanced Studies (CAS)is based on this strategy, successfully bringing together research experts from around the world – more than 200 to date – to collectively focus on key issues facing the software industry today ... and into the future.CASCON ’93 is a demonstration of this strategy in action – visible in the nearly 70 technology demos and the numerous research presentations and workshops you will have a chance to participate in throughout the conference.CASCON ’93 – Working Together marks three years of cooperative research activities between the Toronto Lab’s Centre for Advance Studies and researchers from leading Canadian, U. S. and European universities. I am proud to say that CAS has lived up to its expectations, taking on a leadership role in the software industry – building an extensive network of international experts applying their knowledge and experience to key issues facing the industry today.To date, three projects have moved from CAS back into our product development area, eight joint patents have been filed and resultant products are expected to be delivered to the marketplace in the near future.Throughout the next few days, you will hear from a number of our research partners and you will have the opportunity to view the nearly 70 technology demos that represent the results of their collective efforts. I urge you to spend time viewing the demos, talking to the experts and attending as many of the presentations as you can. I would also encourage you to participate in the technology workshops that have been scheduled for Wednesday and Thursday at the Radisson Hotel. This is your opportunity to discuss, in an open forum, key issues and challenges facing the information technology industry.I would also like to welcome the National Research Council of Canada as the co-sponsor of this year’s conference. By working together we were able to expand the scope of CASCON ’93 to include the participation of leading Canadian and U. S. software organizations. Their technologies are also represented in a number of the demos here today.Welcome to CASCON ’93 ! This conference, our third, is co-sponsored with NRC and emphasizes \"Working Together, \" successfully bridging the gap between the software industry and the research community.In response to the Call for Papers, we received about 126 research papers. The program committee members considered all the papers carefully and each paper was reviewed by at least three reviewers. The review criteria were: technical quality, originality, clarity of presentation, and relevance to CASCON.Our program at the Ontario Science Centre is by design a one-track program where all participants can hear from the many distinguished speakers about their views on the software industry. The main component of the technical program for these two days is the presentation of 17 carefully selected contributed papers of high quality.The main component of Days Four and Five are 16 workshops on selected topics in Quality Engineering, Testing, Broadband Services, Software Integration, Challenges in Deploying Distributed Systems, Parallel Databases, Languages and Compiler Issues for Distributed Memory Machines, New Business Opportunities, Transfer of Technology, Software Evolution, C++ Compiler-Based Development Environments, Software Architecture, Data Integration and Multidatabase Systems, Commercializing Software, Documentation and Interfaces, and Software Development Processes.",
    "id": "10.5555/962367",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "publisher": "IBM Press",
    "publisher-place": "Toronto, Ontario, Canada",
    "title": "CASCON ’93: Proceedings of the 1993 conference of the centre for advanced studies on collaborative research: Distributed computing - volume 2",
    "title-short": "CASCON ’93",
    "type": "book"
  },
  {
    "abstract": "Welcome to CASCON ’93 – Working Together. The theme of this year’s conference is very appropriate, especially given today’s business and economic environment. As an increasing number of businesses and organizations are faced with tough cost-cutting decisions, it is more important than ever to look for ways to utilize our resources more effectively – leveraging our skills, knowledge and expertise by working together.The IBM Centre for Advanced Studies (CAS)is based on this strategy, successfully bringing together research experts from around the world – more than 200 to date – to collectively focus on key issues facing the software industry today ... and into the future.CASCON ’93 is a demonstration of this strategy in action – visible in the nearly 70 technology demos and the numerous research presentations and workshops you will have a chance to participate in throughout the conference.CASCON ’93 – Working Together marks three years of cooperative research activities between the Toronto Lab’s Centre for Advance Studies and researchers from leading Canadian, U. S. and European universities. I am proud to say that CAS has lived up to its expectations, taking on a leadership role in the software industry – building an extensive network of international experts applying their knowledge and experience to key issues facing the industry today.To date, three projects have moved from CAS back into our product development area, eight joint patents have been filed and resultant products are expected to be delivered to the marketplace in the near future.Throughout the next few days, you will hear from a number of our research partners and you will have the opportunity to view the nearly 70 technology demos that represent the results of their collective efforts. I urge you to spend time viewing the demos, talking to the experts and attending as many of the presentations as you can. I would also encourage you to participate in the technology workshops that have been scheduled for Wednesday and Thursday at the Radisson Hotel. This is your opportunity to discuss, in an open forum, key issues and challenges facing the information technology industry.I would also like to welcome the National Research Council of Canada as the co-sponsor of this year’s conference. By working together we were able to expand the scope of CASCON ’93 to include the participation of leading Canadian and U. S. software organizations. Their technologies are also represented in a number of the demos here today.Welcome to CASCON ’93 ! This conference, our third, is co-sponsored with NRC and emphasizes \"Working Together, \" successfully bridging the gap between the software industry and the research community.In response to the Call for Papers, we received about 126 research papers. The program committee members considered all the papers carefully and each paper was reviewed by at least three reviewers. The review criteria were: technical quality, originality, clarity of presentation, and relevance to CASCON.Our program at the Ontario Science Centre is by design a one-track program where all participants can hear from the many distinguished speakers about their views on the software industry. The main component of the technical program for these two days is the presentation of 17 carefully selected contributed papers of high quality.The main component of Days Four and Five are 16 workshops on selected topics in Quality Engineering, Testing, Broadband Services, Software Integration, Challenges in Deploying Distributed Systems, Parallel Databases, Languages and Compiler Issues for Distributed Memory Machines, New Business Opportunities, Transfer of Technology, Software Evolution, C++ Compiler-Based Development Environments, Software Architecture, Data Integration and Multidatabase Systems, Commercializing Software, Documentation and Interfaces, and Software Development Processes.",
    "id": "10.5555/962289",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "publisher": "IBM Press",
    "publisher-place": "Toronto, Ontario, Canada",
    "title": "CASCON ’93: Proceedings of the 1993 conference of the centre for advanced studies on collaborative research: Software engineering - volume 1",
    "title-short": "CASCON ’93",
    "type": "book"
  },
  {
    "DOI": "10.1145/322917.322980",
    "ISBN": "0897912187",
    "URL": "https://doi.org/10.1145/322917.322980",
    "abstract": "In this paper we present a prototype expert system characterized by two major premises: there are multiple sources of knowledge within the knowledge base;human factors considerations must receive paramount attention.The domain of the prototype is AirLand combat planning. (Airland combat is a new Army warfare doctrine developed in the early 1980’s. Its emphases include active defense, interdiction of the second echelon, early counterattack, and other tactical principles.) The potential users are Army division commanders and staff who are engaged in or are training for combat in Central Europe.Our prototype’s knowledge sources are representative of those encountered in a wider class of applications, through its use of sources which may be incomplete, ambiguous and conflicting, such as: doctrinal knowledge found in policy statements, Army regulations, and professional manuals (FM 100-5). Doctrine can be viewed as a constraint on tactics, combat organization, fire and maneuver schemes, and command and control systems;knowledge from an expert from the domain environment (provided by the historian, Colonel Trevor N. Dupuy);distilled wisdom gleaned from the historical writings of great military thinkers, theorists, and commanders. The first sources to be included are the Maxims of Napoleon and material from von Clausewitz;previous experience with analysis of outcome of appropriate historical cases;results from a computer simulation (operations research) model, the Quantified Judgment Model (QJM). The QJM takes information about a combat situation and generates a prediction (based on many variables) of the victor. It also predicts advance rates, casualty rates, equipment loss and recovery rates, plus many other factors.[1] It is being used as a preprocessor for the expert system.Another important feature concerns the status of each of the knowledge components, i.e., whether the overall system is best envisioned as a collection of more or less autonomous expert systems governed by a controlling expert system, or whether the knowledge collection can be organized in some principled way to allow the multiple sources to be handled within a more homogeneous setting, the limit being a single expert system with accessibility to a (relational) database and other resources, especially simulation results. (A simulation capability is considered by some researchers [2,3] to be an important part of an expert system designed to provide task planning.) Consideration is being given to the implementation of the simulation portion on a parallel processing machine, specifically the Sequent 21000.Important human factors exist for many kinds of expert systems and, especially so, for the application study of the paper. [4] Included among these factors are: mode of the system, defining the attitude of the system with regard to the user, e.g., consultation, critique, advisory, alert, advocacy; [5]conversational style;architecture of the system and its relation to user stress;causal assessment and support of good human decision making in expert systems;avoidance of consequence buffering or transfer of responsibility from the user to the expert system.Constrained for a number of reasons to a microcomputer environment for the expert system portion of the prototype, we have chosen to utilize the Texas Instruments Personal Consultant Plus development tool to achieve such goals as: rapid development time, ease of explanation generation, availability of both forward- and backward-chaining control mechanisms, built-in functions for online help and other explanatory features, convenient knowledge base segmentation through use of frames, consistent user interface between development and user environments.",
    "author": [
      {
        "family": "Halkias",
        "given": "Gail F."
      },
      {
        "family": "Reilly",
        "given": "Kevin D."
      }
    ],
    "collection-title": "CSC ’87",
    "container-title": "Proceedings of the 15th annual conference on computer science",
    "id": "10.1145/322917.322980",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "page": "356",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Human factors considerations in the design of a multiple source expert system for military applications (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3544548.3580683",
    "ISBN": "9781450394215",
    "URL": "https://doi.org/10.1145/3544548.3580683",
    "abstract": "Creative coding is a rapidly expanding domain for both artistic expression and computational education. Numerous libraries and IDEs support creative coding, however there has been little consideration of how the environments themselves might be designed to serve these twin goals. To investigate this gap, we implemented and used an experimental editor to teach a sequence of college and high-school creative coding courses. In the first year, we conducted a log analysis of student work (n=39) and surveys regarding prospective features (n=25). These guided our implementation of common enhancements (e.g. color pickers) as well as uncommon ones (e.g. bidirectional shape editing). In the second year, we studied the effects of these features through logging (n=39+) and survey (n=23) studies. Reflecting on the results, we identify opportunities to improve creativity- and novice-focused IDEs and highlight tensions in their design—as in tools that augment artistry or efficiency but may be perceived as hindering learning.",
    "author": [
      {
        "family": "Mcnutt",
        "given": "Andrew M"
      },
      {
        "family": "Outkine",
        "given": "Anton"
      },
      {
        "family": "Chugh",
        "given": "Ravi"
      }
    ],
    "collection-title": "CHI ’23",
    "container-title": "Proceedings of the 2023 CHI conference on human factors in computing systems",
    "id": "10.1145/3544548.3580683",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "Code editors, Creative coding, Introductory programming, p5",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A study of editor features in a creative coding classroom",
    "type": "paper-conference"
  },
  {
    "ISBN": "9781267380456",
    "abstract": "Internet-based distance education (IDE) continues to grow in popularity and ubiquity. Acceptance of IDE among Christian higher education institutions has also increased. However, these institutions seek assistance. Such was the case with the nineteen institutions endorsed by the Assemblies of God (AG). The AG’s oversight organization (The Alliance for Assemblies of God Higher Education, Alliance) was asked by member institutions for IDE aid, resources, and direction. To understand the current environment of IDE within AG higher education, an organizational discovery case study reviewed the historical IDE trends within AG higher education, surveyed institutional faculty members and administrators as to their IDE beliefs and situations, and analyzed the data collected. From the research findings, the Alliance gained a better understanding of the needs and intentions of its member institutions. It also realized the aid and resources to offer its endorsed institutions, what endorsement requirements were needed for spiritual development in an online distance education setting, and an overall IDE direction that the organization could provide or facilitate. To aid the organizational discovery, a research framework was created that the Alliance could reuse and share with similar organizations for their own internal discovery.",
    "author": [
      {
        "family": "Harris",
        "given": "Jeremy W."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/2519614",
    "issued": {
      "date-parts": [
        [
          2012
        ]
      ]
    },
    "note": "AAI3510437",
    "publisher": "Nova Southeastern University",
    "title": "Towards an internet-based distance education (ide) framework for religious-based higher education organizations: A case of the alliance for assemblies of god higher education",
    "title-short": "Towards an internet-based distance education (ide) framework for religious-based higher education organizations",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3279720.3279731",
    "ISBN": "9781450365352",
    "URL": "https://doi.org/10.1145/3279720.3279731",
    "abstract": "It has long been a goal of educators to accurately identify at-risk students early enough in the term to intervene, and the increasing availability of programming process data and learning analytics tools has brought education researchers closer to realizing that objective. The Normalized Programming State Model (NPSM), for example, a recent approach that considers students’ editing and testing behaviors in addition to compilations, has been shown to predict a student’s overall course grade with 36-67",
    "author": [
      {
        "family": "Richards",
        "given": "Brad"
      },
      {
        "family": "Hunt",
        "given": "Ayse"
      }
    ],
    "collection-title": "Koli calling ’18",
    "container-title": "Proceedings of the 18th koli calling international conference on computing education research",
    "id": "10.1145/3279720.3279731",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "Predictive measures of student performance and achievement, Normalized Programming State Model, Learning analytics, Educational data mining, BlueJ, Blackbox",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Investigating the applicability of the normalized programming state model to BlueJ programmers",
    "type": "paper-conference"
  },
  {
    "ISBN": "0131844741",
    "abstract": "From the Book: PREFACE: In case you havent guessed, this book explains how to write, install, and debug kernel-mode device drivers for Windows NT. If youre in the process of designing or coding an NT driver, or if youre porting an existing driver from some other operating system, this book is a valuable companion to the Microsoft DDK documentation. This book might also have something to say to you if you just need a little more insight into the workings of Windows NT, particularly the IO subsystem. Perhaps youre trying to decide if NT is a reasonable platform for some specific purpose. Or you may be studying operating systems, and you want to see how theory gets applied in the real world. And of course, we mustnt discount the power of morbid curiosity. The same fascination that forces us to slow down as we drive past a car accident can also motivate us to pull a volume off the bookstore shelf. What You Should Already Know Throughout this book, I make several assumptions about what you already know. First of all, you need to have all the basic Windows NT user skills such as logging in and running various utilities. Since driver installation requires you to have administrator-level privileges, you can trash things pretty badly if you dont know how to use the system. Second, youll need decent C-language programming skills. Ive tried to avoid the use of “cleverness” in my code examples, but you still have to be able to read them. Next, some experience with Win32 user-mode programming is helpful, but it isnt really required. If you havent worked with the Win32 API, you might want to browse throughvolumetwo of the Win32 Programmers Reference. This is the one that describes system services. Take a look at the chapters on the IO primitives (CreateFile, ReadFile, WriteFile, and DeviceIoControl) and the thread-model. See the bibliography for other books on Win32 programming. Finally, you need to understand something about hardware in order to write drivers. It would be helpful if you already had some experience working with hardware, but if not, Chapter 2 will give you a basic introduction. Again, the bibliography will point you toward other, more-detailed sources for this kind of information. What Youll Find Here One of the most difficult choices any author has to make is deciding what to write about and what to leave out. In general, Ive attempted to focus on core issues that are crucial to kernel-mode driver development. Ive also tried to provide enough background information so that youll be able to read the sample code supplied with the NT DDK, and make intelligent design choices for your own drivers. The overall flow of the book goes from the theoretical to the practical, with earlier chapters providing the underpinnings for later topics. Heres whats covered: Chapters 1-5: The first part of this book provides the basic foundation youll need if you plan to write drivers. This includes a general examination of the Windows NT driver architecture, a little bit about hardware, and a rather detailed look at the NT IO Manager and its data structures. This group of topics ends with some general kernel-mode coding guidelines and techniques. Chapters 6-13: These eight chapters form the nucleus of the book and present all the details of writing kernel-mode NT device drivers. Youll also find discussions here of full-duplex driver architectures, handling timeout conditions, and logging device errors. Unless youre already familiar with NTs driver architecture, you should probably read these chapters in order. Chapters 14 and 15: The next two chapters deal with alternative driver architectures supported by Windows NT. This includes the use of kernel-mode threads in drivers and higher-level drivers. Chapters 16-18: The final part of the book deals with various practical details of writing NT drivers. Chapter 16 takes a look at all the things your mother never told you about the BUILD utility. Chapter 17 covers various aspects of testing and debugging drivers, including how to analyze crash dumps and how to really get WINDBG to work. If youre actually writing a driver while you read this book, you may want to read these chapters out of order. Chapter 18 examines the crucial issue of driver performance and how to tie your driver into NTs performance monitoring mechanisms. Appendices: The appendices cover various topics that people in my classes have asked about. The first one deals with the mechanics of setting up a driver development environment. The second appendix contains a list of the bugcheck codes youre most likely to encounter, along with descriptions of their various parameters. Used in conjunction with the material in Chapter 17, this may help you track down the cause of a blue screen or two. What You Wont Find I excluded topics from this book for several reasons. Some subjects were just too large to cover. Others addressed the needs of too small a segment of the driver-writing community. Finally, some areas of driver-development are simply unsupported by Microsoft. Specifically, you wont find anything here about the following items: File system drivers: At the time this book went to press, Microsoft still hadnt released any kind of developers kit for NT file system drivers. In fact, there seemed to be a great deal of resistance to the idea within Microsoft. Until this situation changes, theres not much point in talking about the architecture of file system drivers. Net-card and network protocol drivers: NDIS and TDI drivers are both very large topics—large enough to fill a book of their own. Unfortunately, there just wasnt enough room for all of it here. I can offer one bit of consolation: The material in this book will give you much of the background you need in order to understand whats happening inside the NDISTDI framework. SCSI miniport and class drivers: Although SCSI HBA miniport drivers are vital system components, the number of people actually writing them is (I suspect) rather small. Consequently, the only reference to SCSI miniports is the overview material in Chapter 1. I would have liked to include a discussion of SCSI class drivers in this book, but unfortunately there just wasnt any time to write it. The material on developing intermediate drivers in Chapter 15 will give you much of the necessary background. Fro m there, take a look at the sample SCSI class driver for CD-ROMs that comes with the NT DDK. Video, display, and printer drivers: This is another area where I had to make a tradeoff between the number of people writing these kinds of drivers and the time available to finish the book. Unfortunately, graphics drivers for video and hardcopy de vices didnt make the cut this time. Perhaps in a later, expanded version of the book. Virtual DOS device drivers: In my opinion, the best way to run 16-bit MS-DOS and Windows applications under Windows NT is to port the source code to Win32. In any event, the Microsoft documentation does a decent job describing the mechanics of writing VDDs so I havent included anything about them here. About the Sample Code Theres a great deal of sample driver code scattered throughout this book. Youll find all of it on the accompanying floppy disk. Ive created separate directories on the floppy for each chapter, and where appropriate, subdirectories for each component or driver in the chapter. Coding style: Since the purpose of this book is instruction, Ive done a couple things to improve the clarity of the samples. First, Ive adopted a coding style that avoids smart tricks. Some of the examples could probably have been written in fewer lines of code, but I dont think they would have been as easy to understand. Also in the name of clarity, Ive eliminated everything except the bare essentials from each sample. For example, most of the drivers dont contain any error-logging or debugging code, although a real driver ought to include these things. These topics have their own chapters, and you shouldnt have too much trouble back-fitting the code into other sample drivers. Naming conventions: Youll notice that almost all the sample drivers appearing in this book are called “XXDRIVER.” (The only exception is the higher-level driver Chapter 15. Its name is “YYDRIVER.”) This makes it somewhat easier to interchange the parts of different samples. It also reduces the amount of clutter that youll be adding to the Registry while youre playing with these drivers. Within any particular driver, Ive also adopted the convention of adding the prefix, Xx to the names of any driver-defined functions. Similarly, device registers, driver structures, and constants are also prefixed with XX_. This makes it easy to see which things you have to write and which ones come from the folks at Microsoft. Platform dependencies: Its worth mentioning that these samples have been targeted to run on Intel 80x86 platforms. In particular, the drivers all assume that device registers live in IO space rather than being memory-mapped. This is relatively easy to fix with a little bit of coding and some modifications to each drivers hardware-specific header file. To build and run the examples: Youll need several tools if you plan to do any driver development for Windows NT. First, get yourself a Level II subscription to the Microsoft Developer Network CDs. This is the only source for the NT DDK and the Win3 2 SDK. Youll also need a C compiler. Ive chosen to use the Microsoft compiler for developing and testing all the code in this book. Your mileage may vary if youre using some other vendors tools. See Appendix A for more information on setting up your driver development environment. Training and Consulting Services The material in this book is based on classes that Ive been delivering for several years through Cydonix Corporation—a training and consulting firm whose goal is to help its clients develop device drivers and other high-performance Windows NT soft ware. Cydonix offers services that range from formal classroom training to direct participation in software design and coding. For the past three years, Cydonix has been helping companies like Adaptec, AT&amp;T, Compaq Computers, Hewlett-Packard, and Intel to learn more about the workings of Windows NT. We have training available in a number of areas including: Windows NT device driver programming Win32 system service programming Advanced server development techniques Cydonix offers both onsite training at customer facilities and open enrollment classes that are available to the general public. The public classes are hosted by training vendors in several geographic areas. For more information about training and consulting from Cydonix Corporation, visit our Web site at ...",
    "author": [
      {
        "family": "Baker",
        "given": "Art"
      }
    ],
    "edition": "2nd",
    "id": "10.5555/524209",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Windows NT device driver book: A guide for programmers, with disk with cdrom",
    "title-short": "Windows NT device driver book",
    "type": "book"
  },
  {
    "DOI": "10.1145/2984043.2998388",
    "ISBN": "9781450344371",
    "URL": "https://doi.org/10.1145/2984043.2998388",
    "abstract": "Abstraction and modularity underlie all successful hardware and software systems: We build complex artifacts by decomposing them into parts that can be understood separately. Modular decomposition depends crucially on the artful choice of interfaces between pieces. As these interfaces become more expressive, we think of them as specifications of components or layers. Rich specifications based on formal logic are little used in industry today, but a practical platform for working with them could signicantly reduce the costs of system implementation and evolution by identifying vulnerabilities, helping programmers understand the behavior of new components, facilitating rigorous change-impact analysis, and supporting maintainable machine-checked verication that components are correct and fit together correctly. Recently, research in the area has begun to focus on a particularly rich class of specifications, which might be called deep specifications. Deep specifications are rich (describing complex component behaviors in detail); two-sided (connected to both implementations and clients); formal (written in a mathematical notation with clear semantics to support tools such as type checkers, analysis and testing tools, automated or machine-assisted provers, and advanced IDEs); and live (connected directly to the source code of implementations via machine-checkable proofs or property-based random testing). These requirements impose strong functional correctness conditions on individual components and permit them to be connected together with rigorous composition theorems. This talk presents the key features of deep specifications, surveys recent achievements and ongoing efforts in the research community (in particular, work at Penn, Princeton, Yale, and MIT on formalizing a rich interconnected collection of deep specifications for critical system software components), and argues that the time is ripe for an intensive effort in this area, involving both academia and industry and integrating research, education, and community building. The ultimate goal is to provide rigorously checked proofs about much larger artifacts than are feasible today, based on decomposition of proof effort across components with deep specifications.",
    "author": [
      {
        "family": "Pierce",
        "given": "Benjamin C."
      }
    ],
    "collection-title": "SPLASH companion 2016",
    "container-title": "Companion proceedings of the 2016 ACM SIGPLAN international conference on systems, programming, languages and applications: Software for humanity",
    "id": "10.1145/2984043.2998388",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "Verified Systems Software, Verified Software Toolchain, Vellvm, QuickChick, Property-Based Testing, Kami, Coq, CompCert, CertiKOS",
    "page": "1",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The science of deep specification (keynote)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICSIP.2014.36",
    "ISBN": "9780769551005",
    "URL": "https://doi.org/10.1109/ICSIP.2014.36",
    "abstract": "Since decades, real time hardware implementation of Text-To-Speech system has been drawing attention of the research community due to its various real time applications. These include reading aids for the blind, talking aid for the vocally handicapped and training aids and other commercial applications. All these applications demand the real time embedded platform to meet the real time specifications such as speed, power, space requirements etc. In this context the embedded processor ARM (Advanced RISC Machine), has been chosen as hardware platform to implement Text-To-Speech conversion. This conversion needs algorithms to perform various operations like parts of speech tagging, phrase marking, word to phoneme conversion and clustergen synthesis. These algorithms are coded and developed in C using eclipse IDE and finally implemented on commercially available ARM9 microcontroller (AT91SAM9263EJ-S). Experiments have been performed on ARM microcontroller using test cases. It has been observed that the performance of the ARM based implementation is very close to x86 implementation.",
    "author": [
      {
        "family": "Rawoof",
        "given": "Abdul"
      },
      {
        "family": "Kulesh"
      },
      {
        "family": "Ray",
        "given": "Kailash Chandra"
      }
    ],
    "collection-title": "ICSIP ’14",
    "container-title": "Proceedings of the 2014 fifth international conference on signal and image processing",
    "id": "10.1109/ICSIP.2014.36",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "Text-to-Speech, Real Time Embedded System, ARM processor",
    "page": "192-196",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "ARM based implementation of text-to-speech (TTS) for real time embedded system",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3180155.3182537",
    "ISBN": "9781450356381",
    "URL": "https://doi.org/10.1145/3180155.3182537",
    "abstract": "Studying developers’ behavior is crucial for designing effective techniques and tools to support developers’ daily work. However, there are two challenges in collecting and analyzing developers’ behavior data. First, instrumenting many software tools commonly used in real work settings (e.g., IDEs, web browsers) is difficult and requires significant resources. Second, the collected behavior data consist of low-level and fine-grained event sequences, which must be abstracted into high-level development activities for further analysis.In this paper [1], to address these two challenges, we first use our ActivitySpace framework to improve the generalizability of the data collection. Then, we propose a Condition Random Field (CRF) based approach to segment and label the developers’ low-level actions into a set of basic, yet meaningful development activities. To evaluate our proposed approach, we deploy the ActivitySpace framework in an industry partner’s company and collect the real working data from ten professional developers’ one-week work. We conduct an experiment with the collected data and a small number of initial human-labeled training data using the CRF model and the other three baselines (i.e., a heuristic-rules based method, a SVM classifier, and a random weighted classifier). The proposed CRF model achieves better performance (i.e., 0.728 accuracy and 0.672 macro-averaged F1-score) than the other three baselines.",
    "author": [
      {
        "family": "Bao",
        "given": "Lingfeng"
      },
      {
        "family": "Xing",
        "given": "Zhenchang"
      },
      {
        "family": "Xia",
        "given": "Xin"
      },
      {
        "family": "Lo",
        "given": "David"
      },
      {
        "family": "Hassan",
        "given": "Ahmed E."
      }
    ],
    "collection-title": "ICSE ’18",
    "container-title": "Proceedings of the 40th international conference on software engineering",
    "id": "10.1145/3180155.3182537",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "conditional random field, developers’ interaction data, software development",
    "page": "897",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Inference of development activities from interaction with uninstrumented applications",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICSE43902.2021.00145",
    "ISBN": "9781450390859",
    "URL": "https://doi.org/10.1109/ICSE43902.2021.00145",
    "abstract": "API recommendation in real-time is challenging for dynamic languages like Python. Many existing API recommendation techniques are highly effective, but they mainly support static languages. A few Python IDEs provide API recommendation functionalities based on type inference and training on a large corpus of Python libraries and third-party libraries. As such, they may fail to recommend or make poor recommendations when type information is missing or target APIs are project-specific. In this paper, we propose a novel approach, PyART, to recommending APIs for Python programs in real-time. It features a light-weight analysis to derive so-called optimistic data-flow, which is neither sound nor complete, but simulates the local data-flow information humans can derive. It extracts three kinds of features: data-flow, token similarity, and token co-occurrence, in the context of the program point where a recommendation is solicited. A predictive model is trained on these features using the Random Forest algorithm. Evaluation on 8 popular Python projects demonstrates that PyART can provide effective API recommendations. When historic commits can be leveraged, which is the target scenario of a state-of-the-art tool ARIREC, our average top-1 accuracy is over 50",
    "author": [
      {
        "family": "He",
        "given": "Xincheng"
      },
      {
        "family": "Xu",
        "given": "Lei"
      },
      {
        "family": "Zhang",
        "given": "Xiangyu"
      },
      {
        "family": "Hao",
        "given": "Rui"
      },
      {
        "family": "Feng",
        "given": "Yang"
      },
      {
        "family": "Xu",
        "given": "Baowen"
      }
    ],
    "collection-title": "ICSE ’21",
    "container-title": "Proceedings of the 43rd international conference on software engineering",
    "id": "10.1109/ICSE43902.2021.00145",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "real-time recommendation, data flow analysis, context analysis, Python, API recommendation",
    "page": "1634-1645",
    "publisher": "IEEE Press",
    "publisher-place": "Madrid, Spain",
    "title": "PyART: Python API recommendation in real-time",
    "title-short": "PyART",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s42979-022-01033-z",
    "URL": "https://doi.org/10.1007/s42979-022-01033-z",
    "abstract": "Due to the difficult educational condition caused by the COVID-19 pandemic, the design and development of mobile phone apps and technologies for teaching and learning are being more considered. Moreover, technology-based infrastructure for the use of distance education is developing rapidly. In this paper, an Android application called Triangular App (TriApp) was designed for teaching multiplication to preschool children. This application uses the Triple Multiplication method in which three numbers (including two numbers, and the product of multiplication of these two numbers) are considered as a group. By repeating and memorizing this group, if any of the numbers are not displayed, the child can guess the missed number. With TriApp, in addition to multiplication, children can also learn division. There is a test and competition section in which the child receives points by giving the correct answers, which increases the children’s desire to learn. To evaluate the effectiveness of the TriApp, two preschool children groups were examined in 10 days. The former learned multiplication using TriApp and the later learned it using the multiplication table (repeated additions). The results showed that during test, 100",
    "author": [
      {
        "family": "Kouhi",
        "given": "Mona"
      },
      {
        "family": "Rahmani",
        "given": "Mohsen"
      }
    ],
    "container-title": "SN Comput. Sci.",
    "id": "10.1007/s42979-022-01033-z",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2022,
          2
        ]
      ]
    },
    "keyword": "Multiplication, Distance education and online learning, Preschool education, Mobile learning, Mobile application",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Design and development of a mobile application for teaching triple multiplication to preschool children",
    "type": "article-journal",
    "volume": "3"
  }
]