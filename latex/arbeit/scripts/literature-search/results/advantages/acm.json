[
  {
    "DOI": "10.1145/3441852.3476553",
    "ISBN": "9781450383066",
    "URL": "https://doi.org/10.1145/3441852.3476553",
    "abstract": "Introduction of computational thinking training in early childhood potentiates cognitive development and better prepares children to live and prosper in a future heavily computational society. Programming environments are now widely adopted in classrooms to teach programming concepts. However, these tools are often reliant on visual interaction, making them inaccessible to children with visual impairments. Also, programming environments in general are usually designed to promote individual experiences, wasting the potential benefits of group collaborative activities. We propose the design of a programming environment that leverages asymmetric roles to foster collaborative computational thinking activities for children with visual impairments, in particular mixed-visual-ability classes. The multimodal system comprises the use of tangible blocks and auditory feedback, while children have to collaborate to program a robot. We conducted a remote online study, collecting valuable feedback on the limitations and opportunities for future work, aiming to potentiate education and social inclusion.",
    "author": [
      {
        "family": "Rocha",
        "given": "Filipa"
      },
      {
        "family": "Guimarães",
        "given": "Guilherme"
      },
      {
        "family": "Gonçalves",
        "given": "David"
      },
      {
        "family": "Pires",
        "given": "Ana Cristina"
      },
      {
        "family": "Abreu",
        "given": "Lúcia Verónica"
      },
      {
        "family": "Guerreiro",
        "given": "Tiago"
      }
    ],
    "collection-title": "ASSETS ’21",
    "container-title": "Proceedings of the 23rd international ACM SIGACCESS conference on computers and accessibility",
    "id": "10.1145/3441852.3476553",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "accessible, children, collaboration, robot, tangible, visually impaired",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Fostering collaboration with asymmetric roles in accessible programming environments for children with mixed-visual-abilities",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3568812.3603446",
    "ISBN": "9781450399753",
    "URL": "https://doi.org/10.1145/3568812.3603446",
    "abstract": "Pair programming is a common collaboration method used in primary and secondary computer science (CS) education. Despite its many benefits, pair programming has been found to create inequitable learning environments in these settings. In this proposal, I discuss my plan to investigate the equity and effectiveness of a new pair programming method for block-based programming environments, called Puzzle. When using this method, the blocks in the programming environment are partitioned between two students. I will use a mixed methods approach to analyze student attitudes, self-assessed behaviors, learning gains, and conversational dialog. I expect this new method to increase students’ enjoyment when learning to program and to increase student interest in CS.",
    "author": [
      {
        "family": "Gransbury",
        "given": "Isabella"
      }
    ],
    "collection-title": "ICER ’23",
    "container-title": "Proceedings of the 2023 ACM conference on international computing education research - volume 2",
    "id": "10.1145/3568812.3603446",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "page": "92-94",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A new way to pair program: The puzzle method",
    "title-short": "A new way to pair program",
    "type": "paper-conference"
  },
  {
    "ISBN": "9783540740230",
    "URL": "https://doi.org/10.1007/978-3-540-74024-7_12",
    "abstract": "Robot building projects are increasingly used in schools and universities to raise the interest of students in technical subjects. They can especially be used to teach the three mechatronics areas at the same time: mechanics, electronics, and software. However, it is hard to find reusable, robust, modular and cost-effective robot development kits in the market. Here, we present &lt;em&gt;qfix&lt;/em&gt;, a modular construction kit for edutainment robotics and mechatronics experiments which fulfills all of the above requirements and receives strong interest from schools and universities. The outstanding advantages of this kit family are the solid aluminium elements, the modular controller boards, and the programming tools which reach from an easy-to-use graphical programming environment to a powerful C++ library for the GNU compiler collection.",
    "author": [
      {
        "family": "Enderle",
        "given": "Stefan"
      }
    ],
    "container-title": "RoboCup 2006: Robot soccer world cup x",
    "id": "10.1007/978-3-540-74024-7_12",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "page": "134-145",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "The robotics and mechatronics kit \"qfix\"",
    "type": "chapter"
  },
  {
    "DOI": "10.1007/s10639-023-12024-9",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-023-12024-9",
    "abstract": "Microcontroller programming competencies contribute to the sustainable employability of engineering graduates of both higher and secondary education. To develop the required programming skills, one of the challenges for educators is to determine which programming environments should be implemented in introductory programming courses. Conceptually, graphical (e.g. iconic or diagrammatic) environments appear to be very different from textual environments. Our study focused on a programming course in a mechatronics vocational training programme at the secondary school level in Slovenia. To investigate the expectations of potential employers towards our graduates, we surveyed local companies. Out of 104 respondents, 90 (86.5",
    "author": [
      {
        "family": "Vrbančič",
        "given": "Franc"
      },
      {
        "family": "Kocijančič",
        "given": "Slavko"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-023-12024-9",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2023,
          7
        ]
      ]
    },
    "keyword": "Introductory programming, Secondary education, Textual vs graphical environment, Teaching/learning strategies, Improving classroom teaching",
    "page": "5115-5137",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Strategy for learning microcontroller programming—a graphical or a textual start?",
    "type": "article-journal",
    "volume": "29"
  },
  {
    "DOI": "10.1145/3328778.3366924",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3366924",
    "abstract": "Recent years have seen an increasing interest in identifying common student misconceptions during introductory programming. In a parallel development, block-based programming environments for novice programmers have grown in popularity, especially in introductory courses. While these environments eliminate many syntax-related errors faced by novice programmers, there has been limited work that investigates the types of misconceptions students might exhibit in these environments. Developing a better understanding of these misconceptions will enable these programming environments and instructors to more effectively tailor feedback to students, such as prompts and hints, when they face challenges. In this paper, we present results from a cluster analysis of student programs from interactions with programming activities in a block-based programming environment for introductory computer science education. Using the interaction data from students’ programming activities, we identify three families of student misconceptions and discuss their implications for refinement of the activities as well as design of future activities. We then examine the value of block counts, block sequence counts, and system interaction counts as programming features for clustering block-based programs. These clusters can help researchers identify which students would benefit from feedback or interventions and what kind of feedback provides the most benefit to that particular student.",
    "author": [
      {
        "family": "Emerson",
        "given": "Andrew"
      },
      {
        "family": "Smith",
        "given": "Andy"
      },
      {
        "family": "Rodriguez",
        "given": "Fernando J."
      },
      {
        "family": "Wiebe",
        "given": "Eric N."
      },
      {
        "family": "Mott",
        "given": "Bradford W."
      },
      {
        "family": "Boyer",
        "given": "Kristy Elizabeth"
      },
      {
        "family": "Lester",
        "given": "James C."
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3366924",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "introductory programming education, cluster analysis, block-based programming",
    "page": "825-831",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Cluster-based analysis of novice coding misconceptions in block-based programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/978-3-642-02774-1_52",
    "ISBN": "9783642027734",
    "URL": "https://doi.org/10.1007/978-3-642-02774-1_52",
    "abstract": "This paper addresses the question how to optimally support projects of students and employees of a higher education institution of computer science by means of a special software environment. At first the motivation to introduce such a supportive system is examined by describing the current situation in the authors’ department of computer science, which is typical for many colleges and universities. On the one hand problems are pointed out, which hamper students and employees in their project work, on the other hand the additional possibilities of a supportive system, which far exceed the ones of a traditional approach, are drafted. The paper shows how a mutual value for students and employees can be generated from the projects by using social software. After the requirements are described we suggest an architecture for such a supportive system and finally the challenges for the implementation and application, which determine the success or failure of the system, are discussed.",
    "author": [
      {
        "family": "Kadenbach",
        "given": "Daniel"
      },
      {
        "family": "Kleiner",
        "given": "Carsten"
      }
    ],
    "collection-title": "OCSC ’09",
    "container-title": "Proceedings of the 3d international conference on online communities and social computing: Held as part of HCI international 2009",
    "id": "10.1007/978-3-642-02774-1_52",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "page": "479-487",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Benefits and challenges of using collaborative development environments with social software in higher computer science education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3631802.3631825",
    "ISBN": "9798400716539",
    "URL": "https://doi.org/10.1145/3631802.3631825",
    "abstract": "The block-based programming paradigm has gained popularity across various application areas, including programming education, physical computing, and creative arts and media. While initially targeting young learners, environments such as Scratch have demonstrated the versatility of this paradigm beyond its original audience. This paper explores the potential application of block-based code manipulation in the field of low-level programming, which is a fundamental component of many computer science curricula. However, existing visualization tools for teaching low-level computing do not leverage the benefits of block-based programming, such as eliminating the need to memorize syntax. This paper presents Blocksambler, a prototype of a block-based programming environment for teaching low-level computing. The purpose of this paper is two-fold, in the first theoretical part we explore the potential application of block-based code manipulation in the field of low-level programming, which is a fundamental component of many computer science curricula. In the second part, we introduce Blocksambler, a prototype of a block-based programming environment for teaching low-level computing. Blocksambler is built upon Blockly, a JavaScript library designed for creating customized block-based programming tools and for the purpose of teaching low-level computing. Reflecting the relevance, benefits, and limitations of Blocksambler for educational purposes, we conclude the discussion started in the first part of the paper and outline further steps.",
    "author": [
      {
        "family": "Wörister",
        "given": "Florian"
      },
      {
        "family": "Knobelsdorf",
        "given": "Maria"
      }
    ],
    "collection-title": "Koli calling ’23",
    "container-title": "Proceedings of the 23rd koli calling international conference on computing education research",
    "id": "10.1145/3631802.3631825",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "block-based programming, computer science education, low-level computing",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A block-based programming environment for teaching low-level computing (discussion paper)",
    "type": "paper-conference"
  },
  {
    "ISBN": "076950275X",
    "abstract": "This paper explores technical issues in the design of programming tools, development environments, simulations, code examples, user interface frameworks and pedagogies for a university-level course on object-oriented software development. The course, M206 \"Computing: An Object-oriented Approach\" has been specifically developed for distance learning, and is enrolling over 5,000 students per year (average age 37) in the UK, Europe and Singapore. The course introduces computing via an object-oriented approach. M206 is substantial in extent, representing one sixth of a degree. It embodies a practical, industry-oriented view of computing and includes programming, analysis, design, and group working. Considerable effort has been invested in making the simplicity, consistency and power of object technology accessible to and capable of being applied by beginners. A diverse set of educational media, such as CD-ROMs, TV and the Web, have been deployed as learning resources. The paper describes the agenda for the course, its object-oriented pedagogy and our strategy for delivery.We explain measures taken to avoid misconceptions about objects, our analysis and design method, and the Smalltalk programming environment we have developed specifically for learners and which is crucial to our approach. The paper outlines how our adherence to the separation of view and domain model leads to technical innovations. Concluding remarks reflect on the benefits a reflexive strategy, both in education and training.",
    "author": [
      {
        "family": "Woodman",
        "given": "Mark"
      },
      {
        "family": "Griffiths",
        "given": "Rob"
      },
      {
        "family": "Holland",
        "given": "Simon"
      },
      {
        "family": "Robinson",
        "given": "Hugh"
      },
      {
        "family": "Macgregor",
        "given": "Malcolm"
      }
    ],
    "collection-title": "TOOLS ’99",
    "container-title": "Proceedings of the technology of object-oriented languages and systems",
    "id": "10.5555/832256.832950",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "page": "371",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Employing object technology to expose fundamental object concepts",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/988316.988319",
    "ISSN": "0362-1340",
    "URL": "https://doi.org/10.1145/988316.988319",
    "abstract": "While languages based upon threaded interpretive systems have been used for a variety of applications, these systems have been generally ignored by serious students of programming languages. We describe research here at the University of South Florida where we are investigating the suitability of these systems for implementing a programming environment - specifically an environment to support programming in a functional style.We hypothesize that threaded interpretive systems may have merit as the basis for more ambitious language implementations than have yet been attempted - and that such languages may offer a reasonable compromise between the flexability of more interpretive systems and the efficiency of compilers that generate native code. We describe extensions to a threaded language which provide the kernel of a functional style language. Our goal is to gain insight into the real and apparent capabilities of threaded languages and to evaluate the potential of such systems for support of functional programming environments.",
    "author": [
      {
        "family": "Glass",
        "given": "Harvey"
      }
    ],
    "container-title": "SIGPLAN Not.",
    "id": "10.1145/988316.988319",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1985,
          4
        ]
      ]
    },
    "page": "24-32",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Threaded interpretive systems and functional programming environments",
    "type": "article-journal",
    "volume": "20"
  },
  {
    "DOI": "10.1145/2960310.2960322",
    "ISBN": "9781450344494",
    "URL": "https://doi.org/10.1145/2960310.2960322",
    "abstract": "Computing education researchers have become increasingly interested in leveraging log data automatically collected within computer programming environments in order to understand students’ learning processes and tailor instruction to student needs. While data on students’ programming activities has been positively correlated with their learning outcomes, those data tell only part of the story. Another part of the story lies in students’ social activities, which, according to social learning theory, can also be predictive of students’ learning outcomes. In order to gain further insight into how computing students’ learning processes influence their learning outcomes, we present an empirical study that explores the interplay of students’ social activities, programming activities, and course outcomes in an early computing course. By analyzing log data collected through a programming environment augmented with a social networking-style activity stream, we found that answers to questions posed through the activity stream were positively correlated with students’ ability to make programming progress, and their eventual success in the course. Based on our findings, we present recommendations for the design of pedagogical environments to support a more social programming process.",
    "author": [
      {
        "family": "Carter",
        "given": "Adam S."
      },
      {
        "family": "Hundhausen",
        "given": "Christopher D."
      }
    ],
    "collection-title": "ICER ’16",
    "container-title": "Proceedings of the 2016 ACM conference on international computing education research",
    "id": "10.1145/2960310.2960322",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "human factors., experimentation, design",
    "page": "201-209",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "With a little help from my friends: An empirical study of the interplay of students’ social activities, programming activities, and course success",
    "title-short": "With a little help from my friends",
    "type": "paper-conference"
  },
  {
    "ISBN": "9608457432",
    "abstract": "We have investigated collaborative problem solving in a teaching experiment, which was organized for 32 senior university students in the computerized collaborative problem solving learning environment. The participating teacher was trained by us and students had available kits, interfaces and computers equipped with 8051 micro chip programming tools. Student activities were video recorded and the analysis proceeded through writing video protocols, edited into episodes and then classified into categories. Categories were mainly derived empirically. In the analysis, we used concepts such as collaboration and problem solving, in accordance with social constructivism. The data showed that typical learning processes were collaborative (51",
    "author": [
      {
        "family": "Yang",
        "given": "Hung-Jen"
      },
      {
        "family": "Yang",
        "given": "Hsieh-Hua"
      },
      {
        "family": "Wang",
        "given": "Cheng Chung"
      },
      {
        "family": "Huang",
        "given": "Kuo-Yan"
      }
    ],
    "collection-title": "ACOS’06",
    "container-title": "Proceedings of the 5th WSEAS international conference on applied computer science",
    "id": "10.5555/1973598.1973643",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "keyword": "social interactions, problem solving, computerized, collaborative learning",
    "page": "227-233",
    "publisher": "World Scientific; Engineering Academy; Society (WSEAS)",
    "publisher-place": "Stevens Point, Wisconsin, USA",
    "title": "Social interactions of the computerized collaborative problem solving on micro chip",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2801081.2801094",
    "ISBN": "9781450333351",
    "URL": "https://doi.org/10.1145/2801081.2801094",
    "abstract": "Specially designed programming environments have been used for decades to support the novice programmers learning programming. In this paper, we present various forms of Educational Technology that have guided the design of educational programming environments the last two decades. The design and aspirations of three distinct programming environments developed at the University of Macedonia are presented. These include a Programming Microworld, an Educational Game and a Distributed Pair Programming system. The potential benefits of the different features of the three environments are presented along with results from their evaluation. Conclusions are drawn regarding the technologies incorporated in these different programming environments. Specifically, emphasis is given on technologies and features that seem to be important for motivating and engaging students in learning programming and should be taken into account by researchers designing new educational programming environments.",
    "author": [
      {
        "family": "Xinogalos",
        "given": "Stelios"
      },
      {
        "family": "Malliarakis",
        "given": "Christos"
      },
      {
        "family": "Tsompanoudi",
        "given": "Despina"
      },
      {
        "family": "Satratzemi",
        "given": "Maya"
      }
    ],
    "collection-title": "BCI ’15",
    "container-title": "Proceedings of the 7th balkan conference on informatics conference",
    "id": "10.1145/2801081.2801094",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "structure editors, programming microworlds, educational games, distributed pair programming, collaboration scripts, Novice programmer",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Microworlds, games and collaboration: Three effective approaches to support novices in learning programming",
    "title-short": "Microworlds, games and collaboration",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.compedu.2019.103646",
    "ISSN": "0360-1315",
    "URL": "https://doi.org/10.1016/j.compedu.2019.103646",
    "author": [
      {
        "family": "Weintrop",
        "given": "David"
      },
      {
        "family": "Wilensky",
        "given": "Uri"
      }
    ],
    "container-title": "Comput. Educ.",
    "id": "10.1016/j.compedu.2019.103646",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          12
        ]
      ]
    },
    "keyword": "Teaching/learning strategies, Secondary education, Programming and programming languages, Interactive learning environments, Evaluation of CAL systems",
    "publisher": "Elsevier Science Ltd.",
    "publisher-place": "GBR",
    "title": "Transitioning from introductory block-based and text-based environments to professional programming languages in high school computer science classrooms",
    "type": "article-journal",
    "volume": "142"
  },
  {
    "ISBN": "013374163X",
    "abstract": "Prelude to Programming is appropriate for Pre-Programming and Introductory Programming courses in community colleges, 4-year colleges, and universities. No prior computer or programming experience is necessary although readers are expected to be familiar with college entry-level mathematics. Prelude to Programming provides beginning students with a language-independent framework for learning core programming concepts and effective design techniques. This approach gives students the foundation they need to understand the logic behind program design and to establish effective programming skills. The Sixth Edition offers students a lively and accessible presentation as they learn core programming concepts including data types, control structures, data files and arrays, and program design techniques such as top-down modular design and proper program documentation and style. Problem-solving skills are developed when students learn how to use basic programming tools and algorithms, which include data validation, defensive programming, calculating sums and averages, and searching and sorting lists. Teaching and Learning Experience This program presents a better teaching and learning experiencefor you and your students. It provides: A Language-Independent, Flexible Presentation: The text has been designed so that instructors can use it for students at various levels. Features that Help Solidify Concepts: Examples, exercises, and programming challenges help students understand how concepts in the text apply to real-life programs. Real Programming Experience with RAPTOR: Students gain first-hand programming experience through the optional use of RAPTOR, a free flowchart-based programming environment. Support Learning: Resources are available to expand on the topics presented in the text.",
    "author": [
      {
        "family": "Venit",
        "given": "Stewart"
      },
      {
        "family": "Drake",
        "given": "Elizabeth"
      }
    ],
    "edition": "6th",
    "id": "10.5555/2636689",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Prelude to programming",
    "type": "book"
  },
  {
    "DOI": "10.1145/2023607.2023610",
    "ISBN": "9781450309172",
    "URL": "https://doi.org/10.1145/2023607.2023610",
    "abstract": "Web 2.0 has enabled Web users to create and share a variety of hyper-text based artifacts including embedded images, sound, and video on the Web. Creating Web-based interactive artifacts such as computer games, however, has remained a challenge: to end users due to the lack of end user programming tools; and to programmers due to the poor interactivity performance of the Web. With the emergence of HTML5 and improving performance of JavaScript engines, professional Web programmers have only just begun to develop Web-native interactive artifacts. Today’s standard Web technologies make the Web a hospitable platform for efficient interactive applications both for professional programmers and end-users. With proper support, in tools and languages, end-user programming of interactive applications is feasible. In this paper, we review the current state of Web application development and the possibilities and potential benefits of end-user programming on the Web. We will use a case study, AgentWeb, a Web-based end-user development environment, as a representative of interactive Web applications. It is based completely on open Web technologies, rather than on any proprietary technologies. Given that 2D graphic interactive applications may be developed and efficiently executed on the Web, we discuss some of the potential applications in educational settings, including individual and collaborative learning.",
    "author": [
      {
        "family": "Jazayeri",
        "given": "Mehdi"
      },
      {
        "family": "Ahmadi",
        "given": "Navid"
      }
    ],
    "collection-title": "CompSysTech ’11",
    "container-title": "Proceedings of the 12th international conference on computer systems and technologies",
    "id": "10.1145/2023607.2023610",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "keyword": "web programming, web native applications, web applications, open web, end-user programming, World Wide Web, HTML5",
    "page": "11-16",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "End-user programming of web-native interactive applications",
    "type": "paper-conference"
  },
  {
    "ISBN": "3540424997",
    "abstract": "This paper presents the benefits of using a generic FPGA tool set developed at the university of Brest for programming virtual FPGA. From a high level description of the FPGA architecture, the basic tools such a placer, a router or an editor are automatically generated. The description is not constrained by any model, so that abstract architectures, such as virtual FPGAs, can directly exploit the tool set as their basic programming tools.",
    "author": [
      {
        "family": "Lagadec",
        "given": "Loı̈c"
      },
      {
        "family": "Lavenier",
        "given": "Dominique"
      },
      {
        "family": "Fabiani",
        "given": "Erwan"
      },
      {
        "family": "Pottier",
        "given": "Bernard"
      }
    ],
    "collection-title": "FPL ’01",
    "container-title": "Proceedings of the 11th international conference on field-programmable logic and applications",
    "id": "10.5555/647928.740044",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "page": "357-366",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Placing, routing, and editing virtual FPGAs",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1868358.1868361",
    "URL": "https://doi.org/10.1145/1868358.1868361",
    "abstract": "Greenfoot is an educational integrated development environment aimed at learning and teaching programming. It is aimed at a target audience of students from about 14 years old upwards, and is also suitable for college- and university-level education. Greenfoot combines graphical, interactive output with programming in Java, a standard, text-based object-oriented programming language. This article first describes Greenfoot and then goes on to discuss design goals and motivations, strengths and weaknesses of the system, and its relation to two environments with similar goals, Scratch and Alice.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/1868358.1868361",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2010,
          11
        ]
      ]
    },
    "keyword": "programming environment, programming education, Greenfoot",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The greenfoot programming environment",
    "type": "article-journal",
    "volume": "10"
  },
  {
    "DOI": "10.1016/j.comnet.2010.07.016",
    "ISSN": "1389-1286",
    "URL": "https://doi.org/10.1016/j.comnet.2010.07.016",
    "abstract": "This paper presents iPlumber, a user-oriented management system for ubiquitous computing environments. Different from previous low-benefit ”zero-configuration” systems or high cognitive-cost ”end user programming” tools, our work attempts to attain a better balance between user benefits and cost by exploring the meta-design approach. A set of typical management activities in ubicomp environments are supported, from basic-level software sharing, foraging, and low-cost software configuration to advanced-level cooperative software co-design and error handling. These activities are elaborated through a smart home control scenario. The usability of our system is validated through an initial user study with a total of 33 subjects to test the management activities from an open exhibition environment and a controlled university environment.",
    "author": [
      {
        "family": "Guo",
        "given": "Bin"
      },
      {
        "family": "Zhang",
        "given": "Daqing"
      },
      {
        "family": "Imai",
        "given": "Michita"
      }
    ],
    "container-title": "Comput. Netw.",
    "id": "10.1016/j.comnet.2010.07.016",
    "issue": "16",
    "issued": {
      "date-parts": [
        [
          2010,
          11
        ]
      ]
    },
    "keyword": "Wireless sensor network, Ubiquitous computing management, Smart object, Semantic Web, Meta-design, End user development, Cooperation",
    "page": "2840-2855",
    "publisher": "Elsevier North-Holland, Inc.",
    "publisher-place": "USA",
    "title": "Enabling user-oriented management for ubiquitous computing: The meta-design approach",
    "title-short": "Enabling user-oriented management for ubiquitous computing",
    "type": "article-journal",
    "volume": "54"
  },
  {
    "DOI": "10.1145/236452.236537",
    "ISBN": "089791757X",
    "URL": "https://doi.org/10.1145/236452.236537",
    "abstract": "Teaching object-oriented programming has clearly become an important part of computer science education. We agree with many others that the best place to teach it is in the CS1 introductory course. Many problems with this have been reported in the literature. These mainly result from inadequate languages and environments. Blue is a new language and integrated programming environment, currently under development explicitly for object-oriented teaching. We expect clear advantages from the use of Blue for first year teaching compared to using other available languages. This paper describes the design principles on which the language was based and the most important aspects of the language itself.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      },
      {
        "family": "Rosenberg",
        "given": "John"
      }
    ],
    "collection-title": "SIGCSE ’96",
    "container-title": "Proceedings of the twenty-seventh SIGCSE technical symposium on computer science education",
    "id": "10.1145/236452.236537",
    "issued": {
      "date-parts": [
        [
          1996
        ]
      ]
    },
    "page": "190-194",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Blue—a language for teaching object-oriented programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3059009.3059035",
    "ISBN": "9781450347044",
    "URL": "https://doi.org/10.1145/3059009.3059035",
    "abstract": "This article discusses an emerging phenomenon of streaming programming to a live audience who in turn can interact with the streamer. In essence, this means broadcasting the programming environment and typically a web camera feed of the streamer to viewers. Streaming programming bears many similarities with live-streaming playing of video games, which has become extremely popular among gamers over the recent years. In fact, streaming programming often use the same web services as streaming gaming, and the audiences overlap.In this article, we describe this novel approach to programming and situate it in the broader context of computer science education. To gain a deeper insight into this phenomena, we analyzed viewer discussions during a particular programming stream broadcasted during a game programming competition. Finally, we discuss the benefits this approach could offer to computer science education.",
    "author": [
      {
        "family": "Haaranen",
        "given": "Lassi"
      }
    ],
    "collection-title": "ITiCSE ’17",
    "container-title": "Proceedings of the 2017 ACM conference on innovation and technology in computer science education",
    "id": "10.1145/3059009.3059035",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "streaming, online communities, game-based learning, computer science education",
    "page": "353-358",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Programming as a performance: Live-streaming and its implications for computer science education",
    "title-short": "Programming as a performance",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/29650.29662",
    "ISBN": "0897912357",
    "URL": "https://doi.org/10.1145/29650.29662",
    "abstract": "As part of Rice University’s project to build a programming environment for scientific software, we have built a facility for program execution that solves some of the problems inherent in debugging large, computationally intensive programs. By their very nature such programs do not lend themselves to full-scale interpretation. In moderation however, interpretation can be extremely useful during the debugging process. In addition to discussing the particular benefits that we expect from interpretation, this paper addresses how interpretive techniques can be effectively used in conjunction with the execution of compiled code. The same implementation technique that permits interpretation to be incorporated as part of execution will also permit the execution facility to be used for debugging parallel programs running on a remote machine.",
    "author": [
      {
        "family": "Chase",
        "given": "B. B."
      },
      {
        "family": "Hood",
        "given": "R. T."
      }
    ],
    "collection-title": "SIGPLAN ’87",
    "container-title": "Papers of the symposium on interpreters and interpretive techniques",
    "id": "10.1145/29650.29662",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "page": "113-124",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Selective interpretation as a technique for debugging computationally intensive programs",
    "type": "paper-conference"
  },
  {
    "ISBN": "0780398025",
    "abstract": "We present a new parallel programming tool environment that is (1) accessible and executable “anytime, anywhere,” through standard Web browsers and (2) integrated in that it provides tools which adhere to a common underlying methodology for parallel programming and performance tuning. The environment is based on a new network computing infrastructure developed at Purdue University. We evaluate our environment qualitatively by comparing our tool access method with conventional schemes of software download and installation. We also quantitatively evaluate the efficiency of interactive tool access in our environment. We do this by measuring the response times of various functions of the Ursa Minor tool and compare them with those of a Java Applet-based \"anytime, anywhere\" tool access method. We found that our environment offers significant advantages in terms of tool accessibility, integration, and efficiency.",
    "author": [
      {
        "family": "Park",
        "given": "Insung"
      },
      {
        "family": "Kapadia",
        "given": "Nirav H."
      },
      {
        "family": "Figueiredo",
        "given": "Renato J."
      },
      {
        "family": "Eigenmann",
        "given": "Rudolf"
      },
      {
        "family": "Fortes",
        "given": "José A. B."
      }
    ],
    "collection-title": "SC ’00",
    "container-title": "Proceedings of the 2000 ACM/IEEE conference on supercomputing",
    "id": "10.5555/370049.370067",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "page": "9-es",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Towards an integrated, web-executable parallel programming tool environment",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ETCS.2009.672",
    "ISBN": "9780769535579",
    "URL": "https://doi.org/10.1109/ETCS.2009.672",
    "abstract": "This paper analyzes the applications of modern educational technologies for students with disabilities in higher special education. In recent years, modern educational technologies have been utilized rapidly in special education. When used, student’s role is often to work as a user of technologies instead of the role of doer, controller or creator of a technology. The high utilization of educational technologies in the special education reflects the situation that students with individual needs have the potential to learn programming or to take advantage of technology in general. Educational technology refers to technology tools and software that have been created to support learning and teaching. In this study educational technology is mainly focused on mind storming tools for planning, physical tools such as computers, documentation tools, and software such as a programming environment.",
    "author": [
      {
        "family": "Bian",
        "given": "Li"
      }
    ],
    "collection-title": "ETCS ’09",
    "container-title": "Proceedings of the 2009 first international workshop on education technology and computer science - volume 03",
    "id": "10.1109/ETCS.2009.672",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "students with disabilities, modern educational technologies, higher special education",
    "page": "622-625",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Modern education technologies in higher special education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3149572.3149601",
    "ISBN": "9781450353373",
    "URL": "https://doi.org/10.1145/3149572.3149601",
    "abstract": "Due to the impact of high performance customer service, many organizations attempt to improve customer support services using helpdesk systems. The objective of this study is to develop a Central Trouble Ticketing (CTT) system for effective information dissemination, efficient management of operations and to resolve challenges of Center of Training and Learning (CTL) through using e-learning website at a University. As for implementation phase, the Hypertext Preprocessor (PHP) was used as the server side programming tool and MySQL database as backend. The benefits of the Central Trouble Ticketing system include creation of a medium for lecturers to pass their complaints or messages to the technical department for speedy attention; and provision of better and faster operational processes which will reduce time spent on documentation. The system is more reliable, effective and convenient than the manual method in reporting cases of complain within the university technical community.",
    "author": [
      {
        "family": "ahmadpour",
        "given": "Sima"
      },
      {
        "family": "Khaleghi",
        "given": "Ali"
      }
    ],
    "collection-title": "ICIME 2017",
    "container-title": "Proceedings of the 9th international conference on information management and engineering",
    "id": "10.1145/3149572.3149601",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "information management system, helpdesk systems, Trouble ticketing",
    "page": "91-95",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Central trouble ticketing (CTT) system as a communication tool between stakeholders of center of training and learning (CTL)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1565799.1565822",
    "ISBN": "9781605582177",
    "URL": "https://doi.org/10.1145/1565799.1565822",
    "abstract": "Statistics for underrepresented minority groups and women continue to show low numbers in enrollment and rates of retention in academic computer science programs. A new approach to increase student interest in computer science in a first year program is introduced.Laboratory modules for an introductory programming course have been developed at the University of Alabama with the goal to increase student motivation and understanding of fundamental programming concepts. The course utilizes robots and Alice, a 3D graphical programming environment. The drag and drop interface of Alice allows students to program real robots using instructions that correspond to statements of programming languages such as Java, C++, and C#. Students gain programming experience that is transferable to upper level courses by engaging in a stimulating and less frustrating environment using Alice interfaced with robots.",
    "author": [
      {
        "family": "Wellman",
        "given": "Briana Lowe"
      },
      {
        "family": "Davis",
        "given": "James"
      },
      {
        "family": "Anderson",
        "given": "Monica"
      }
    ],
    "collection-title": "TAPIA ’09",
    "container-title": "The fifth richard tapia celebration of diversity in computing conference: Intellect, initiatives, insight, and innovations",
    "id": "10.1145/1565799.1565822",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "keyword": "education, diversity, computer science",
    "page": "98-102",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Alice and robotics in introductory CS courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3544548.3580981",
    "ISBN": "9781450394215",
    "URL": "https://doi.org/10.1145/3544548.3580981",
    "abstract": "Computational thinking (CT) education reaches only a fraction of young children, in part because CT learning tools often require expensive hardware or fluent literacy. Block-based programming environments address these challenges through symbolic graphical interfaces, but users often need instructor support to advance. Alternatively, voice-based tools provide direct instruction on CT concepts but can present memory and navigation challenges to users. In this work, we present Visual StoryCoder, a multimodal tablet application that combines the strengths of each of these approaches to overcome their respective weaknesses. Visual StoryCoder introduces children ages 5–8 to CT through creative storytelling, offers direct instruction via a pedagogical voice agent, and eases use through a block-like graphical interface. In a between-subjects evaluation comparing Visual StoryCoder to a leading block-based programming app for this age group (N = 24), we show that Visual StoryCoder is more understandable to independent learners, leads to higher-quality code after app familiarization, and encourages personally meaningful projects.",
    "author": [
      {
        "family": "Dietz",
        "given": "Griffin"
      },
      {
        "family": "Tamer",
        "given": "Nadin"
      },
      {
        "family": "Ly",
        "given": "Carina"
      },
      {
        "family": "Le",
        "given": "Jimmy K"
      },
      {
        "family": "Landay",
        "given": "James A."
      }
    ],
    "collection-title": "CHI ’23",
    "container-title": "Proceedings of the 2023 CHI conference on human factors in computing systems",
    "id": "10.1145/3544548.3580981",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "children, computational thinking, multimodal interface, storytelling",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Visual StoryCoder: A multimodal programming environment for children’s creation of stories",
    "title-short": "Visual StoryCoder",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3102113.3102144",
    "ISBN": "9781450350839",
    "URL": "https://doi.org/10.1145/3102113.3102144",
    "abstract": "Self-adaptive UIs (SAUIs) have been promoted as a solution for context variability due to their ability to automatically adapt to the context-of-use at runtime. The development of SAUIs is a complex task since self-adaptivity and context management aspects have to be incorporated in the UI development process. In this paper, we present an integrated development environment (IDE) for model-driven development of SAUIs. This IDE, named Adapt-UI, provides integrated views for UI, context and adaptation modeling. Based on the specified models, final UI code and context as well as adaptation services are generated and integrated in an overall UI framework. This allows runtime UI adaptation realized by an automatic reaction to context-of-use changes. The benefit of our approach is demonstrated by a case study, showing the development of self-adaptive UIs for a university library application, utilizing the Angular 2 JavaScript framework.",
    "author": [
      {
        "family": "Yigitbas",
        "given": "Enes"
      },
      {
        "family": "Sauer",
        "given": "Stefan"
      },
      {
        "family": "Engels",
        "given": "Gregor"
      }
    ],
    "collection-title": "EICS ’17",
    "container-title": "Proceedings of the ACM SIGCHI symposium on engineering interactive computing systems",
    "id": "10.1145/3102113.3102144",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "self-adaptive UIs, model-driven UI development, context-management, UI adaptation",
    "page": "99-104",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Adapt-UI: An IDE supporting model-driven development of self-adaptive UIs",
    "title-short": "Adapt-UI",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2532748.2532761",
    "ISBN": "9781450324557",
    "URL": "https://doi.org/10.1145/2532748.2532761",
    "abstract": "Computer programming has become an important skill and it can be taught from early school years. Previous research has developed and evaluated several visual programming tools that are suitable for computer education in schools. However, little is known about how pedagogic styles affect student attitudes towards learning computer programming. This paper reports on a preliminary study on the influence of alternative teaching styles on student’s enjoyment and attitude towards computing. Two groups of twelve students each were asked to revise a computer game. The traditional instruction group was provided with detailed information, while the encouragement group was asked to help the teacher to change the variables of the game. The results indicate that an encouraging pedagogic style promotes more positive attitudes towards computer programming and more self-confidence than traditional instruction. Further research should repeat the experiment across several weeks for more programming concepts and should also assess the cognitive benefits.",
    "author": [
      {
        "family": "Makris",
        "given": "Dimosthenis"
      },
      {
        "family": "Euaggelopoulos",
        "given": "Kleomenis"
      },
      {
        "family": "Chorianopoulos",
        "given": "Konstantinos"
      },
      {
        "family": "Giannakos",
        "given": "Michail N."
      }
    ],
    "collection-title": "WiPSE ’13",
    "container-title": "Proceedings of the 8th workshop in primary and secondary computing education",
    "id": "10.1145/2532748.2532761",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "keyword": "secondary education, scratch, programming, encouragement, confidence, computer education, computational thinking",
    "page": "79-82",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Could you help me to change the variables? Comparing instruction to encouragement for teaching programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "9783540899617",
    "URL": "https://doi.org/10.1007/978-3-540-89962-4_5",
    "abstract": "Developments in computer networking and the Internet in the last decade have provided new possibilities and new challenges for designing web-based learning environment for embedded applications. The design elements should facilitate instruction delivery, interaction, quality of learning and support for learner. This paper presents a technology, which supports remote experimentation on an embedded system. The ability to combine practical applications with visualization of real hardware using powerful and efficient virtual instrumentation and multimedia tool is the advantage of technology-based education. The paper describes the hardware and software structure of such a system and the interface between various data processing units. The design is based on interfacing a graphical programming tool such as LabVIEW with an embedded development board. It describes the ongoing research in this area exploiting current telematics techniques, which supports remote experimentation with real hardware via the Internet.",
    "author": [
      {
        "family": "Chandra A. P.",
        "given": "Jagadeesh"
      },
      {
        "family": "Samuel",
        "given": "R. D."
      }
    ],
    "container-title": "Advances in blended learning: Second workshop on blended learning, WBL 2008, jinhua, china, augustl 20-22, 2008. Revised selected papers",
    "id": "10.1007/978-3-540-89962-4_5",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "page": "46-54",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Design of a real-time on-line web-based collaborative learning environment for embedded applications",
    "type": "chapter"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "This tutorial will introduce Alice 2.0, an interactive programming course developed at Carnegie Mellon University. This program is an ideal introductory high school or college one-semester Computer Science course. This program is especially useful for recruiting female students into the work of Computer Science. Alice is an innovative 3D programming environment that makes it easy to create an animation for telling a story, playing an interactive game, or a video to share on the web. Alice is a freely available teaching tool designed to be a student’s first exposure to object-oriented programming. In Alice’s interactive interface, students drag and drop graphic tiles to create a program, where the instructions correspond to standard statements in a production oriented programming language, such as Java. By manipulating the objects in their virtual world, students gain experience with all the programming constructs typically taught in an introductory programming course. Attendees will gain knowledge on how to incorporate Alice 2.0 into their introductory curriculum.",
    "author": [
      {
        "family": "Amerikaner",
        "given": "Erik W."
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1734797.1734824",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2010,
          4
        ]
      ]
    },
    "page": "141",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Introduction to computer science using alice 2.0: Tutorial presentation",
    "title-short": "Introduction to computer science using alice 2.0",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "DOI": "10.1145/3408877.3432534",
    "ISBN": "9781450380621",
    "URL": "https://doi.org/10.1145/3408877.3432534",
    "abstract": "The process of writing code and use of features in an integrated development environment (IDE) is a fruitful source of data in computing education research. Existing studies use records of students’ actions in the IDE, consecutive code snapshots, compilation events, and others, to gain deep insight into the process of student programming.In this paper, we present a set of tools for collecting and processing data of student activity during problem-solving. The first tool is a plugin for IntelliJ-based IDEs (PyCharm, IntelliJ IDEA, CLion). By capturing snapshots of code and IDE interaction data, it allows to analyze the process of writing code in different languages — Python, Java, Kotlin, and C++. The second tool is designed for the post-processing of data collected by the plugin and is capable of basic analysis and visualization. To validate and showcase the toolkit, we present a dataset collected by our tools. It consists of records of activity and IDE interaction events during solution of programming tasks by 148 participants of different ages and levels of programming experience. We propose several directions for further exploration of the dataset.",
    "author": [
      {
        "family": "Lyulina",
        "given": "Elena"
      },
      {
        "family": "Birillo",
        "given": "Anastasiia"
      },
      {
        "family": "Kovalenko",
        "given": "Vladimir"
      },
      {
        "family": "Bryksin",
        "given": "Timofey"
      }
    ],
    "collection-title": "SIGCSE ’21",
    "container-title": "Proceedings of the 52nd ACM technical symposium on computer science education",
    "id": "10.1145/3408877.3432534",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "programming education, ide instrumentation, code tracking, activity tracking",
    "page": "495-501",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TaskTracker-tool: A toolkit for tracking of code snapshots and activity data during solution of programming tasks",
    "title-short": "TaskTracker-tool",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3364510.3364522",
    "ISBN": "9781450377157",
    "URL": "https://doi.org/10.1145/3364510.3364522",
    "abstract": "Courses in C programming at two Finnish universities were assessed with electronic exams. In the study setting, two types of electronic exams were used: lecture hall exams and exam studio exams. Student experiences were collected with surveys and interviews, and system data was used for exam statistics. The results were compared between exam types and between universities. The results show that electronic exams are perceived by the students as more realistic and natural in programming exams than traditional pen and paper exams. Thus, electronic exams support the development of working life skills above pen and paper exams. Students in the lecture hall exam described challenges not relevant in the exam studio exam, and on the other hand, students in the exam studio exam described benefits not available in the lecture hall exam. Based on the study, electronic exams are strongly recommended for programming courses using exams for summative assessment. In addition, programming environments are recommended for added authenticity in reflection to working-life skills, and exam studios are recommended because of the added values they provide compared to lecture hall exams.",
    "author": [
      {
        "family": "Rytkönen",
        "given": "Anni"
      },
      {
        "family": "Virtakoivu",
        "given": "Venla"
      }
    ],
    "collection-title": "Koli calling ’19",
    "container-title": "Proceedings of the 19th koli calling international conference on computing education research",
    "id": "10.1145/3364510.3364522",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "student assessment, programming in C, programming course, lecture hall exam, exam studio exam, electronic examining, C programming",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Comparative student experiences on electronic examining in a programming course - case c",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1504/ijlt.2018.098500",
    "ISSN": "1477-8386",
    "URL": "https://doi.org/10.1504/ijlt.2018.098500",
    "abstract": "The fast development of several programming tools has enabled researchers to explore interactive technology targeting various areas of human knowledge. Despite the several studies about the benefits of using the interactive technologies in the educational field, it is necessary to generalise these affirmations through of field studies that determine how those devices facilitate and improve teaching and learning. This research aims to apply an MS-Kinect-based learning system in a real pre-school environment and based on the results of this experiment, to answer some questions related to the motivational impact, effectiveness and acceptance of the teacher in teaching and learning process. This research uses a MS-Kinect-based learning system and several children’s educational games in an initial stage of studies; the developed learning system has been tested in two preschool education centres and was evaluated positively. In the field test, the learning system evaluation was determined to have a mean 95.5",
    "author": [
      {
        "family": "Lozada",
        "given": "Raul Marcelo"
      },
      {
        "family": "Escriba",
        "given": "Luis Rivera"
      },
      {
        "family": "Granja",
        "given": "Fernando T. Molina"
      }
    ],
    "container-title": "Int. J. Learn. Technol.",
    "id": "10.1504/ijlt.2018.098500",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2018,
          1
        ]
      ]
    },
    "keyword": "learning game, HCI, human-computer interaction, Kinect, preschoolers education",
    "page": "277-305",
    "publisher": "Inderscience Publishers",
    "publisher-place": "Geneva 15, CHE",
    "title": "MS-kinect in the development of educational games for preschoolers",
    "type": "article-journal",
    "volume": "13"
  },
  {
    "DOI": "10.1007/978-3-540-31958-0_21",
    "ISBN": "354025336X",
    "URL": "https://doi.org/10.1007/978-3-540-31958-0_21",
    "abstract": "Traditionally programming is considered to be a core content of informatics education. Just as traditional is the discussion of how to teach programming at school. One major aspect seems to be the choice of a suitable software tool allowing to focus on the basic concepts and avoiding tool-specific overhead at the same time. Therefore, special learning environments (so called microworlds) have been developed, designed to reduce the complexity learners are confronted with. But – in most cases – these microworlds are a sort of iso lated solution and call for a shift to “real” programming environments later on. The contrary approach is to downsize professional programming or (to be more general) software environments to the needs of the learner, which appears to be almost impossible due to the complexity of current software. This paper discusses how this might be achieved though by concentrating on programmable spread-sheet software. It points at possible didactic and methodical benefits by teaching programming this way and presents a list of criteria that can be helpful in deciding the relevance of software-tools for informatics classes.",
    "author": [
      {
        "family": "Antonitsch",
        "given": "Peter K."
      }
    ],
    "collection-title": "ISSEP’05",
    "container-title": "Proceedings of the 2005 informatics in secondary schools - evolution and perspectives international conference on from computer literacy to informatics fundamentals",
    "id": "10.1007/978-3-540-31958-0_21",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "189-197",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Standard software as microworld?",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/CERMA.2010.98",
    "ISBN": "9780769542041",
    "URL": "https://doi.org/10.1109/CERMA.2010.98",
    "abstract": "Teaching robotics is often a theoretical task, since many universities may have one or none robots for practical courses, specially in underdeveloped countries that suffer the lack of technology facilities. Many robot simulators exist, all of them allow the user to modify the joint values or to solve inverse kinematics. Nevertheless, a low cost, immersive virtual reality system, to manipulate and program a robot is not yet developed. This paper proposes a novel virtual reality system to train on robotics systems. The main contribution of this paper is a system the lets the user immerse in a virtual reality simulation of a real robot programming environment, enhancing the experience by means of tactile (haptic) and 3D visual feedback. Additionally, forward and inverse kinematics for a CRS robot is presented to clarify some of our system advantages, ease of configuration and extendability. Our system is open source under the GNU/GPL license.",
    "author": [
      {
        "family": "Hurtado",
        "given": "Carlos Vazquez"
      },
      {
        "family": "Valerio",
        "given": "Alejandro Rojo"
      },
      {
        "family": "Sanchez",
        "given": "Luis Ruvalcaba"
      }
    ],
    "collection-title": "CERMA ’10",
    "container-title": "Proceedings of the 2010 IEEE electronics, robotics and automotive mechanics conference",
    "id": "10.1109/CERMA.2010.98",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "haptic aided robot programming, Virtual robotics training",
    "page": "162-167",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Virtual reality robotics system for education and training",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.chb.2017.04.058",
    "ISSN": "0747-5632",
    "URL": "https://doi.org/10.1016/j.chb.2017.04.058",
    "abstract": "This article describes the implementation of various core elements of Computational Thinking (CT) in the classrooms of schools of Latin America and USA in two specific courses: PC-01 and ECE130. These courses were designed for students of primary and secondary education, as well as for students of high school as part of a dual enrollment program with a local university. Both courses introduce the core concepts and processes of CT aided by the visual programming environments Scratch and Alice. The courses are facilitated by the classroom teacher with the support of a learning platform. This platform is configured to provide innovative pedagogical strategies based on emerging educational technologies. This article describes the concepts integrated under the term CT, and discusses the benefits of learning environments used to incorporate CT in the classroom. It describes as well the syllabi and assessments of both courses, and analyzes their impact of these courses on the educational institutions, the teachers and the students. Computational Thinking trough object-based programming.Human Cognitive Primitives: in search of new computational tools.Blended Learning: added value for teachers and students.Student Peer Review: new roles and responsibilities for students.Mastery Learning through student portfolios and peer review.",
    "author": [
      {
        "family": "Basogain",
        "given": "Xabier"
      },
      {
        "dropping-particle": "ngel",
        "family": "Olabe",
        "given": "Miguel"
      },
      {
        "family": "Olabe",
        "given": "Juan Carlos"
      },
      {
        "family": "Rico",
        "given": "Mauricio Javier"
      }
    ],
    "container-title": "Comput. Hum. Behav.",
    "id": "10.1016/j.chb.2017.04.058",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2018,
          3
        ]
      ]
    },
    "keyword": "Scratch, Learning technologies, Educational technology, Computational Thinking, Cognitive science, Alice",
    "page": "412-419",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Computational thinking in pre-university blended learning classrooms",
    "type": "article-journal",
    "volume": "80"
  },
  {
    "DOI": "10.1145/2839509.2850492",
    "ISBN": "9781450336857",
    "URL": "https://doi.org/10.1145/2839509.2850492",
    "abstract": "Computing educators have become increasingly interested in learning analytics, which involves collecting and analyzing data on students’ learning processes and outcomes for the purpose of improving learning and instructional practices. A variety of computer programming environments enable the automated collection of log data on students’ programming processes. In addition, log data on students’ online social behavior can be easily collected. All of these data can be analyzed alongside data on students’ learning outcomes in order to identify correlations between learning processes and outcomes, and ultimately to better tailor instruction to students’ needs. This BOF will provide a platform for discussing the emerging field of learning analytics within the context of computing education. The following questions will serve as a starting point for our discussions: (1) What types of data should we be collecting on computing students’ (2) How can we best analyze these data in order to gain meaningful insights into students’ learning processes? (3) How can we design effective instructional interventions based on the data we collect and analyze?",
    "author": [
      {
        "family": "Hundhausen",
        "given": "Christopher D."
      },
      {
        "family": "Carter",
        "given": "Adam S."
      }
    ],
    "collection-title": "SIGCSE ’16",
    "container-title": "Proceedings of the 47th ACM technical symposium on computing science education",
    "id": "10.1145/2839509.2850492",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "learning management systems, learning analytics, computer science education",
    "page": "707",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Exploring learning analytics for computing education (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3159450.3162177",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3162177",
    "abstract": "CS Education makes heavy use of online educational tools like IDEs, Learning Management Systems, eTextbooks, interactive programming environments, and other smart content. Instructors and students would benefit from greater interoperability between tools. CS Ed researchers increasingly make use of the large collections of data generated by click streams coming from them. However, we all face barriers that slow progress: (1) Educational tools do not integrate well. (2) Information about CS learning process and outcome data generated by one system is not compatible with that from other systems. (3) CS problem solving and learning (e.g., coding solutions) is different from the type of data (discrete answers to questions or verbal responses) that current educational data mining focuses on. This BOF will discuss ways that we might support and better coordinate efforts to build community and capacity among CS Ed researchers, data scientists, and learning scientists toward reducing these barriers. CS Ed infrastructure should support broader re-use of innovative learning content that is instrumented for rich data collection, formats and tools for analysis of learner data, and best practices to make large collections of learner data available to researchers. Achieving these goals requires engaging a large community of researchers to define, develop, and use critical elements of this infrastructure to address specific data-intensive research questions.",
    "author": [
      {
        "family": "Shaffer",
        "given": "Clifford A."
      },
      {
        "family": "Brusilovsky",
        "given": "Peter"
      },
      {
        "family": "Koedinger",
        "given": "Kenneth R."
      },
      {
        "family": "Edwards",
        "given": "Stephen H."
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3162177",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "student analytics, smart content, interoperability, infrastructure, computer science education research, LTI",
    "page": "1063",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CS education infrastructure for all: Interoperability for tools and data analytics (abstract only)",
    "title-short": "CS education infrastructure for all",
    "type": "paper-conference"
  },
  {
    "ISBN": "3319367587",
    "abstract": "This unique text/reference describes an exciting and novel approach to supercomputing in the DataFlow paradigm. The major advantages and applications of this approach are clearly described, and a detailed explanation of the programming model is provided using simple yet effective examples. The work is developed from a series of lecture courses taught by the authors in more than 40 universities across more than 20 countries, and from research carried out by Maxeler Technologies, Inc. Topics and features: presents a thorough introduction to DataFlow supercomputing for big data problems; reviews the latest research on the DataFlow architecture and its applications; introduces a new method for the rapid handling of real-world challenges involving large datasets; provides a case study on the use of the new approach to accelerate the Cooley-Tukey algorithm on a DataFlow machine; includes a step-by-step guide to the web-based integrated development environment WebIDE.",
    "author": [
      {
        "family": "Milutinovi",
        "given": "Veljko"
      },
      {
        "family": "Salom",
        "given": "Jakob"
      },
      {
        "family": "Trifunovic",
        "given": "Nemanja"
      },
      {
        "family": "Giorgi",
        "given": "Roberto"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3122732",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "Guide to DataFlow supercomputing: Basic concepts, case studies, and a detailed example",
    "title-short": "Guide to DataFlow supercomputing",
    "type": "book"
  },
  {
    "ISBN": "3319162284",
    "abstract": "This unique text/reference describes an exciting and novel approach to supercomputing in the DataFlow paradigm. The major advantages and applications of this approach are clearly described, and a detailed explanation of the programming model is provided using simple yet effective examples. The work is developed from a series of lecture courses taught by the authors in more than 40 universities across more than 20 countries, and from research carried out by Maxeler Technologies, Inc. Topics and features: presents a thorough introduction to DataFlow supercomputing for big data problems; reviews the latest research on the DataFlow architecture and its applications; introduces a new method for the rapid handling of real-world challenges involving large datasets; provides a case study on the use of the new approach to accelerate the Cooley-Tukey algorithm on a DataFlow machine; includes a step-by-step guide to the web-based integrated development environment WebIDE.",
    "author": [
      {
        "family": "Milutinovic",
        "given": "Veljko"
      },
      {
        "family": "Salom",
        "given": "Jakob"
      },
      {
        "family": "Trifunovic",
        "given": "Nemanja"
      },
      {
        "family": "Giorgi",
        "given": "Roberto"
      }
    ],
    "id": "10.5555/2785658",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "Guide to DataFlow supercomputing: Basic concepts, case studies, and a detailed example",
    "title-short": "Guide to DataFlow supercomputing",
    "type": "book"
  },
  {
    "DOI": "10.1109/ICComm.2018.8430148",
    "URL": "https://doi.org/10.1109/ICComm.2018.8430148",
    "abstract": "An optimized implementation for a parameter-less radial-basis neural paradigm called super fast vector support classifier (SFSVC) is presented. Training resides only in a process of selecting centers and consequently it is a very fast process, linear in the number of hidden neurons. Several improvements make the resulting implementation a highly effective, high speed., machine learning engine convenient for various applications on a large variety of platforms. It is shown that among various programming environments., Python with optimized math library support represents the best choice for its implementation. An important (up to 40 times) speed-up for the testing time is achieved by implementing the distance calculations as matrix multiplications., thus accelerating RBF computations on platforms with optimized math and linear algebra libraries such as Intel’s MKL. Another important aspect of SFSVC., making it suitable for various embedded platforms (e.g. micro controllers., FPGA., etc.) is the lack of any tunable parameter except a unique radius., leading to a very convenient structure. The overall test plus training speed is better than for support vector machines while SFSVC has the important advantage of accepting arbitrary RBF kernels.",
    "author": [
      {
        "family": "Dogaru",
        "given": "Radu"
      },
      {
        "family": "Dogaru",
        "given": "Ioana"
      }
    ],
    "container-title": "2018 international conference on communications (COMM)",
    "id": "10.1109/ICComm.2018.8430148",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "page": "193-196",
    "publisher": "IEEE Press",
    "publisher-place": "Bucharest",
    "title": "Optimized super fast support vector classifiers using python and acceleration of RBF computations",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s11227-016-1633-y",
    "ISSN": "0920-8542",
    "URL": "https://doi.org/10.1007/s11227-016-1633-y",
    "abstract": "In this paper, we show that the GPU (graphics processing unit) can be used not only for processing graphics, but also for high speed computing. We provide a comparison between the times taken on the CPU and GPU to perform the training and testing of a back-propagation artificial neural network. We implemented two neural networks for recognizing handwritten digits; one consists of serial code executed on the CPU, while the other is a GPU-based version of the same system which executes in parallel. As an experiment for performance evaluation, a system for neural network training on the GPU is developed to reduce training time. The programming environment that the system is based on is CUDA which stands for compute unified device architecture, which allows a programmer to write code that will run on an NVIDIA GPU card. Our results over an experiment of digital image recognition using neural network confirm the speed-up advantages by tapping on the resources of GPU. Our proposed model has an advantage of simplicity, while it shows on par performance with the state-of-the-arts algorithms.",
    "author": [
      {
        "family": "Brito",
        "given": "Ricardo"
      },
      {
        "family": "Fong",
        "given": "Simon"
      },
      {
        "family": "Cho",
        "given": "Kyungeun"
      },
      {
        "family": "Song",
        "given": "Wei"
      },
      {
        "family": "Wong",
        "given": "Raymond"
      },
      {
        "family": "Mohammed",
        "given": "Sabah"
      },
      {
        "family": "Fiaidhi",
        "given": "Jinan"
      }
    ],
    "container-title": "J. Supercomput.",
    "id": "10.1007/s11227-016-1633-y",
    "issue": "10",
    "issued": {
      "date-parts": [
        [
          2016,
          10
        ]
      ]
    },
    "keyword": "Parallel execution, NVIDIA, CUDA, Artificial neural networks",
    "page": "3868-3886",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "GPU-enabled back-propagation artificial neural network for digit recognition in parallel",
    "type": "article-journal",
    "volume": "72"
  },
  {
    "ISBN": "9780889867062",
    "abstract": "Data mining applications have facilitated knowledge discovery in a multitude of areas including marketing, biological and geological sciences, and image processing. Through well established mathematical algorithms related to pattern recognition, predictive modeling, and anomaly detection, warehouses of data have been explored and interpreted with the purposes of helping researchers unveil and understand complex patterns. In this paper, we present the development of a web-based Data Mining Utility, created with the ultimate goal of allowing medical researchers to detect new artifacts that have been previously obscured through conventional signal processing techniques in neurological datasets. This web tool is powered by Data to Knowledge, which was created by the Automated Learning Group of the National Center for Supercomputing Applications at the University of Illinois, by integrating a vast library of customizable data mining techniques into a unified programming environment. Using this framework, along with the D2K Web Service, this Data Mining Utility will enhance an established Multi-Site Pediatric Network for fMRI in Childhood Epilepsy, as a means for researchers to gain further insight on medical case studies.",
    "author": [
      {
        "family": "Sanchez",
        "given": "Daniel"
      },
      {
        "family": "Shirk",
        "given": "Andrew"
      },
      {
        "family": "Sanchez",
        "given": "Danmary"
      },
      {
        "family": "Marrero",
        "given": "Adrian"
      }
    ],
    "collection-title": "SEA ’07",
    "container-title": "Proceedings of the 11th IASTED international conference on software engineering and applications",
    "id": "10.5555/1647636.1647741",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "keyword": "web services, distributed computing, data mining",
    "page": "603-608",
    "publisher": "ACTA Press",
    "publisher-place": "USA",
    "title": "Introducing the data mining utility: A web-based application for data mining experimentation on neurological datasets",
    "title-short": "Introducing the data mining utility",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130829293",
    "author": [
      {
        "family": "Deitel",
        "given": "Harvey M."
      },
      {
        "family": "Deitel",
        "given": "Paul J."
      },
      {
        "family": "Nieto",
        "given": "T. R."
      }
    ],
    "id": "10.5555/552832",
    "issued": {
      "date-parts": [
        [
          1998
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "The complete visual basic 6 training course",
    "type": "book"
  },
  {
    "DOI": "10.1145/3017680.3017749",
    "ISBN": "9781450346986",
    "URL": "https://doi.org/10.1145/3017680.3017749",
    "abstract": "The recent introduction of computer science (CS) education into schools in many countries has led to a surge in interest in programming tools and approaches which make CS concepts and tasks engaging, motivating and accessible to all. There is renewed interest in supporting learning through physical computing, which has been shown to be motivational whilst offering opportunities for collaboration and creativity. Within this context the BBC recently led a collaborative venture in the UK to develop a portable and low-cost programmable device. The consortium funded and produced one million devices, enough for every 11-12 year-old in the UK. In this paper, we report on what we believe to be the first study to investigate the usability and affordances of the BBC micro:bit. We interviewed 15 teachers and 54 pupils in schools in England about their experiences with the device who were, in general, enthusiastic about the potential of the BBC micro:bit. We describe pupils’ experiences in terms of usability, creativity, the tangibility of the device and their learning of programming, and analyse their experiences in the context of previously reported benefits of physical computing.",
    "author": [
      {
        "family": "Sentance",
        "given": "Sue"
      },
      {
        "family": "Waite",
        "given": "Jane"
      },
      {
        "family": "Hodges",
        "given": "Steve"
      },
      {
        "family": "MacLeod",
        "given": "Emily"
      },
      {
        "family": "Yeomans",
        "given": "Lucy"
      }
    ],
    "collection-title": "SIGCSE ’17",
    "container-title": "Proceedings of the 2017 ACM SIGCSE technical symposium on computer science education",
    "id": "10.1145/3017680.3017749",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "tangibility, physical computing, creativity, K-12 computer science, BBC micro:bit",
    "page": "531-536",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "\"Creating cool stuff\": Pupils’ experience of the BBC micro:bit",
    "title-short": "\"Creating cool stuff\"",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2818314.2818342",
    "ISBN": "9781450337533",
    "URL": "https://doi.org/10.1145/2818314.2818342",
    "abstract": "Learning to program in computer code has been considered one of the pillars of contemporary education with benefits that reach well beyond the skills required by the computing industry, into creativity and self-expression. Nevertheless, the execution of computer programs usually takes place on a traditional desktop computer, which has a limited repertoire of input and output interfaces to engage with the user. On the other hand, pedagogy has emphasized that physical representations and tangible interactive objects benefit learning especially for young students. In this work, we explore the benefits of learning to code for ubiquitous computers, such as robots and wearable computers, in comparison to programming for the desktop computer. For this purpose, thirty-six students participated in a within groups study that involved three types of tangibility at the target computer platform: 1) desktop with Scratch, 2) wearable with Arduino LilyPad, and 3) robotic with Lego Mindstorms. Regardless of the target platform, we employed the same desktop visual programming environment (MIT Scratch, Modkit and Enchanting) and we measured emotional engagement and assessed students’ programming skills. We found that students expressed more positive emotions while programming with the robotic rather than the desktop computer. Furthermore, tangible computing platforms didn’t affect dramatically students’ performance in computational thinking.",
    "author": [
      {
        "family": "Merkouris",
        "given": "Alexandros"
      },
      {
        "family": "Chorianopoulos",
        "given": "Konstantinos"
      }
    ],
    "collection-title": "WiPSCE ’15",
    "container-title": "Proceedings of the workshop in primary and secondary computing education",
    "id": "10.1145/2818314.2818342",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "wearable, robot, learning, experiment, embodiment, children, Ubiquitous computing",
    "page": "69-72",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Introducing computer programming to children through robotic and wearable devices",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3078072.3079740",
    "ISBN": "9781450349215",
    "URL": "https://doi.org/10.1145/3078072.3079740",
    "abstract": "Computational thinking and coding is gradually becoming an important part of K-12 education. Most parents, policy makers, teachers, and industrial stakeholders want their children to attain computational thinking and coding competences, since learning how to code is emerging as an important skill for the 21st century. Currently, educators are leveraging a variety of technological tools and programming environments, which can provide challenging and dynamic coding experiences. Despite the growing research on the design of coding experiences for children, it is still difficult to say how children of different ages learn to code, and to cite differences in their task-based behaviour. This study uses eye-tracking data from 44 children (here divided into \"kids\" [age 8-12] and \"teens\" [age 13-17]) to understand the learning process of coding in a deeper way, and the role of gaze in the learning gain and the different age groups. The results show that kids are more interested in the appearance of the characters, while teens exhibit more hypothesis-testing behaviour in relation to the code. In terms of collaboration, teens spent more time overall performing the task than did kids (higher similarity gaze). Our results suggest that eye-tracking data can successfully reveal how children of different ages learn to code.",
    "author": [
      {
        "family": "Papavlasopoulou",
        "given": "Sofia"
      },
      {
        "family": "Sharma",
        "given": "Kshitij"
      },
      {
        "family": "Giannakos",
        "given": "Michail"
      },
      {
        "family": "Jaccheri",
        "given": "Letizia"
      }
    ],
    "collection-title": "IDC ’17",
    "container-title": "Proceedings of the 2017 conference on interaction design and children",
    "id": "10.1145/3078072.3079740",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "teens, maker movement, kids, eye-tracking, coding",
    "page": "171-181",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using eye-tracking to unveil differences between kids and teens in coding activities",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ICPC.2019.00028",
    "URL": "https://doi.org/10.1109/ICPC.2019.00028",
    "abstract": "As deep learning (DL) opens the way to many technological innovations in a wild range of fields, more and more researchers and developers from diverse domains start to take advantage of DLs. In many circumstances, a developer leverages a DL framework and programs the training software in the form of source code (e.g., Python, Java). However, not all of the developers across domains are skilled at programming. It is highly desirable to provide a way so that a developer could focus on how to design and optimize their DL systems instead of spending too much time on programming. To simplify the programming process towards saving time and effort especially for beginners, we propose and implement DeepVisual, a visual programming tool for the design and development of DL systems. DeepVisual represents each layer of a neural network as a component. A user can drag-and-drop components to design and build a DL model, after which the training code is automatically generated. Moreover, DeepVisual supports to extract the neural network architecture on the given source code as input. We implement DeepVisual as a PyCharm plugin and demonstrate its usefulness on two typical use cases.",
    "author": [
      {
        "family": "Xie",
        "given": "Chao"
      },
      {
        "family": "Qi",
        "given": "Hua"
      },
      {
        "family": "Ma",
        "given": "Lei"
      },
      {
        "family": "Zhao",
        "given": "Jianjun"
      }
    ],
    "collection-title": "ICPC ’19",
    "container-title": "Proceedings of the 27th international conference on program comprehension",
    "id": "10.1109/ICPC.2019.00028",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "visualization, visual programming, deep neural networks, deep learning",
    "page": "130-134",
    "publisher": "IEEE Press",
    "publisher-place": "Montreal, Quebec, Canada",
    "title": "DeepVisual: A visual programming tool for deep learning systems",
    "title-short": "DeepVisual",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3484272.3484970",
    "ISBN": "9781450390897",
    "URL": "https://doi.org/10.1145/3484272.3484970",
    "abstract": "In teaching and learning programming at first-year-university level, simple languages with small feature sets are preferable over industry-strength languages with extensive feature sets, to reduce the learners’ cognitive load. At the same time, there is increasing pressure to familiarise students with mainstream languages early in their learning journey, and these languages accumulate features as years go by. In response to these competing requirements, we developed Source, a collection of JavaScript sublanguages with feature sets just expressive enough to introduce first-year computer science students to the elements of computation. These languages are supported by a web-based programming environment custom-built for learning at beginner’s level, which provides transpiler, interpreter, virtual machine, and algebraic-stepper-based implementations of the languages, and includes tracing, debugging, visualization, type-inference, and smart-editor features. This paper motivates the choice of JavaScript as starting point and describes the syntax and semantics of the Source languages compared to their parent language, and their implementations in the system. We report our experiences in developing and improving the languages and implementations over a period of three years, teaching a total of 1561 computer science first-year students at a university.",
    "author": [
      {
        "family": "Anderson",
        "given": "Boyd"
      },
      {
        "family": "Henz",
        "given": "Martin"
      },
      {
        "family": "Low",
        "given": "Kok-Lim"
      },
      {
        "family": "Tan",
        "given": "Daryl"
      }
    ],
    "collection-title": "SPLASH-e 2021",
    "container-title": "Proceedings of the 2021 ACM SIGPLAN international symposium on SPLASH-e",
    "id": "10.1145/3484272.3484970",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "teaching programming, learning tools, learning environments, JavaScript",
    "page": "87-96",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Shrinking JavaScript for CS1",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2538862.2539024",
    "ISBN": "9781450326056",
    "URL": "https://doi.org/10.1145/2538862.2539024",
    "abstract": "This workshop will conduct an exploration of the newly released Lego Mindstorms EV3 robot platform and its applicability to the college computer science curriculum. Participants will learn about the EV3 through handouts and hands-on programming exercises. The first part of the workshop will focus on demonstrating EV3 robots as well as the STEM concepts and computing concepts they illustrate. The second part of the workshop will focus in on the new capabilities of the EV3. This workshop will be more detailed than the vendor led workshop. It will be of benefit to participants new to Mindstorms robotics as well as those with NXT/RCX experience who want to see the evolution of the platform and new components featured in the EV3. These include a revision of the controller brick hardware and software, new color and gyroscopic sensors, and increased processing and memory capabilities. The organizers have a combined 20 years of experience using Mindstorms in CS courses (including courses in introductory programming, systems, and artificial intelligence) with Lego and third party programming environments. Participants must bring a Bluetooth-capable laptop (Mac or Windows), and will have a robot, software, and kit to use for the workshop. Participants will receive a promotion code to purchase a 10",
    "author": [
      {
        "family": "Klassner",
        "given": "Frank"
      },
      {
        "family": "Schafer",
        "given": "Benjamin"
      }
    ],
    "collection-title": "SIGCSE ’14",
    "container-title": "Proceedings of the 45th ACM technical symposium on computer science education",
    "id": "10.1145/2538862.2539024",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "mindstorms, lego, educational robotics, EV3",
    "page": "745-746",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using the new lego MindStorms EV3 robotics platform in CS courses (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3341525.3387428",
    "ISBN": "9781450368742",
    "URL": "https://doi.org/10.1145/3341525.3387428",
    "abstract": "This paper reports on an intervention in introductory Computer Graphics courses, where practical coursework is transitioned from standard OpenGL Graphics APIs to the Unity Game Development Engine. Game Development Engines (GDEs) provide powerful programming tools and computing components. Software development in GDEs is facilitated by full-fledged IDEs. Complex scene modeling and image rendering are managed through a rich catalogue of rendering assets. Graphics APIs are evolving towards a lower level of hardware abstraction, reduced overhead, and multithreading capabilities. Such changes in APIs benefit software developers who build graphics engines; how much they benefit Computer Graphics education is yet to be determined. New graphics APIs represent a shift in graphics programming practices, nearly as big as programmable GPUs and shader-based APIs over a decade ago. As then, Computer Graphics instructors have to decide: either use outdated models, or again change how Computer Graphics is taught. This paper describes an educational approach that acknowledges the increasing divide between the ease of use and development speed of GDEs, and the complexity and vastness of new graphics APIs. We show the use of a GDE as software development framework, to support programming assignments covering core Computer Graphics concepts. Relying on a GDE, such graphics assignments don’t have to shy away from shader-based graphics programming, while non-graphics low-level tasks are managed by the engine itself. With our approach, we hope to contribute to the discussion about evolving best practices in teaching Computer Graphics.",
    "author": [
      {
        "family": "Hmeljak",
        "given": "Dimitrij (Mitja)"
      },
      {
        "family": "Zhang",
        "given": "Holly"
      }
    ],
    "collection-title": "ITiCSE ’20",
    "container-title": "Proceedings of the 2020 ACM conference on innovation and technology in computer science education",
    "id": "10.1145/3341525.3387428",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "game development engine, educational technology, computer-aided learning, computer graphics",
    "page": "75-81",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Developing a computer graphics course with a game development engine",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3093338.3093346",
    "ISBN": "9781450352727",
    "URL": "https://doi.org/10.1145/3093338.3093346",
    "abstract": "We present performance results obtained with a new single-node performance benchmark of the R programming environment on the many-core Xeon Phi Knights Landing and standard Xeon-based compute nodes of the Stampede supercomputer cluster at the Texas Advanced Computing Center. The benchmark consists of microbenchmarks of linear algebra kernels and machine learning functionality that includes clustering and neural network training from the R distribution. The standard Xeon-based nodes outperformed their Xeon Phi counterparts for matrices of small to medium dimensions, performing approximately twice as fast for most of the linear algebra microbenchmarks. For matrices of medium to large dimensions, the Knights Landing nodes were competitive with or outperformed the standard Xeon-based nodes with most of the linear algebra microbenchmarks, executing as much as five times faster than the standard Xeon-based nodes. For the clustering and neural network training microbenchmarks, the standard Xeon-based nodes performed up to four times faster than their Xeon Phi counterparts for many large data sets, indicating that commonly used R packages may need to be reengineered to take advantage of existing optimized, scalable kernels.",
    "author": [
      {
        "family": "McCombs",
        "given": "James R."
      },
      {
        "family": "Michael",
        "given": "Scott"
      }
    ],
    "collection-title": "PEARC ’17",
    "container-title": "Proceedings of the practice and experience in advanced research computing 2017 on sustainability, success and impact",
    "id": "10.1145/3093338.3093346",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "keyword": "scalability, many-core, benchmarking, Xeon Phi, XSEDE, R",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Performance benchmarking of the r programming environment on the stampede 1.5 supercomputer",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3368308.3415397",
    "ISBN": "9781450370455",
    "URL": "https://doi.org/10.1145/3368308.3415397",
    "abstract": "Jupyter notebooks are widely used in industry and in academic research, but have only begun to make inroads into the classroom. The design of the Jupyter notebook is in many ways well suited for teaching subjects in information technology and computer science, but it is a tool that departs significantly from a standard text editor or integrated development environment, and thus carries with it several unique advantages as well as several surprising potential pitfalls. As use of Jupyter notebooks has grown, so has criticism of the notebook, for varied reasons: notebooks can behave in unexpected ways, they can be difficult to reproduce, they open up potential security issues, and they may encourage poor coding practices. A set of best practices to guide instructors and help addressing these concerns when using Jupyter notebooks in the classroom is currently lacking. This paper addresses the strengths and weaknesses of the Jupyter notebook for education, drawing on existing literature as well as the author’s experience teaching a range of courses with Jupyter notebooks for over five years, and recommends a set of best practices for teaching with the Jupyter notebook.",
    "author": [
      {
        "family": "Johnson",
        "given": "Jeremiah W."
      }
    ],
    "collection-title": "SIGITE ’20",
    "container-title": "Proceedings of the 21st annual conference on information technology education",
    "id": "10.1145/3368308.3415397",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "literate programming, jupyter notebooks, ipython",
    "page": "32-37",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Benefits and pitfalls of jupyter notebooks in the classroom",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/800227.806922",
    "ISBN": "0897910311",
    "URL": "https://doi.org/10.1145/800227.806922",
    "abstract": "The long-term goal of the User Software Engineering (USE) project at the University of California, San Francisco, is to provide an integrated homogeneous programming environment for the design and development of interactive information systems. Realization of this goal involves the development of new software tools, their integration with existing tools, and the creation of an information system development methodology in which these tools are systematically used [1,2].The successful construction of interactive information systems requires the utilization of principles of user-centered design [3,4,5], combined with features traditionally associated with the separate areas of programming languages, operating systems, and data base management [6]. It has become increasingly clear that the key to being able to provide such a unified view lies in providing a unified view of data [7]. The potential benefits of such a unification are considerable, including:1) conceptual simplification of the system structure permitting, for example, joint design of data structures and data bases2) the elimination of duplication or inconsistencies among diverse software components3) the ability to achieve greater reliability in systems because of reduced dependence upon multiple software systems",
    "author": [
      {
        "family": "Wasserman",
        "given": "Anthony I."
      }
    ],
    "container-title": "Proceedings of the 1980 workshop on data abstraction, databases and conceptual modeling",
    "id": "10.1145/800227.806922",
    "issued": {
      "date-parts": [
        [
          1980
        ]
      ]
    },
    "page": "198-200",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The extension of data abstraction to database management",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1930464.1930474",
    "ISBN": "9781450305204",
    "URL": "https://doi.org/10.1145/1930464.1930474",
    "abstract": "Complexity being an essential part of our everyday and occupational life, the following question arises: Which fundamental skills do pupils need to develop, in order to be well prepared for handling future complex technological, and social, systems? We believe that general education should address this issue by cultivating computational—or rather \"informatical\"— thinking, i. e. an informatical view on the world.The educational programming environment Greenfoot consolidates the strengths of traditional microworlds with Java’s scalability [1], thus enabling the provision of rather complex systems, most notably simulations of material or traffic streams. In Greenfoot, these systems can be interactively explored and manipulated. Thus Greenfoot is not only an excellent learning environment for introductory programming courses but it is also particularly well suited to address more application-oriented issues in computer science.In a one week school project pupils in their eighth year were presented with a Greenfoot simulation of a highly simplified airport baggage handling system. Using the example of baggage handling, they got involved not only with programming but also with applied computing, namely with issues related to the field of Business Informatics (BI, German Wirtschaftsinformatik). Our aim in including applied computing issues in the school project was to present a broad image of computer science.",
    "author": [
      {
        "family": "Rick",
        "given": "Detlef"
      },
      {
        "family": "Ludwig",
        "given": "Julia"
      },
      {
        "family": "Meyer",
        "given": "Sebastian"
      },
      {
        "family": "Rehder",
        "given": "Carsten"
      },
      {
        "family": "Schirmer",
        "given": "Ingrid"
      }
    ],
    "collection-title": "Koli calling ’10",
    "container-title": "Proceedings of the 10th koli calling international conference on computing education research",
    "id": "10.1145/1930464.1930474",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "keyword": "simulation, complex systems, business informatics and general education, applied computing, Greenfoot",
    "page": "68-69",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Introduction to business informatics with greenfoot using the example of airport baggage handling",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1080/13614568.2016.1152314",
    "ISSN": "1361-4568",
    "URL": "https://doi.org/10.1080/13614568.2016.1152314",
    "abstract": "Students in secondary education strive hard enough to understand basic programming concepts. With all that is known regarding the benefits of programming, little is the published evidence showing how high school students can learn basic programming concepts following innovative instructional formats correctly with the respect to gain/enhance their computational thinking skills. This distinction has caused lack of their motivation and interest in Computer Science courses. This case study presents the opinions of twenty-eight n = 28 high school students who participated voluntarily in a 3D-game-like environment created in Second Life. This environment was combined with the 2D programming environment of Scratch4SL for the implementation of programming concepts i.e. sequence and concurrent programming commands in a blended instructional format. An instructional framework based on Papert’s theory of Constructionism to assist students how to coordinate or manage better the learning material in collaborative practice-based learning activities is also proposed. By conducting a mixed-method research, before and after finishing several learning tasks, students’ participation in focus group qualitative data and their motivation based on their experiences quantitative data are measured. Findings indicated that an instructional design framework based on Constructionism for acquiring or empowering students’ social, cognitive, higher order and computational thinking skills is meaningful. Educational implications and recommendations for future research are also discussed.",
    "author": [
      {
        "family": "Pellas",
        "given": "Nikolaos"
      },
      {
        "family": "Peroutseas",
        "given": "Efstratios"
      }
    ],
    "container-title": "New Rev. Hypermedia Multimedia",
    "id": "10.1080/13614568.2016.1152314",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2017,
          1
        ]
      ]
    },
    "page": "51-79",
    "publisher": "Taylor &amp; Francis, Inc.",
    "publisher-place": "USA",
    "title": "Leveraging Scratch4SL and second life to motivate high school students’ participation in introductory programming courses: Findings from a case study",
    "title-short": "Leveraging Scratch4SL and second life to motivate high school students’ participation in introductory programming courses",
    "type": "article-journal",
    "volume": "23"
  },
  {
    "DOI": "10.1145/3408877.3439661",
    "ISBN": "9781450380621",
    "URL": "https://doi.org/10.1145/3408877.3439661",
    "abstract": "The growing interest in teaching Computer Science (CS) to K-12 students has led to the development of blocks-based programming languages (BBPLs) for young students where a program can be created by connecting blocks in a structured way. One of the benefits of a BBPL is removing the necessity to recall the syntax rules of a language. However, the visual nature of these languages makes learning and creating code difficult for children with visual impairments and blindness (VIB). Although a few BBPLs were designed for children with VIB, such environments are rarely used by sighted children. Therefore, to investigate the requirements for designing and implementing an accessible blocks-based programming environment that can be used by both students with and without VIB, we developed a BBPL environment for middle school children. The environment consists of a two-dimensional grid where a character can be moved by creating a simple blocks program. Our future plans include performing several empirical experiments to evaluate our BBPL, including the educational impact of the environment on all students and accessibility support for students with VIB. To perform the study, we also plan to prepare lessons for training the students. The results of the study will inform the design of future BBPL environments, as well as contribute toward broadening participation in computing by enabling children with visual impairments to participate fully in CS education opportunities.",
    "author": [
      {
        "family": "Tabassum",
        "given": "Moumita"
      },
      {
        "family": "Gray",
        "given": "Jeff"
      },
      {
        "family": "Smith",
        "given": "Derrick"
      }
    ],
    "collection-title": "SIGCSE ’21",
    "container-title": "Proceedings of the 52nd ACM technical symposium on computer science education",
    "id": "10.1145/3408877.3439661",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "visual impairment, blocks-based programming environment",
    "page": "1309",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Designing accessibility into blocks languages",
    "type": "paper-conference"
  },
  {
    "ISBN": "3832540172",
    "abstract": "Originally developed by James McCartney in 1996 and now an open source project, SuperCollider is a software package for the synthesis and control of audio in real time. Currently, it represents the state of the art in the field of audio programming: there is no other software available that is equally powerful, efficient or flexible. Yet, SuperCollider is often approached with suspicion or awe by novices, but why? One of the main reasons is the use of a textual user interface. Furthermore, like most software packages that deal with audio, SuperCollider prerequisites a series of skills, ranging from expertise in analog/digital signal processing, to musical composition, to computer science. However, as the beginner overcomes these initial obstacles and understands the powerful flexibility of SuperCollider, what once were seen as weaknesses become its strengths. SuperCollider’s features also mean versatility in advanced software applications, generality in terms of computer modelling, and expressivity in terms of symbolic representations. This book aims at providing a brief overview of, and an introduction to, the SuperCollider programming environment. It also intends to informally present, by employing SuperCollider, a series of key notions relevant to what is broadly referred to as computer music. Andrea Valle is a researcher/aggregate professor in film, photography and television at the University of Turin-DAMS, and is active as a musician and composer. He has been a SuperCollider user since 2005.",
    "author": [
      {
        "family": "Valle",
        "given": "Andrea"
      }
    ],
    "id": "10.5555/3055864",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Logos Verlag",
    "publisher-place": "DEU",
    "title": "Introduction to SuperCollider",
    "type": "book"
  },
  {
    "DOI": "10.1109/CGIV.2008.24",
    "ISBN": "9780769533599",
    "URL": "https://doi.org/10.1109/CGIV.2008.24",
    "abstract": "VRML is one of the most common and popular virtual reality development tools available in the market. This low end product is widely used in school or college. High end product such as Sense8, EON, Cartia and many others have been in the market for quite number of years. These applications have been popularly used in the big industries such as medical, automobile and infrastructure design. However, for our purpose of environment visualization and immersion, Virtools development kit was used. The main focus of this paper is to describe the approach used in producing an immersive and interactive 3D environment used to treat acrophobia. The 3D environment consists of a busy city surrounded by tall buildings. The advantages and benefit of using Virtools as virtual reality development tool is then explained.",
    "author": [
      {
        "family": "Balbed",
        "given": "Mustafa Agil Muhamad"
      },
      {
        "family": "Ibrahim",
        "given": "Nazrita"
      },
      {
        "family": "Yusof",
        "given": "Azmi Mohd"
      }
    ],
    "collection-title": "CGIV ’08",
    "container-title": "Proceedings of the 2008 fifth international conference on computer graphics, imaging and visualisation",
    "id": "10.1109/CGIV.2008.24",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "Virtual Reality, Virtools, 3D Virtual Environment",
    "page": "101-106",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Implementation of virtual environment using VIRTOOLS",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2839509.2850525",
    "ISBN": "9781450336857",
    "URL": "https://doi.org/10.1145/2839509.2850525",
    "abstract": "Block languages (e.g., Scratch, Snap!, Alice, App Inventor, Blockly) offer a gentle introduction to programming and have been adopted widely in both K-12 and CS0 courses. However, block languages often are dependent on the mouse/keyboard for input and typically are visual in their output and representation. Because of these dependencies, students with a disability (e.g., mobility limitations or vision impairment) generally are unable to use block languages, thereby reducing the opportunities for broader participation in computational learning activities. Given the increasing need to broaden the participation of computing to those with diverse skills and backgrounds, it is important that the tools used to initiate the earliest entre into computing do not erect immediate roadblocks that impede initial interest and opportunity. There are many variations of user interfaces and assistive technologies that benefit those who may have difficulties utilizing traditional Graphical User Interfaces (GUIs), but these tools often cannot be used universally across block languages. As more block languages are being developed and integrated into K12 and University curriculum, it is imperative that accessible solutions are discussed and implemented. These discussions require participation from the block language developer community, accessible computing community, and those educators who encounter accessibility needs among the students in their classrooms. The goal of this lightning talk is to call attention to the need for more accessible block-based programming environments and to spark conversation surrounding possible standard accessibility APIs that could possibly be supported by block language environment tool developers.",
    "author": [
      {
        "family": "Wagner",
        "given": "Amber"
      },
      {
        "family": "Gray",
        "given": "Jeff"
      },
      {
        "family": "Marghitu",
        "given": "Daniela"
      },
      {
        "family": "Stefik",
        "given": "Andreas"
      }
    ],
    "collection-title": "SIGCSE ’16",
    "container-title": "Proceedings of the 47th ACM technical symposium on computing science education",
    "id": "10.1145/2839509.2850525",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "keyword": "broadening participation, block languages, accessibility",
    "page": "497",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Raising the awareness of accessibility needs in block languages (abstract only)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3328778.3372680",
    "ISBN": "9781450367936",
    "URL": "https://doi.org/10.1145/3328778.3372680",
    "abstract": "In the past several years, there has been an increase in web-based compilers that allow students to learn how to code using a browser. Many Universities use online code editors for their large Computer Science (CS) courses. For example, the CS200 course at UC Berkeley uses Jupyter Notebooks to teach Python for data science to 800+ students. All the students in the course must write and submit their code assignments in the web-browser. These online code editors for large CS courses presents several benefits. One benefit is that it becomes easier to monitor the steps that a student takes to solve a coding problem since keystrokes can be tracked using Javascript. Another benefit is that the code written by students can be stored in one central database, creating less barriers for code analysis. The CodeKey project aims to take advantage of analyzing code patterns of students in a CS course in order to find key insights. CodeKey aims to find these insights by monitoring the interactions (i.e. clicks and keystrokes) of students as each student attempts to solve a coding problem. The goal is to study the code patterns of students in a CS course in order to understand similarities and differences between students who perform well on a problem and students who do not. We also aim to study how revealing these coding patterns to a student can increase his understanding of how to solve a difficult coding problem by showing common mistakes, and by showing simple steps that lead to the correct solution.",
    "author": [
      {
        "family": "Williams",
        "given": "Renaldo"
      },
      {
        "family": "Garcia",
        "given": "Dan"
      }
    ],
    "collection-title": "SIGCSE ’20",
    "container-title": "Proceedings of the 51st ACM technical symposium on computer science education",
    "id": "10.1145/3328778.3372680",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "web-compilers, intelligent tutor systems, computer science education",
    "page": "1357",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CodeKey - an online code editor to study code patterns and enhance student performance in CS courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3484272.3484959",
    "ISBN": "9781450390897",
    "URL": "https://doi.org/10.1145/3484272.3484959",
    "abstract": "As Scratch has become one of the most popular educational programming languages, understanding its common programming idioms can benefit both computing educators and learners. This understanding can fine-tune the curricular development to help learners master the fundamentals of writing idiomatic code in their programming pursuits. Unfortunately, the research community’s understanding of what constitutes idiomatic Scratch code has been limited. To help bridge this knowledge gap, we systematically identified idioms as based on canonical source code, presented in widely available educational materials. We implemented a tool that automatically detects these idioms to assess their prevalence within a large dataset of over 70K Scratch projects in different experience backgrounds and project categories. Since communal learning and the practice of remixing are one of the cornerstones of the Scratch programming community, we studied the relationship between common programming idioms and remixes. Having analyzed the original projects and their remixes, we observed that different idioms may associate with dissimilar types of code changes. Code changes in remixes are desirable, as they require a meaningful programming effort that spurs the learning process. The ability to substantially change a project in its remixes hinges on the project’s code being easy to understand and modify. Our findings suggest that the presence of certain common idioms can indeed positively impact the degree of code changes in remixes. Our findings can help form a foundation of what comprises common Scratch programming idioms, thus benefiting both introductory computing education and Scratch programming tools.",
    "author": [
      {
        "family": "Long",
        "given": "Xingyu"
      },
      {
        "family": "Techapalokul",
        "given": "Peeratham"
      },
      {
        "family": "Tilevich",
        "given": "Eli"
      }
    ],
    "collection-title": "SPLASH-e 2021",
    "container-title": "Proceedings of the 2021 ACM SIGPLAN international symposium on SPLASH-e",
    "id": "10.1145/3484272.3484959",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "Scratch, Project remixing, Programming idioms, Novice programmers, Block-based programming",
    "page": "1-12",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The common coder’s scratch programming idioms and their impact on project remixing",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.chb.2019.03.003",
    "ISSN": "0747-5632",
    "URL": "https://doi.org/10.1016/j.chb.2019.03.003",
    "author": [
      {
        "family": "Papavlasopoulou",
        "given": "Sofia"
      },
      {
        "family": "Sharma",
        "given": "Kshitij"
      },
      {
        "family": "Giannakos",
        "given": "Michail N."
      }
    ],
    "container-title": "Comput. Hum. Behav.",
    "id": "10.1016/j.chb.2019.03.003",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2020,
          4
        ]
      ]
    },
    "keyword": "Learning strategies, Gender differences, Eye-tracking, Computational thinking, Coding",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Coding activities for children: Coupling eye-tracking with qualitative data to investigate gender differences",
    "title-short": "Coding activities for children",
    "type": "article-journal",
    "volume": "105"
  },
  {
    "DOI": "10.1109/FIE49875.2021.9637261",
    "URL": "https://doi.org/10.1109/FIE49875.2021.9637261",
    "abstract": "This Innovative Practice Full Paper presents BlocklyPar, a set of three tutorial games to move from sequential to parallel programming using a block-based visual language. Block-based tutorial games are attractive tools for introducing programming to novices. A few of existing tools can express multiple tasks running at the same time, but none of them address parallel programming concepts and terms used in the field of parallel computing. Our tutorial games are targeted for first-year Computer Science students, as a resource to anticipate parallel computing using a self-taught approach with engaging challenges. The challenges involve university students’ day-to-day tasks to make the games more meaningful for the audience, thus collaborating with the idea that everyday tasks can benefit from parallel approaches. The first game introduces the programming environment and the sequential blocks; the second introduces the concepts of tasks, resources allocation, and parallel task execution; and the third presents the concepts of computational load distribution and performance metrics for evaluating improvements in a parallel solution. The concepts are expressed through animation components and three new programming blocks. We have conducted preliminary tests with Computer Science students for evaluating the platform usage and parallel programming concepts assessed. The results suggest that the games contribute to the student’s learning on parallelism as an extension of practicing sequential programming. It can also motivate students to design parallel solutions to explore today’s multi-core and multiprocessor computers.",
    "author": [
      {
        "family": "Solórzano",
        "given": "Ana Luisa Veroneze"
      },
      {
        "family": "Charão",
        "given": "Andrea Schwertner"
      }
    ],
    "container-title": "2021 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE49875.2021.9637261",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "1-8",
    "publisher": "IEEE Press",
    "publisher-place": "Lincoln, NE, USA",
    "title": "BlocklyPar: From sequential to parallel with block-based visual programming",
    "title-short": "BlocklyPar",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/s10639-023-12325-z",
    "ISSN": "1360-2357",
    "URL": "https://doi.org/10.1007/s10639-023-12325-z",
    "abstract": "While numerous studies have highlighted the potential benefits of programming environment (PE) use for children’s learning, the boundary conditions of children’s PE acceptance within the programming education context are less clear. This study fills this gap in the literature by investigating the critical determinants of children’s PE use intention and extending the boundary conditions to programming competition, computational thinking, and programming modality. A total of 1527 primary students participated in this study. Using structural equation modelling (SEM) analyses, the measurement model was validated, and the configural, metric and scalar invariance of the measurement model was established. The structural model was also confirmed, with most of the hypothesized relationships were supported. Multigroup SEM analyses were conducted to compare structural path coefficient differences across different personal moderators (i.e., gender, grade, and experience), environmental moderators (i.e., both parents’ education level), and PE use-relevant moderators (i.e., programming competition, computational thinking, and programming modality). The results revealed significant path differences in six group comparisons, with most of the path differences associated with perceived self-efficacy and perceived ease of use. It should be noted that no significant path differences were identified for the gender and programming competition group comparisons. This work serves as a pioneer study of a comprehensive understanding of the determinants and moderators of children’s PE use intention. The findings offer important theoretical implications through accommodating essential constructs within a PE acceptance framework and recommending effective strategies to improve primary students’ PE acceptance for programming learning in primary education.",
    "author": [
      {
        "family": "Cheng",
        "given": "Miaoting"
      },
      {
        "family": "Lai",
        "given": "Xiaoyan"
      },
      {
        "family": "Tao",
        "given": "Da"
      },
      {
        "family": "Lai",
        "given": "Juntong"
      },
      {
        "family": "Yang",
        "given": "Jun"
      }
    ],
    "container-title": "Education and Information Technologies",
    "id": "10.1007/s10639-023-12325-z",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2023,
          11
        ]
      ]
    },
    "keyword": "Programming education, Programming environment, Technology acceptance, Primary students, Multigroup structural equation modeling",
    "page": "939-969",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Children’s programming environment acceptance: Extending the boundary conditions to programming competition, computational thinking, and programming modality",
    "title-short": "Children’s programming environment acceptance",
    "type": "article-journal",
    "volume": "29"
  },
  {
    "ISBN": "9798516902383",
    "abstract": "In recent years, we have witnessed a progressive increase in enrollment in computer science education programs; this has unfortunately been matched by a constantly low representation of students with visual impairments in the area of computer science. A possible explanation for this phenomenon is the environmental aspects of teaching programming to students with visual impairment, such as input (keyboard and mouse), output (display screen), and feedback (visual information). Although there exist different techniques (e.g., Block-based programming, program visualization, and tangible interfaces) which have proven to be effective for the development of creativity and computational thinking in students, learners with visual impairments face limitations that make difficult or impossible to use them due to the dependence on visual artifacts. Therefore, there is an urgent need for interfaces that allow novice students with visual impairments and low vision to develop computational thinking skills. We addressed the challenges of learning basic programming concepts by young learners with visual impairments and low vision through a literature review. The systematic review provides a guideline for an effective design of accessible programming learning environments for novice students with visual impairments and low vision. We obtained an in-depth knowledge of features needed to make Block-based environments accessible and feedback to improve our prototype through a preliminary user study performed with nine participants. Moreover, this dissertation presents the final version of the tangible music programming tool and findings of a qualitative study performed to validate the tool. The results show that the participants could gain a deep understanding of basic programming concepts using our system.",
    "author": [
      {
        "family": "Utreras-Mercado",
        "given": "Emmanuel"
      },
      {
        "family": "Huiping",
        "suffix": "Cao"
      },
      {
        "family": "Loana",
        "suffix": "Mason"
      },
      {
        "family": "O",
        "given": "Z.",
        "suffix": "Toups"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI28416713",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "note": "AAI28416713",
    "publisher": "New Mexico State University",
    "publisher-place": "USA",
    "title": "Tangible music programming tool for students with visual impairments and low vision",
    "type": "thesis"
  },
  {
    "ISBN": "012803761X",
    "abstract": "Shared Memory Application Programming presents the key concepts and applications of parallel programming, in an accessible and engaging style applicable to developers across many domains. Multithreaded programming is today a core technology, at the basis of all software development projects in any branch of applied computer science. This book guides readers to develop insights about threaded programming and introduces two popular platforms for multicore development: OpenMP and Intel Threading Building Blocks (TBB). Author Victor Alessandrini leverages his rich experience to explain each platforms design strategies, analyzing the focus and strengths underlying their often complementary capabilities, as well as their interoperability. The book is divided into two parts: the first develops the essential concepts of thread management and synchronization, discussing the way they are implemented in native multithreading libraries (Windows threads, Pthreads) as well as in the modern C++11 threads standard. The second provides an in-depth discussion of TBB and OpenMP including the latest features in OpenMP 4.0 extensions to ensure readers skills are fully up to date. Focus progressively shifts from traditional thread parallelism to modern task parallelism deployed by modern programming environments. Several chapter include examples drawn from a variety of disciplines, including molecular dynamics and image processing, with full source code and a software library incorporating a number of utilities that readers can adapt into their own projects.Designed to introduce threading and multicore programming to teach modern coding strategies for developers in applied computingLeverages author Victor Alessandrini’s rich experience to explain each platforms design strategies, analyzing the focus and strengths underlying their often complementary capabilities, as well as their interoperabilityIncludes complete, up-to-date discussions of OpenMP 4.0 and TBBBased on the authors training sessions, including information on source code and software libraries which can be repurposed",
    "author": [
      {
        "family": "Alessandrini",
        "given": "Victor"
      }
    ],
    "edition": "1st",
    "id": "10.5555/2911144",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "publisher": "Morgan Kaufmann Publishers Inc.",
    "publisher-place": "San Francisco, CA, USA",
    "title": "Shared memory application programming: Concepts and strategies in multicore application programming",
    "title-short": "Shared memory application programming",
    "type": "book"
  },
  {
    "DOI": "10.1145/3545947.3569611",
    "ISBN": "9781450394338",
    "URL": "https://doi.org/10.1145/3545947.3569611",
    "abstract": "For CS50 at Harvard, we have long provided students with a standardized programming environment, to avoid start-of-term technical difficulties that might otherwise arise if students had to install and configure compilers, interpreters, and debuggers on their own Macs and PCs. (For many students, \"hello, world\" is challenge enough on day 0, without also encountering \"command not found\" at the same time!) We originally provided students with shell accounts on a university-managed cluster of systems. We then transitioned to a cloud-based equivalent so as to manage the systems ourselves, root access and all. We transitioned thereafter to client-side virtual machines, to scale to more students and enable GUI-based assignments. We have since transitioned to web-based environments, complete with code tabs, terminal windows, and file explorers, initially implemented atop AWS Cloud9 and now, most recently, GitHub Codespaces, an implementation of Visual Studio (VS) Code in the cloud, free for teachers and students alike. In this workshop, we’ll discuss the pedagogical and technological advantages and disadvantages of every approach and focus most of our time, hands-on, on using and configuring GitHub Codespaces itself for teaching and learning. Along the way, attendees will learn how to create their own Docker images and \"devcontainers\" for their own classes and any languages they teach. Attendees will learn what is possible educationally by writing their own VS Code extensions as well. And how, at term’s end, to \"offboard\" students to VS Code itself on their own Macs and PCs, so as to continue programming independent of Codespaces.",
    "author": [
      {
        "family": "Malan",
        "given": "David J."
      },
      {
        "family": "Carter",
        "given": "Jonathan"
      },
      {
        "family": "Liu",
        "given": "Rongxin"
      },
      {
        "family": "Zenke",
        "given": "Carter"
      }
    ],
    "collection-title": "SIGCSE 2023",
    "container-title": "Proceedings of the 54th ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3545947.3569611",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "web application, web app, text editor, terminal window, programming, integrated development environment, ide, gui, graphical user interface, editor, docker, container, command-line interface, code editor, code, cli",
    "page": "1183",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Providing students with standardized, cloud-based programming environments at term’s start (for free)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3563296",
    "URL": "https://doi.org/10.1145/3563296",
    "abstract": "Block-based programming environments, already popular in computer science education, have been successfully used to make programming accessible to end-users in domains like robotics, mobile apps, and even DevOps. Most studies of these applications have examined small programs that fit within a single screen, yet real-world programs often grow large, and editing these large block-based programs quickly becomes unwieldy. Traditional programming language features, like functions, allow programmers to decompose their programs. Unfortunately, both previous work, and our own findings, suggest that end-users rarely use these features, resulting in large monolithic code blocks that are hard to understand. In this work, we introduce a block-based system that provides users with a hierarchical, domain-specific program structure and requires them to decompose their programs accordingly. Through a user study with 92 users, we compared this approach, which we call guided program decomposition, to a traditional system that supports functions, but does not require decomposition. We found that while almost all users could successfully complete smaller tasks, those who decomposed their programs were significantly more successful as the tasks grew larger. As expected, most users without guided decomposition did not decompose their programs, resulting in poor performance on larger problems. In comparison, users of guided decomposition performed significantly better on the same tasks. Though this study investigated only a limited selection of tasks in one specific domain, it suggests that guided decomposition can benefit end-user programmers. While no single decomposition strategy fits all domains, we believe that similar domain-specific sub-hierarchies could be found for other application areas, increasing the scale of code end-users can create and understand.",
    "author": [
      {
        "family": "Ritschel",
        "given": "Nico"
      },
      {
        "family": "Fronchetti",
        "given": "Felipe"
      },
      {
        "family": "Holmes",
        "given": "Reid"
      },
      {
        "family": "Garcia",
        "given": "Ronald"
      },
      {
        "family": "Shepherd",
        "given": "David C."
      }
    ],
    "container-title": "Proc. ACM Program. Lang.",
    "id": "10.1145/3563296",
    "issue": "OOPSLA2",
    "issued": {
      "date-parts": [
        [
          2022,
          10
        ]
      ]
    },
    "keyword": "program decomposition, mobile robots, block-based programming",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Can guided decomposition help end-users write larger block-based programs? A mobile robot experiment",
    "type": "article-journal",
    "volume": "6"
  },
  {
    "DOI": "10.1145/3427596",
    "URL": "https://doi.org/10.1145/3427596",
    "abstract": "As Information and Communication Technology (ICT) literacy education has recently shifted to fostering computing thinking ability as well as ICT use, many countries are conducting research on national curriculum and evaluation. In this study, we measured Korean students’ ICT literacy levels by using the national measurement tool that assesses abilities of the IT (Information Technology) area and the CT (Computational Thinking) area. A research team revised an existing ICT literacy assessment tool for the IT test and developed a new CT test environment in which students could perform actual coding through a web-based programming tool such as Scratch. Additionally, after assessing ICT literacy levels, differences in ICT literacy levels by gender and grade were analyzed to provide evidence for national education policies. Approximately 23,000 elementary and middle school students participated in the 2018 national assessment of ICT literacy, accounting for 1",
    "author": [
      {
        "family": "Kim",
        "given": "Han Sung"
      },
      {
        "family": "Kim",
        "given": "Soohwan"
      },
      {
        "family": "Na",
        "given": "Wooyoul"
      },
      {
        "family": "Lee",
        "given": "Woon Jee"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/3427596",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2021,
          1
        ]
      ]
    },
    "keyword": "secondary education, elementary education, computational thinking, ICT literacy, 21st century abilities",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Extending computational thinking into information and communication technology literacy measurement: Gender and grade issues",
    "title-short": "Extending computational thinking into information and communication technology literacy measurement",
    "type": "article-journal",
    "volume": "21"
  },
  {
    "ISBN": "9780542825583",
    "abstract": "The focus of this dissertation work is the formulation and improvement of anemia management process involving trial-and-error. A two-stage method is adopted toward this objective. Given a medical treatment process, a discrete Markov representation is first derived as a formal translation of the treatment process to a control problem under uncertainty. A simulative numerical solution of the control problem is then obtained on-the-fly in the form of a control law maximizing the long-term benefit at each decision stage. Approximate dynamic programming methods are employed in the proposed solution. The motivation underlying this choice is that, in reality, some patient characteristics, which are critical for the sake of treatment, cannot be determined through diagnosis and remain unknown until early stages of treatment, when the patient demonstrates them upon actions by the decision maker. A review of these simulative control tools, which are studied extensively in reinforcement learning theory, is presented. Two approximate dynamic programming tools, namely SARSA and Q -learning, are introduced. Their performance in discovering the optimal individualized drug dosing policy is illustrated on hypothetical patients made up as fuzzy models for simulations. As an addition to these generic reinforcement learning methods, a state abstraction scheme for the considered application domain is also proposed. The control methods of this study, capturing the essentials of a drug delivery problem, constitutes a novel computational framework for model-free medical treatment. Experimental evaluation of the dosing strategies produced by the proposed methods against the standard policy, which is being followed actually by human experts in Kidney Diseases Program, University of Louisville, shows the advantages for use of reinforcement learning in the drug dosing problem in particular and in medical decision making in general.",
    "author": [
      {
        "family": "Muezzinoglu",
        "given": "Mehmet K."
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1236791",
    "issued": {
      "date-parts": [
        [
          2006
        ]
      ]
    },
    "note": "AAI3228046",
    "publisher": "University of Louisville",
    "publisher-place": "USA",
    "title": "Approximate dynamic programming for anemia management",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3626253.3633427",
    "ISBN": "9798400704246",
    "URL": "https://doi.org/10.1145/3626253.3633427",
    "abstract": "For CS50 at Harvard, we have long provided students with a standardized programming environment, to avoid start-of-term technical difficulties that might otherwise arise if students had to install and configure compilers, interpreters, and debuggers on their own Macs and PCs. (For many students, \"hello, world\" is challenge enough on day 0, without also encountering \"command not found\" at the same time!) We originally provided students with shell accounts on a university-managed cluster of systems. We then transitioned to a cloud-based equivalent so as to manage the systems ourselves, root access and all. We transitioned thereafter to client-side virtual machines, to scale to more students and enable GUI-based assignments. We have since transitioned to web-based environments, complete with code tabs, terminal windows, and file explorers, initially implemented atop AWS Cloud9 and now, most recently, GitHub Codespaces, an implementation of Visual Studio (VS) Code in the cloud, free for teachers and students alike. In this workshop, we’ll discuss the pedagogical and technological advantages and disadvantages of every approach and focus most of our time, hands-on, on using and configuring GitHub Codespaces itself for teaching and learning. Along the way, attendees will learn how to create their own Docker images and \"devcontainers\" for their own classes and any languages they teach. Attendees will learn what is possible educationally by writing their own VS Code extensions as well. And how, at term’s end, to \"offboard\" students to VS Code itself on their own Macs and PCs, so as to continue programming independent of Codespaces.",
    "author": [
      {
        "family": "Malan",
        "given": "David J."
      },
      {
        "family": "Liu",
        "given": "Rongxin"
      },
      {
        "family": "Zenke",
        "given": "Carter"
      },
      {
        "family": "Lloyd",
        "given": "Doug"
      }
    ],
    "collection-title": "SIGCSE 2024",
    "container-title": "Proceedings of the 55th ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3626253.3633427",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "cli, code, code editor, command-line interface, container, docker, editor, graphical user interface, gui, ide, integrated development environment, programming, terminal window, text editor, web app, web application",
    "page": "1903",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Providing students with standardized, cloud-based programming environments at term’s start (for free)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ITNG.2015.47",
    "ISBN": "9781479988280",
    "URL": "https://doi.org/10.1109/ITNG.2015.47",
    "abstract": "Several virtual communities have spread during the last decade where hundreds of people interact and socialize. Users use these communities in many fields including education, health, business, and entertainment. They use them to communicate, share information, and collaborate to achieve common goals and finish their tasks. To our knowledge, no existing literature or research studies show the benefit of using virtual world in 1) improving software engineering education, 2) enhancing the collaboration in distributed software development environment, and 3) increasing their effectiveness in the distributed developers’ progress. For this purpose we conducted a case study to test effect of integrating a virtual environment called CVE in software development environments. This study presents both qualitative and quantitative analysis of the data collected from the case study surveys and log files. It conducted a survey on the users’ preferences a. Also, it collected data about the developer’s interactions with the 3D objects, and analyzed the collected results.",
    "author": [
      {
        "family": "Bani-Salameh",
        "given": "Hani"
      },
      {
        "family": "Jeffery",
        "given": "Clinton"
      }
    ],
    "collection-title": "ITNG ’15",
    "container-title": "Proceedings of the 2015 12th international conference on information technology - new generations",
    "id": "10.1109/ITNG.2015.47",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "Virtual Environments, Social Networking, Social Interaction, IDE (Integrated Development Environment), CVEs, 3D World",
    "page": "255-260",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Evaluating the effect of 3D world integration within a social software environment",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/268084.268090",
    "ISBN": "0897918894",
    "URL": "https://doi.org/10.1145/268084.268090",
    "abstract": "Although a computer science curriculum may use a single language as its \"core\" language, many curricula require students to learn and use multiple languages for course or practicum work. Students benefit from the exposure to other languages and other language models. However, a problem arising from the multi-lingual nature of a curriculum is the necessity to learn and use different development environments and language front-ends. GRASP (Graphical Representations of Algorithms, Structures, and Processes) is a software engineering tool currently being successfully utilized as a common development environment for the multi-lingual computer science curriculum at Auburn University. Besides providing a common front-end for different languages, GRASP also provides automated visualization of source code in the form of the control structure diagram and the complexity profile graph. This paper describes GRASP and its current use in the computer science curriculum. GRASP is freely available via the Internet at the following URL: http://www.eng.auburn.edu/grasp",
    "author": [
      {
        "family": "Hendrix",
        "given": "T. Dean"
      },
      {
        "family": "Barowski",
        "given": "Larry A."
      },
      {
        "family": "Cross",
        "given": "James H."
      }
    ],
    "collection-title": "SIGCSE ’97",
    "container-title": "Proceedings of the twenty-eighth SIGCSE technical symposium on computer science education",
    "id": "10.1145/268084.268090",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "page": "20-24",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A visual development environment for multi-lingual curricula",
    "type": "paper-conference"
  },
  {
    "ISBN": "0387898816",
    "abstract": "Ecology is more quantitative and theory-driven than ever before, and A Primer of Ecology with R combines an introduction to the major theoretical concepts in general ecology with a cutting edge open source tool, the R programming language. Starting with geometric growth and proceeding through stability of multispecies interactions and species-abundance distributions, this book demystifies and explains fundamental ideas in population and community ecology. Graduate students in ecology, along with upper division undergraduates and faculty, will find this to be a useful overview of important topics. In addition to the most basic topics, this book includes construction and analysis of demographic matrix models, metapopulation and source-sink models, host-parasitoid and disease models, multiple basins of attraction, the storage effect, neutral theory, and diversity partitioning. Several sections include examples of confronting models with data. Chapter summaries and problem sets at the end of each chapter provide opportunities to evaluate and enrich one’s understanding of the ecological ideas that each chapter introduces. R is rapidly becoming the lingua franca of quantitative sciences, and this text provides a tractable introduction to using the R programming environment in ecology. An appendix provides a general introduction, and examples of code throughout each chapter give readers the option to hone their growing R skills. \"The distinctive strength of this book is that truths are mostly not revealed but discovered, in the way that R-savvy ecologistsempirical and theoreticalwork and think now. For readers still chained to spreadsheets, working through this book could be a revolution in their approach to doing science.\" (Stephen P. Ellner, Cornell University) \"One of the greatest strengthsis the integration of ecological theory with examples ... pulled straight from the literature.\" (James R. Vonesh, Virginia Commonwealth University)",
    "author": [
      {
        "family": "Henry",
        "given": "M."
      },
      {
        "family": "Stevens",
        "given": "H."
      }
    ],
    "edition": "1st",
    "id": "10.5555/1717944",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "A primer of ecology with r",
    "type": "book"
  },
  {
    "DOI": "10.1145/1273039.1273042",
    "ISSN": "0362-1340",
    "URL": "https://doi.org/10.1145/1273039.1273042",
    "abstract": "The article describes an IDE for functional programming, called WinHIPE. It provides an interactive and flexible tracer, as well as a powerful visualization and animation system. The former tool is based on the rewriting model of evaluation, and the latter provides automatic generation of visualizations and animations, friendly support for customization, maintenance and exportation of animations to the Web, and facilities to cope with large scale. Its main advantage over other visualization systems is an effortless approach to animation creation and maintenance, based on generating visualizations and animations automatically, as a side effect of program execution. Finally, we briefly describe our experience using the system during several years in educational settings.",
    "author": [
      {
        "family": "Pareja-Flores",
        "given": "Cristóbal"
      },
      {
        "family": "Urquiza-Fuentes",
        "given": "Jamie"
      },
      {
        "family": "Velázquez-Iturbide",
        "given": "J. Ángel"
      }
    ],
    "container-title": "SIGPLAN Not.",
    "id": "10.1145/1273039.1273042",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2007,
          3
        ]
      ]
    },
    "keyword": "tracing, term rewriting, programming environments, program visualization, program animation, functional programming, expression evaluation",
    "page": "14-23",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "WinHIPE: An IDE for functional programming based on rewriting and visualization",
    "title-short": "WinHIPE",
    "type": "article-journal",
    "volume": "42"
  },
  {
    "DOI": "10.1016/j.chb.2018.11.043",
    "ISSN": "0747-5632",
    "URL": "https://doi.org/10.1016/j.chb.2018.11.043",
    "author": [
      {
        "family": "Cheng",
        "given": "Gary"
      }
    ],
    "container-title": "Comput. Hum. Behav.",
    "id": "10.1016/j.chb.2018.11.043",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          3
        ]
      ]
    },
    "page": "361-372",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "Exploring factors influencing the acceptance of visual programming environment among boys and girls in primary schools",
    "type": "article-journal",
    "volume": "92"
  },
  {
    "ISBN": "0131478230",
    "abstract": "Praise for Mark Sobell’s Books “I keep searching for books that collect everything you want to know about a subject in one place, and keep getting disappointed. Usually the books leave out some important topic, while others go too deep in some areas and must skim lightly over the others. A Practical Guide to Red Hat® Linux® is one of those rare books that actually pulls it off. Mark G. Sobell has created a single reference for Red Hat Linux that cannot be beat! This marvelous text (with a 4-CD set of Linux Fedora Core 2 included) is well worth the price. This is as close to an ’everything you ever needed to know’ book that I’ve seen. It’s just that good and rates 5 out of 5.” -Ray Lodato, Slashdot contributor “Mark Sobell has written a book as approachable as it is authoritative.” -Jeffrey Bianchine, Advocate, Author, Journalist “Excellent reference book, well suited for the sysadmin of a linux cluster, or the owner of a PC contemplating installing a recent stable linux. Don’t be put off by the daunting heft of the book. Sobell has striven to be as inclusive as possible, in trying to anticipate your system administration needs.” -Wes Boudville, Inventor “A Practical Guide to Red Hat® Linux® is a brilliant book. Thank you Mark Sobell.” -C. Pozrikidis, University of California at San Diego “This book presents the best overview of the Linux operating system that I have found. . . . It should be very helpful and understandable no matter what the reader’s background is: traditional UNIX user, new Linux devotee, or even Windows user. Each topic is presented in a clear, complete fashion and very few assumptions are made about what the reader knows. . . . The book is extremely useful as a reference, as it contains a 70-page glossary of terms and is very well indexed. It is organized in such a way that the reader can focus on simple tasks without having to wade through more advanced topics until they are ready.” -Cam Marshall, Marshall Information Service LLC, Member of Front Range UNIX Users Group FRUUG, Boulder, Colorado “Conclusively, this is THE book to get if you are a new Linux user and you just got into RH/Fedora world. There’s no other book that discusses so many different topics and in such depth.” -Eugenia Loli-Queru, Editor in Chief, OSNews.comThe Most Useful Linux Tutorial and Reference Ever, with Hundreds of High-Quality Examples Covering Every Linux Distribution!To be truly productive with Linux, you need to thoroughly master the shells and the command line. Until now, you had to buy two books to gain that mastery: a tutorial on fundamental Linux concepts and techniques, plus a separate reference. Worse, most Linux references offer little more than prettied-up man pages. Now, there’s a far better solution. Renowned Linux expert Mark Sobell has brought together comprehensive, insightful guidance on the tools system administrators, developers, and power users need most, and an outstanding day-to-day reference, both in the same book.This book is 100 percent distribution and release agnostic: You can use it on any Linux system, now and for years to come. What’s more, it’s packed with hundreds of high-quality examples: better examples than you’ll find in any other Linux guidebook. This is Linux from the ground up: the clearest explanations and most useful knowledge about everything from filesystems to shells, editors to utilities, and programming tools to regular expressions. And when you need instant answers, you’ll constantly turn to Sobell’s comprehensive command reference section-organized and tabbed for easy, fast access!Don’t settle for yesterday’s Linux guidebook. Get the one book that meets today’s challenges-and tomorrow’s!A Practical Guide to Linux® Commands, Editors, and Shell Programming is the most useful, most comprehensive Linux tutorial and reference you can find. It’s the only book to deliver Better, more realistic examples covering tasks you’ll actually need to perform Deeper insight, based on Sobell’s immense knowledge of every Linux nook and cranny More practical explanations of more than eighty core utilities, from aspell to xargs Techniques for implementing secure communications using ssh and scp-plus dozens of tips for making your system more secure A superior introduction to the Linux programming environment, including make, gcc, gdb, CVS, and much more Expert guidance on basic and advanced shell programming using bash and tcsh Tips and tricks for customizing the shell and using it interactively from the command line Thorough guides to vim and emacs, designed to help you get productive fast and maximize your editing efficiency Dozens of exercises to help you practice and gain confidence Instructions for using Apt, yum, and BitTorrent for keeping your system up to date automatically And much more, including coverage of gawk, sed, find, sort, bzip2, and regular expressions",
    "author": [
      {
        "family": "Sobell",
        "given": "Mark G."
      }
    ],
    "id": "10.5555/1051260",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "A practical guide to linux commands, editorsnd shell programming, a",
    "type": "book"
  },
  {
    "abstract": "Cultures deal with their environments by adapting to them and simultaneously changing them. This is particularly true for technological cultures, such as the dynamic culture of computer users. To date, the ability to change computing environments in non-trivial ways has been dependent upon the skill of programming. Because this skill has been hard to acquire, most computer users must adapt to computing environments created by a small number of programmers. In response to the scarcity of programming ability, the computer science community has concentrated on producing general-purpose tools that cover wide spectrums of applications. As a result, contemporary programming languages largely ignore the intricacies arising from complex interactions between different people solving concrete problems in specific domains.This dissertation describes Agentsheets, a substrate for building domain-oriented, visual, dynamic programming environments that do not require traditional programming skills. It discusses how Agentsheets supports the relationship among people, tools, and problems in the context of four central themes: (1) Agentsheets features a versatile construction paradigm to build dynamic, visual environments for a wide range of problem domains such as art, artificial life, distributed artificial intelligence, education, environmental design, and computer science theory. The construction paradigm consists of a large number of autonomous, communicating agents organized in a grid, called the agentsheet. Agents utilize different communication modalities such as animation, sound, and speech. (2) The construction paradigm supports the perception of programming as problem solving by incorporating mechanisms to incrementally create and modify spatial and temporal representations. (3) To interact with a large number of autonomous entities Agentsheets postulates participatory theater, a human-computer interaction scheme combining the advantages of direct manipulation and delegation into a continuous spectrum of control and effort. (4) Metaphors serve as mediators between problem solving-oriented construction paradigms and domain-oriented applications. Metaphors are used to represent application semantics by helping people to conceptualize problems in terms of concrete notions. Furthermore, metaphors can simplify the implementation of applications. Application designers can explore and reuse existing applications that include similar metaphors.",
    "author": [
      {
        "family": "Repenning",
        "given": "Alexander"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/193426",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "note": "UMI Order No. GAX94-23532",
    "publisher": "University of Colorado at Boulder",
    "publisher-place": "USA",
    "title": "Agentsheets: A tool for building domain-oriented dynamic, visual environments",
    "title-short": "Agentsheets",
    "type": "thesis"
  },
  {
    "ISBN": "9798662455146",
    "abstract": "The goal of traditional optimizations is to map applications onto limited machine resources such that application performance is maximized while application semantics (program correctness), is preserved. Semantics is thought of as a unique mapping from inputs to outcomes. Relaxing application semantics through approximations has the potential of orders of magnitude performance improvements by trading off outcome quality for resource usage. Here, an execution outcome is not only based on its inputs but also resource availability and user quality expectations.Emerging approximation techniques provides various ways to trade-off output quality for lower resource consumption. However, as a developer, the guidance and support on how to utilize the power of approximation in everyday applications are limited and rarely discussed in recent works. The offline training overhead to support approximation is usually huge, but often be treated as \"free.\" Besides, it is surprising that end-users involvement is always overlooked when determining the quality notion, which should be highly subjective. Finally, supporting approximation in a multi-programming environment is crucial to let approximation be widely accepted as a general technique.In this dissertation, I introduce Rapids, Reconfiguration, Approximation, Preferences, Implementation, Dependencies, and Structure, a framework for developing and executing applications suitable for dynamic configuration management for approximate computing. The main contribution of Rapids is its design to address the above concerns through exploiting the different expertise/strengths of the three actors (developers, users, applications) involved. I conduct comprehensive experiments and show that Rapids is adaptive and extendable by providing customizable configuration spaces for developers and the support for customizable quality for end-users. It has low overheads and small cross-platform porting costs. I also introduce an extension of Rapids, Rapids-M (Rapids for Multiprogramming), which is the first system that discusses cross-application approximation management. The target is to understand and overcome the challenges in approximation management fundamentally, then let both developers and end-users benefit from approximation with little extra efforts so that a wider audience can accept the technique.",
    "author": [
      {
        "family": "Liu",
        "given": "Liu"
      },
      {
        "family": "Isaacman",
        "given": "Sibren"
      },
      {
        "family": "Zhang",
        "given": "Desheng"
      },
      {
        "family": "Martin",
        "given": "Richard"
      },
      {
        "family": "Yu",
        "given": "Linbin"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI27735970",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "note": "AAI27735970",
    "publisher": "Rutgers The State University of New Jersey, School of Graduate Studies",
    "title": "Trading quality for resource consumption through approximation management",
    "type": "thesis"
  },
  {
    "ISBN": "9781450377980",
    "abstract": "This foreword sketches the history of the Eclipse project. It then presents the context of the present workshop, the eclipse Technology Exchange (eTX), which was held on October 24, 2004 at OOPSLA 2004, Vancouver, British Columbia, Canada.&lt;b&gt;The Eclipse Project&lt;/b&gt;The Eclipse Project began in April 1999 at IBM’s OTI laboratory. It was initially conceived as a successor product for the VisualAge family of software development tools. VisualAge was a commercially successful IDE, but it was also a closed environment built on proprietary APIs. It did not integrate well with other vendors’ tools, and only the IBM/OTI team could enhance or extend the product. Moreover, it was becoming apparent from customer experience that more was required than a simple re-write of VisualAge. In fact, there was growing demand for a tool integration platform — a programming environment that would provide kernel IDE functionality, but also allow developers, third party vendors and users to seamlessly add their own extensions, personalizations, and enhancements.The Eclipse team set out to identify the essential kernel concepts underlying the VisualAge product line (or any other IDE for that matter). In effect, they wanted to strip out all of the functionality within an IDE that was specific to a particular programming language, development task, or programming model. The hope was that there would be substantial residual function left behind, that could then be restructured to form a content-neutral, and programming language-neutral, foundation on which IDEs and similar products could be built from components. It was a bold venture, since there was no guarantee that anything practically useful would result.What they discovered was Eclipse: a tool integration platform together with a set of components (plugins, in the Eclipse vernacular) that could be seamlessly assembled into a wide variety of software development products. The Java Development Toolkit (JDT) — the Eclipse Java IDE — became their proof-point. It was built in parallel by a separate team, which operated independently from the Eclipse Platform project. The JDT team had no special privileges; they had to use the same APIs as any third party product and were allowed no \"back door\" access to Platform kernel functionality. The intent was that, despite these constraints, the finished JDT should be indistinguishable from a purpose-built, vertically integrated IDE product like VisualAge. This goal was realized, the Eclipse Project was a success, and the Eclipse Community was born.In the years since the Eclipse code base was released into open source by IBM, its growth has been nothing short of spectacular. Tens of thousands download the Eclipse SDK every week from over fifty mirror sites around the globe. Thousands of Eclipse plugins are now available from open source and commercial suppliers. Software vendors are now shipping several hundred commercial products based on Eclipse. Approximately 60 companies are members of the Eclipse Foundation, which hosts Eclipse open source development. The first Eclipse Developer Conference (EclipseCON 2004) was held in February 2004 in Anaheim, California. Over 220 companies and organizations from nearly 25 countries were represented.&lt;b&gt;ECLIPSE AND COMPUTER SCIENCE RESEARCH&lt;/b&gt;It has been particularly interesting to see the uptake of Eclipse within the research community. In retrospect one could perhaps have anticipated this. Computing is, after all, an empirical discipline — ideas must be implemented to be validated. For software researchers in particular, the computer becomes our laboratory. We necessarily build on the work of those who have gone before, and of course as time progresses our technology pyramids keep getting higher. Complexity is our bane: the low-hanging fruit were picked long ago, and most interesting problems are just not simple. Consequently, experimentation usually requires complex infrastructure, plumbing, as we often call it. Most researchers spend far too much time building (and rebuilding, and fixing) this plumbing, and far too little time actually developing new ideas. Given the nature of research, there are seldom any applicable standards for such infrastructure (these only come much later when the research has matured into products). Consequently researchers up to now have had to live and work in their own vertical towers, sharing their ideas but only infrequently sharing code. The only common programming platform among researchers was \"emacs\", and while this continues to be very flexible, it lags far behind industrial-scale IDEs in terms of functionality.But Eclipse changes this context. It provides a means to create and share that necessary common infrastructure, particularly for investigators in such areas as programming languages, tools, and environments. Researchers can focus more of their time on their real mission of innovation, and much less on the tedious plumbing tasks. Moreover, Eclipse-based implementations are built from commercial-quality components, resulting in robust demonstration systems that make it much easier for researchers to publicize and promote their work.What specifically does Eclipse offer researchers that makes it so attractive? First, it is an extensible platform for integrating components, which comes replete with a large number of commercial quality components out of the box. It runs on nearly all operating systems and GUI combinations, and is one of the few Java implementations that actually realizes that language’s \"write once run everywhere\" potential (rather than the typical \"write once test everywhere\" experience). Perhaps most importantly, it is available in open source with a generous non-viral license. Finally, it has tremendous visibility due to broad based industry support, which includes the backing of such powerhouse firms as IBM, HP, SAP, Intel, and many more.&lt;b&gt;ECLIPSE AND COMPUTER SCIENCE EDUCATION&lt;/b&gt;There are numerous challenges in education these days such as distance, limited resources and the recognized need to make learning a personalized and active experience. Many educators are consequently looking at how technology can address these challenges and enhance learning in the classroom and beyond. For computer science education, Eclipse has already been widely adopted as an IDE to support programming. The advantages for some are that it is free, platform independent and industrially relevant. But beyond these obvious advantages, other researchers have recognized that Eclipse provides an excellent infrastructure for developing learning tools. These tools can leverage the wealth of technology already present in the Eclipse community, as well as benefit from integration with other learning tools developed by other researchers and educators. The result of these multiple efforts is the emergence of Eclipse as an effective and powerful platform to support research in educational technologies and an improved learning experience in many settings.&lt;b&gt;THE ECLIPSE TECHNOLOGY EXCHANGE&lt;/b&gt;That idea that Eclipse would provide exactly the rich, open and robust platform that IT researchers needed was not initially an obvious one, and so it needed to be promoted within the academic community. IBM and eclipse.org set out to popularize these ideas by hosting a series of workshops and birds-of-a-feather events at various software research conferences. This ad hoc program gradually evolved into the eclipse Technology Exchange (eTX) workshops, the most recent of which was held at OOPSLA 2004 in Vancouver. These events provide a forum for researchers who are using Eclipse to network and share their experiences and their code.The foundation for a successful eTX is a set of high quality, refereed presentations, which serve to illustrate the breadth and vitality of the Eclipse research and teaching communities. The papers in this volume are exemplary in this regard. Several describe plugins that build on the Eclipse Platform to offer new programming tools, such as for aspect browsing; debugging distributed applications; profiling and monitoring program behaviour; visualization of complex data; and feature modeling, a technique used in product-line development to model similarities and differences of products. About half of the papers describe the use of Eclipse for teaching object-oriented programming and software engineering, in both classroom and distance settings. One such paper addresses distributed collaborative programming. Others describe Eclipse courseware plugins for code-based tutorials; visualization of computer organization concepts; and tracking student programming projects.Each paper illustrates the advantages that Eclipse offers researchers and teachers. They describe rich full-featured implementations, which can be used and modified by other researchers/teachers in their respective areas, at minimal cost in terms of incremental programming effort. This works because they all leverage the rich infrastructure and base of components provided by Eclipse. And of course by developing their own new components, each of these projects extends that base and enables others to build on their work — a virtuous cycle that is creating an eco-system around Eclipse and enriching the entire software research and teaching communities.",
    "id": "10.1145/1066129",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Eclipse ’04: Proceedings of the 2004 OOPSLA workshop on eclipse technology eXchange",
    "title-short": "Eclipse ’04",
    "type": "book"
  },
  {
    "abstract": "To date, reuse of software has not had its anticipated effect on improvements in software productivity. This is because we do not fully understand the concepts behind reusability and because there has been relatively little experimentation with reusability systems. In this research we attack these problems in three ways: (1) An investigation of the conceptual foundations of reuse for a parallel programming environment based on the Unified Computation Graph Model designed by Dr. James C. Browne at the University of Texas, Austin. (2) A realization of these concepts in a software base management system, ROPE, to support reuse in such an environment. (3) An experimental evaluation of the effectiveness of ROPE. The research addresses each of the fundamental steps of finding, understanding, modifying, and composing reusable components: (1) The problem of finding components is addressed by a new classification method, called the structured relational classification method. This method appears to be an effective technique for combining the strengths of relational methods in the maintenance and query areas with the strengths of more traditional methods in the browsing area. (2) For understanding components, we have introduced design analysis methods which basically flow from the UCGM model itself. (3) Modifying components is addressed in several ways. First through a suitable definition of generic designs and secondly through techniques for composing and decomposing graphs. (4) Composition of components is discussed in detail and a framework is laid for a calculus of composition of components. This required a formalization of some new aspects of the UCGM model and definitions and theorems about the structure of UCGM.The reusability system ROPE was built, tested and used by a variety of people. Each of the concepts discussed above was realized to some degree in the final system though the theory outstripped the implementation in several areas. This was a very substantial programming project.A fairly extensive evaluation of ROPE was done. The initial set of experiments has clearly established the effectiveness of CODE and ROPE in promoting component reuse in programs of modest size and complexity and in delivery of nearly error free programs with relatively little effort.",
    "author": [
      {
        "family": "Lee",
        "given": "Taejae"
      },
      {
        "family": "Browne",
        "given": "James C."
      },
      {
        "family": "Werth",
        "given": "John"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/915812",
    "issued": {
      "date-parts": [
        [
          1989
        ]
      ]
    },
    "note": "AAI9005613",
    "publisher": "The University of Texas at Austin",
    "title": "Software reuse in parallel programming environments",
    "type": "thesis"
  },
  {
    "ISBN": "0599358882",
    "abstract": "Over the past several years, systems are increasingly supporting a new class of multimedia applications that need to trade off Quality of Service with respect to resource constraints. In particular, soft-real time applications, such as continuous media ( CM ý) systems, have an important property, viz, they allow for graceful adaptation of the application Quality-of-Service (QoS), and therefore are able to have acceptable performance with reduced resource utilization. The use of graceful adaptation of the application for admission control leads to an integrated admission control and service negotiation protocol. This dissertation specifically deals with the policies the system adopts, which are referred to as the application admission and negotiation process. For this, we use the constructs of resource demand functions and benefit functions , which simplify the mechanisms for graceful adaptation of the applications. We adopt welfare economic theories into our system model and define a price-based framework for resource allocation and QoS support in distributed multimedia systems. By formulating a computational economy and finding its competitive equilibrium using market-based techniques that are widely used in economic theories, we can solve the distributed resource allocation problem. In the first part of the dissertation, we present a QoS-based resource management model for multimedia applications for both single resource allocation and multiple resource environments. The second part of the dissertation focuses on the problem of the Soft-QoS framework , including QoS-based admission control, negotiations, and scheduling for continuous media applications. In this dissertation, we develop novel admission control and QoS negotiation algorithms using benefit and resource demand functions. In the next chapter, our effort focuses on disk bandwidth-based admission control and scheduling in video servers. The fourth part of the dissertation involves actual system implementation and performance analysis; that is, QoS-based evaluation of the file system and distributed system services for continuous media provisioning. We designed and developed a QoS-based continuous media server system which was incorporated into the HDIMI ( Heterogeneous Distributed Multimedia Information Management for the Infosphere ) and Presto projects, which were Air Force-sponsored at the University of Minnesota. Our CM servers were implemented both on Socket programming environments and on CORBA. The comparison of performance between such various network protocols on the Internet was also done. (Abstract shortened by UMI.)",
    "author": [
      {
        "family": "Lee",
        "given": "Wonjun"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/929168",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "note": "AAI9934977",
    "publisher": "University of Minnesota",
    "publisher-place": "USA",
    "title": "Quality-of-service provisioning for multimedia applications",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3516529.3516580",
    "ISBN": "9781450384100",
    "URL": "https://doi.org/10.1145/3516529.3516580",
    "abstract": "my country’s colleges and universities have completed the transition from elite education to popular education. Under the globalized development environment, Subject Education, as an important feature and advantage of modern college education, is facing new tasks and challenges. The research on general education in my country is relatively in-depth at this stage, and the general education practice carried out by universities has also begun to bear fruit. This paper constructs the SECI model of the practical teaching of the Subject Educations of general education in colleges and universities, uses the analytic hierarchy process and the fuzzy comprehensive evaluation method to establish the evaluation system and weight indicators of the practical teaching of the Subject Educations in general education in the colleges and universities, and then proposes the practical teaching of the Subject Educations in general education in colleges and universities. Strategy.",
    "author": [
      {
        "family": "Lingyu",
        "given": "Li"
      },
      {
        "family": "Linlin",
        "given": "Jin"
      }
    ],
    "collection-title": "AICSconf ’21",
    "container-title": "2021 2nd artificial intelligence and complex systems conference",
    "id": "10.1145/3516529.3516580",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "subject educations, general education, evaluation system, SECI model",
    "page": "262-265",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Research on the practical teaching of subject educations of general education in colleges and universities based on the SECI model",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3159450.3159602",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3159602",
    "abstract": "The increasing number of students in computer science courses leads to high efforts in manual assessment of exercises. Existing assessment systems are not designed for exercises with immediate feedback in large classes. In this paper, we present an AuTomated assEssment Management System for interactive learning.ArTEMiS assesses solutions to programming exercises automatically and provides instant feedback so that students can iteratively solve the exercise. It is open source and highly scalable based on version control, regression testing and continuous integration. ArTEMiS offers an online code editor with interactive exercise instructions, is programming language independent and applicable to a variety of computer science courses. By using it, students gain experiences in version control, dependency management and continuous integration.We used ArTEMiS in 3 university and 1 online courses and report about our experiences. We figured out that ArTEMiS is suitable for beginners, helps students to realize their progress and to gradually improve their solutions. It reduces the effort of instructors and enhances the learning experience of students.",
    "author": [
      {
        "family": "Krusche",
        "given": "Stephan"
      },
      {
        "family": "Seitz",
        "given": "Andreas"
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3159602",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "version control, programming exercises, online editor, online courses, interactive exercise instructions, instant feedback, in-class exercises, continuous integration, automated assessment",
    "page": "284-289",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "ArTEMiS: An automatic assessment management system for interactive learning",
    "title-short": "ArTEMiS",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/242604.242618",
    "ISSN": "0362-1340",
    "URL": "https://doi.org/10.1145/242604.242618",
    "abstract": "Object-orientation has a long tradition at the Computer Science Department, Aarhus University, starting with Simula in the early seventies. For more than 20 years there have been courses in object-oriented programming, including BETA, Smalltalk, Self and others. Recently object-orientation has started to be integrated in other parts of the curriculum such as in software engineering, distributed systems and databases. In this paper we report on this approach to teaching object-orientation. One of the advantages of object-orientation is that it provides an integrating perspective on the various areas to be taught. Besides providing a common conceptual framework, it also makes it possible to use common languages and tools that have a profound influence on the integration. Especially in the software engineering course, it has been possible to let the students experience an iterative software development method where they make a number of iterations through analysis, design and implementation. To do these iterations, it is necessary with good development tools like a CASE tool that supports code generation and reverse engineering. The Mjølner BETA System is used in the various courses as a common platform, but the students are also introduced to other object-oriented environments like Smalltalk, Self, Eiffel, and C++. The Mjølner BETA System that is a software development environment for object-oriented development based on the BETA programming language.",
    "author": [
      {
        "family": "Knudsen",
        "given": "Jørgen Lindskov"
      },
      {
        "family": "Madsen",
        "given": "Ole Lehrmann"
      }
    ],
    "container-title": "SIGPLAN Not.",
    "id": "10.1145/242604.242618",
    "issue": "12",
    "issued": {
      "date-parts": [
        [
          1996,
          12
        ]
      ]
    },
    "page": "52-62",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using object-orientation as a common basis for system development education",
    "type": "article-journal",
    "volume": "31"
  },
  {
    "ISBN": "9798209808770",
    "abstract": "In the last few years, ISEP in collaboration with FEUP and other universities, created a realistic driving simulator called DriS, which had the objective to help in researches of different areas, as civil engineer, computer graphics, psychology, education, etc.The result of this thesis pretends to help the professionals who analyse the data collected in each driving experience, in order to allow them the study of the driver’s reactions at different obstacles during a ride, at the same time.DriS simulator consists in one white screen where the driving simulators environments are projected, in one real car to make the driving experience and four cameras placed in the car. Of these four cameras, three are inside the car and one of them outside the car. Each camera is focused in one specific and critical part of the driving: the road, the driver, the pedals and the controls (gearshift, steering wheel, wiper controls, etc.).Each one of the camera records a video that is save in one computer placed in the control room, inside the Laboratório de Análise de Tráfego in FEUP. Also, a text file is saved in this computer. This text file contains some information about the driver’s experience, as it can be the car coordinates, the speed of the car, the time, etc.The work of this thesis arises in order to improve the way on how professionals analyse and perform data collected from a DriS driving experience. For that purpose, was created a video-­‐monitorization system, consists in a video application, that allows load and player four videos simultaneously as well as a text file which contains all the data collected from the experience. All of them will be time-coordinated and the user could move forward and backward through them using a slider. Also, as a basic video player, contains some buttons to control the status of the video (play, stop, pause) allowing the professionals analyse with detail the four videos and the data.Take advantage of the new progresses in software development, the application was made in C++ using the Qt library, and its integrated development environment the Qt Creator, which made easier the implementation.At the end of this report (Chapter 4) is attached a user manual in order to explain and help the professionals to use the application.",
    "author": [
      {
        "family": "Formoso",
        "given": "Laura Dapena"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI28991918",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "note": "AAI28991918",
    "publisher": "Instituto Politecnico do Porto (Portugal)",
    "title": "Video-monitorization system for a realistic driving simulator",
    "type": "thesis"
  },
  {
    "ISBN": "9781109750638",
    "abstract": "Data structures and algorithms are important foundation topics in computer science education. However, they are often complex and hard to understand. As a result, educational tools, such as algorithm visualization systems, are always needed to help students better learn and understand algorithms. The focus on graphics and sound instead of pedagogical aspects in the design of current algorithm visualization systems undermines effectiveness in teaching algorithms. In addition, most algorithm visualization systems lack features that encourage student engagement. This research addresses some required issues in creating algorithm visualization techniques by integrating learning theories and models in algorithm learning and by visualizing algorithms using computer games to fully engage students in the algorithm learning process. A new algorithm visualization and learning approach, namely Algorithm Visualization using Serious Games (AVuSG), has been introduced. It visualizes algorithms using educational or serious games to benefit from their popularity and engagement to motivate students who are learning algorithms. Moreover, it facilitates the students’ assessment using the winning-losing criteria of computer games without the need for external questions. The conceptual framework of AVuSG visualizes the algorithm to be learned using three forms of representations: Text, Flowchart, and Computer Game. Moreover, it defines three types of learning processes: Viewing,Playing, and Designing, which learners can use to engage with any of the three forms of the produced algorithm visualizations. Finally, AVuSG integrates learning theories with game design to introduce three learning models: Bloom Based, Gagne Based, and Constructivist Models, which can be adopted either by students to learn the algorithm or by the instructors to teach the algorithm depending on the learning objectives that they want to achieve. To demonstrate AVuSG framework, a software system called Serious Algorithm Game Visualizer (Serious-AV) has been developed to provide a viewer and a designer for each algorithm representation form (Text, Flowchart, and Computer Game). Serious-AV is used on two levels: by the user interacting with the visualizations and by the developer creating these visualizations. The user views the algorithm text and flowchart using the Algorithm Text Viewer and the Algorithm Flowchart Viewer, respectively, and plays its game using the Algorithm Game Viewer. On the other hand, the developer uses the three development tools: Algorithm Text Designer, Algorithm Flowchart Designer, and Algorithm Game Designer to create each of those three algorithm representation forms. The Algorithm Game Designer is an integrated development environment tailored to create computer science educational games, namely an Algorithm Game, for the Windows platform to teach about specific algorithms and data structures. To visualize an algorithm, an Algorithm Game must have a game-play that simulates the behavior of the visualized algorithm and graphics to depict the features of its data structure. Several components and editors have been added to the Algorithm Game Designer to automate and simplify the visual development of algorithm games using as little code as possible. First, it is built on top of a game engine called SAVGEngine, which contains several modules that provide the basic functionality to the newly created game in addition to a repository of ready-to-use algorithm game components that can be altered and plugged in to the new game. Moreover, the Algorithm Game Designer includes an Algorithm Game Template to be used as a blueprint in the creation of a new algorithm game by providing basic game classes that implement the algorithm game basic architecture. Furthermore, the Algorithm Game Designer contains five visual editors: Properties, Assets, Screens, Classes, and Graphic Items Editors for creating all game content visually with no code, using a flexible, user-friendly graphical user interface (GUI). Lastly, it takes advantage of current software tools and libraries, such as XNA-GS, and VS Shell-Isolated Mode to simplify game design. At last, several algorithm visualizations, including texts, flowcharts, and algorithm games prototypes, have been developed using the developed systems.",
    "author": [
      {
        "family": "Shabanah",
        "given": "Sahar Siraj"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1925240",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "note": "AAI3407063",
    "publisher": "George Mason University",
    "publisher-place": "USA",
    "title": "Simplifying algorithm learning using serious games",
    "type": "thesis"
  },
  {
    "ISBN": "032194786X",
    "abstract": "The Only Tutorial Covering BOTH iOS and Androidfor students and professionals alike! Now, one book can help you master mobile app development with both market-leading platforms: Apples iOS and Googles Android. Perfect for both students and professionals, Learning Mobile App Development is the only tutorial with complete parallel coverage of both iOS and Android. With this guide, you can master either platform, or bothand gain a deeper understanding of the issues associated with developing mobile apps. Youll develop an actual working app on both iOS and Android, mastering the entire mobile app development lifecycle, from planning through licensing and distribution. Each tutorial in this book has been carefully designed to support readers with widely varying backgrounds and has been extensively tested in live developer training courses. If youre new to iOS, youll also find an easy, practical introduction to Objective-C, Apples native language. All source code for this book, organized by chapter, is available at https://github.com/LearningMobile/BookApps Coverage includes Understanding the unique design challenges associated with mobile apps Setting up your Android and iOS development environments Mastering Eclipse development tools for Android and Xcode 5 tools for iOS Designing interfaces and navigation schemes that leverage each platforms power Reliably integrating persistent data into your apps Using lists (Android) or tables (iOS) to effectively present data to users Capturing device location, displaying it, and using it in your apps Accessing hardware devices and sensors Publishing custom apps internally within an organization Monetizing your apps on Apples AppStore or the Google Play marketplace, as well as other ways of profiting from app development, such as consulting and developer jobs",
    "author": [
      {
        "family": "Iversen",
        "given": "Jakob"
      },
      {
        "family": "Eierman",
        "given": "Michael"
      }
    ],
    "edition": "1st",
    "id": "10.5555/2613605",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Learning mobile app development: A hands-on guide to building apps with iOS and android",
    "title-short": "Learning mobile app development",
    "type": "book"
  },
  {
    "ISBN": "1782173331",
    "abstract": "Key FeaturesBuild an effective development environment in Azure using the right set of technologies. Architect a full-stack solution in the cloud to choose the best service setA comprehensive guide full of real-life examples to help you take your developer skills up a notchBook Description Microsoft Azure is a cloud computing platform that supports many different programming languages, tools, and frameworks, including both Microsoft-specific and third-party software and systems. This book starts by helping you set up a professional development environments in the cloud and integrating them with your local environment to achieve improved efficiency. You will move on to create front-end and back-end services, and then build cross-platform applications using Azure. Next you’ll get to grips with advanced techniques used to analyze usage data and automate billing operations. Following on from that, you will gain knowledge of how you can extend your on-premise solution to the cloud and move data in a pipeline. In a nutshell, this book will show you how to build high-quality, end-to-end services using Microsoft Azure. By the end of this book, you will have the skillset needed to successfully set up, develop, and manage a full-stack Azure infrastructure. What You Will LearnSet up a development environment with VMs, ARM, and Remote App Connect with VPNs to manage security and backups Establish a front-end architecture with App Service, storage, search, and caching Implement identity solutions, integrate applications, and use dataIntegrate cross-platform mobile applications with the cloud Consistently build and manage an API layer for millions of users Work with messages in the enterprise Deploy your services as an IT expert with ARM templates About the Author Roberto Freato has been an independent IT consultant since he started to work. Working for small software factories while he was studying, after his M.Sc. in Computer Science Engineering with his thesis on Consumer Cloud Computing, he got specialization in Cloud and Azure. Today, he works as a freelance consultant for major companies in Italy, helping clients design and kick off their distributed software solutions. He trains the developer community in his free time, speaking at many conferences. He has been a Microsoft MVP since 2010. Marco Parenzan is an experienced .NET developer, now also a Cloud Computing and Azure trainer. A Microsoft MVP on Azure since 2014, he is curious about the IoT business and architectures. He loves retrogaming, and he tries programming little games in his spare time. He is a community lead for 1nn0va, a local Microsoft community in Pordenone, Italy, and he likes training developers in companies and university.",
    "author": [
      {
        "family": "Freato",
        "given": "Roberto"
      },
      {
        "family": "Parenzan",
        "given": "Marco"
      }
    ],
    "id": "10.5555/3055808",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Mastering cloud development using microsoft azure",
    "type": "book"
  },
  {
    "DOI": "10.1145/3632530",
    "URL": "https://doi.org/10.1145/3632530",
    "abstract": "Background and Context: Understanding how a student programmer solves different task types in different programming languages is essential to understanding how we can further improve teaching tools to support students to be industry-ready when they graduate. It also provides insight into students’ thought processes in different task types and languages. Few (if any) studies investigate whether any differences exist between the reading and navigation behavior while completing different types of tasks in different programming languages.Objectives: We investigate whether the use of a certain programming language (C++ versus Python) and type of task (new feature versus bug fixing) has an impact on performance and eye movement behavior in students exposed to both languages and task types.Participants: Fourteen students were recruited from a Python course that taught Python as an introductory programming language.Study Method: An eye tracker was used to track how student programmers navigate and view source code in different programming languages for different types of tasks. The students worked in the Geany Integrated Development Environment (IDE, used also in their course) while eye-tracking data was collected behind the scenes making their working environment realistic compared to prior studies. Each task type had a Python and C++ version, albeit on different problems to avoid learning effects. Standard eye-tracking metrics of fixation count and fixation durations were calculated on various areas of the screen and on source code lines. Normalized versions of these metrics were used to compare across languages and tasks.Findings: We found that the participants had significantly longer average fixation duration and total fixation duration adjusted for source code length during bug fixing tasks than the feature addition tasks, indicating bug fixing is harder. Furthermore, participants looked at lines adjacent to the line containing the bug more often before looking at the buggy line itself. Participants who added a new feature correctly made their first edit earlier compared to those who failed to add the feature. Tasks in Python and C++ have similar overall fixation duration and counts when adjusted for character count. The participants spent more time fixating on the console output while doing Python tasks. Overall, task type has a bigger effect on the overall fixation duration and count compared to the programming language.Conclusions: CS educators can better support students in debugging their code if they know what they typically look at while bug fixing. For new feature tasks, training students not to fear edits to learn about the code could also be actively taught and encouraged in the classroom. CS education researchers can benefit by building better IDE plugins and tools based on eye movements that guide novices in recognizing bugs and aid in adding features. These results will lead to updating prior theories on mental models in program comprehension of how developers read and understand source code. They will eventually help in designing better programming languages and better methods of teaching programming based on evidence on how developers use them.",
    "author": [
      {
        "family": "Mansoor",
        "given": "Niloofar"
      },
      {
        "family": "Peterson",
        "given": "Cole S."
      },
      {
        "family": "Dodd",
        "given": "Michael D."
      },
      {
        "family": "Sharif",
        "given": "Bonita"
      }
    ],
    "container-title": "ACM Trans. Comput. Educ.",
    "id": "10.1145/3632530",
    "issue": "1",
    "issued": {
      "date-parts": [
        [
          2024,
          1
        ]
      ]
    },
    "keyword": "eye-tracking study, learning behavior, programming education, new feature tasks, bug fixing, Python, C++, source code, Program comprehension",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Assessing the effect of programming language and task type on eye movements of computer science students",
    "type": "article-journal",
    "volume": "24"
  },
  {
    "DOI": "10.1109/FIE49875.2021.9637170",
    "URL": "https://doi.org/10.1109/FIE49875.2021.9637170",
    "abstract": "Full Paper Research-to-Practice The current COVID-19 crisis has created significant challenges for schools. The growing importance of “flipping the classroom” and the needful emphasizing of online-learning were owed to the situation. To meet these requirements, materials and tasks must be adapted. The Open Educational Resource (OER) textbook “Computational Thinking with the BBC micro:bit” was developed for the introduction of Computational Thinking (CT) for 10-14-year-old pupils in Austria’s secondary schools. Example tasks in the textbook are designed with an open end and present extensions with ideas for further development instead of ending abruptly. This article provides a guideline for a clear distinction in redesigning existing lessons following the Inverted Classroom Model (ICM) using videos for pre-class work and live task extensions for in-class work. Which parts in the learning design must remain as live lessons and which parts can be adapted for video lessons? The respective research shows that examples that have a makerspace activity as an extension are especially helpful for an efficient determination of the appropriate part in the learning design and particularly suitable for an adaptation with ICM. The central advantage of the ICM is that it responds flexibly to the individual learning needs of each student. It allows students to take their time reviewing the material at their own pace without getting left behind. The textbook used here encourages pupils to find their own solutions by explorative learning using the block-based programming environment MakeCode. Additional information to be uncovered by the learner is provided for every single step in the accompanying online wiki website. Results from observations showed that this uncover-function, being a central element of the online material, encouraged the learners to explore their own way in finding a solution with playful elements and increased motivation. The many haptic elements of a makerspace activity are in particular useful for consolidation of the learned and are predisposed for in-class work and deepening the understanding following the constructionism theory. A Design-Based Research (DBR) approach is used to create and evaluate the redesign of a proven example task in a pilot project. Teachers, who are already familiar with the BBC micro:bit and the OER textbook, were trained on how to use the “flip-version” of an example task in their lessons and asked to develop a lesson plan for implementation. The didactic approach to redesigning the material and teacher training was evaluated during the first cycle of DBR. Results from expert interviews showed that the redesigned material and training deliver a solid ground for rework and further research on a larger scale.",
    "author": [
      {
        "family": "Kastner-Hauler",
        "given": "Oliver"
      },
      {
        "family": "Tengler",
        "given": "Karin"
      },
      {
        "family": "Demarle-Meusel",
        "given": "Heike"
      },
      {
        "family": "Sabitzer",
        "given": "Barbara"
      }
    ],
    "container-title": "2021 IEEE frontiers in education conference (FIE)",
    "id": "10.1109/FIE49875.2021.9637170",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "1-8",
    "publisher": "IEEE Press",
    "publisher-place": "Lincoln, NE, USA",
    "title": "Adapting an OER textbook for the inverted classroom model — how to flip the classroom with BBC micro:bit example tasks",
    "title-short": "Adapting an OER textbook for the inverted classroom model — how to flip the classroom with BBC micro",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/330908.331912",
    "ISBN": "1581132131",
    "URL": "https://doi.org/10.1145/330908.331912",
    "abstract": "Object-oriented languages have been taught for some time at universities. The most common approach has been to teach those constructs required for imperative programming first and to introduce the notion of classes and objects somewhat later in the course. More recently, many educators have been promoting the notion of teaching about classes and objects first. This helps students to adopt the object-oriented paradigm at an early stage and encourages them to focus on the application structure before beginning coding. Most new textbooks have followed such an approach.While this method has clear advantages, it is not easy to realise in practice. This is partly a result of the languages used for teaching. However, we would argue that the major difficulty comes from the lack of program development environments and tools which themselves fully embrace the object-oriented paradigm.The use of Java as the language for teaching addresses some of the problems. Java with its clean support for the object-oriented paradigm is now widely regarded as a suitable choice for introductory teaching. The choice of environment, however, remains an issue.The view of the development environment as a major difficulty in Java courses is further supported by numerous reports of educators relating their experiences with teaching introductory Java courses. While Java was consistently described as an excellent language for teaching the object-oriented paradigm, the environments available are regularly identified as a significant source of problems. These may be divided into two areas: The environments are designed for professional programmers. They are too complex and have a steep learning curve. Thus valuable teaching time is spent teaching the students how to use the environment and this detracts from the principles of programming.Most of the existing environments fail to fully adopt the object-oriented paradigm. Users of the environment must deal with files, lines of code and directory hierarchies rather than classes, objects and relationships.In this seminar we will argue the case that the requirements for teaching the object-oriented paradigm and Java can only be satisfied by the provision of a program development environment specifically designed for teaching.We will introduce BlueJ, a relatively new development environment which addresses all of these issues. We will show how the unique features of this environment can be used to create an introductory Java course that fully embraces the “object first” approach and supports the presentation of a cleaner picture of the paradigm than previously possible.BlueJ is based heavily on earlier work by us on a language and environment called Blue. BlueJ is a complete Java development environment, written entirely in Java. It provides graphical support for object-oriented design, abstracts over files and the operating system and provides fully integrated support for a design, edit, compile and test cycle. In addition, BlueJ supports interactive creation of objects and interactive calling of methods of objects. This provides support for incremental development, one of the major advantages of object-orientation. It includes an easy-to-use debugger and support for applications and applets.One of the main differences between BlueJ and other environments is its distinct focus on a teaching context. It combines powerful tools with an easy-to-use interface, avoiding the complexity that creates so many problems when using existing environments in a classroom.BlueJ has been used very successfully for two semesters as Monash University.The presentation will provide the context in which the BlueJ project has been developed. We will discuss the design principles for BlueJ, the major aims of the project and our experiences with using it in class. A demonstration of the current version of BlueJ will be given. We will also demonstrate a set of examples and problems which can be used in a first Java course and show how the course structure can be improved and support teaching “objects first” with the availability of an environment that fully supports the paradigm.BlueJ is available free of charge and can be used by any interested institution. Details of how to obtain a copy of BlueJ will be provided at the seminar.",
    "author": [
      {
        "family": "Kölling",
        "given": "Michael"
      },
      {
        "family": "Rosenberg",
        "given": "John"
      }
    ],
    "collection-title": "SIGCSE ’00",
    "container-title": "Proceedings of the thirty-first SIGCSE technical symposium on computer science education",
    "id": "10.1145/330908.331912",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "page": "429",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Objects first with java and BlueJ (seminar session)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1384271.1384395",
    "ISBN": "9781605580784",
    "URL": "https://doi.org/10.1145/1384271.1384395",
    "abstract": "Informatics education, not only in higher but also in secondary education, is often assisted by special learning software to teach the fundamental ideas of algorithms [2]. In this context pupils also learn the basics of programming using didactically reduced, textbased or visual programming languages. Therefore in Germany, in some federal countries (for example Bavaria), where the basics of algorithms are already taught in the 7th grade (age 12 to 13 years), age-based learning and programming environments, such as Karel, the robot and Kara, the programmable ladybug [1], are used. Although the design of these environments is age-based, working with them to solve algorithmic problems often causes problems in the classroom. These tools give feedback to the learners based on the analysis of a current solution attempt without taking the previous problem solving process into account. The system messages are often rather technical and therefore hardly helpful especially for weaker learners to enable them to correct arisen problems by themselves. In order to give optimal support to pupils in these situations and therefore improve the learning processes, the learner-system interaction of the used educational software environments should be enhanced and better be adapted to the learners? individual problem solving strategies.The main objective of this research project is to find out, to what extent the automated diagnosis of a problem solving strategy of a learner is possible, and to what extent this knowledge can be used to enhance the learner-system interaction. Starting from the advantages and disadvantages of standardized process observation methods, two software-based research instruments for the system supported diagnosis of the individual proceedings, using the learning environment Kara, were designed and implemented. With the first component learner-system interactions are recorded, the second one provides functions to analyse the collected data. Using test-cases gives a first idea of the quality of the solution attempts.The requirements for the software components resulted from several test scenarios with a small number of participants with different qualification in computer science (from novices to graduating computer science students). During these tests each individual was observed by a researcher and additionally interviewed afterwards. A first version of the implemented instruments was tested in case studies with more than 100 participants (12 to 13 years old) from Bavarian grammar schools to evaluate the suitability for daily use. During the studies the learners were asked to solve three given tasks in a session of 45 minutes, provided by the Kara system, individually (one pupil per computer), but communication between the test persons was allowed. The tasks required knowledge of the control structures (sequence, selection, iteration).The results of these studies indicate that it is possible to identify and to evaluate different problem solving patterns with the help of the developed instruments. To identify different types of learners? strategies it is necessary to combine the various kinds of visualizations of the collected data. To support automatic categorization pattern-recognition methods will be used. The collected ordinal (test-case results) and nominal data can be used for analyses of the correlation between different factors (for example number of error messages or program executions compared with the assessment of the solution attempt) with methods of descriptive statistics.",
    "author": [
      {
        "family": "Kiesmueller",
        "given": "Ulrich"
      },
      {
        "family": "Brinda",
        "given": "Torsten"
      }
    ],
    "collection-title": "ITiCSE ’08",
    "container-title": "Proceedings of the 13th annual conference on innovation and technology in computer science education",
    "id": "10.1145/1384271.1384395",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "tool-based analysis, secondary computer science education, problem solving process, kara, didactics of informatics, algorithms",
    "page": "353",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "How do 7th graders solve algorithmic problems? A tool-based analysis",
    "type": "paper-conference"
  },
  {
    "ISBN": "0131367366",
    "abstract": "Praise for the First Edition of A Practical Guide to Linux Commands, Editors, and Shell Programming First Sobell taught people how to use Linuxnow he teaches you the power of Linux. A must-have book for anyone who wants to take Linux to the next level. Jon maddog Hall, Executive Director, Linux International This book is a very useful tool for anyone who wants to look under the hood so to speak, and really start putting the power of Linux to work. What I find particularly frustrating about man pages is that they never include examples. Sobell, on the other hand, outlines very clearly what the command does and then gives several common, easy-tounderstand examples that make it a breeze to start shell programming on ones own. As with Sobells other works, this is simple, straight-forward, and easy to read. Its a great book and will stay on the shelf at easy arms reach for a long time. Ray Bartlett, Travel Writer Overall I found this book to be quite excellent, and it has earned a spot on the very front of my bookshelf. It covers the real guts of Linuxthe command line and its utilitiesand does so very well. Its strongest points are the outstanding use of examples, and the Command Reference section. Highly recommended for Linux users of all skill levels. Well done to Mark Sobell and Prentice Hall for this outstanding book! Dan Clough, Electronics Engineer and Slackware Linux user Totally unlike most Linux books, this book avoids discussing everything via GUI and jumps right into making the power of the command line your friend. Bjorn Tipling, Software Engineer, ask.com This book is the best distro-agnostic, foundational Linux reference Ive ever seen, out of dozens of Linux-related books Ive read. Finding this book was a real stroke of luck. If you want to really understand how to get things done at the command line, where the power and flexibility of free UNIX-like OSes really live, this book is among the best tools youll find toward that end. Chad Perrin, Writer, TechRepublic Praise for Other Books by Mark G. Sobell I keep searching for books that collect everything you want to know about a subject in one place, and keep getting disappointed. Usually the books leave out some important topic, while others go too deep in some areas and must skim lightly over the others. A Practical Guide to Red Hat Linux is one of those rare books that actually pulls it off. Mark G. Sobell has created a single reference for Red Hat Linux that cant be beat! This marvelous text (with a 4-CD set of Linux Fedora Core 2 included) is well worth the price. This is as close to an everything you ever needed to know book that Ive seen. Its just that good and rates 5 out of 5. Ray Lodato, Slashdot contributor Mark Sobell has written a book as approachable as it is authoritative. Jeffrey Bianchine, Advocate, Author, Journalist Excellent reference book, well suited for the sysadmin of a Linux cluster, or the owner of a PC contemplating installing a recent stable Linux. Dont be put off by the daunting heft of the book. Sobell has strived to be as inclusive as possible, in trying to anticipate your system administration needs. Wes Boudville, Inventor A Practical Guide to Red Hat Linux is a brilliant book. Thank you Mark Sobell. C. Pozrikidis, University of California at San Diego This book presents the best overview of the Linux operating system that I have found. . . . [It] should be very helpful and understandable no matter what the readers background: traditional UNIX user, new Linux devotee, or even Windows user. Each topic is presented in a clear, complete fashion, and very few assumptions are made about what the reader knows. . . . The book is extremely useful as a reference, as it contains a 70-page glossary of terms and is very well indexed. It is organized in such a way that the reader can focus on simple tasks without having to wade through more advanced topics until they are ready. Cam Marshall, Marshall Information Service LLC, Member of Front Range UNIX Users Group [FRUUG], Boulder, Colorado Conclusively, this is THE book to get if you are a new Linux user and you just got into the RH/Fedora world. Theres no other book that discusses so many different topics and in such depth. Eugenia Loli-Queru, Editor in Chief, OSNews.com For use with all versions of Linux, including Ubuntu, Fedora, openSUSE, Red Hat, Debian, Mandriva, Mint, and now OS X, too! Get more done faster, and become a true Linux guru by mastering the command line! Learn from hundreds of realistic, high-quality examples NEW! Coverage of the Mac OS X command line and its unique tools NEW! Expert primer on automating tasks with Perl The Most Useful Linux Tutorial and Reference, with Hundreds of High-Quality Examples for Every DistributionNow Covers OS X and Perl, Too! To be truly productive with Linux, you need to thoroughly master shells and the command line. Until now, you had to buy two books to gain that mastery: a tutorial on fundamental Linux concepts and techniques, plus a separate reference. Now, theres a far better solution. Renowned Linux expert Mark Sobell has brought together comprehensive, insightful guidance on the tools system administrators, developers, and power users need most, and an outstanding day-to-day reference, both in the same book. This book is 100 percent distribution and release agnostic: You can use it with any Linux system, now and for years to come. Use Macs, too? This new edition adds comprehensive coverage of the Mac OS X command line, including essential OS X-only tools and utilities other Linux/UNIX books ignore. Packed with hundreds of high-quality, realistic examples, this book gives you Linux from the ground up: the clearest explanations and most useful knowledge about everything from filesystems to shells, editors to utilities, and programming tools to regular expressions. Sobell has also added an outstanding new primer on Perl, the most important programming tool for Linux admins seeking to automate complex, time-consuming tasks. A Practical Guide to Linux Commands, Editors, and Shell Programming, Second Edition, is the only book to deliver Better, more realistic examples covering tasks youll actually need to perform Deeper insight, based on Sobells immense knowledge of every Linux and OS X nook and cranny A start-to-finish primer on Perl for every system administrator In-depth coverage of basic and advanced Linux shell programming with bash and tcsh Practical explanations of 100 core utilities, from aspell to xargsincluding Mac OS X specific utilities from ditto to SetFile All-new coverage of automating remote backups with rsync Dozens of system security tips, including step-by-step walkthroughs of implementing secure communications using ssh and scp Tips and tricks for customizing the shell and using it interactively from the command line Complete guides to high-productivity editing with both vim and emacs A comprehensive, 286-page command reference sectionnow with revised and expanded indexes for faster access to the information you need Instructions for updating systems automatically with apt-get and yum Dozens of exercises to help you practice and gain confidence And much more, including coverage of BitTorrent, gawk, sed, find, sort, bzip2, and regular expressions",
    "author": [
      {
        "family": "Sobell",
        "given": "Mark G."
      }
    ],
    "edition": "2nd",
    "id": "10.5555/1667111",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Practical guide to linux commands, editors, and shell programming, a",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "This workshop and accompanying paper will discuss and demonstrate some of the strengths and weaknesses of the new VB.Net object-oriented programming language. It is appropriate for anyone who is contemplating a course in the new language or anyone who just wants to know more about VB.Net architecture. Database connectivity and web applications will be demonstrated in addition to some fundamental navigational and Interactive Development Environment (IDE) issues. Finally, the authors will share their experiences in developing and teaching VB.Net as a second or third language to junior and senior CS/IS majors and minors at Northwest Missouri State University.",
    "author": [
      {
        "family": "Ury",
        "given": "Gary"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/767598.767646",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2003,
          4
        ]
      ]
    },
    "page": "332-335",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Workshop on moving to visual basic.net",
    "type": "article-journal",
    "volume": "18"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Logicwriter Actual is a web app (https://www.cs.drexel.edu/ bchar/logicwriter/standardConfig/web/index.html) designed for freeform entry and linear display in Unicode of text combined with symbolic logic characters such as ≡, ∃, ∧, ⇒, λ, and Ω. It is designed for the writing done by students or instructors in foundational-level (second year) courses introducing mathematical reasoning: elementary formal or informal proofs often involving commonplace situations or computer science contexts such as program behavior. Rather than being a scaffolded practice harness [1], or an automated reasoning tool/proof checker [2, 5], the goal of Logicwriter Actual is just to make it easier for students to practice more mathematical writing. The WYSIWYG result can be copy/pasted into most document processors (for submitted or shared work), Discord or Slack channels (for chat conversations), email, code editors, etc. It is designed to be immediately usable by browser- and laptop-savvy students, so more convenient to use in a foundational course than available alternatives (word processors, LaTeX, LyX, keyboard entry of Unicode indices, Math Jax plugins, etc. [3, 4, 6]) It is designed to need minimal computer resources (runs in browser, can be delivered from any web page server), and instructor time (for student training, or tech support). Because it is just a writing tool, it is compatible with most instructional approaches that ask students to write their own proofs and explanations. Assessment is underway through student survey of usage experience and effects, and by instructor survey/interview.to see if there are perceived benefits to its approach to text entry and style of implementation as a web app.",
    "author": [
      {
        "family": "Char",
        "given": "Bruce"
      },
      {
        "family": "Earth",
        "given": "Steve"
      },
      {
        "family": "Johnson",
        "given": "Jeremy"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/3606402.3606429",
    "issue": "8",
    "issued": {
      "date-parts": [
        [
          2023,
          4
        ]
      ]
    },
    "page": "220-221",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "A web app for writing with mathematical logic",
    "type": "article-journal",
    "volume": "38"
  },
  {
    "ISBN": "1928994512",
    "abstract": "From the Publisher: All the essential information needed to take full advantage of Microsoft’s newest Web development platform. What is ASP.NET ASP.NET is a revolutionary new programming framework that enables the rapid development of powerful web applications and services. Part of the emerging Microsoft .NET Platform, it provides the easiest and most scalable way to build, deploy and run distributed web applications that can target any browser or device. ASP.NET (formerly referred to as ASP+) is more than the next version of Active Server Pages (ASP); it is a unified Web development platform that provides the services necessary for developers to build enterprise-class Web applications. ASP.NET Web Developer’s Guide will teach Web developers to quickly and easily build solutions for the Microsoft .NET platform. Programmers who are expert in asp and other languages will find this book invaluable. Features: This book will appeal to all web developers - regardless of what language they are using or what platform they will be using You can take it with you. The book comes packaged with Syngress’ revolutionary wallet-sized CD containing a printable HTML version of the book, all of the source code examples and demos of popular ASP.NET programming tools Comprehensive Coverage of the Entire .net Framework for B2B commerce About the Author Jeremy Faircloth (CCNA, MCSE, MCP+I, A+) is a Systems Analyst for Gateway, Inc. In this position, he develops and maintains enterprise-wide clientserver and Web-based technologies. As a Systems Analyst with over 10 years of real-world IT experience, he has become an expert in many areas of IT including Web development, database administration, enterprise security, network design, and project management. Mesbah Ahmed (PhD and MS, Industrial Engineering) is a Professor of Information Systems at the University of Toledo. In addition to teaching and research, he provides technical consulting and training for IT and manufacturing industries in Ohio and Michigan. His consulting experience includes systems design and implementation projects with Ford Motors, Dana Corporation, Riverside Hospital, Sears, and others. Currently, he provides IT training in the areas of Java Server, XML, and .NET technologies. He teaches graduate level courses in Database Systems, Manufacturing Systems, and Application Development in Distributed and Web Environment. Recently, he received the University of Toledo Outstanding Teaching award, and the College of Business Graduate Teaching Excellence award. He has published many research articles in academic journals such as Decision Sciences, Information &amp; Management, Naval Research Logistic Quarterly, Journal of Operations Management, IIE Transaction, and International Journal of Production Research. Chris Garrett is the Technical Manager for a large European Web agency. He has been working with Internet technologies since 1994 and has provided technical and new media expertise for some of the world s biggest brands. Chris Payne, author of Teach Yourself ASP.NET in 21 Days, is the Co-Founder and CIO of Enfused Media, Inc., which designs and develops applications to automate and facilitate business processes. Chris has taught ASP and solution techniques through articles and tutorials. Jonothon Ortiz is Vice President of Xnext, Inc. in Winter Haven, FL. Xnext, Inc. is a small, privately owned company that develops Web sites and applications for prestigious companies such as the New York Times. Wei Meng Lee is Series Editor for Syngress Publishings .NET Developer Series. He is currently lecturing at The Center for Computer Studies, Ngee Ann Polytechnic, Singapore. Wei Meng is actively involved in Web development work and conducts training for Web developers and Visual Basic programmers. He has co-authored two books on WAP. He holds a bachelor s degree in Information Systems and Computer Science from the National University of Singapore. The first book in the .NET series, VB.NET Developers Guide (ISBN: 1-928994-48-2), is currently available from Syngress Publishing.",
    "author": [
      {
        "family": "Payne",
        "given": "Chris"
      },
      {
        "family": "Lee",
        "given": "Wei Meng"
      },
      {
        "family": "Garrett",
        "given": "Chris"
      },
      {
        "family": "Ahmed",
        "given": "Mesbah"
      },
      {
        "family": "Faircloth",
        "given": "Jeremy"
      },
      {
        "family": "Ortiz",
        "given": "Jonothon"
      },
      {
        "family": "Patton",
        "given": "Robert"
      }
    ],
    "id": "10.5555/559981",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Syngress Publishing",
    "title": "ASP.NET web developer’s guide",
    "type": "book"
  },
  {
    "DOI": "10.1145/199688.199713",
    "ISBN": "089791693X",
    "URL": "https://doi.org/10.1145/199688.199713",
    "abstract": "A student internship in a suitable business or organization can augment, reinforce, and embellish material learned in the classroom. Computer Science student interns can experience such things as real-world development environments, projects which greatly exceed the scale of typical programming assignments, the utter importance of (possibly lacking) documentation, as well as diverse languages, operating systems, and hardware. Opportunities for such internships occur rarely, however, for many rural two-year colleges, especially those geographically isolated from companies which could provide this experience.Despite such a situation at our college, we still provide students with an internship experience by creating an internal organization: the Software Development Internship (SDI) with the mission to develop custom software for other departments on campus. In this paper we describe the formation of the SDI, its activities, and some of the benefits and lessons learned to date.",
    "author": [
      {
        "family": "Cohen",
        "given": "Norman"
      },
      {
        "family": "Dann",
        "given": "Wanda"
      }
    ],
    "collection-title": "SIGCSE ’95",
    "container-title": "Proceedings of the twenty-sixth SIGCSE technical symposium on computer science education",
    "id": "10.1145/199688.199713",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "page": "44-47",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Using an internal internship to enhance computer science education in a two-year college",
    "type": "paper-conference"
  },
  {
    "ISBN": "1787283690",
    "abstract": "Key Features Covers the latest and advanced concepts of Python such as parallel processing with Python 3.6 Explore the Python language from its basic installation and setup to concepts such as reactive programming and microservices Get introduced to the mechanism for rewriting code in a compiled language along with ctypes and Cython tools Book Description Daniel Arbuckle’s Mastering Python covers the basics of operating in a Python development environment, before moving on to more advanced topics. Daniel presents you with real-world solutions to Python 3.6 and advanced-level concepts, such as reactive programming, microservices, ctypes, and Cython tools. You don’t need to be familiar with the Python language to use this book, as Daniel starts with a Python primer. Throughout, Daniel highlights the major aspects of managing your Python development environment, shows you how to handle parallel computation, and helps you to master asynchronous I/O with Python 3.6 to improve performance. Finally, Daniel will teach you the secrets of metaprogramming and unit testing in Python, helping you acquire the perfect skillset to be a Python expert. Daniel will get you up to speed on everything from basic programming practices to high-end tools and techniques, things that will help set you apart as a successful Python programmer. What you will learnGet to grips with the basics of operating in a Python development environment Build Python packages to efficiently create reusable code Become proficient at creating tools and utility programs in Python Use the Git version control system to protect your development environment from unwanted changes Harness the power of Python to automate other software Distribute computational tasks across multiple processors Handle high I/O loads with asynchronous I/O to get a smoother performance Take advantage of Python’s metaprogramming and programmable syntax featuresGet acquainted with the concepts behind reactive programming and RxPyAbout the Author Daniel Arbuckle gained his PhD in Computer Science from the University of Southern California. He has published numerous papers along with several books and video courses, and he is both a teacher of computer science and a professional programmer.",
    "author": [
      {
        "family": "Arbuckle",
        "given": "Daniel"
      }
    ],
    "id": "10.5555/3161092",
    "issued": {
      "date-parts": [
        [
          2017
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Daniel arbuckle’s mastering python",
    "type": "book"
  },
  {
    "ISBN": "1595933425",
    "abstract": "eTX and The Eclipse PhenomenonThe following sketches the history of the Eclipse project and the eTX events.The Eclipse ProjectThe Eclipse Project began in April 1999 at IBM’s OTI laboratory. It was initially conceived as a successor product for the VisualAge family of software development tools. VisualAge was a commercially successful IDE, but it was also a closed environment built on proprietary APIs. It did not integrate well with other vendors’ tools, and only the IBM/OTI team could enhance or extend the product. Moreover, it was becoming apparent from customer experience that more was required than a simple re-write of VisualAge. In fact, there was growing demand for a tool integration platform — a programming environment that would provide kernel IDE functionality, but also allow developers, third party vendors and users to seamlessly add their own extensions, personalizations, and enhancements.The Eclipse team set out to identify the essential kernel concepts underlying the VisualAge product line (or any other IDE for that matter). In effect, they wanted to strip out all of the functionality within an IDE that was specific to a particular programming language, development task, or programming model. The hope was that there would be substantial residual function left behind, that could then be restructured to form a content-neutral, and programming language-neutral, foundation on which IDEs and similar products could be built from components. It was a bold venture, since there was no guarantee that anything practically useful would result.What they discovered was Eclipse: a tool integration platform together with a set of components (plugins, in the Eclipse vernacular) that could be seamlessly assembled into a wide variety of software development products. The Java Development Toolkit (JDT) — the Eclipse Java IDE — became their proof-point. It was built in parallel by a separate team, which operated independently from the Eclipse Platform project. The JDT team had no special privileges; they had to use the same APIs as any third party product and were allowed no \"back door\" access to Platform kernel functionality. The intent was that, despite these constraints, the finished JDT should be indistinguishable from a purpose-built, vertically integrated IDE product like VisualAge. This goal was realized, the Eclipse Project was a success, and the Eclipse Community was born.In the years since the Eclipse code base was released into open source by IBM, its growth has been nothing short of spectacular. Tens of thousands download the Eclipse SDK every week from over fifty mirror sites around the globe. Thousands of Eclipse plugins are now available from open source and commercial suppliers. Software vendors are now shipping several hundred commercial products based on Eclipse. Over 60 companies are members of the Eclipse Foundation, which hosts Eclipse open source development. The first Eclipse Developer Conference (EclipseCON 2004) was held in February 2004 in Anaheim, California. Over 220 companies and organizations from nearly 25 countries were represented. EclipseCON 2005, another success, was held in February 2005 in Burlingame, California.Eclipse and Computer Science ResearchIt has been particularly interesting to see the uptake of Eclipse within the research community. In retrospect one could perhaps have anticipated this. Computing is, after all, an empirical discipline — ideas must be implemented to be validated. For software researchers in particular, the computer becomes our laboratory. We necessarily build on the work of those who have gone before, and of course as time progresses our technology pyramids keep getting higher. Complexity is our bane: the low-hanging fruit were picked long ago, and most interesting problems are just not simple. Consequently, experimentation usually requires complex infrastructure, plumbing, as we often call it. Most researchers spend far too much time building (and rebuilding, and fixing) this plumbing, and far too little time actually developing new ideas. Given the nature of research, there are seldom any applicable standards for such infrastructure (these only come much later when the research has matured into products). Consequently researchers up to now have had to live and work in their own vertical towers, sharing their ideas but only infrequently sharing code. The only common programming platform among researchers was \"emacs\", and while this continues to be very flexible, it lags far behind industrial-scale IDEs in terms of functionality.But Eclipse changes this context. It provides a means to create and share that necessary common infrastructure, particularly for investigators in such areas as programming languages, tools, and environments. Researchers can focus more of their time on their real mission of innovation, and much less on the tedious plumbing tasks. Moreover, Eclipse-based implementations are built from commercial-quality components, resulting in robust demonstration systems that make it much easier for researchers to publicize and promote their work.What specifically does Eclipse offer researchers that makes it so attractive? First, it is an extensible platform for integrating components, which comes replete with a large number of commercial quality components out of the box. It runs on nearly all operating systems and GUI combinations, and is one of the few Java implementations that actually realizes that language’s \"write once run everywhere\" potential (rather than the typical \"write once test everywhere\" experience). Perhaps most importantly, it is available in open source with a generous non-viral license. Finally, it has tremendous visibility due to broad based industry support, which includes the backing of such powerhouse firms as IBM, HP, SAP, Intel, and many more.Eclipse and Computer Science EducationThere are numerous challenges in education these days such as distance, limited resources and the recognized need to make learning a personalized and active experience. Many educators are consequently looking at how technology can address these challenges and enhance learning in the classroom and beyond. For computer science education, Eclipse has already been widely adopted as an IDE to support programming. The advantages for some are that it is free, platform independent and industrially relevant. But beyond these obvious advantages, other researchers have recognized that Eclipse provides an excellent infrastructure for developing learning tools. These tools can leverage the wealth of technology already present in the Eclipse community, as well as benefit from integration with other learning tools developed by other researchers and educators. The result of these multiple efforts is the emergence of Eclipse as an effective and powerful platform to support research in educational technologies and an improved learning experience in many settings.The eclipse Technology eXchangeThat idea that Eclipse would provide exactly the rich, open and robust platform that IT researchers needed was not initially an obvious one, and so it needed to be promoted within the academic community. IBM and eclipse.org set out to popularize these ideas by hosting a series of workshops and birds-of-a-feather events at various software research conferences. This ad hoc program gradually evolved into the eclipse Technology eXchange (eTX) workshops held in 2003, 2004 and 2005, the most recent of which being held at OOPSLA 2005 in San Diego. These events provide a forum for researchers who are using Eclipse to network and share their experiences and their code. The foundation for a successful eTX is a set of high quality, refereed presentations, which serve to illustrate the breadth and vitality of the Eclipse research and teaching communities. The paper presentations are combined with lively discussions which will help set the stage for future research and development using Eclipse.",
    "id": "10.1145/1117696",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Eclipse ’05: Proceedings of the 2005 OOPSLA workshop on eclipse technology eXchange",
    "title-short": "Eclipse ’05",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "The GitKit facilitates teaching Git and GitHub workflow in the context of an authentic Free and Open Source Software (FOSS) project. It is appropriate for use in software development courses ranging from high school through college. The GitKit is a snapshot of a FOSS project’s artifacts (codebase(s), issues, etc.) packaged with student learning activities, an instructor guide, and a containerized development environment. The GitKit can be used to provide a light introduction in a few class sessions, or a more comprehensive experience over 4-6 sessions. Participants will gain hands-on experience with the GitKit from both the student and instructor perspectives.",
    "author": [
      {
        "family": "Braught",
        "given": "Grant"
      },
      {
        "family": "Jackson",
        "given": "Stoney"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/3636988.3636991",
    "issue": "3",
    "issued": {
      "date-parts": [
        [
          2023,
          10
        ]
      ]
    },
    "page": "21",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "GitKit: Teaching git and GitHub/GitLab workflow in an authentic context",
    "title-short": "GitKit",
    "type": "article-journal",
    "volume": "39"
  },
  {
    "DOI": "10.1016/j.future.2018.02.004",
    "ISSN": "0167-739X",
    "URL": "https://doi.org/10.1016/j.future.2018.02.004",
    "author": [
      {
        "family": "Sperhac",
        "given": "Jeanette M."
      },
      {
        "family": "Gallo",
        "given": "Steven M."
      }
    ],
    "container-title": "Future Gener. Comput. Syst.",
    "id": "10.1016/j.future.2018.02.004",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          5
        ]
      ]
    },
    "keyword": "Undergraduate education, Data analytics, Science gateway",
    "page": "833-840",
    "publisher": "Elsevier Science Publishers B. V.",
    "publisher-place": "NLD",
    "title": "VIDIA: A HUBzero gateway for data analytics education",
    "title-short": "VIDIA",
    "type": "article-journal",
    "volume": "94"
  },
  {
    "ISBN": "9780769531007",
    "abstract": "A range of technologies and teaching strategies may be used to improve the quality of teaching object-oriented (OO) concepts where there is a close relationship between OO analysis and design (OOAD) combined with OO programming (OOP). This study investigates the application of a number of these technologies and teaching strategies across university courses in OOAD and OOP, using an empirical approach based upon attitudinal and student performance data. The systems used include: development environments that provide two-way linkage between UML diagrams and OO program code; interactive whiteboards to allow educational demonstrations that more closely represent actual practice; and an online delivery tool for course content, messages and discussions. Close integration between the processes of OOAD and OOP courses is also investigated. The approaches significantly improved student grades, perceived levels of understanding and productivity. The integration of course concepts and assignments, and the electronic discussion boards, are key benefit drivers.",
    "author": [
      {
        "family": "Debuse",
        "given": "Justin C. W."
      },
      {
        "family": "Stiller",
        "given": "Tony"
      }
    ],
    "collection-title": "ASWEC ’08",
    "container-title": "Proceedings of the 19th australian conference on software engineering",
    "id": "10.5555/1395083.1395659",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "page": "97-103",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Technologies and strategies for integrating object-oriented analysis and design education with programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1384271.1384315",
    "ISBN": "9781605580784",
    "URL": "https://doi.org/10.1145/1384271.1384315",
    "abstract": "While collaborative approaches in the classroom have been shown to be highly beneficial for students of computer science, obstacles inherent in today’s academic environment often prevent collocated collaborative approaches from being implemented. One solution to the collocation problem may lie with tools that facilitate distributed collaboration. This paper presents RIPPLE (Remote Interactive Pair Programming and Learning Environment), a development environment for distributed synchronous collaborative programming. RIPPLE is an open source software tool. Initial user tests demonstrate positive responses from students, and the potential for long term learning, motivation, and retention benefits is significant. In addition to its benefits for students, RIPPLE is a tool for computing education researchers who wish to collect data on collaborative programming.",
    "author": [
      {
        "family": "Boyer",
        "given": "Kristy Elizabeth"
      },
      {
        "family": "Dwight",
        "given": "August A."
      },
      {
        "family": "Fondren",
        "given": "R. Taylor"
      },
      {
        "family": "Vouk",
        "given": "Mladen A."
      },
      {
        "family": "Lester",
        "given": "James C."
      }
    ],
    "collection-title": "ITiCSE ’08",
    "container-title": "Proceedings of the 13th annual conference on innovation and technology in computer science education",
    "id": "10.1145/1384271.1384315",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "programming environments, laboratory/active learning, distributed tutoring, distributed pair programming, distributed collaboration, distance learning",
    "page": "158-162",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "A development environment for distributed synchronous collaborative programming",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3478431.3499422",
    "ISBN": "9781450390705",
    "URL": "https://doi.org/10.1145/3478431.3499422",
    "abstract": "One notable part of the academia-industry gap is the deficiency in computing ecosystem literacy, which may result in college graduates exhibiting little technical knowledge of software development tools and practices commonly used in industry. This paper presents our experience developing and teaching \"The Missing CS Class,\" the student-led 1-unit course that we created at our university to address computing ecosystem literacy. This course primarily targets lower-division students and, based on our observations as peer tutors, covers four common but crucial gaps in technical knowledge: (1) Unix-like command-line environments and tools, (2) Software testing and debugging, (3) Scripting, and (4) Version control. Based on the collected feedback from two consecutive offerings of this course during the winter and spring quarters of 2021, most surveyed students reported having increased their self-efficacy on all course topics and incorporated them into their software development workflow.To benefit the community at large, we have published all the lecture materials online at &lt;a href=\"https://missing.cs.ucdavis.edu\"&gt;https://missing.cs.ucdavis.edu&lt;/a&gt;.",
    "author": [
      {
        "family": "Gilson",
        "given": "Grant"
      },
      {
        "family": "Ott",
        "given": "Stephen"
      },
      {
        "family": "Rose Ledesma",
        "given": "Noah"
      },
      {
        "family": "Prabhu",
        "given": "Aakash"
      },
      {
        "family": "Porquet-Lupine",
        "given": "Joël"
      }
    ],
    "collection-title": "SIGCSE 2022",
    "container-title": "Proceedings of the 53rd ACM technical symposium on computer science education - volume 1",
    "id": "10.1145/3478431.3499422",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "student-led undergraduate course, computing ecosystem literacy, computer science education, academia-industry gap",
    "page": "467-473",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design and evaluation of \"the missing CS class,\" a student-led undergraduate course to reduce the academia-industry gap",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/ASE.2011.6100095",
    "ISBN": "9781457716386",
    "URL": "https://doi.org/10.1109/ASE.2011.6100095",
    "abstract": "For decades now, mainstream development environments provide the same basic automations for navigating source code: mainly searching and the tree exploration of files and folders. This may imply that other automations have little additional value or too steep a learning curve for mainstream adoption. This paper investigates whether source code navigation enriched with traceability benefit basic maintenance tasks such as changing features and fixing bugs in code. To test this, we conducted a controlled experiment with 52 subjects performing real maintenance tasks on two third-party development projects: all with the same navigation tool but half of the tasks with and the other half without traceability navigation. We found that the existence of traceability profoundly affected the quality of the change tasks and fundamentally changed how software engineers navigated through source code. We show that software engineers benefit instantly from traceability, without training, which is to show that the current automations available to software engineers are by no means sufficient or the only easy ones to use.",
    "author": [
      {
        "family": "Mader",
        "given": "Patrick"
      },
      {
        "family": "Egyed",
        "given": "Alexander"
      }
    ],
    "collection-title": "ASE ’11",
    "container-title": "Proceedings of the 26th IEEE/ACM international conference on automated software engineering",
    "id": "10.1109/ASE.2011.6100095",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "page": "444-447",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Do software engineers benefit from source code navigation with traceability? – an experiment in software change management",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3291280.3291787",
    "ISBN": "9781450365680",
    "URL": "https://doi.org/10.1145/3291280.3291787",
    "abstract": "Scratch is a visual, block-based programming language, adopted as a computational thinking development tool in elementary education among many countries. Thailand has also recently included Scratch as part of the computing science course in its basic education. However, Thailand is facing a shortage of ICT teachers who are skillful in Scratch programming, especially in small provincial schools. This research aims to overcome the shortage by developing ScratchThAI, a Scratch tutorial chatbot. It is designed to assist young learners directly through a messaging platform. By giving supports through a textual conversation, more relevant advice, knowledge, and resources could be provided precisely. Different levels of each computational thinking concept are extracted and evaluated by the designed assessment algorithm. Extra predefined exercises are assigned based on the analyzed learner’s strengths and weaknesses in order to actively improving the learner’s understanding. Moreover, gamification is incorporated to engage and motivate young learners in computational thinking development.",
    "author": [
      {
        "family": "Katchapakirin",
        "given": "Kantinee"
      },
      {
        "family": "Anutariya",
        "given": "Chutiporn"
      }
    ],
    "collection-title": "IAIT ’18",
    "container-title": "Proceedings of the 10th international conference on advances in information technology",
    "id": "10.1145/3291280.3291787",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "Virtual Teaching Assistant, Virtual Scratcher, Scratch Tutoring Chatbot, Personalized Learning, Game-Based Learning, Educational Technology, Computational thinking development, AI in Education",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An architectural design of ScratchThAI: A conversational agent for computational thinking development using scratch",
    "title-short": "An architectural design of ScratchThAI",
    "type": "paper-conference"
  },
  {
    "ISBN": "0789724731",
    "abstract": "From the Publisher: Platinum Edition XHTML, XML and Java 2 is separated into several sections, each of which focuses on a specific technology, including XHTML, XML, JavaScript, Dynamic HTML, CGI programming with Perl, Server-side Programming with ASP, ColdFusion and PHP, and Java 2. Throughout the book, the authors focus on the features and benefits of each technology, giving readers a well-rounded education in current web development tools and techniques. In addition, the authors demonstrate the value of combining various technologies (such as Java and XML) for more powerful web solutions. All the code and working applications developed in the book will be available for download from Que’s web site at www.mcp.com/que Completely updated and revised with the latest information about the newest web technologies including XHTML, Java 2 and XML.",
    "author": [
      {
        "family": "Ladd",
        "given": "Eric"
      },
      {
        "family": "Watt",
        "given": "Andrew H."
      },
      {
        "family": "Morgan",
        "given": "Mike"
      }
    ],
    "id": "10.5555/557698",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "Que Corp.",
    "publisher-place": "USA",
    "title": "Platinum edition using XHTML, XML, and java 2",
    "type": "book"
  },
  {
    "ISBN": "178646795X",
    "abstract": "Key Features Configure, build, and run Android projects with Android Studio 2Test your apps using the Android emulator and learn how to manage virtual devices Explore how Android Studio 2 can be made a part of your workflow to reduce the overall development time Book Description Android Studio 2, the official IDE for Android application development, dramatically improves your workflow by letting you quickly see changes running on your device or emulator. It gives developers a unique platform by making app builds and deployment faster. This book will get you up and running with all the essential features of Android Studio 2 to optimize your development workflow. Starting off with the basic installation and configuration of Android Studio 2, this book will help you build a new project by showing you how to create a custom launcher icon and guiding you to choose your project. You will then gain an insight into the additional tools provided in Android Studio, namely the Software Development Kit (SDK) Manager, Android Virtual Device (AVD) Manager, and Javadoc. You’ll also see how to integrate Google Play Services in an Android project. Finally, you’ll become familiar with the Help section in Android Studio, which will enable you to search for support you might require in different scenarios. What you will learn Install Android Studio on your system and configure the Android Software Development KitCreate your first project and explore its structure Manage a project in Android Studio 2 with Gradle Improve your productivity while programming by getting the best of the code editor Design the user interface using layouts and see how to handle various user events Integrate Google Play services into your project efficiently Monitor your app while it’s running and constantly improve its performance About the Author Belen Cruz Zapata received her engineer’s degree in computer science from the University of Murcia in Spain, specializing in software technologies, and intelligent and knowledge technologies. She earned an MSc in computer science and is now working on her PhD in the Software Engineering Research Group from the University of Murcia. During the 2013/2014 academic year, Belen collaborated with the Universite Mohammed V-Soussi, in Rabat, Morocco. Her research is focused on usability applied to mobile health (mHealth) applications. Belen is currently working as a mobile developer for Android and iOS in the San Francisco Bay area. She is also the author of the book: Testing and Securing Android Studio Applications, Packt Publishing. To follow her projects, you can visit her personal webpage at http://www.belencruz.com and you can follow her on Twitter: @belen_cz.",
    "author": [
      {
        "family": "Zapata",
        "given": "Belen Cruz"
      }
    ],
    "edition": "2nd",
    "id": "10.5555/3055949",
    "issued": {
      "date-parts": [
        [
          2016
        ]
      ]
    },
    "publisher": "Packt Publishing",
    "title": "Android studio 2 essentials",
    "type": "book"
  },
  {
    "ISSN": "1937-4771",
    "abstract": "Group projects are widely used in software engineering courses. With group projects come issues of group management and individual student assessment. At the University of Mary Washington, a different approach to group composition and management was used in a semester-long undergraduate software engineering course. In this approach, the student composition of each group changes at each phase of the software lifecycle. This approach offered several advantages including increased fairness in group composition, more honest peer assessments, and lower risk of group failure. In addition, this approach modeled the software development environment seen in the real-world. The details of the software engineering course and dynamic group element are described in this paper along with reactions from students and the instructor.",
    "author": [
      {
        "family": "Anewalt",
        "given": "Karen"
      }
    ],
    "container-title": "J. Comput. Sci. Coll.",
    "id": "10.5555/1629036.1629060",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2009,
          12
        ]
      ]
    },
    "page": "146-151",
    "publisher": "Consortium for Computing Sciences in Colleges",
    "publisher-place": "Evansville, IN, USA",
    "title": "Dynamic group management in a software projects course",
    "type": "article-journal",
    "volume": "25"
  },
  {
    "ISBN": "0970284624",
    "abstract": "From the Publisher:Helping developers harness the power of Intel s new line of very long instruction word (VLIW) processors, this guide provides insight into the effective use of Itanium software development tools. Beginning with code optimization advice, including low-level explanation of the process of code compilation, this resource then gives an explanation of ways programmers can take advantage of the EPIC architecture’s parallelism. A thorough treatment of porting applications to the Itanium environment is provided along with unique insights into optimization and tuning of Itanium applications. Included are numerous examples and an extensive case history. Walter Triebel is the author of Itanium Architecture for Software Developers and is currently an adjunct professor at Fairleigh Dickinson University. He lives in Wayne, New Jersey. Joe Bissell teaches computer architecture, assembly language and embedded systems at the University of Delaware. He lives in Media, Pennsylvania. Rick Booth manages digital video production and delivery at Visible World and is the author of Inner Loops. He lives in Bensalem, Pennsylvania.",
    "author": [
      {
        "family": "Triebel",
        "given": "Walter"
      },
      {
        "family": "Booth",
        "given": "Rick"
      },
      {
        "family": "Bissell",
        "given": "Joe"
      }
    ],
    "id": "10.5555/581807",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Intel Press",
    "title": "Programming itanium-based systems",
    "type": "book"
  },
  {
    "DOI": "10.1145/3484272.3484969",
    "ISBN": "9781450390897",
    "URL": "https://doi.org/10.1145/3484272.3484969",
    "abstract": "First-year students benefit from robotics-based programming exercises by learning how to use sensors to gain information on the (changing) world surrounding the robot, how to model this information using data structures, and how to design algorithms for performing meaningful activities. Robotics-based exercises are naturally experiential and team-based and provide among the most memorable teachable moments of first-year programming courses. We summarize the pedagogical challenges that robotics-based exercises face, even under ideal circumstances, and how a university responded to these challenges. We report on the additional challenges faced in late 2020 at the same university as a result of the COVID pandemic, and how the course staff addressed these challenges using programming language implementation and network tools. The crucial components were (1) a custom-built web-based development environment with collaborative features including a built-in compiler, (2) a portable virtual machine, (3) collaborative editing, (4) open source protocols, and (5) peer-to-peer teleconferencing software. We report on the lessons learnt and how to further improve the resilience of robotics-based programming exercises.",
    "author": [
      {
        "family": "Anderson",
        "given": "Boyd"
      },
      {
        "family": "Henz",
        "given": "Martin"
      },
      {
        "family": "Tee",
        "given": "Hao-Wei"
      }
    ],
    "collection-title": "SPLASH-e 2021",
    "container-title": "Proceedings of the 2021 ACM SIGPLAN international symposium on SPLASH-e",
    "id": "10.1145/3484272.3484969",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "keyword": "teaching CS1 using robotics, online robotics, learning tools, educational robotics",
    "page": "82-86",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Ruggedizing CS1 robotics: Tools and approaches for online teaching",
    "title-short": "Ruggedizing CS1 robotics",
    "type": "paper-conference"
  },
  {
    "ISBN": "0818679964",
    "abstract": "Cache memory design in embedded systems can take advantage from the analysis of the software that runs on that system, which usually remains the same for its whole life. Programs can be characterized, in respect of the memory hierarchy, using locality analysis. We propose an environment which permits to analyze the locality of a program and the effects on the target system performance. The student can thus figure out the best tradeoff between costs and performance for cache, memory and timings exploring different system configurations. A fully graphical interface permits to observe the program behavior from many points of view: locality surface, working set evolution, performance metrics. The tool is currently used as a teaching tool at our University and it is distributed as part of a commercial development environment for embedded systems.",
    "author": [
      {
        "family": "Giorgi",
        "given": "Roberto"
      },
      {
        "family": "Prete",
        "given": "Cosimo Antonio"
      },
      {
        "family": "Prina",
        "given": "Gianpaolo"
      }
    ],
    "collection-title": "MSE ’97",
    "container-title": "Proceedings of the 1997 international conference on microelectronics systems education (MSE ’97)",
    "id": "10.5555/523205.882907",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "keyword": "Program Locality, Performance Evaluation, Embedded System, Didactic Tool, Cache",
    "page": "16",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Cache memory design for embedded systems based on program locality analysis",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321286081",
    "abstract": "\"Over the years I have seen the software development pendulum swing from one extreme to the other, as deficiencies in ’best practices’ at one end of the spectrum spawned a new set of ’best practices’ at the opposite end. Kevin Tate’s book has finally brought the pendulum to a screeching halt, right about dead center. This book provides a balanced and practical guide to what’s important if your goal is to develop software that lasts.\"-Mary Poppendieck, Poppendieck.LLC. Author of \"Lean Software Development\"\"1) In this very practical and accessible book interspersed with real-world examples and personal opinions, Kevin has distilled his years of developing quality software into a set of principles and practices that have been proven to work. If you are thinking of introducing an agile development environment (ADE) into your organization or of improving the one you already have, this book will help you clearly understand the benefits of a sustainable ADE, establish the practices to make it happen and coach you through the follow-up required to change the culture of your organization to make sure the changes take hold.I am currently faced with exactly this challenge and this book has already given me several ideas I am looking forward to trying out.2) In an industry plagued with missed deadlines despite long overtime hours, this book offers a refreshing alternative: a set of guiding principles and simple practices to follow that allow you to get the job done by working smarter, not harder. Drawing on the author’s extensive experience developing quality software, the book clearly explains the principles behind a sustainable agile development environment, why it works, the practices to make it happen and the follow through required to turn these practices into habits.\"-Peter Schoeler, Technical Director, Artificial Mind &amp; Movement\"It’s a familiar scene-the schedule’s tight, people are putting in heroic efforts to get everything done, then at the last minute a change request comes in that wipes out the gains you had finally managed to make in meeting your ship date. Looks like it’s pizza at your desk for the weekend again! An unfortunate situation to be in but a pattern that repeats itself all too often. \"Sustainable Software Development\" offers hope to break this cycle. It shows how a change in mindset can free you from the tyranny of unrealistic expectations and brings development realities out onto the table for everyone to see. By following these techniques you will be able to define and manage a software development environment that will work for the long haul.\"-Kevin PicottSoftware development for immediate success and long-term sustainabilitySustainable Software Development brings together principles and practices for building software that is technically superior, delivers exceptional business value, and can evolve rapidly to reflect any change to your business or technical environment.Kevin Tate shows how to eliminate practices that make development unsustainable and replaces these practices with a sustainable approach that draws on the best ideas from both agile and conventional development. Tate demonstrates how to balance rapid releases and long-term sustainability, achieving both rich functionality and superior quality. You’ll learn how to build a development organization that is more productive and can continually improve its capability to handle complexity and change.Writing for developers, architects, project leaders, and other software team members, Tate shows how to: Take control of your development environment, so you can outship your competitors, leveraging new technologies and responding to new business opportunities Maintain a consistent pace that optimally balances short- versus long-term requirements Keep your code base in a \"near-shippable\" state between releases Prevent defects, rather than just recognizing and fixing them Invest continually and cost-effectively in software design improvements Leverage the fundamentals of the craft of software development Integrate sustainable processes with Agile and traditional methodologies© Copyright Pearson Education. All rights reserved.",
    "author": [
      {
        "family": "Tate",
        "given": "Kevin"
      }
    ],
    "id": "10.5555/1076970",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Sustainable software development: An agile perspective",
    "title-short": "Sustainable software development",
    "type": "book"
  },
  {
    "DOI": "10.1145/1953163.1953165",
    "ISBN": "9781450305006",
    "URL": "https://doi.org/10.1145/1953163.1953165",
    "abstract": "In 1995, my research team and I decided to create TeachScheme!, an educational outreach project, with the hope that our work on programming languages could effect a dramatic change in K-12 computer science. Specifically, we envisioned a virtuous cycle of two mutually reinforcing ideas. On the one hand, we would create a design-oriented curriculum path from middle school through college. On the other hand, our approach would help kids with learning school mathematics. Hence a course on programming would benefit every student, not just those who end up choosing computer science as a college major. At this point, we have a new design-oriented curriculum; a pedagogic program development environment to make it fun; and a series of matching programming languages. After focusing at the overlap between high schools and colleges at first, we now use after-school programs to move upstream, and we are working on two major downstream courses for the second semester in college: one on object-oriented design and another on logic in program design.My talk will focus on just one aspect of the project: the design-oriented curriculum and its smooth path from middle school to college. I will first demonstrate how to teach an intellectually interesting and fun course on programming with something that looks like plain school mathematics. For the rest of the talk, I will sketch the path from there through college.",
    "author": [
      {
        "family": "Felleisen",
        "given": "Matthias"
      }
    ],
    "collection-title": "SIGCSE ’11",
    "container-title": "Proceedings of the 42nd ACM technical symposium on computer science education",
    "id": "10.1145/1953163.1953165",
    "issued": {
      "date-parts": [
        [
          2011
        ]
      ]
    },
    "keyword": "scheme, design-oriented curriculum",
    "page": "1-2",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TeachScheme!",
    "type": "paper-conference"
  },
  {
    "abstract": "Multimedia systems integrate text, audio, video, graphics, and other media and allow them to be utilized in a combined and interactive manner. Using this exciting and rapidly developing technology, multimedia applications can provide extensive benefits in a variety of arenas, including research, education, medicine, and commerce. While there are many commercial multimedia development packages, the easy and fast creation of a useful, full-featured multimedia document is not yet a straightforward task. This paper addresses issues in the development of multimedia documents, ranging from user-interface tools that manipulate multimedia documents to multimedia communication technologies such as compression, digital video editing and information retrieval. It outlines the basic steps in the multimedia authoring process and some of the requirements that need to be met by multimedia development environments. It also presents the role of video, an essential component of multimedia systems and the role of programming in digital video editing. A model is described for remote access of distributed video. The paper concludes with a discussion of future research directions and new uses of multimedia documents.",
    "author": [
      {
        "family": "Makedon",
        "given": "Fillia"
      },
      {
        "family": "Matthews",
        "given": "James"
      },
      {
        "family": "Owen",
        "given": "Charles B."
      },
      {
        "family": "Rebelsky",
        "given": "Samuel A."
      }
    ],
    "id": "10.5555/867967",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Dartmouth College",
    "publisher-place": "USA",
    "title": "Multimedia authoring, development environments, and digital video editing.",
    "type": "report"
  },
  {
    "DOI": "10.1155/2020/8868793",
    "ISSN": "1076-2787",
    "URL": "https://doi.org/10.1155/2020/8868793",
    "abstract": "In this paper, the forest algorithm and the decision tree algorithm are mainly used to analyze students’ physical education information, course exam results, and student learning data and relevant feature attributes from the online teaching platform. We aim to generate decision trees using the decision tree algorithm for the purpose of generating classification rules, based on which we can find factors that are important to students’ physical education performance and form data basis for improving teaching quality to help teaching management and teachers improve teaching methods and adjust teaching strategies. We specifically achieved this objective by constructing a model for assessing the effectiveness of student teaching, the steps of which include data collection and preparation, data preprocessing (data cleaning, conversion, integration), model construction (algorithm training), and algorithm optimization, as well as realizing the simulation results of the model. At the same time, the importance of the relevant attributes of the model is analyzed, and some measures are proposed to improve the universities: the standard of physical education teaching and the corresponding strategies for improving teaching methods. The mainstream development environment is chosen to ensure the complete operation of the project system that integrates learning, operation, and evaluation. The sports virtual simulation experimental teaching system realized in this paper has good functionality, stability, and application benefits in operation and use.",
    "author": [
      {
        "family": "Zhang",
        "given": "Zhifei"
      },
      {
        "family": "Zhao",
        "given": "Zijian"
      },
      {
        "family": "Yeom",
        "given": "Doo-Seoung"
      },
      {
        "family": "Lv",
        "given": "Zhihan"
      }
    ],
    "container-title": "Complex.",
    "id": "10.1155/2020/8868793",
    "issued": {
      "date-parts": [
        [
          2020,
          1
        ]
      ]
    },
    "publisher": "John Wiley &amp; Sons, Inc.",
    "publisher-place": "USA",
    "title": "Decision tree algorithm-based model and computer simulation for evaluating the effectiveness of physical education in universities",
    "type": "article-journal",
    "volume": "2020"
  },
  {
    "DOI": "10.1145/971300.971323",
    "ISBN": "1581137982",
    "URL": "https://doi.org/10.1145/971300.971323",
    "abstract": "Computer science instructors frequently teach using slides displayed with a computer and a data projector. This has many advantages, e.g., ability to present prepared materials and ease of switching the display to a development environment during mid-presentation. However, existing computer-based presentation systems severely limit flexibility in delivery, hindering instructors’ extemporaneous adaptation of their presentations to match their audiences. One major limitation of computer-based systems is lack of support for high-quality handwriting over slides, as with overhead projectors and other manual presentation systems. We developed and deployed Classroom Presenter, a Tablet PC-based presentation system that (1) combines the advantages of existing computer-based and manual presentation systems and (2) builds on these systems, introducing novel affordances. Classroom Presenter has been used in 25 Computer Science courses at three universities. In this paper we describe the system, summarize results from its deployment, and detail several novel uses of the system by instructors in computer science courses.",
    "author": [
      {
        "family": "Anderson",
        "given": "Richard"
      },
      {
        "family": "Anderson",
        "given": "Ruth"
      },
      {
        "family": "Simon",
        "given": "Beth"
      },
      {
        "family": "Wolfman",
        "given": "Steven A."
      },
      {
        "family": "VanDeGrift",
        "given": "Tammy"
      },
      {
        "family": "Yasuhara",
        "given": "Ken"
      }
    ],
    "collection-title": "SIGCSE ’04",
    "container-title": "Proceedings of the 35th SIGCSE technical symposium on computer science education",
    "id": "10.1145/971300.971323",
    "issued": {
      "date-parts": [
        [
          2004
        ]
      ]
    },
    "keyword": "tablet PC, digital ink, classroom presentation",
    "page": "56-60",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Experiences with a tablet PC based lecture presentation system in computer science courses",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.advengsoft.2009.01.019",
    "ISSN": "0965-9978",
    "URL": "https://doi.org/10.1016/j.advengsoft.2009.01.019",
    "abstract": "With the evolution of technology, and especially of the Internet, a growing interest has appeared for on-line education. The many advantages of e-Learning have made this teaching philosophy an ideal partner for teachers, either as a complement to regular education or as a substitute for traditional education. The development of an e-Learning system poses extra challenges for software developers, since there are other facets, such as contents and user tracking, not usually considered in software development methodologies. In this paper eLearniXML approach to the development of e-Learning systems is presented. This approach enriches the development of e-Learning systems method proposed in ADDIE with the model-based development of user interfaces and software quality consideration. By doing so, we aim at the development of, what we have named, a Model-Based Instructional Development Environment (MB-ISDE), to include e-Learning development in the current trends of model-based software development.",
    "author": [
      {
        "family": "Fardoun",
        "given": "Habib"
      },
      {
        "family": "Montero",
        "given": "Francisco"
      },
      {
        "family": "López Jaquero",
        "given": "Vı́ctor"
      }
    ],
    "container-title": "Adv. Eng. Softw.",
    "id": "10.1016/j.advengsoft.2009.01.019",
    "issue": "12",
    "issued": {
      "date-parts": [
        [
          2009,
          12
        ]
      ]
    },
    "keyword": "e-Learning, Model-based design of user interfaces, MB-ISDE",
    "page": "1297-1305",
    "publisher": "Elsevier Science Ltd.",
    "publisher-place": "GBR",
    "title": "eLearniXML: Towards a model-based approach for the development of e-learning systems considering quality",
    "title-short": "eLearniXML",
    "type": "article-journal",
    "volume": "40"
  },
  {
    "DOI": "10.4018/jvple.2012040103",
    "ISSN": "1947-8518",
    "URL": "https://doi.org/10.4018/jvple.2012040103",
    "abstract": "Task-based language learning using the benefits of online computer-assisted language learning CALL can be effective for rapid vocabulary expansion, especially when target vocabulary has been pre-arranged into bilingual categories under simpler, common Semantic Field Keywords. Results and satisfaction levels for both Chinese English majors and Japanese Engineering majors were high in this qualitative comparative study, indicating its potential for helping many students from various language backgrounds to rapidly expand their target language vocabulary, especially when blended with other real language negotiation tasks, preferably for an authentic audience. Print versus online reading and vocabulary development methods are compared, as well as surveys of both Chinese and Japanese college students, after they were engaged in a \"Collaborative Writing Exchange Project\" using similar online vocabulary development tools. All target terms were pre-organized and made available under common Semantic Field Keywords online in both Japanese and Chinese, but students had freedom to choose within sets of most relevant words from five academic disciplines. Writing themes were suggested to learners in both countries to keep their email exchanges consistent.",
    "author": [
      {
        "family": "Loucky",
        "given": "John Paul"
      }
    ],
    "container-title": "Int. J. Virtual Pers. Learn. Environ.",
    "id": "10.4018/jvple.2012040103",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2012,
          4
        ]
      ]
    },
    "keyword": "Second Language Vocabulary Acquisition SLVA, Immediate-Access Automatic Glossing, Enhancing Online Reading, Digital Vocabulary Learning, Density and Placement of Word Glosses in Reading Texts, Computer-Assisted Language Learning CALL, Clickable Glossing",
    "page": "35-58",
    "publisher": "IGI Global",
    "publisher-place": "USA",
    "title": "Designing distance learning tasks to help maximize vocabulary development",
    "type": "article-journal",
    "volume": "3"
  },
  {
    "ISBN": "0542155397",
    "abstract": "Scope of study. This dissertation investigated differences in students’ perceptions of the relative perceived complexity of traditionally developed software programs versus object-oriented developed software programs. Previous research and students at two different academic institutions were surveyed to gain insights for developing a framework by which different programming paradigms may be compared for complexity. Findings and conclusions. This dissertation discovered that the surveyed students’ perceptions of programs’ relative complexity increase when object-oriented technologies are used to solve a given business problem instead of traditional programming technologies. It will be of interest to faculty and administrators at technical institutes who want to have a greater understanding of student perceptions of complexity in different programming paradigms. It identified critical success factors, such as formatting and input/output commands, that can impact perceived program complexity. The findings also indicated a need for more efficient development tools, better training for existing tools, and more consistent design approaches.",
    "author": [
      {
        "family": "Dyck",
        "given": "Randall"
      },
      {
        "family": "Neiman",
        "given": "Amiram"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1104364",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "note": "AAI3176270",
    "publisher": "Northcentral University",
    "title": "A comparison of student perceptions of complexity for traditional and object-oriented programs",
    "type": "thesis"
  },
  {
    "DOI": "10.1109/ICGSE.2007.44",
    "ISBN": "0769529208",
    "URL": "https://doi.org/10.1109/ICGSE.2007.44",
    "abstract": "Siemens Austria’s Program and System Engineering Division SIS PSE has moved away from the classic approach of offering training via an inhouse Training Center towards a new approach called \"Learning Network\". This Learning Network is part of PSE wide international knowledge networking, and consists of about 100 internal trainers, who perform their training activities beside their main job as engineers, project managers, quality managers, or the like. Given the organization’s set-up in a global software development environment, this has particular advantages in terms of international standardization of content (where needed), provision of local content, cost, and pedagogical efficiency. This paper briefly outlines the challenges PSE is faced with, introduces the approach adopted by PSE in detail, gives three examples of training for skills development specifically needed in global software development, highlights the critical success factors of such an approach, and provides a résumé.",
    "author": [
      {
        "family": "Lutz",
        "given": "Benedikt"
      }
    ],
    "collection-title": "ICGSE ’07",
    "container-title": "Proceedings of the international conference on global software engineering",
    "id": "10.1109/ICGSE.2007.44",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "page": "140-150",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Training for global software development in an international \"learning network\"",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3524383.3533247",
    "ISBN": "9781450395793",
    "URL": "https://doi.org/10.1145/3524383.3533247",
    "abstract": "By exploring the characteristic of interaction of network teaching, we proposed to develop an English teaching interaction system based on artificial intelligence, which can solve the problems in current English teaching class. We analyzed the functional requirements of the system corresponding to different user. By buiding Ubuntu operating system as the computing platform and exploring the object-oriented dynamic teaching environment provided by artificial intelligence platform, we build the LAMP development environment with MySQL database and PHP script language. We constructed a three-tier separated architecture system by using B/S mode, and refined the design and implementation of each module function through the secondary development of platform module plug-ins. To exhibit the advantages of the artificial intelligence system, we take college English teaching as an example to illustrate its functions. The functions of curriculum creation, teaching resources and activity design can be realized in the system, which verifies the effectiveness of the artificial intelligence system in interactive teaching and learning.",
    "author": [
      {
        "family": "Zhao",
        "given": "Huimin"
      }
    ],
    "collection-title": "ICBDE ’22",
    "container-title": "Proceedings of the 5th international conference on big data and education",
    "id": "10.1145/3524383.3533247",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "LAMP development environment, English teaching, B/S architecture, Artificial intelligence",
    "page": "451-454",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design of english teaching interactive system based on artificial intelligence",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/2676723.2677275",
    "ISBN": "9781450329668",
    "URL": "https://doi.org/10.1145/2676723.2677275",
    "abstract": "The recent renaissance in early computer science education has provided K-12 teachers with multiple options for introducing children to computer science. However, tools for teaching programming for children with wide-scale adoption have been targeted mostly at pre-readers or middle school and higher grade-levels. This leaves a gap for 4th – 6th grade students, who differ developmentally from older and younger students.In this paper, we investigate block-based programming languages targeted at elementary and middle school students and demonstrate a gap in existing programming languages appropriate for 4th – 6th grade classrooms. We analyze the benefits of Scratch, ScratchJr, and Blockly for students and curriculum developers. We describe the design principles we created based on our experiences using block-based programming in 4th – 6th grade classrooms, and introduce LaPlaya, a language and development environment designed specifically for children in the gap between grades K-3 and middle school students.",
    "author": [
      {
        "family": "Hill",
        "given": "Charlotte"
      },
      {
        "family": "Dwyer",
        "given": "Hilary A."
      },
      {
        "family": "Martinez",
        "given": "Tim"
      },
      {
        "family": "Harlow",
        "given": "Danielle"
      },
      {
        "family": "Franklin",
        "given": "Diana"
      }
    ],
    "collection-title": "SIGCSE ’15",
    "container-title": "Proceedings of the 46th ACM technical symposium on computer science education",
    "id": "10.1145/2676723.2677275",
    "issued": {
      "date-parts": [
        [
          2015
        ]
      ]
    },
    "keyword": "novice programming environments, middle school, graphical programming, elementary school, computer science education",
    "page": "546-551",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Floors and flexibility: Designing a programming environment for 4th-6th grade classrooms",
    "title-short": "Floors and flexibility",
    "type": "paper-conference"
  },
  {
    "abstract": "This study examines the organizational and technological factors that contribute to the successful implementation of CASE (computer-aided software engineering) technology. A questionnaire was developed to determine a profile of CASE users. This profile was used to determine with whom interviews would be conducted. Data were collected through personal interviews with integrated CASE tool users. These interviews were analyzed using a grounded theory approach. A theory of CASE implementation was developed based on this analysis. This study found that CASE implementation success relies on the interaction between management’s understanding of information technology, the information systems development environment, and the complexity of application systems that are developed in an organization. Some of the factors underlying these core themes were suggested by the literature, but most emerged from the analysis of the data.The core theme of organizational understanding of information systems technology is described by: the presence of a champion; the factors that were considered in the decision; the commitment of management; the expected benefits of CASE technology; and the role of an information systems development methodology in the organization. The core theme of information systems development environment is described by: the skill set of the information systems professionals that the organization employs; the way the CASE tool is used; the implementation strategy chosen; and the role of an information systems development methodology in the organization. Finally, the core theme of information systems development complexity is described by: the training approach followed; the expected benefits of CASE technology; the implementation strategy used; and the role of an information systems development methodology in the organization. This study found that adherence to a systems development methodology is of particular importance when integrated CASE technology is being implemented.This research adds to the body or knowledge that explores the relationship between factors in an organization and CASE adoption success. This work also extends the stream of information systems research which utilizes qualitative techniques.",
    "author": [
      {
        "family": "Knapp",
        "given": "Constance Anne"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/220790",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "note": "UMI Order No. GAX95-30890",
    "publisher": "City University of New York",
    "publisher-place": "USA",
    "title": "An investigation into the organizational and technological factors that contribute to the successful implementation of CASE technology",
    "type": "thesis"
  },
  {
    "DOI": "10.1145/3568739.3568802",
    "ISBN": "9781450398091",
    "URL": "https://doi.org/10.1145/3568739.3568802",
    "abstract": "With the continuous promotion of the digitalization of Library and document resources, there are more and more types and scales of outsourced and self built databases in University Libraries and information units at home and abroad. In order to obtain complete digital resources, it needs to spend a lot of time searching in various types of resource systems. Therefore, at present, digital library is a user-oriented service resource system based on digital resources, which can integrate information resources, information services and information activities as a dynamic mechanism. Based on Visual Studio c# and SQL Server development environment, the Russian digital characteristic resource construction platform expounds the process of Russian database construction and Russian document resource construction from the system design and platform implementation according to the development process of software engineering. This platform has the advantages of convenient operation, fast pre search, effective management of Russian literature and strong support for the use of literature.",
    "author": [
      {
        "family": "Zhang",
        "given": "Shang"
      }
    ],
    "collection-title": "ICDTE ’22",
    "container-title": "Proceedings of the 6th international conference on digital technology in education",
    "id": "10.1145/3568739.3568802",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "database, Russian, Resource integration, Relying on color resources",
    "page": "375-380",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Design of russian digital resource construction platform",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1275604.1275610",
    "ISBN": "9781450347341",
    "URL": "https://doi.org/10.1145/1275604.1275610",
    "abstract": "In the course of a major curriculum change at California Polytechnic State University, the embedded processing course was redesigned. During this process, the course had the opportunity to purchase new hardware. Analog Device’s Black-fin processor was chosen based mostly on cost, but also on performance, development environment, and documentation.We first present our goals in the class. We then give an overview of the Blackfin architecture and how the Blackfin fits in with many of our goals. We then present the implementation of an expansion board developed to interface with Blackfin’s EZ-KIT Lite board.We present our experiences with this setup in the hopes that others who might be thinking of a similar curricular change can learn from our successes and failures. We outline the strengths and weaknesses of the Blackfin architecture as an educational platform, followed by a discussion of our experiences and a presentation of the support materials we developed to accompany the course, including lecture material and laboratories. Finally, we discuss our future directions for our uses with the board.",
    "author": [
      {
        "family": "Franklin",
        "given": "Diana"
      },
      {
        "family": "Seng",
        "given": "John"
      }
    ],
    "collection-title": "WCAE ’05",
    "container-title": "Proceedings of the 2005 workshop on computer architecture education: Held in conjunction with the 32nd international symposium on computer architecture",
    "id": "10.1145/1275604.1275610",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "page": "3-es",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Experiences with the blackfin architecture for embedded systems education",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3573051.3596180",
    "ISBN": "9798400700255",
    "URL": "https://doi.org/10.1145/3573051.3596180",
    "abstract": "The popularity of Massive Open Online Courses (MOOCs) as a means of delivering education to large numbers of students has been growing steadily over the last decade. As technology improves, more educational content is becoming readily available to the public. JupyterLab, an open-source web-based interactive development environment (IDE), is also becoming increasingly popular in education, however, it is so far primarily used in small classroom settings. JupyterLab can provide a more interactive, hands-on, and collaborative learning experience for students in MOOCs, and it is highly customizable and can be accessed from anywhere. To capitalize on these benefits, we have developed OpenJupyter, which integrates JupyterLab at scale with MOOCs, enhancing the student learning experience and providing hands-on exercises for data science courses, making them more interactive and engaging. While MOOCs provide access to education for a large number of students, one of the significant challenges is providing effective and timely feedback to learners.&nbsp;OpenJupyter includes an auto-assessment capability that addresses this problem in MOOCs by automating the evaluation process and providing feedback to learners in a timely manner. In this paper, we provide an overview of the architecture of OpenJupyter, its scalability in the context of MOOCs, and its effectiveness in addressing the auto-assessment challenge. We also discuss the Advantages and limitations associated with using OpenJupyter in a MOOC context and provide a reference for educators and researchers who wish to implement similar tools. Our efforts aim to foster an open educational environment in the field of programming by providing learners with an interactive learning tool and a streamlined technical setup, allowing them to acquire and test their knowledge at their own pace.",
    "author": [
      {
        "family": "Elhayany",
        "given": "Mohamed"
      },
      {
        "family": "Meinel",
        "given": "Christoph"
      }
    ],
    "collection-title": "L@s ’23",
    "container-title": "Proceedings of the tenth ACM conference on learning @ scale",
    "id": "10.1145/3573051.3596180",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "programming, openjupyter, auto-assessment, MOOC, JupyterLab",
    "page": "321-325",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Towards automated code assessment with OpenJupyter in MOOCs",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1007/11499053_40",
    "ISBN": "3540262776",
    "URL": "https://doi.org/10.1007/11499053_40",
    "abstract": "Genesys Solutions is a bespoke IT company, first of its kind, run by MSc and fourth year students of Department of Computer Science, University of Sheffield under the supervision of Prof. Mike Holcombe and Dr. Marian Gheorghe. Genesys follows the eXtreme Programming (XP) methodology for software development based on client requirements. The commitment towards XP and its ‘good software practices’ can be considered as the greatest strength of Genesys.Agile Development Environment for Programming and Testing (ADEPT) is our contribution towards supporting the XP methodology by adopting the Eclipse platform along with its associated tools and frameworks within Genesys Solutions. It aimed to teach good software practices in Genesys to support XP by providing a software development life cycle management tool that will encompass the best practices of XP. It comprises of tools based on the principles of XP such as story cards, system metaphor, estimations, testing and quality assurance. ADEPT was the result of the IBM Eclipse Innovation 2004 awarded to the University of Sheffield. Also, based on the previous year’s performance and more innovative ideas to implement more principles of XP we have been awarded another grant under the IBM Eclipse Innovation 2005 programme.",
    "author": [
      {
        "family": "Holcombe",
        "given": "Mike"
      },
      {
        "family": "Kalra",
        "given": "Bhavnidhi"
      }
    ],
    "collection-title": "XP’05",
    "container-title": "Proceedings of the 6th international conference on extreme programming and agile processes in software engineering",
    "id": "10.1007/11499053_40",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "keyword": "software life cycle, project management, extreme programming, eclipse",
    "page": "255-258",
    "publisher": "Springer-Verlag",
    "publisher-place": "Berlin, Heidelberg",
    "title": "Agile development environment for programming and testing (ADEPT) – eclipse makes project management extreme",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1016/j.cageo.2010.10.017",
    "ISSN": "0098-3004",
    "URL": "https://doi.org/10.1016/j.cageo.2010.10.017",
    "abstract": "LavaNet is a series of scripts written in Perl that gives access to a neural network simulation environment inside a general mine planning package. A well known and a very popular neural network development environment, the Stuttgart Neural Network Simulator, is used as the base for the development of neural networks. LavaNet runs inside VULCAN(TM)-a complete mine planning package with advanced database, modelling and visualisation capabilities. LavaNet is taking advantage of VULCAN’s Perl based scripting environment, Lava, to bring all the benefits of neural network development and application to geologists, mining engineers and other users of the specific mine planning package. LavaNet enables easy development of neural network training data sets using information from any of the data and model structures available, such as block models and drillhole databases. Neural networks can be trained inside VULCAN(TM) and the results be used to generate new models that can be visualised in 3D. Direct comparison of developed neural network models with conventional and geostatistical techniques is now possible within the same mine planning software package. LavaNet supports Radial Basis Function networks, Multi-Layer Perceptrons and Self-Organised Maps.",
    "author": [
      {
        "family": "Kapageridis",
        "given": "Ioannis Konstantinou"
      },
      {
        "family": "Triantafyllou",
        "given": "A. G."
      }
    ],
    "container-title": "Comput. Geosci.",
    "id": "10.1016/j.cageo.2010.10.017",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          2011,
          4
        ]
      ]
    },
    "keyword": "VULCAN, SNNS, Perl, Neural networks, Mine planning, Estimation",
    "page": "634-644",
    "publisher": "Pergamon Press, Inc.",
    "publisher-place": "USA",
    "title": "LavaNet-neural network development environment in a general mine planning package",
    "type": "article-journal",
    "volume": "37"
  },
  {
    "ISBN": "1931836590",
    "abstract": "From the Publisher:Ok. You bought the kit for yourself or one of your kids. You used the instructions in the box to build a robot or two. Now what__ __ You may not be ready to design and build your own robots, but you don’t want to build the same robot over again. This book is the perfect way to build additional projects from the same kit, and then to improvise and design your own. Ten Cool Projects. One hour each. Perfect. Robots Included: Ludic Ordinance Units, (LOUs), are usually put together to create entertainment for the troops, but they usually end up serving as moving targets for Imperial Stormtroopers. Scorpion Assassin Droid a silent and deadly hunter. Tracking its intended target with a variety of sensors, it moves stealthily to within striking distance. Draigons swoop from the sky to attack their prey, carrying off to their lairs to be devoured those creatures unfortunate enough to become their victims. Droid Transporters can carry up to a dozen Droids over rough terrain and deliver them where they are needed. X-Stormer is a prototype of what would eventually become the AT-AT. Imperial engineers worked for many years to create the X-Stormers. Super Battle Droid is a biped that walks on two legs by shifting its weight from side to side and moving its legs forwards and backwards. Go-Rillas are fast biped robots often used by the smugglers and bounty hunters of the galaxy to defend their hideouts. What they lack in intelligence they more than make up for in speed and brute strength. Imperial All-Terrain Scout Transport, better known as the AT-ST, is a small, agile, armored biped that can carry two Imperial Stormtroopers. Orbital Defense Cannons, guided by their large targeting radar dish, can shoot down even the largest Imperial Star Destroyers and Corellian Cruisers. Imperial Hounds serve as both companions for the troops and as powerful tools of war on the battlefields of the Empire. Author Biographies: Hideaki Yabuki works as a Media Activist promoting new technologies to the next generation. To him, robotics is the most important of these technologies. He was first introduced to LEGO robots in 1985 by a friend of his who had recently returned from the MIT Media Lab with some LEGO Dacta products. His robot in this book, the Scorpion, is the result of much trial and error on his part. Kevin Clague graduated in 1983 from Iowa State University with a bachelor’s of Science degree in Computer Engineering. For the past 18 years, Kevin has worked as a Diagnostic Engineer at the Amdahl Corporation. For the last two years, he has also acted as a Senior Staff Engineer doing verification work at Sun Microsystems on their Ultra-Sparc V RISC processor. Kevin has two major hobbies: theatrical lighting and LEGO Mindstorms. Kevin has been playing with the RIS 1.5 for several years now and is currently working on LPub, an application to revolutionize the world of creating online LEGO building instructions. Miguel Agullo was born in Spain but has lived abroad for long periods of time, from the Far East to South America, from central Europe to the U.S. His wide range of interests is responsible for his work in such diverse industries as finance, media, aeronautics, and antique trading. Trained as a journalist and impressed with the candor and resourcefulness of the online LEGO community, Miguel tries to give something back by regularly updating his Web site with instructions for new models, new Ldraw pieces, and anything he thinks is worth sharing with other LEGO aficionados. His building interests revolve around robotics, and specifically biomechanics: creating mechanisms that mimic the behavior of natural devices such as legs or arms. His creations include biped walkers, robots that jump, and a fully functional (including a brake!) LEGO motorcycle. Søren Rolighed is a data warehouse consultant, working on building and maintaining databases for telco-data in the largest data warehouse in Denmark. Like almost all Danish kids, he started playing with LEGO at an early age. As an adult he has continued with his passion for LEGOs, and the introduction of the LEGO Technics and LEGO Mindstorms kits opened up a whole new world of possibilities! J.P. Brown is a Consultant Environmental Conservator who has worked on such historical sites as Independence Hall, Philadelphia, PA and George Washington’s mansion, Mount Vernon, VA. He first became interested in LEGO Mindstorms in July 1999, but his interest did not really take off until he discovered Dave Baum’s Not Quite C (NQC) programming environment for the RCX brick later that year. He quickly became involved as a moderator for LEGO Mindstorms forums on the Web, and was later selected by LEGO as a preview builder for the Mindstorms Vision Command. His robot, Biped II, won the February 2001 Mindstorms Hall of Fame, Special Competition, but he is perhaps best known for his Rubik’s Cube solving robot, CubeSolver, which was featured in the New York Times in October 2001 and other papers around the world.",
    "author": [
      {
        "family": "Clague",
        "given": "Kevin"
      },
      {
        "family": "Rolighed",
        "given": "Soren"
      },
      {
        "family": "Brown",
        "given": "J. P."
      },
      {
        "family": "Agullo",
        "given": "Miguel"
      },
      {
        "family": "Yabuki",
        "given": "Hideaki"
      },
      {
        "family": "Ferrari",
        "given": "Giulio"
      }
    ],
    "id": "10.5555/579602",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Syngress Publishing",
    "title": "10 cool LEGO mindstorms: Dark side robots, transports, and creatures – amazing projects you can build in under an hour",
    "title-short": "10 cool LEGO mindstorms",
    "type": "book"
  },
  {
    "DOI": "10.1109/13.804563",
    "ISSN": "0018-9359",
    "URL": "https://doi.org/10.1109/13.804563",
    "abstract": "Multi-disciplinary product design teams are now an accepted project development tool in industry. Many advantages cited are: rapid prototyping, cost reduction and the design of a more marketable product. While multi-disciplinary teams are common in such environments, it is more problematical to offer students in higher education experience of working in such a team. A variety of difficulties are encountered by educators wishing to provide such an experience for their students, ranging from cultural through logistical to the level of intellectual rigour required and the assessment methodologies used. This paper describes the research methodologies and results of an investigation into the operation of a large multi-disciplinary team project conducted by the authors over a period of two years to two sets of undergraduates, each consisting of over one hundred and eighty full-time students drawn from a number of engineering, design and design management disciplines. An action research programme to investigate the group experience and attitudes was undertaken and the principal findings are presented and briefly debated. The findings support the view that the exercise provided a wide range of tangible and intangible benefits. This enables the authors to propose a conceptual model of large multi-disciplinary team working which may be used by other educators as a basis for developing future project modules within their host institution’s environment. Finally, the benefits gained, as shown by previous research, for students and staff from such projects are summarised",
    "author": [
      {
        "family": "Ivins",
        "given": "J. R."
      },
      {
        "family": "Holland",
        "given": "R."
      }
    ],
    "container-title": "IEEE Trans. on Educ.",
    "id": "10.1109/13.804563",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1999,
          11
        ]
      ]
    },
    "page": "9 pp.",
    "publisher": "IEEE Press",
    "title": "Reflections on the operation of large multidisciplinary projects in engineering, design and design management",
    "type": "article-journal",
    "volume": "42"
  },
  {
    "DOI": "10.1007/s11042-020-09772-y",
    "ISSN": "1380-7501",
    "URL": "https://doi.org/10.1007/s11042-020-09772-y",
    "abstract": "The main element of extended reality (XR) environments is behavior-rich 3D content consisting of objects that act and interact with one another as well as with users. Such actions and interactions constitute the evolution of the content over time. Multiple application domains of XR, e.g., education, training, marketing, merchandising, and design, could benefit from the analysis of 3D content changes based on general or domain knowledge comprehensible to average users or domain experts. Such analysis can be intended, in particular, to monitor, comprehend, examine, and control XR environments as well as users’ skills, experience, interests and preferences, and XR objects’ features. However, it is difficult to achieve as long as XR environments are developed with methods and tools that focus on programming and 3D modeling rather than expressing domain knowledge accompanying content users and objects, and their behavior. The main contribution of this paper is an approach to creating explorable knowledge-based XR environments with semantic annotations. The approach combines description logics with aspect-oriented programming, which enables knowledge representation in an arbitrary domain as well as transformation of available environments with minimal users’ effort. We have implemented the approach using well-established development tools and exemplify it with an explorable immersive car showroom. The approach enables efficient creation of explorable XR environments and knowledge acquisition from XR.",
    "author": [
      {
        "family": "Flotyński",
        "given": "Jakub"
      }
    ],
    "container-title": "Multimedia Tools Appl.",
    "id": "10.1007/s11042-020-09772-y",
    "issue": "5",
    "issued": {
      "date-parts": [
        [
          2021,
          2
        ]
      ]
    },
    "keyword": "Annotations, Ontologies, Semantic web, Queries, Reasoning, Exploration, 3D Web, Extended reality",
    "page": "6959-6989",
    "publisher": "Kluwer Academic Publishers",
    "publisher-place": "USA",
    "title": "Creating explorable extended reality environments with semantic annotations",
    "type": "article-journal",
    "volume": "80"
  },
  {
    "ISBN": "1576102610",
    "abstract": "From the Publisher:Helps programming professionals gain knowledge that directly applies to the Sun Microsystems exam for Java. Covers all the curriculum objectives established by Sun Education that are needed to successfully pass the Java exam. Serves as an essential resource to the programmer who wants to learn Java quickly; it builds on the reader’s knowledge of C++ by spending less time on programming fundamentals and more time on topics that are unique or difficult in Java. Gartner Research estimates that there will be market demand for over 1 million Java programmers by the year 2000. Covers two development environments, Sun’s JavaWorkShop and IBM’s VisualAge and relates objectives in the chapter material to required topics on the certification exam. Includes all topics required for successful completion of the Java Programmer Certification Exam, as well as covering additional topics essential to using Java in business situations. Written by Sun-certified programmers who use Java in a professional setting. Features a unique exam simulation program designed especially for Certification Insider Press that includes two complete interactive practice tests, allowing readers to measure their skills and build confidence before taking the actual certifcation exam. Although the questions are formatted like those encountered on the actual exam, they are based on the book’s content to reinforce critical concepts and their practical applications.",
    "author": [
      {
        "family": "Brogden",
        "given": "William B."
      },
      {
        "family": "Brogden",
        "given": "Bill"
      }
    ],
    "id": "10.5555/553951",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "publisher": "Coriolis Group Books",
    "publisher-place": "USA",
    "title": "Java 2 exam prep: Exam: 310-025 with cdrom",
    "title-short": "Java 2 exam prep",
    "type": "book"
  },
  {
    "ISBN": "1555442455",
    "abstract": "From the Publisher:Written for designers, programmers, and users of SAS applications, this book shows how to build client/server database applications through table-driven technology. Each chapter addresses these three different audiences, detailing ways to construct high-quality, reliable applications that are easy to maintain. The \"code-free\" approach offers you flexibility in design, reduces development time, and provides the advantages of integrated data dictionaries, user-defined integrity rules, and trigger-message mechanisms that implement and manage data processing. With the many realistic examples included here, experienced users who build or regularly use SAS applications can master techniques of application development and data analysis that are straightforward and powerful. Supports releases 6.09 and higher of SAS software.Author Biography: Tanya Kolosova Tanya Kolosova is an independent consultant with expertise in time series and forecasting, operations research, and statistical training. With Berestizhevsky, she is the coauthor of TARGET, a fully integrated applications development tool based on SAS software. Also published in scientific journals, she has extensive experience working with the SAS System. Samuel Berestizhevsky Samuel Berestizhevsky is an independent consultant specializing in statistical data analysis, the design of experiments, quality control and assurance, system analysis, and training. Published in several scientific magazines, he has an impressive amount of experience working with the SAS System.",
    "author": [
      {
        "family": "Kolosova",
        "given": "Tanya"
      },
      {
        "family": "Berestizhevsky",
        "given": "Samuel"
      }
    ],
    "edition": "1st",
    "id": "10.5555/546215",
    "issued": {
      "date-parts": [
        [
          1995
        ]
      ]
    },
    "publisher": "SAS Publishing",
    "title": "Table-driven strategies for rapid SAS applications development",
    "type": "book"
  },
  {
    "DOI": "10.1145/3419635.3419727",
    "ISBN": "9781450387729",
    "URL": "https://doi.org/10.1145/3419635.3419727",
    "abstract": "In the current situation of the development of science and technology, virtual technology arises at the historic moment. As a kind of computer simulation technology, it has the simulation ahead of the real world. Because of its many advantages, virtual technology is already being used in fields such as education and medicine. However, there are still some shortcomings in the current virtual technology. Although the development tools are equipped, there are still some disadvantages in the process of using them, which hinders the developers to improve their work efficiency significantly. Among the prospects, this technology is the most widely used in education, and this paper aims to develop a virtual reality application engine that is convenient for party school teaching. In the education and learning of the party school, the design and r&amp;d of VR products should be completed under the support of the model and theory of education, and should respond to the characteristics of the discipline. This paper expounds a series of processes from design to r&amp;d of VR products. At the beginning, I analyses the subject and investigated the market prospect of VR education, so as to get a product with the same learning efficiency and teaching efficiency. Secondly, the depth plane analysis is carried out on the mathematical knowledge needed in the construction of 3d model, and the emphasis is put on the introduction of quaternions, transformation matrix, homogeneous coordinates and the functions of these knowledge in 3d application.",
    "author": [
      {
        "family": "Yuan",
        "given": "Menghui"
      }
    ],
    "collection-title": "CIPAE 2020",
    "container-title": "Proceedings of the 2020 international conference on computers, information processing and advanced education",
    "id": "10.1145/3419635.3419727",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "keyword": "Virtual reality technology, VR education, Party school teaching",
    "page": "472-475",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Research on the construction of virtual reality engine for party school teaching application",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1109/HICSS.2012.198",
    "ISBN": "9780769545257",
    "URL": "https://doi.org/10.1109/HICSS.2012.198",
    "abstract": "End-user training is complicated to implement in global corporations whose activities are typically scattered across multiple sites in different countries and leverage information systems in various ways. This is especially true in global software development where the sites may leverage a development tool for totally different purposes. Web-based Virtual Meeting Tools (VMT) enable synchronous communication globally through interactive audio, online chats, video, and the sharing of presentations. They provide potentially a cost effective way to train even complex topics to large numbers of people in global settings. Few industrial experiences from the design and use of VMT-based training innovations have been reported. This paper draws upon a case study in a global corporation to describe the design, implementation, and evaluation of a training innovation, consisting of a set of courses delivered by means of a VMT and conference calls, to support the global deployment of a Unified Modeling Language (UML) modeling tool and to develop UML modeling skills. Evaluation is based on interviews to verify 1) the impacts of the innovation on skills, knowledge and motivation, 2) perceived learner satisfaction with respect to the innovation. The innovation proved successful in improving skills, knowledge, and motivation in the case organization and learners were satisfied with it. Other organizations may benefit from using VMT to train people to use similar complex information systems for supporting global software development.",
    "author": [
      {
        "family": "Koivulahti-Ojala",
        "given": "Mervi"
      },
      {
        "family": "Kakola",
        "given": "Timo"
      }
    ],
    "collection-title": "HICSS ’12",
    "container-title": "Proceedings of the 2012 45th hawaii international conference on system sciences",
    "id": "10.1109/HICSS.2012.198",
    "issued": {
      "date-parts": [
        [
          2012
        ]
      ]
    },
    "keyword": "web-based learning, learning, global software development, UML",
    "page": "3980-3989",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Design, implementation, and evaluation of a virtual meeting tool-based innovation for UML technology training in global organizations",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3508352.3549478",
    "ISBN": "9781450392174",
    "URL": "https://doi.org/10.1145/3508352.3549478",
    "abstract": "Multiplication is arguably the most cost-dominant operation in modern deep neural networks (DNNs), limiting their achievable efficiency and thus more extensive deployment in resource-constrained applications. To tackle this limitation, pioneering works have developed handcrafted multiplication-free DNNs, which require expert knowledge and time-consuming manual iteration, calling for fast development tools. To this end, we propose a Neural Architecture Search and Acceleration framework dubbed NASA, which enables automated multiplication-reduced DNN development and integrates a dedicated multiplication-reduced accelerator for boosting DNNs’ achievable efficiency. Specifically, NASA adopts neural architecture search (NAS) spaces that augment the state-of-the-art one with hardware inspired multiplication-free operators, such as shift and adder, armed with a novel progressive pretrain strategy (PGP) together with customized training recipes to automatically search for optimal multiplication-reduced DNNs; On top of that, NASA further develops a dedicated accelerator, which advocates a chunk-based template and auto-mapper dedicated for NASA-NAS resulting DNNs to better leverage their algorithmic properties for boosting hardware efficiency. Experimental results and ablation studies consistently validate the advantages of NASA’s algorithm-hardware co-design framework in terms of achievable accuracy and efficiency tradeoffs. Codes are available at https://github.com/shihuihong214/NASA.",
    "author": [
      {
        "family": "Shi",
        "given": "Huihong"
      },
      {
        "family": "You",
        "given": "Haoran"
      },
      {
        "family": "Zhao",
        "given": "Yang"
      },
      {
        "family": "Wang",
        "given": "Zhongfeng"
      },
      {
        "family": "Lin",
        "given": "Yingyan"
      }
    ],
    "collection-title": "ICCAD ’22",
    "container-title": "Proceedings of the 41st IEEE/ACM international conference on computer-aided design",
    "id": "10.1145/3508352.3549478",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "NASA: Neural architecture search and acceleration for hardware inspired hybrid networks",
    "title-short": "NASA",
    "type": "paper-conference"
  },
  {
    "ISBN": "3030336239",
    "abstract": "This book focuses on the development and implementation of cloud-based, complex software that allows parallelism, fast processing, and real-time connectivity. Software engineering (SE) is the design, development, testing, and implementation of software applications, and this discipline is as well developed as the practice is well established whereas the Cloud Software Engineering (CSE) is the design, development, testing, and continuous delivery of service-oriented software systems and applications (Software as a Service Paradigm). However, with the emergence of the highly attractive cloud computing (CC) paradigm, the tools and techniques for SE are changing. CC provides the latest software development environments and the necessary platforms relatively easily and inexpensively. It also allows the provision of software applications equally easily and on a pay-as-you-go basis. Business requirements for the use of software are also changing and there is a need for applications in big data analytics, parallel computing, AI, natural language processing, and biometrics, etc. These require huge amounts of computing power and sophisticated data management mechanisms, as well as device connectivity for Internet of Things (IoT) environments. In terms of hardware, software, communication, and storage, CC is highly attractive for developing complex software that is rapidly becoming essential for all sectors of life, including commerce, health, education, and transportation. The book fills a gap in the SE literature by providing scientific contributions from researchers and practitioners, focusing on frameworks, methodologies, applications, benefits and inherent challenges/barriers to engineering software using the CC paradigm.",
    "author": [
      {
        "family": "Ramachandran",
        "given": "Muthu"
      },
      {
        "family": "Mahmood",
        "given": "Zaigham"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3385370",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "publisher": "Springer Publishing Company, Incorporated",
    "title": "Software engineering in the era of cloud computing",
    "type": "book"
  },
  {
    "ISBN": "0131863339",
    "abstract": "Praise for Mark Sobell’s Books \"If you want to become a real Linux guru, this is one of the better books available. Readable, straightforward, educational, it is a superb reference that blends the educational aspect of a typical book on learning Linux with a typical book of command line references. I highly recommend A Practical Guide to Linux® Commands, Editors, and Shell Programming.\" Harold D. McFarland, Editor, Readers Preference Reviews \"I keep searching for books that collect everything you want to know about a subject in one place, and keep getting disappointed. Usually the books leave out some important topic, while others go too deep in some areas and must skim lightly over the others. A Practical Guide to Red Hat® Linux® is one of those rare books that actually pulls it off. Mark G. Sobell has created a single reference for Red Hat Linux that cannot be beat! This marvelous text (with a 4-CD set of Linux Fedora Core 2 included) is well worth the price. This is as close to an ’everything you ever needed to know’ book that I’ve seen. It’s just that good and rates 5 out of 5.\" Ray Lodato, Slashdot contributor \"Mark Sobell has written a book as approachable as it is authoritative.\" Jeffrey Bianchine, Advocate, Author, Journalist \"Excellent reference book, well suited for the sysadmin of a Linux cluster, or the owner of a PC contemplating installing a recent stable Linux. Don’t be put off by the daunting heft of the book. Sobell has striven to be as inclusive as possible, in trying to anticipate your system administration needs.\" Wes Boudville, Inventor \"A Practical Guide to Red Hat® Linux® is a brilliant book. Thank you Mark Sobell.\" C. Pozrikidis, University of California at San Diego \"This book presents the best overview of the Linux operating system that I have found. . . . [It] should be very helpful and understandable no matter what the reader’s background is: traditional UNIX user, new Linux devotee, or even Windows user. Each topic is presented in a clear, complete fashion and very few assumptions are made about what the reader knows. . . . The book is extremely useful as a reference, as it contains a 70-page glossary of terms and is very well indexed. It is organized in such a way that the reader can focus on simple tasks without having to wade through more advanced topics until they are ready.\" Cam Marshall, Marshall Information Service LLC, Member of Front Range UNIX Users Group [FRUUG], Boulder, Colorado \"Conclusively, this is THE book to get if you are a new Linux user and you just got into the RH/Fedora world. There’s no other book that discusses so many different topics and in such depth.\" Eugenia Loli-Queru, Editor in Chief, OSNews.comThe Most Useful UNIX Guide for Mac OS X Users Ever, with Hundreds of High-Quality Examples!Beneath Mac OS® X’s stunning graphical user interface (GUI) is the most powerful operating system ever created: UNIX®. With unmatched clarity and insight, this book explains UNIX for the Mac OS X user giving you total control over your system, so you can get more done, faster. Building on Mark Sobell’s highly praised A Practical Guide to the UNIX System, it delivers comprehensive guidance on the UNIX command line tools every user, administrator, and developer needs to master together with the world’s best day-to-day UNIX reference.This book is packed with hundreds of high-quality examples. From networking and system utilities to shells and programming, this is UNIX from the ground up both the \"whys\" and the \"hows\" for every Mac user. You’ll understand the relationships between GUI tools and their command line counterparts. Need instant answers? Don’t bother with confusing online \"manual pages\": rely on this book’s example-rich, quick-access, 236-page command reference!Don’t settle for just any UNIX guidebook. Get one focused on your specific needs as a Mac user!A Practical Guide to UNIX® for Mac OS® X Users is the most useful, comprehensive UNIX tutorial and reference for Mac OS X and is the only book that delivers Better, more realistic examples covering tasks you’ll actually need to perform Deeper insight, based on the authors’ immense knowledge of every UNIX and OS X nook and cranny Practical guidance for experienced UNIX users moving to Mac OS X Exclusive discussions of Mac-only utilities, including plutil, ditto, nidump, otool, launchctl, diskutil, GetFileInfo, and SetFile Techniques for implementing secure communications with ssh and scp plus dozens of tips for making your OS X system more secure Expert guidance on basic and advanced shell programming with bash and tcsh Tips and tricks for using the shell interactively from the command line Thorough guides to vi and emacs designed to help you get productive fast, and maximize your editing efficiency In-depth coverage of the Mac OS X filesystem and access permissions, including extended attributes and Access Control Lists (ACLs) A comprehensive UNIX glossary Dozens of exercises to help you practice and gain confidence And much more, including a superior introduction to UNIX programming tools such as awk, sed, otool, make, gcc, gdb, and CVS",
    "author": [
      {
        "family": "Seebach",
        "given": "Peter"
      },
      {
        "family": "Sobell",
        "given": "Mark G."
      }
    ],
    "id": "10.5555/1051099",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "A practical guide to unix for mac OS x users",
    "type": "book"
  },
  {
    "DOI": "10.1145/2538862.2538928",
    "ISBN": "9781450326056",
    "URL": "https://doi.org/10.1145/2538862.2538928",
    "abstract": "Higher education is facing a paradigm shift in the ownership and use of computer hardware. The school computer lab is no longer the primary place of student computer use. Instead, students increasingly expect to use their own hardware to complete their school assignments. This creates a challenge for computer science educators: we must now support a wide range of heterogeneous hardware without the benefits of tight control over its use. To address this “Bring-Your-Own-Device” (BYOD) challenge, we leverage virtualization and software packaging systems to gracefully deploy and support a standardized development environment for all core CS courses across a range of both school-owned and student-owned computing devices. We have deployed and evaluated our system for the previous two years at scale and continue to actively use and develop it. It has effectively helped us support multiple classes comprising hundreds of students with very limited IT staffing. We describe the design and management of our system, present our experience using our system, and discuss the lessons we’ve learned. We also provide data reflecting current student user experience with our system. Our system has proven very effective in addressing the student BYOD challenge in a manageable, cost-efficient, and easy-to-use manner.",
    "author": [
      {
        "family": "Sayler",
        "given": "Andy"
      },
      {
        "family": "Grunwald",
        "given": "Dirk"
      },
      {
        "family": "Black",
        "given": "John"
      },
      {
        "family": "White",
        "given": "Elizabeth"
      },
      {
        "family": "Monaco",
        "given": "Matthew"
      }
    ],
    "collection-title": "SIGCSE ’14",
    "container-title": "Proceedings of the 45th ACM technical symposium on computer science education",
    "id": "10.1145/2538862.2538928",
    "issued": {
      "date-parts": [
        [
          2014
        ]
      ]
    },
    "keyword": "virtual machines, tools, package management, education, development environment, bring your own device, best practices, BYOD",
    "page": "313-318",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Supporting CS education via virtualization and packages: Tools for successfully accommodating \"bring-your-own-device\" at scale",
    "title-short": "Supporting CS education via virtualization and packages",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3606150.3606158",
    "ISBN": "9798400707353",
    "URL": "https://doi.org/10.1145/3606150.3606158",
    "abstract": "Secondary school physical education (PE) teachers are continuously challenged to find ways to support students learning and motivate them for an active and healthy lifestyle. To address this complexity, continuing teacher professional development (TPD) is key. Technological tools can facilitate the effective delivery of TPD in this context. Successful implementation of this technology, however, is not self-evident. Based on the general aim of effectively integrating technologies in the educational process and focusing on the needs of educators, this study examines how the evidence-based theoretical TARGET framework for creating a motivating PE learning climate might be embedded into a digital professional development tool for PE teachers, useful in everyday practice. It presents a case study in which a multidisciplinary team of researchers, designers, and end-users iteratively went through several phases of need identification, idea generation, designing, development, and testing. By using a participatory approach, we were able to collect contextualized data and gain insights into users’ preferences, requirements, and ideas for designing and engaging with the tool. Based on these insights the TPD TARGET-tool for PE teachers was ultimately developed. The most prominent characteristics of this tool are (1) the combination of an evaluative function with teaching strategy support, (2) the strong emphasis on ease of use due to the complex PE teaching context, (3) the avoidance of social comparison, and suggestions of normative judgment, and (4) the allowance for a high level of customization and teacher autonomy.",
    "author": [
      {
        "family": "Weeldenburg",
        "given": "Gwen"
      },
      {
        "family": "Kromkamp",
        "given": "Len"
      },
      {
        "family": "Borghouts",
        "given": "Lars"
      },
      {
        "family": "Verburg",
        "given": "Pepijn"
      },
      {
        "family": "Hansen",
        "given": "Nicolai Brodersen"
      },
      {
        "family": "Vos",
        "given": "Steven"
      }
    ],
    "collection-title": "ICFET ’23",
    "container-title": "Proceedings of the 2023 9th international conference on frontiers of educational technologies",
    "id": "10.1145/3606150.3606158",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "Teacher Professional Development, Physical Education, Participatory Design, Human-computer Interaction, Educational Technology",
    "page": "40-51",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "TARGET-tool: Participatory design of an interactive professional development tool for secondary school physical education teachers",
    "title-short": "TARGET-tool",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321375777",
    "abstract": "How to Design for Software Reliability, Security, and MaintainabilityMany enterprises unfortunately depend on software that is insecure, unreliable, and fragile. They compensate by investing heavily in workarounds and maintenance, and by employing hordes of \"gurus\" to manage their systems’ flaws. This must change. And it can. In this book, respected software architect Clifford J. Berg shows how to design high-assurance applications-applications with proven, built-in reliability, security, manageability, and maintainability.High-Assurance Design presents basic design principles and patterns that can be used in any contemporary development environment and satisfy the business demand for agility, responsiveness, and low cost. Berg draws on real-world experience, focusing heavily on the activities and relationships associated with building superior software in a mainstream business environment. Practicing architects, lead designers, and technical managers will benefit from the coverage of the entire software lifecycle, showing how to: Understand and avoid the problems that lead to unreliable, insecure software Refocus design and development resources to improve software Identify project risks and plan for assurable designs Obtain the requirements needed to deliver high assurance Design application systems that meet the identified requirements Verify that the design satisfies these requirements Plan and design tests for reliability and security Integrate security design, reliability design, and application design into one coherent set of processes Incorporate these concerns into any software development methodology© Copyright Pearson Education. All rights reserved.",
    "author": [
      {
        "family": "Berg",
        "given": "Clifford"
      }
    ],
    "id": "10.5555/1076985",
    "issued": {
      "date-parts": [
        [
          2005
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "High-assurance design: Architecting secure and reliable enterprise applications",
    "title-short": "High-assurance design",
    "type": "book"
  },
  {
    "ISSN": "1092-0617",
    "abstract": "Present computer-aided design (CAD) systems, intentionally developed as detail oriented designing tools, do not fully support the activities at the early stage of product development. CAD systems, which require a detailed level of design, prohibit the creative and free expression of a design idea. The solution to the limitations of present CAD systems is to fully utilize the graphical ability of current computer systems to represent a design with an easily understood design description in the conceptual design stage. We have developed a computerized product development tool to support designing activities in the conceptual design phase. The attribute-based design description system (ADDS) is a feature-based system that incorporates life-cycle engineering analysis and solid modeling to form an integrated CAD system. It provides a simple design representation interface and assembly modeling, evaluates the design for life-cycle engineering issues, and exports the design to AutoCAD as a solid model with flexible information input requirements. The research thus provides a starting point to the development of CAD systems that support productivity in the conceptual design stage. ADDS has been validated by describing three different design examples of power transmission systems in ADDS and exporting them to AutoCAD. This paper examines the benefits of applying a specification driven approach and presents a framework for environments that can support the related design activities. The Design Analysis and Simulation Environment (DASE) based upon this framework has been successfully implemented through a joint initiative between Bell Canada and McGill University.",
    "author": [
      {
        "family": "Paluri",
        "given": "Srinivas"
      },
      {
        "family": "Gershenson",
        "given": "John K."
      }
    ],
    "container-title": "J. Integr. Des. Process Sci.",
    "id": "10.5555/1241721.1241728",
    "issue": "2",
    "issued": {
      "date-parts": [
        [
          2001,
          4
        ]
      ]
    },
    "page": "83-94",
    "publisher": "IOS Press",
    "publisher-place": "NLD",
    "title": "Attribute-based design description system in design for manufacturability and assembly",
    "type": "article-journal",
    "volume": "5"
  },
  {
    "ISBN": "1488523347",
    "abstract": "There has never been a Application Development Guide like this. Application Development 62 Success Secrets is not about the ins and outs of Application Development. Instead, it answers the top 62 questions that we are asked and those we come across in our forums, consultancy and education programs. It tells you exactly how to deal with those questions, with tips that have never before been offered in print. Get the information you need–fast! This comprehensive guide offers a thorough view of key knowledge and detailed insight. This Guide introduces everything you want to know to be successful with Application Development. A quick look inside of the subjects covered: IT disciplines impacted by a security program - Certified Information Security Manager, DSDM , Deployment , Supporting PaaS and SaaS , Configuration Management ITIL, The Service Level Agreement of Data Base Administration, Application Management Lifecycle , Supporting the Customer, Enterprise s Software &amp; Platforms , The Importance Of Configuration Management Tutorial, Internet Companies , Open Source Software and security - CISSP - Certified Information Systems Security Professional, The Future of Cloud Computing , Cloud Application Development Tools, Summarizing Project Management, PMBOK and ITIL, Accelerator , The 13 Levels of MCP CCNA, Planning , Adaptive Software Development , There are six distinct levels of MDM maturity. , What is the reason to perform Qualitative Risk Assessments? - Certified Information Systems Auditor, Benefits of MDM , Agile Development Methods and ITIL, Introducing Applications on the Web , System Development and Maintenance , Speed , History, , Zoho Office Suite , The Different MCTS Certifications, MDM Component Layer Model , Microsoft Office Access, Application Management , Service Catalog, The Importance of Software Functional Testing, Origins , Architecture , Application Management, Typical Architecture of Data Warehouse , This is especially true fo...etc...",
    "author": [
      {
        "family": "Gamble",
        "given": "Willie"
      }
    ],
    "id": "10.5555/2559530",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "Emereo Publishing",
    "publisher-place": "Newstead, Queensland, AUS",
    "title": "Application development 62 success secrets: 62 most asked questions on application development - what you need to know",
    "title-short": "Application development 62 success secrets",
    "type": "book"
  },
  {
    "ISBN": "9781109465778",
    "abstract": "Training and development are necessary components to insure the success of small businesses in the changing global economy. Previous small- and medium-size enterprise (SME) research has shown that the owners and employees of small businesses receive less formal education than employees at larger firms due to high costs, inconvenient locations, inflexible schedules, lack of human resources, and owner attitudes. Technology and the advancement of internet-based learning may be a solution to many of these potential barriers. This descriptive study examines the current adoption and attitudes towards the Internet as a formal and informal training and development tool by small tourism and hospitality businesses (STHB) in Northern Norway. The study provides an introduction to SMEs and the attitudes and barriers they face in pursuing training, the advantages and disadvantages of internet-based training and a discussion of formal versus informal training methods followed by a description of the methodology and results. For this study a web-based survey link was e-mailed to 615 STHBs in Northern Norway in June and July 2008. The findings of this research have significance in the context of STHBs in Northern Norway, but given the low response rate of 24.2",
    "author": [
      {
        "family": "Fyllingness",
        "given": "Jennifer Lynne"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/1834920",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "note": "AAI3383804",
    "publisher": "Seattle University",
    "title": "Internet as a training tool in small tourism and hospitality businesses in norway",
    "type": "thesis"
  },
  {
    "ISBN": "1861000375",
    "author": [
      {
        "family": "Li",
        "given": "Sing"
      },
      {
        "family": "Economopoulos",
        "given": "Panos"
      }
    ],
    "id": "10.5555/548919",
    "issued": {
      "date-parts": [
        [
          1997
        ]
      ]
    },
    "publisher": "Wrox Press Ltd.",
    "publisher-place": "GBR",
    "title": "Professional visual c++ activex intranet programming",
    "type": "book"
  },
  {
    "ISBN": "9781595939951",
    "abstract": "Welcome to SIGSOFT 2008 and the Sixteenth ACM SIGSOFT International Symposium on the Foundations of Software Engineering (FSE-16).SIGSOFT 2008 provides many different opportunities for software engineering researchers and practitioners to interact. Four workshops, ranging in topics from specification and verification to collaborative development tools, provide an opportunity for in-depth discussion of particular areas. A doctoral symposium and a student research forum allow for lively exchange between experienced researchers and student participants. A symposium for new faculty and new researchers allows for sharing of experiences and the opportunity for those new to the field to gain advice from more experienced researchers. A symposium dedicated to software engineering educators aims to improve the recruitment, education and retention of students in software engineering. Also co-located with SIGOSFT 2008 is the 8th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering (PASTE), which provides an opportunity to explore how program analysis can help improve and extend the software tools available to developers.The main event at SIGSOFT 2008 is FSE, a leading conference for research in software engineering theory and practice. This year, FSE received 152 submissions from the global software engineering community. Each paper was reviewed by at least three members of the high-qualified technical program committee. The program committee met for one-and-a-half days to discuss the submissions in detail. Based on this discussion, the program committee selected 31 papers for presentation at the conference and publication in the conference proceedings. In addition to these papers, the conference proceedings contains abstracts from the keynote speakers and the SIGSOFT award winners that we are thrilled to have as part of the FSE-16 program.",
    "id": "10.1145/1453101",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "SIGSOFT ’08/FSE-16: Proceedings of the 16th ACM SIGSOFT international symposium on foundations of software engineering",
    "title-short": "SIGSOFT ’08/FSE-16",
    "type": "book"
  },
  {
    "ISBN": "0136449336",
    "abstract": "Creative professionals seeking the fastest, easiest, most comprehensive way to learn Adobe Animate choose Adobe Animate Classroom in a Book (2020 release) from Adobe Press. The 11 project-based step-by-step lessons in this book show users the key techniques for working in Animate. Adobe Animate provides more expressive tools, powerful controls for animation, and robust support for playback across a wide variety of platforms. Create interactive virtual reality immersive environments with VR 360 and VR Panorama documents. Gain advanced control over character animations with layer parenting and AI-driven lip syncing. Learn to create dynamic strokes with the new fluid brush, and work smarter with the revamped Timeline, Tools palette and Properties inspector. Support for SVG, WebGL, HTML5, animated GIFs, and HD video, and seamless collaboration with other designers and with other Adobe applications through Creative Cloud libraries make Adobe Animate the ideal development environment for creative animation and multimedia. Classroom in a Book is the best-selling series of hands-on software training books designed to help you learn the features of Adobe software quickly and easily. Developed by the training experts at Adobe Systems, these books offer complete, self-paced lessons designed to fit your busy schedule and help you learn the features of Adobe software quickly and easily. The online companion files include all the necessary assets for students to complete the projects featured in each chapter as well as eBook updates when Adobe releases new features for Creative Cloud customers. And all buyers of the book get full access to the Web Edition: a Web-based version of the complete eBook enhanced with video and interactive multiple-choice quizzes.",
    "author": [
      {
        "family": "Chun",
        "given": "Russell"
      }
    ],
    "edition": "1st",
    "id": "10.5555/3387334",
    "issued": {
      "date-parts": [
        [
          2020
        ]
      ]
    },
    "publisher": "Adobe Press",
    "title": "Adobe animate: 2020 release",
    "title-short": "Adobe animate",
    "type": "book"
  },
  {
    "ISBN": "9789606766428",
    "abstract": "In the recent years, software development has become larger in scale and more complicated. Furthermore, development with faster delivery and lower cost is required, thus the software development environment is becoming more and more complex. Accordingly, companies seek high potential students in universities who have a practical sense. The information engineering department of Shibaura Institute of Technology provides classes that adopt a more practical approach to software development so that students can obtain knowledge and skills necessary for software development. However, as class hours assigned for learning software engineering are not sufficient, a support system that enables students to practice outside the classroom or school is required. This support system should have work such that it enables each member belonging to the same group to collectively perform tasks just like in the classroom. In order to solve this problem, the authors developed EtUDE [1][2], the group exercise support environment for software development. Although group exercise helps to reduce the burden of instructing compared to individual exercise, it is difficult to offer instructions that meet the individual’s needs. However, it is the goal of the exercise-based classes to accomplish the obtainment of knowledge and skills for software development according to each student’s level. Therefore, the authors developed the group exercise support environment for software development, EtUDE which features various functions necessary for group exercise support as well as the function that detects learners who do not benefit from the group exercise and need individual instruction. With this, the software development exercise in more practical form will be available, and at the same time, it is made possible to acquire the knowledge and skills necessary for software development according to each student’s level. This essay presents the overview of EtUDE system and the outcome of the application of the system.",
    "author": [
      {
        "family": "Hashiura",
        "given": "Hiroaki"
      },
      {
        "family": "Yamashita",
        "given": "Kotaro"
      },
      {
        "family": "Ishikawa",
        "given": "Tatsuya"
      },
      {
        "family": "Isozaki",
        "given": "Yuka"
      },
      {
        "family": "Komiya",
        "given": "Seiichi"
      }
    ],
    "collection-title": "SEPADS’08",
    "container-title": "Proceedings of the 7th WSEAS international conference on software engineering, parallel and distributed systems",
    "id": "10.5555/1416502.1416527",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "keyword": "software development group exercises, software development environment",
    "page": "124-131",
    "publisher": "World Scientific; Engineering Academy; Society (WSEAS)",
    "publisher-place": "Stevens Point, Wisconsin, USA",
    "title": "A software development group exercise support environment, EtUDE: The system overview and the system evaluation through applying to classes",
    "title-short": "A software development group exercise support environment, EtUDE",
    "type": "paper-conference"
  },
  {
    "abstract": "A critiquing expert system was developed to assist in operating San Francisco’s water supply network. The critiquing system goes beyond a traditional expert system by refining (rather than supplying) the user’s proposed operating plan through a critique. A traditional expert system requests problem-specific data, then provides the operator with a plan. In the critiquing approach, the operator submits not only relevant information to the system, but also a proposed plan. The system evaluates the plan and provides feedback, which includes suggestions for improvement, warnings, and alternatives. The SFWD was motivated to have the critiquing system developed because of the perceived benefits in formalizing operating expertise in a critiquing system. Operating decisions are based on heuristic knowledge, not mathematical models. When personnel leave, the SFWD loses key information about how to operate the water supply network. A critiquing system can improve operators’ decisions by providing expert feedback on their proposed plans, and can aid in training novice operators.Building the critiquing expert system provided several technical challenges. A new paradigm was designed to implement critiquing in an expert system development tool. Also, developing a critiquing system is more complex than developing a traditional expert system. The critiquing paradigm and system development techniques designed for this research can be used to build critiquing systems in a variety of domains.The research included experiments to test the postulated advantages of the critiquing approach over the traditional approach to expert systems. The results were unambiguous; the critiquing system was preferred to the traditional expert system for each of several measures of system performance and acceptability.The research makes three main contributions. First, the research establishes the feasibility of implementing a critiquing system for decision support in a civil engineering problem domain. Second, the research demonstrates, both theoretically and empirically, the substantial benefits of the critiquing approach to expert systems. Third, the research reveals ways the organization influences the system’s development, and how system development profoundly influences the organization. Not only the system itself, but also the development process that creates the system, fosters organizational acceptance and use of the system.",
    "author": [
      {
        "family": "Steinemann",
        "given": "Anne Carol"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/193660",
    "issued": {
      "date-parts": [
        [
          1993
        ]
      ]
    },
    "note": "UMI Order No. GAX94-04052",
    "publisher": "Stanford University",
    "publisher-place": "Stanford, CA, USA",
    "title": "A critiquing expert system to assist in operations of the san francisco water supply system",
    "type": "thesis"
  },
  {
    "ISBN": "0130331155",
    "abstract": "From the Publisher: Dont wait another day to get started with tomorrows most important enterprise development technology! Master .NET hands-on with this start-to-finish multimedia training course. Based on Bertrand Meyers amazing in person .NET seminar, this course delivers all the guidance and code you need to get results with .NET — now! Youll start with the big picture then gain insiders insights into .NETs advantages, architecture, runtime, object model, deployment, and migration. Discover practical techniques for working with every key .NET technology, from C# to ASP+, SOAP to .NET frameworks, and beyond. Its all the .NET you need, in one box! Video lectures from one of the worlds top .NET experts! 6+ hours of comprehensive digital seminars on every aspect of the .NET platform — planning through coding! Covers every key .NET technology! C#, ASP+, ADO+, SOAP, and more Real-world insights into .NET deployment, migration, handling legacy code, and more Workbook includes all lecture slides, background material, and .NET glossary All the .NET skills you need, in one box! .NET in 15 minutes: an insiders overview .NET and Internet-centered mission-critical applications Beyond the limits of yesterdays components .NET architecture: runtime, framework, platform, and web services .NET runtime vs. Java Virtual Machine The MSIL intermediate language: security, variability, and more Managed code C++ under .NET: Managed and unmanaged versions Assemblies &amp; metadata: Organizing and extending your componentscomponents with contracts. .NET object model and type system Classes, methods, fields, properties and events .NET types: reference and value types, array types, arrays Inheritance concepts: multiple interface inheritance, novariance Encapsulating behavior: delegates Understanding C#: Microsofts new .NET programming language Language interoperability: Java, C++, VB, and more Cross-language inheritance and debugging The Common Language System Visual Studio.NET: a common multi-language development environment Frameworks and applications Web and Win Forms Remoting and threading ASP+: advanced e-commerce &amp; Web solutions Web services, SOAP, and Building Block Services Database access and manipulation: ADO The significance and future of .NET Corporate strategies: Getting ready for .NET",
    "author": [
      {
        "family": "Meyer",
        "given": "Bertrand"
      }
    ],
    "id": "10.5555/516473",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": ".NET training course by bertrand meyer",
    "type": "book"
  },
  {
    "abstract": "Context: Software defects occurring in code bases lead to an increased cost for software production and maintenance. To err is human nature and the process of software development is human centric. My analysis of the literature shows that the use of human error theory is emerging as an important tool for software development. Aim: The aim of my thesis is to present a training tool aimed at reducing the number of human errors developers make while working within the development phase of the Software Development Life cycle (SDLC) by improving developer situation awareness. Methods: My first study uses semi structured interviews to gain insight into what Skill-based (SB) errors developers make and how they mitigate these errors. My second study employs an experimental setup where developers log all human errors they make during developmental tasks across two weeks. At the beginning of week two the developers are asked to complete an online training package which I have developed on situation awareness. Results: The first study shows that the complexity of the development environment is one of the most frequently reported reasons for errors. I found that software developers struggle with effective mitigation strategies for their errors, reporting strategies largely based on improving their own willpower to concentrate better on development tasks. The results from the second study show that training software developers in situation awareness does lead to a decrease in the number of human errors made by those software developers. Conclusion: My doctoral research shows that human errors are a problem for software developers and loss of situation awareness is key for many of these developers. My preliminary results show that training tools which address situation awareness can aid developers in reducing the number of human errors that they make. Further work is required to investigate other means of improving developer situation awareness and determine whether my findings are generalisable.",
    "author": [
      {
        "family": "Nagaria",
        "given": "Bhaveet"
      }
    ],
    "genre": "PhD thesis",
    "id": "10.5555/AAI29351245",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "note": "AAI29351245",
    "publisher": "Brunel University (United Kingdom)",
    "title": "An investigation of human error in software development",
    "type": "thesis"
  },
  {
    "ISBN": "0321934113",
    "abstract": "Few books in computing have had as profound an influence on software management as Peopleware . The unique insight of this longtime best seller is that the major issues of software development are human, not technical. Theyre not easy issues; but solve them, and youll maximize your chances of success. Peopleware has long been one of my two favorite books on software engineering. Its underlying strength is its base of immense real experience, much of it quantified. Many, many varied projects have been reflected on and distilled; but what we are given is not just lifeless distillate, but vivid examples from which we share the authors inductions. Their premise is right: most software project problems are sociological, not technological. The insights on team jelling and work environment have changed my thinking and teaching. The third edition adds strength to strength. Frederick P. Brooks, Jr., Kenan Professor of Computer Science, University of North Carolina at Chapel Hill, Author of The Mythical Man-Month and The Design of Design Peopleware is the one book that everyone who runs a software team needs to read and reread once a year. In the quarter century since the first edition appeared, it has become more important, not less, to think about the social and human issues in software development. This is the only way were going to make more humane, productive workplaces. Buy it, read it, and keep a stock on hand in the office supply closet. Joel Spolsky, Co-founder, Stack Overflow When a book about a field as volatile as software design and use extends to a third edition, you can be sure that the authors write of deep principle, of the fundamental causes for what we readers experience, and not of the surface that everyone recognizes. And to bring people, actual human beings, into the mix! How excellent. How rare. The authors have made this third edition, with its additions, entirely terrific. Lee Devin and Rob Austin, Co-authors of The Soul of Design and Artful Making For this third edition, the authors have added six new chapters and updated the text throughout, bringing it in line with todays development environments and challenges. For example, the book now discusses pathologies of leadership that hadnt previously been judged to be pathological; an evolving culture of meetings; hybrid teams made up of people from seemingly incompatible generations; and a growing awareness that some of our most common tools are more like anchors than propellers. Anyone who needs to manage a software project or software organization will find invaluable advice throughout the book.",
    "author": [
      {
        "family": "DeMarco",
        "given": "Tom"
      },
      {
        "family": "Lister",
        "given": "Tim"
      }
    ],
    "edition": "3rd",
    "id": "10.5555/2505459",
    "issued": {
      "date-parts": [
        [
          2013
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Peopleware: Productive projects and teams (3rd edition)",
    "title-short": "Peopleware",
    "type": "book"
  },
  {
    "DOI": "10.1016/j.cageo.2019.02.009",
    "ISSN": "0098-3004",
    "URL": "https://doi.org/10.1016/j.cageo.2019.02.009",
    "author": [
      {
        "family": "Pu",
        "given": "Yingxia"
      },
      {
        "family": "Zhao",
        "given": "Xinyi"
      },
      {
        "family": "Chi",
        "given": "Guangqing"
      },
      {
        "family": "Zhao",
        "given": "Shuhe"
      },
      {
        "family": "Wang",
        "given": "Jiechen"
      },
      {
        "family": "Jin",
        "given": "Zhibin"
      },
      {
        "family": "Yin",
        "given": "Junjun"
      }
    ],
    "container-title": "Comput. Geosci.",
    "id": "10.1016/j.cageo.2019.02.009",
    "issue": "C",
    "issued": {
      "date-parts": [
        [
          2019,
          6
        ]
      ]
    },
    "keyword": "Parallel gwk-NN classifier, Geostatistical models, Parallel computing, Remotely sensed image classification",
    "page": "111-122",
    "publisher": "Pergamon Press, Inc.",
    "publisher-place": "USA",
    "title": "Design and implementation of a parallel geographically weighted k-nearest neighbor classifier",
    "type": "article-journal",
    "volume": "127"
  },
  {
    "ISBN": "0805370838",
    "abstract": "From the Book: Preface: Motivation After teaching file processing courses for years using COBOL as the vehicle language, I concluded that the students do learn to use COBOL for a variety of file organizations (sequential, indexed sequential, and relative) but do not gain an understanding of the data structures involved in implementing the more complex file structures such as direct files and indexed sequential files. A programming language with less support for file organizations than COBOL allows the students to gain greater in-depth knowledge about the implementation of routines that access data structures on external files. Pascal, with its support for relative files, fills this need. Goal This textbook meets the requirements for The Association for Computing Machinery (ACM) course CS5 as defined in the ACM curriculum guidelines. The goal of the book is to study the external data structures necessary for implementing different file organizations. Most texts currently available present file processing by using languages such as COBOL or PL/1, which have built-in support for direct access and indexed sequential access. Pascal does not have this built-in support. Instead, this language can be used in a more practical, prdagogical way by allowing students to gain more in-depth file implementation experience as they analyze data structures for efficiency and write their own access routines. The algorithms in this book are presented in a Pascal-like pseudocode, which provides students with a familiar environment in which to study the key concepts and structures necessary to implement a variety of file organizations.Datastructures such as trees, linked lists, stacks and queues are studied and analyzed for efficient use in the implementation of various file organizations. By using a superior pedagogical language such as Pascal and analyzing key data structures, students will gain a better understanding of design analysis and the implementation of file organization. Level/Audience/Prerequisites The prerequisites for the course addressed by this book, CS5, are two semesters of Pascal; in other words students should already have taken ACM CS1 and CS2 courses. Third-semester Computer Science majors constitute the primary audience for this book. Organization and Coverage Chapter 1 presents a conceptual overview of the file-processing environment, including discussions of common file organizations, file types and characteristics, and different ways of manipulating files as factors that affect file design. Several of the examples of file applications in this chapter are referenced in later chapters. Chapter 2 reviews the syntax for declaring and using records and for declaring and accessing files in Pascal. This chapter may be omitted for those students with a good understanding of Pascal records and files. Chapter 3 deals with the topics of blocking and buffering of records in a file. The central theme of the chapter is the fewer I/O operations required for a program that accesses a blocked file and the reduction of the time that the CPU waits for an I/O operation to be completed when using a buffered file. Interfacing algorithms for record blocking and deblocking are also presented. Quantitative measures of the effects of blocking and buffering effects are given solely in terms of the number of I/O accesses. Chapter 4 describes external storage devices as a background for understanding the impact of storage devices on file design and manipulation. Quantitative measures of the effects of blocking and buffering (similar to those in Chapter 3) are repeated in terms of physical access time of the devices using various blocking factors and different numbers of buffers. Chapter 5 deals with the design and maintenance of sequential files on both sequential and random-access storage devices. Algorithms for maintenance of sequential files stored on sequential devices are contrasted with algorithms for maintenance of sequential files stored on random-access devices. Sample data for a car-rental agency are used for implementating a sequential file. Quantitative measures of access times are given. Chapter 6 describes external sort/merge techniques, which are necessary for sorting very large sequential files. Sorting is a common file-processing task, especially for manipulating sequential files. Sorting methods discussed at length are the two-way merge, the balanced k-way merge, and the polyphase merge. These methods are compared in terms of the number of merge cycles and external storage devices needed for several example data sets. Chapter 7 begins with a discussion of the basic structures of direct files. A variety of techniques are presented for obtaining random access to data files, including the use of hashing. Examples are used to illustrate several methods for handling hashing collisions. Also included are some algorithms for creating and maintaining random-access files in versions of Pascal with the random-access files extension. In order to compare random and sequential access, the car-rental agency data used in Chapter 5 are stored in a random-access file and quantitative measures of access times are computed. Chapter 8 describes several types of tree structures that are useed to accessing random-access files sequentially. The most important tree structure is the B-Tree, and ways of representing and manipulating the B-tree are discussed along with accompanying algorithms. The chapter also discusses the application of trees that allow sequential and random access to the car-rental agency data file created in Chapter 7. Chapter 9 describes common implementations of indexed sequential organization, including implementations that use a tree structure, such as a B+-Tree, for the indexes. The chapter studies Scope Indexed Sequential files used on CDC computers, cylinder-and-surface-indexed sequential files (ISAM) used on IBM computers, and VSAM file organization used on IBM computers. Also included are algorithms for implementing indexed sequential files using a variety of data structures. Applications include the car- rental agency data, and access times for sequential, random, and indexed sequential files are compared. Chapter 10 investigates other types of file organization that use linked lists or tree structures to provide multiple-key access to random-access data files. Included in this chapter is a discussion of inverted files and multilist files along with creation and manipulation algorithms. The car-rental agency data are implemented as an inverted file and multilist files to provide access by several keys. Quantitative measures of access times are given by comparing these file organizations with others discussed previously. Outstanding Features Pedagogy Case Studies: Chapter 5 introduces a case study based on an actual car-rental agency, and this case study is used throughout the book as an on-going example illustrating practical file concepts and issues. Additional practical, real-world case studies are presented in Chapter 2. They include discussions of an inventory of products, student class schedules, and the assignment of course grades for a class. Examples/Illustrations: Throughout the book algorithms are presented in Pascal-like pseudocode. Students learn best by working with files of varying organizations rather than just reading about them. A variety of exercises and programming projects have been provided that illustrate the creation and manipulation of files for each type of organization. Students can implement the algorithms from the book in a hands-on, file organization programming environment, thus gaining experience and greater knowledge of all key concepts. The program solutions for these exercises are available from the author. Solutions to odd- numbered exercises are provided at the back of the book while the solutions to even-numbered exercises are provided in the Instructor’s Guide. Glossary/Key Terms: Key terms are highlighted and defined as they occur in the test, and are also included in the glossary in the end of the book. Class Tested: This book was thoroughly class tested for six semesters in a sophomore-level file structures course. The readability of the book was greatly enhanced because of student and reviewer feedback over the course of several drafts. The Use of Pascal Chapter 2 reviews the Pascal syntax for declaring, using, and accessing Pascal records and files. This chapter can be omitted for those students with a good understanding of Pascal. The Pascal syntax for records, linked lists and trees is included in corresponding sections. The first two sections of the book (I and II) reference the ISO standard Pascal, while sections III and IV require random-access files, which are not included in the ISO standard. Most versions of Pascal have been extended to allow random access (OMSI Pascal, TURBO Pascal, UCSD P-System Pascal, and VAX-11 Pascal, to name a few). Appendix A includes a sequential simulation of random access using arrays in internal memory as an easy alternative to those versions of Pascal without random access. The syntax for random access for various versions of Pascal is included in Appendix B. Instructor’s Guide The accompanying Instructor’s Guide includes: guidelines for presenting the material in each chapter additional examples for classroom use, including points to be emphasized solutions to all even-numbered exercises transparency masters of various illustrations and tables from the book quizzes for each chapter Software: A disk of solutions to all programming problems is available from the author for a nomimal fee to all instructors. Acknowledgements I am grateful to the numerous individuals that have helped me in preparing this book. I am indebted to the faculty of the Computer Science Department of Mississippi State University for providing equipment and an environment conducive to writing a book. My thanks also go to the reviewers: James D. Schoeffler, Cleveland State University; Rayno D. Niemi, Rochester Institute of Technology; James Blahnik, St. Norbert’s College; Medhi Owrand, University of Oklahoma; Robert Uzgalis, University of California at Los Angeles; Walter Scacchi, University of Southern California. Special thanks to the students in my classes who corrected typing errors in earlier versions of the book. I express my appreciation to my Editor Alan Apt and all those individuals at Benjamin/Cummings who have organized the reviewing and production of this book. Finally, I thank my husband for his continued support, encouragement, and understanding. Nancy E. Miller",
    "author": [
      {
        "family": "Miller",
        "given": "Nancy E."
      }
    ],
    "id": "10.5555/535835",
    "issued": {
      "date-parts": [
        [
          1987
        ]
      ]
    },
    "publisher": "Benjamin-Cummings Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "File structures using pascal",
    "type": "book"
  },
  {
    "ISBN": "0072123869",
    "abstract": "From the Publisher: Windows 2000 advantage includes decreased cost of ownership through improved directory services,increased security,better integration with database and development tools,and vastly expanded network and /Internet/Web capabilities. Explains how to optimize and maintain the Active Directory,plan the active directory namespace,develop the organization and implementation of a domain,and manage Active Directory replication. Visually maps complicated processes wth frequent screen shots to help build familiarity with the new functions. CD-RO contains more than 300 practice questions on TEST YOURSELF Personal Testing Center software along with lings to the chapter in the book for review. The Only Classroom-Based Training and Self-Assessment System 100",
    "author": [
      {
        "family": "Shinder",
        "given": "Thomas W."
      },
      {
        "family": "Shinder",
        "given": "Debra Littlejohn"
      }
    ],
    "id": "10.5555/557256",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "McGraw-Hill Professional",
    "title": "MCSE windows 2000 server study guide (exam 70-215) (book/CD-ROM)",
    "type": "book"
  },
  {
    "DOI": "10.1145/100348.100412",
    "ISBN": "0897913485",
    "URL": "https://doi.org/10.1145/100348.100412",
    "abstract": "Software reusability has been proclaimed as the common sense solution to many software development problems. The concept of reusability promotes productivity because it avoids “reinventing the wheel.” Using existing components which are similar to the current needs can be much faster than creating components from scratch. Reusability can also be viewed as promoting reliability since reused components have the benefit of both experimental and field testing.However, reusability has not fulfilled its potential for revolutionizing the software development industry. Identifying the factors which cause current reuse efforts to fail is essential to its later success. Likewise, identifying the factors that seem to promote successful reusability is equally important. Furthermore, practical ways to eliminate the detrimental factors must be developed.An experiment designed to ferret out the causes of software reuse success and failure must consider several important issues: (1) The experiment must consist of actual development and reuse. Questionnaires and subjective measurements about whether to reuse, etc. are necessary but not sufficient. (2) The experiment must be greatly controlled to avoid extraneous factors from skewing the results. Factors which might influence the outcome must be deliberately tested for, or controlled such that they do not bias the experimental data. (3) The components to be reused must be determined. Reusing requirements and designs has been suggested, but with little success. On the other hand, reusing test cases has been greatly successful. In between is code. Current experiments should still concentrate on the ability to reuse source code. You must walk before you run. (4) Finally, the factors being tested must be established and they must consider two main tangents. First, specific factors concerning the code characteristics, the organization of components, and the development environment must be considered. Other concerns deal with the human factors. Predisposition, ego, training and skill must be taken into account for an accurate study of reusability.A current reusability experiment concentrates on the use of an object-oriented organization scheme, reusable code characteristics, and several human factors. The experimental subjects actually design and implement code under varying conditions. Subjects are divided into groups that must reuse whenever possible, may reuse if desired, and cannot reuse at all. Comparing the results of the various groups will lead to a better understanding of the problems faced in software reusability.",
    "author": [
      {
        "family": "Lewis",
        "given": "John A."
      }
    ],
    "collection-title": "CSC ’90",
    "container-title": "Proceedings of the 1990 ACM annual conference on cooperation",
    "id": "10.1145/100348.100412",
    "issued": {
      "date-parts": [
        [
          1990
        ]
      ]
    },
    "page": "405",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "An experiment to determine software reusability factors (abstract)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1155/2021/7106104",
    "ISSN": "1530-8669",
    "URL": "https://doi.org/10.1155/2021/7106104",
    "abstract": "With the rapid development of the economy, the integration of corporate strategic management and human resource management has become an issue of concern. This research mainly discusses the role of intelligent communication management terminal in the construction of human resource management mode. In this research, the system development process of this research mainly uses the class library in the software architecture layer to support the software development process. The main development language of Android, JAVA, is to install the Android Develop Tools plug-in on eclipse and install the Android SDK in the computer operating system to build the Android development environment. The development and application of the system not only make the enterprise managers more convenient and efficient in the process of managing the enterprise but also smooth the operation of the enterprise while reducing the human resource investment and also gives the employees more right to know and the right to participate in the enterprise construction. By creating more value while reducing human resource input, enterprises will enable it to obtain more benefits, and thus enter a cycle of good development and contribute to society. The system has the functions of personnel management, recruitment management, attendance management, training management, work management, and salary management. The recruitment management function of the system is mainly composed of recruitment plan management, recruitment information management, and talent pool. In the system’s recruitment plan management function, important information such as the recruitment part, the number of recruits, personnel requirements, and the specific arrival time of the personnel must be clarified. The personnel in charge of the enterprise personnel department shall conduct corresponding regulations according to the specific needs of the enterprise and shall be experienced by the personnel department. The review is carried out, and all parts of the enterprise are coordinated and completed at the same time. In the platform performance test, when the number of concurrent users reaches 50000, the request time is about 6 seconds, which meets the requirement that the response time of 10000 people per second is less than 10 seconds. This research puts forward suggestions and countermeasures for the optimization of human resource management, which can not only improve the efficiency of Y company’s human resource management but also provide useful reference and reference for other enterprises facing the same problem.",
    "author": [
      {
        "family": "Wu",
        "given": "Shumei"
      },
      {
        "family": "Lv",
        "given": "Zhihan"
      }
    ],
    "container-title": "Wirel. Commun. Mob. Comput.",
    "id": "10.1155/2021/7106104",
    "issued": {
      "date-parts": [
        [
          2021,
          1
        ]
      ]
    },
    "publisher": "John Wiley; Sons Ltd.",
    "publisher-place": "GBR",
    "title": "Intelligent communication management terminal in the construction of human resource management mode",
    "type": "article-journal",
    "volume": "2021"
  },
  {
    "DOI": "10.1145/3626252.3630816",
    "ISBN": "9798400704239",
    "URL": "https://doi.org/10.1145/3626252.3630816",
    "abstract": "Many CS1 teachers focus on specific content approaches in CS1. Some want objects early, some functions early, some decisions/loops first. Some put emphasis on language details, some on language-neutral problem solving. Some demand real-world IDEs, code versioning tools, industry-quality comments, specifications, documentation, or test coverage. While the focus shows teachers care and may indeed provide benefits, those specific focuses can also prevent increased cooperation among universities in defining a more \"common\" CS1 curricula. With a more common curriculum, better content and tool support is enabled due to economies of scale. Such cooperation could yield a more powerful approach to teaching CS1, elevating the role of CS1 instructors. CS1 instructors, by being more flexible in their content approaches, may help show the college education community the great benefits of increased cooperation among universities, especially in the design and delivery of introductory gateway courses taken by large numbers of students. We describe results of discussions with over 100 instructors at over 50 universities during the past decade, highlighting frequently-stated content approaches that have little or no evidence supporting the approach and that may hamper cooperation, and we end by encouraging flexibility in content approaches to enable the community and publishers to provide better CS1 support.",
    "author": [
      {
        "family": "Vahid",
        "given": "Frank"
      }
    ],
    "collection-title": "SIGCSE 2024",
    "container-title": "Proceedings of the 55th ACM technical symposium on computer science education v. 1",
    "id": "10.1145/3626252.3630816",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "common courses, cooperation, cs1, programming, teaching",
    "page": "1368-1373",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CS1 instructors: Flexibility in content approaches is justified, and can enable more cross-university cooperation",
    "title-short": "CS1 instructors",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321545494",
    "abstract": "Regardless of your perceptions of Agile, this is a must read! Douglasss book is a powerful and practical guide to a well-defined process that will enable engineers to confidently navigate the complexity, risk, and variability of real-time and embedded systemsincluding CMMI compliance. From requirements specification to product delivery, whatever your modeling and development environment, this is the instruction manual. Mark Scoville, software architect This book will provide you with the framework of agile development for real-time projects ranging from embedded systems to web-based, data collection applications. I wish I had this book three years ago when we began a real-time, embedded drilling control system project, but all my engineers will be getting copies now that it is available. And, for my academic colleagues, this is the perfect book for graduate seminars in applied software development techniques. Don Shafer, chief technology officer, Athens Group; adjunct professor, Cockrell School of Engineering, The University of Texas at Austin We have used Dr. Douglasss books on real-time (Doing Hard Time, Real-Time UML, and Real-Time Design Patterns) for years. His books are always informative, accessible, and entertaining. Real-Time Agility continues that tradition, and I cant wait to introduce it to my colleagues. Chris Talbott, principal software designer Until now, agile software development has been mostly applied within the IT domain. This book breaks new ground by showing how to successfully traverse the perceived chasm between agility and real-time development. Although embedded systems impose challenging constraints on development teams, you can always benefit from increasing your agility. Scott W. Ambler, chief methodologist/Agile, IBM Rational; author of Agile Modeling Real-time and embedded systems face the same development challenges as traditional software: shrinking budgets and shorter timeframes. However, these systems can be even more difficult to successfully develop due to additional requirements for timeliness, safety, reliability, minimal resource use, and, in some cases, the need to support rigorous industry standards. In Real-Time Agility, leading embedded-systems consultant Bruce Powel Douglass reveals how to leverage the best practices of agile development to address all these challenges. Bruce introduces the Harmony/ESW process: a proven, start-to-finish approach to software development that can reduce costs, save time, and eliminate potential defects. Replete with examples, this book provides an ideal tutorial in agile methods for real-time and embedded-systems developers. It also serves as an invaluable in the heat of battle reference guide for developers working to advance projects, both large and small. Coverage includes How Model-Driven Development (MDD) and agile methods work synergistically The Harmony/ESW process, including roles, workflows, tasks, and work products Phases in the Harmony/ESW microcycle and their implementation Initiating a real-time agile project, including the artifacts you may (or may not) need Agile analysis, including the iteration plan, clarifying requirements, and validation The three levels of agile design: architectural, mechanistic, and detailed Continuous integration strategies and end-of-the-microcycle validation testing How Harmony/ESWs agile process self-optimizes by identifying and managing issues related to schedule, architecture, risks, workflows, and the process itself",
    "author": [
      {
        "family": "Douglass",
        "given": "Bruce Powel"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1572526",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Real-time agility: The harmony/ESW method for real-time and embedded systems development",
    "title-short": "Real-time agility",
    "type": "book"
  },
  {
    "ISBN": "1861005040",
    "abstract": "From the Publisher: ASP.NET is the latest incarnation of Microsoft’s Active Server Pages (ASP) - a powerful server-based technology, designed to create dynamic and interactive HTML pages for your Web site, or corporate intranet. ASP.NET also constitutes a core element in Microsoft’s .NET vision, providing web-based access to an immensely powerful new development environment, .NET; in this respect alone, it’s a great leap ahead of all previous versions of ASP. This book will provide you with a step-by-step introduction to ASP.NET using VB.NET, with plenty of worked examples that will help you to gain a deep understanding of what ASP.NET is all about, and how you can harness it to build powerful web applications. This book covers: Creating basic ASP.NET pages Learning the basics of VB.NET Understanding the concepts of Object Oriented Programming Working with Data and XML The ASP.NET Server Controls Creating User Controls and Components Exploring the world of Web Services Configuring your ASP.NET Applications The future of VoiceXML technologies, including VoiceXML 2.0 This book is aimed at relatively inexperienced web builders who are looking to enrich their sites with dynamically-generated content, and want to learn how to start building web applications using ASP.NET. Developers who have a little experience with previous versions of ASP (and are looking to move over to ASP.NET), may also find this book helpful in getting a simple grasp on what ASP.NET is, what it does, and how it can be used. Experience of basic HTML is required, but previous experience of ASP or VBScript is not essential. We’ll be teaching the basics of VB.NET in this book, so prior experience of VB.NET is not required. This is one of two editions of Beginning ASP.NET. This version presents all code examples in Visual Basic .NET. The C# version of the same title (Beginning ASP.NET using C#, ISBN: 1-861006-15-2) will be available from November 2001. Author Biography: Chris Ullman is a Computer Science graduate who came to Wrox five years ago, when 14.4 modems were the hottest Internet technology and Netscape Navigator 2.0 was a groundbreaking innovation. Since then he’s applied his knowledge of HTML, server-side web technologies, Java and Visual Basic to developing, editing and authoring books. Ollie Cornes has been working with the Internet and the Microsoft platform since the early 90’s. In 1999 he co-founded a business-to-business Internet company and until recently was their Chief Technical Officer. Prior to that his various roles involved programming, technical authoring, network management, writing, leading development projects and consulting. He has worked with Demon Internet, Microsoft, Saab, Travelstore and Vodafone. Ollie holds a degree in computer science and is Microsoft certified. Juan T. Llibre is the Director of the Computer Sciences and Distance Education departments at Universidad Nacional Pedro Henrı́quez Ureña in Santo Domingo, Dominican Republic. He has been a consultant to the Caribbean Export Development Agency and the Dominican Republic’s Central Bank and is currently the Technical Architect for the Caribbean Virtual University. Juan has been an Active Server Pages Microsoft MVP for 4 years and can regularly be found in the newsgroups and mailing lists, offering advice on ASP and ASP.NET in English and Spanish. He co-authored Wrox’s \"Beginning ASP 2.0\" and \"Beginning ASP 3.0\", and has been a Technical Reviewer for over a dozen books on ASP and its related technologies. Chris Goode is a Technical Architect in the .NET team at Wrox, currently specializing in ASP.NET. She has a degree in Mechanical Engineering, but decided that the engineering world wasn’t for her. She’s now back firmly in the world of computers, finding that life at Wrox combines the fun stuff with the work stuff pretty well.",
    "author": [
      {
        "family": "Team",
        "given": "Wrox Author"
      },
      {
        "family": "Llibre",
        "given": "Juan T."
      },
      {
        "family": "Goode",
        "given": "Chris"
      }
    ],
    "edition": "1st",
    "id": "10.5555/559366",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Wrox Press Ltd.",
    "publisher-place": "GBR",
    "title": "Beginning ASP.NET using VB.NET",
    "type": "book"
  },
  {
    "ISBN": "0201185377",
    "abstract": "From the Book: PREFACE: Why Another Book on Microsoft Foundation Classes Programming To answer this question, let us look at a typical MFC programming scenario. First, you attend an MFC training session or read some introductory books on MFC programming. You quickly become able to write and customize small tutorial applications. AppWizard and ClassWizard allow you reach an unprecedented level of productivity. Your applications support the multiple document interface (MDI) and have a professional-looking user interface with a floating toolbar, a status bar, printing and print preview, and so on. You then go back to work and start using MFC to produce great-looking applications. Code flows freely from your keyboard, the wizards work hard at your side, and life looks great under the MFC sun. One day, you start wondering about how to implement new features that were not explicitly covered in the training session. For example: Make your application remember the last active document and automatically reopen it. Support multiple kinds of views on the same document and allow the user to explicitly open any kind of view. Add ToolTips to the controls in a form view. Dynamically switch the view displayed in a window to replace it with another kind of view. Implement an expanding dialog box. Embed a property sheet (tabbed dialog box) inside another window, such as a form view, a dialog box, or a mini frame window. Display a progress indicator in a status bar pane. Have a menu pop up when the user clicks a button on a toolbar or in a dialog box. Support headers and footers in your print and print preview. Displaya custom Printing . . . dialog box with a progress indicator. You feel that implementing these features cannot be that difficult: after all, you have already seen them in other Windows applications. But where do you start looking for an answer The solution may be as easy as knowing the specific MFC virtual functions that you must override to produce the desired effect or knowing the Windows messages you should trap and handle appropriately. For some features, however, more involved techniques may be neededeven to the point of tracing into MFC’s source code to understand just where and how you can act to modify your application’s default behavior. One infuriating fact of life is that the answer to your particular question may be lying around somewhere: buried in some MFC programming book or magazine article, on the Microsoft Developer’s Network CD-ROM, in the Microsoft Knowledge Base, in the various threads and mailing lists maintained on the Internet, or even in the online books or samples contained on the Visual C++ CD-ROM. The problem is this: How are you going to locate the most relevant and reliable source of information among all these resources How are you going to find the solution you need right now Introducing The MFC Answer Book This book is intended to provide ready-to-use techniques that answer the most common real-world questions that typically confront MFC developers. The structure of this book is specifically designed to help you quickly locate the answers youire looking for and integrate the relevant solutions into your own programs. The FAQ format of this book makes it ideally suited to the needs of the developer looking for a quick answer to a pressing question. At the same time, you will find that many techniques will give you a better understanding of the inner workings of MFC applications and more generally help you improve your MFC programming skills. In particular, the Explanations and Additional Comments sections often delve into the MFC source code or undocumented functions to explain how the techniques discussed work and how they differ from or integrate with MFC’s default behavior. Key Features of This Book Although most books about Visual C++ and MFC programming answer valid questions about MFC programming and provide useful tips if you read them from cover to cover, most of them are not structured in a way that allows you to quickly find an answer to a given problem. Moreover, even if you find the answer, it is likely to be buried inside a larger discussion and not readily available as a step-by-step technique that you can simply incorporate into your current project to add a required feature. In contrast, The MFC Answer Book is specifically designed to help MFC developers solve their programming problems in the most efficient way: This book is organized so that the table of contents will help you to quickly zoom in on the FAQs that answer your questions. I have made every effort to build a convenient and comprehensive index that will direct you to all the pages relating to any keyword or function referenced in this book. Each FAQ is written in a concise way that first gives you the step-by-step answer you need. Explanations and additional comments are deferred to later sections so that they do not get in the way of the solution but are readily available for those who want to go further than the cookbook recipe and wish to understand what goes on under the hood. Each explanation comes with tested and reusable sample code that you can plug into your MFC application in a few minutes to integrate the required functionality immediately. To summarize: The goal of this book is to offer you the shortest way from a problem to the corresponding step-by-step solution that you can integrate immediately into your current project. Who Should Read This Book This book is written for all MFC developers who wish to solve their MFC-related problems and at the same time learn advanced MFC techniques that will allow them to add a range of sophisticated features to their applications. This book assumes a basic proficiency both in the C++ language and in MFC programming as well as a knowledge of how to use the Visual C++ integrated development environment and tools such as AppWizard and ClassWizard. The Visual C++ wizards are discussed only when used in nonstandard ways to achieve a specific result. To benefit fully from this book, you should already understand the basic MFC concepts presented in the Scribble tutorial described in the Visual C++ documentation: the document/view architecture, message maps, the UPDATE_COMMAND_UI mechanism, dialog data exchange (DDX), and so on. Typically, you will either have followed the Scribble tutorial, attended a training session in MFC programming, or read one of the many introductory books on this topic. Of course, having a more extensive background in MFC programming will not hurt! Quite to the contrary. Based on feedback from reviewers and colleagues, I know that this book will also appeal to experienced MFC developers, who will find many useful techniques to add to their bag of MFC programming tricks. Finally, reading this book will allow all MFC developers to improve their understanding of fundamental MFC concepts and sharpen their MFC programming skills. How To Use This Book This book focuses on the 32-bit MFC version 4.x for Windows 95 and Windows NT. However, most techniques and concepts discussed here also apply to older versions of MFC. They should also remain valid for future MFC versions, because they rely on core MFC classes and behaviors that are not likely to evolve in a way that breaks existing code. I tried to write this book so that it will become a flexible tool that you can use as you want to. This means that you can either read this book from cover to coverI would certainly appreciate it if you door use it as a reference to look up only the specific topics that interest you. Most FAQs are cross-referenced to help you locate all the relevant information you might need even if you jump into the middle of the book. However, before you start hunting for answers to your MFC questions, I suggest that you take a few minutes to read Chapter 0 (Terminology and Conventions) and Chapter 1 (Document/View Architecture Backgrounder) to make sure that we start on the same ground with respect to fundamental document/view architecture concepts. What Is on the CD-ROM The companion CD-ROM contains source code and executables for all of the book’s sample programs. The folder hierarchy is organized first by chapter number and then by project name. Thus, the AutoSaveDoc project for Chapter 2 is located in the d:Chap02AutoSaveDoc folder, where \"d:\" is your CD-ROM drive’s letter. All the executables are located under their respective chapter folders. For example, all the executable sample programs for Chapter 2 are located in the d:Chap02 folder. The EkUtil.h and EkUtil.cpp files located at the root of the hierarchy contain the various helper Ek . . . . . . functions and classes that are presented throughout the book. You can choose to copy the whole folder hierarchy from the CD-ROM to your hard disk, copy only the examples that are of interest to you, or access the files directly from the CD-ROM. If you copy files from the CD-ROM to your hard disk, remember to remove the read-only attribute from the files on your hard disk. All sample programs have been compiled and tested under both Visual C++ 5.0 and Visual C++ 6.0. They will also work properly with Visual C++ 4.x, but you will have to manually create the appropriate .mdp project file. Note, however, that the .dsp project files on the CD-ROM have the Visual C++ 5.0 format: if you open them with Visual C++ 6.0, simply answer Yes to the dialog box asking whether you want to convert these files to the new format. Your Feedback Is Welcome I have done my best to accurately present topics that I feel should be of interest to most MFC developers. However, if you think that a topic should be covered differently or should use another technique, don’t hesitate to send me e-mail at ekain@awl.com. Also, e-mail me if you want to submit a topic idea or a technique of your own that solves a problem you have encountered, if you find an error or have any problem with this book, or if you have suggestions or want to discuss anything with me. I can promise that I will read all e-mail messages, take them into account, and try to respond to each of them as soon as possible. Note, however, that I may not have the time to answer specific MFC programming questions. You can also visit my Web site at ...",
    "author": [
      {
        "family": "Kain",
        "given": "Eugene"
      },
      {
        "family": "Wingo",
        "given": "Scot"
      }
    ],
    "id": "10.5555/552037",
    "issued": {
      "date-parts": [
        [
          1998
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "The MFC answer book: Solutions for effective visual c++ applications",
    "title-short": "The MFC answer book",
    "type": "book"
  },
  {
    "ISBN": "9781605580777",
    "abstract": "We are pleased to introduce the technical program of the 2008 ACM Conference on Computing Frontiers, the fifth in the series. The conference was established as a forum to present and discuss explorations of territory at the edge of computing, perhaps risky, but intellectually challenging and with the potential to substantially improve the state of the art. In this context, papers have been solicited and submitted on theory, methods, technologies, and implementations concerned with innovations in computing paradigms, computational models, architectural paradigms, computer architectures, development environments, compilers, and operating environments.This year’s program includes 30 technical papers selected out of 110 submissions (a 27",
    "id": "10.1145/1366230",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "CF ’08: Proceedings of the 5th conference on computing frontiers",
    "title-short": "CF ’08",
    "type": "book"
  },
  {
    "ISBN": "0769500013",
    "abstract": "The choice of techniques to support system design is important in order to achieve a satisfactory result with regards to the quality of the future system. In the IDEnet development project we chose to work with techniques used within, or inspired by, three different research areas, Sociology, Participatory Design and Hu-man Computer Interaction. The paper discusses the use of one technique from each of these research areas, ranging from ’scratch to sketch’ in the development of an Intranet (IDEnet) at the Department of Computer Science and Business Administration (IDE), University College of Karlskrona/Ronneby in Sweden. The advantages and disadvantages for the use of each technique for system design are also discussed.",
    "author": [
      {
        "family": "Berndtsson",
        "given": "Johan"
      }
    ],
    "collection-title": "HICSS ’99",
    "container-title": "Proceedings of the thirty-second annual hawaii international conference on system sciences-volume 2 - volume 2",
    "id": "10.5555/874069.875990",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "keyword": "Techniques, Intranet, Information Systems Design, Informal interviewing, Future Workshop with Democratic Dialogue, Card Sorting",
    "page": "2019",
    "publisher": "IEEE Computer Society",
    "publisher-place": "USA",
    "title": "Designing an intranet from scratch to sketch: Experiences from techniques used in the IDEnet project",
    "title-short": "Designing an intranet from scratch to sketch",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321685865",
    "abstract": "Successfully Implement High-Value Configuration Management Processes in Any Development Environment As IT systems have grown increasingly complex and mission-critical, effective configuration management (CM) has become critical to an organizations success. Using CM best practices, IT professionals can systematically manage change, avoiding unexpected problems introduced by changes to hardware, software, or networks. Now, todays best CM practices have been gathered in one indispensable resource showing you how to implement them throughout any agile or traditional development organization. Configuration Management Best Practices is practical, easy to understand and apply, and fully reflects the day-to-day realities faced by practitioners. Bob Aiello and Leslie Sachs thoroughly address all six pillars of CM: source code management, build engineering, environment configuration, change control, release engineering, and deployment. They demonstrate how to implement CM in ways that support software and systems development, meet compliance rules such as SOX and SAS-70, anticipate emerging standards such as IEEE/ISO 12207, and integrate with modern frameworks such as ITIL, COBIT, and CMMI. Coverage includes Using CM to meet business objectives, contractual requirements, and compliance rules Enhancing quality and productivity through lean processes and just-in-time process improvement Getting off to a good start in organizations without effective CM Implementing a Core CM Best Practices Framework that supports the entire development lifecycle Mastering the people side of CM: rightsizing processes, overcoming resistance, and understanding workplace psychology Architecting applications to take full advantage of CM best practices Establishing effective IT controls and compliance Managing tradeoffs and costs and avoiding expensive pitfalls Configuration Management Best Practices is the essential resource for everyone concerned with CM: from CTOs and CIOs to development, QA, and project managers and software engineers to analysts, testers, and compliance professionals. Praise for Configuration Management Best Practices Understanding change is critical to any attempt to manage change. Bob Aiello and Leslie Sachss Configuration Management Best Practices presents fundamental definitions and explanations to help practitioners understand change and its potential impact. Mary Lou A. Hines Fritts, CIO and Vice Provost Academic Programs, University of Missouri-Kansas City Few books on software configuration management emphasize the role of people and organizational context in defining and executing an effective SCM process. Bob Aiello and Leslie Sachss book will give you the information you need not only to manage change effectively but also to manage the transition to a better SCM process. Steve Berczuk, Agile Software Developer, and author of Software Configuration Management Patterns: Effective Teamwork, Practical Integration Bob Aiello and Leslie Sachs succeed handsomely in producing an important book, at a practical and balanced level of detail, for this topic that often goes without saying (and hence gets many projects into deep trouble). Their passion for the topic shows as they cover a wonderful range of topicseven culture, personality, and dealing with resistance to changein an accessible form that can be applied to any project. The software industry has needed a book like this for a long time! Jim Brosseau, Clarrus Consulting Group, and author of Software Teamwork: Taking Ownership for Success A must read for anyone developing or managing software or hardware projects. Bob Aiello and Leslie Sachs are able to bridge the language gap between the myriad of communities involved with successful Configuration Management implementations. They describe practical, real world practices that can be implemented by developers, managers, standard makers, and even Classical CM Folk. Bob Ventimiglia, Bobev Consulting A fresh and smart review of todays key concepts of SCM, build management, and related key practices on day-to-day software engineering. From the voice of an expert, Bob Aiello and Leslie Sachs offer an invaluable resource to success in SCM. Pablo Santos Luaces, CEO of Codice Software Bob Aiello and Leslie Sachs have a gift for stimulating the types of conversation and thought that necessarily precede needed organizational change. What they have to say is always interesting and often important. Marianne Bays, Business Consultant, Manager and Educator",
    "author": [
      {
        "family": "Aiello",
        "given": "Robert"
      },
      {
        "family": "Sachs",
        "given": "Leslie"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1869711",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "publisher": "Addison-Wesley Professional",
    "title": "Configuration management best practices: Practical methods that work in the real world",
    "title-short": "Configuration management best practices",
    "type": "book"
  },
  {
    "DOI": "10.1145/1937117.1937126",
    "ISBN": "9781450305471",
    "URL": "https://doi.org/10.1145/1937117.1937126",
    "abstract": "In this paper, we compare the usability of a library approach with a language approach to task parallelism. There are many practical advantages and disadvantages to both approaches. A key advantage of a library-based approach is that it can be deployed without requiring any change in the tool chain, including compilers and IDEs. However, the use of library APIs to express all aspects of task parallelism can lead to code that is hard to understand and modify. A key advantage of a language-based approach is that the intent of the programmer is easier to express and understand, both by other programmers and by program analysis tools. However, a language-based approach usually requires the standardization of new constructs and (possibly) of new keywords. In this paper, we compare the java.util.concurrent (j.u.c) library [14] from Java 7 and the Habanero-Java (HJ) [16] language, supported by our experiences in teaching both models at Rice University.",
    "author": [
      {
        "family": "Cavé",
        "given": "Vincent"
      },
      {
        "family": "Budimlić",
        "given": "Zoran"
      },
      {
        "family": "Sarkar",
        "given": "Vivek"
      }
    ],
    "collection-title": "PLATEAU ’10",
    "container-title": "Evaluation and usability of programming languages and tools",
    "id": "10.1145/1937117.1937126",
    "issued": {
      "date-parts": [
        [
          2010
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Comparing the usability of library vs. Language approaches to task parallelism",
    "type": "paper-conference"
  },
  {
    "abstract": "The explosive growth of cameras, image sensors, and computer vision as a discipline of Artificial Intelligence (AI) has garnered strong interest from researchers, developers, businesses and consumers. Image classification refers to a process to classify an image according to a model and match it to a set of classes or categories. Object detection is similar to image classification, which is a process to classify, locate and count multiple objects in an image and their respective locations within the image. Object tracking involves using object detection in each frame of a video to track the desired object through a series of image frames or video [1]. There are a number of use cases for computer vision including face recognition for application or device security, automatically counting and classifying items on a production line, and monitoring and responding to traffic conditions on busy road sections.Computer vision seeks to understand information in digital images through processing and analyzing digital images. This understanding is achieved through extracting high dimension data from images and processing them to produce usable information. Practical applications of computer vision in the context of machine learning include classification, segmentation, and tracking [2].IBM Watson Studio (https://www.ibm.com/watson) is IBM’s suite of enterprise-ready AI services, applications and tooling. As a service on IBM Cloud, IBM Watson Visual Recognition uses deep learning algorithms to analyze images for scenes, faces, and objects. This service provides built-in models and can also be used to create and train custom models for specific needs. Watson Studio provides a collaborative platform on top of IBM Cloud’s cloud computing capabilities to use existing models or train and deploy new models with minimal coding. Watson Studio has the added capability of setting up custom environments and Notebooks, allowing quick, cloud-enabled development machines that can scale as your projects scale.IBM PowerAI Vision (https://www.ibm.com/caen/marketplace/ibm-powerai-vision) is a Graphics Processing Unit (GPU) accelerated visual recognition solution running on IBM Power Systems. PowerAI Vision (https://www.ibm.com/caen/marketplace/ibm-powerai-vision) puts data science in the hands of subject matter experts. This tool simplifies building machine learning models with IBM Power Systems. As a result, users can build models and deploy them to the web without coding. The models can be accessed through an Application Program Interface (API). On the other hand, users can call the API from their own applications with a few lines of code.IBM provides developers free, open source, state-of-the-art assets for deep learning through the Model Asset Exchange (MAX) (https://developer.ibm.com/exchanges/models/) on IBM Developer. In the repository developers can find both assets for training deep learning models and pre-trained models to use in their projects.The first half of this workshop will focus on exploring the Watson Visual Recognition and Watson Machine Learning Services in IBM Cloud. We will begin by building and deploying a model on Watson Visual Recognition. We will focus on the key benefits of the service, including the ability of anyone with minimal coding experience to be able to train and deploy a computer vision model to the cloud. We will then demonstrate how easy it can be to integrate the model in any web-enabled application through a demo web application. Once this has been completed, we will give a soft introduction to Watson Machine Learning, including how to choose development environments, setting up a Jupyter notebook (https://jupyter.org/), and go over some prepared code snippets to train and analyze a model fully on the cloud. [We will then demonstrate how we can export the model and use it in our applications.In the second half of the workshop, we will demonstrate detecting and labeling objects within an image using PowerAI Vision object detection (https://github.com/IBM/powerai-vision-object-detection), based on customized training. Instead of writing code to train, deploy, and test the new model, we will only need to upload the images, and label the objects in the provided application. Once the model is deployed, we will use the PowerAI Vision user interface (UI) to test it. We will also use our application as a Representational State Transfer (REST) client to locate and count objects in an image using the provided REST API endpoint. At the end of the workshop we will briefly introduce Model Asset Exchange, we will demonstrate how to find a visual recognition model on MAX, deploy it as a microservice and test it.In summary, we will introduce some visual recognition services provided by IBM in this workshop. We together will develop an image classification model using Watson Visual Recognition service with Watson Studio. We also consume a visual recognition service from a client side. Then we discuss the features of PowerAI Vision and demonstrate object detection in PowerAI Vision. Finally, we introduce Model Asset Exchange.",
    "author": [
      {
        "family": "Ahmed",
        "given": "Imtihan"
      },
      {
        "family": "House",
        "given": "Rachael"
      },
      {
        "family": "Deilma",
        "given": "Neil"
      },
      {
        "family": "Luo",
        "given": "Li"
      }
    ],
    "collection-title": "CASCON ’19",
    "container-title": "Proceedings of the 29th annual international conference on computer science and software engineering",
    "id": "10.5555/3370272.3370324",
    "issued": {
      "date-parts": [
        [
          2019
        ]
      ]
    },
    "keyword": "watson studio, visual recognition, powerai vision, model asset exchange, machine learning, deep learning, artificial intelligence, IBM cloud, IBM Watson visual recognition",
    "page": "376-377",
    "publisher": "IBM Corp.",
    "publisher-place": "USA",
    "title": "Custom visual recognition model with watson studio",
    "type": "paper-conference"
  },
  {
    "ISBN": "0321116208",
    "abstract": "From the Book: As a fairly public figure in the Windows developer community, I often get asked if I think that .NET is going to take off. I always answer the same thing; its not a matter of if, its a matter of when. Microsofts .NET Framework has so many benefits that even as a grizzled old C++Win32 guy, I wasnt able to resist the siren song of a managed development environment. Its ironic that the temporary dip in the economy has caused folks to avoid anything new just when .NET comes along to deliver significant reductions in time to market and cost while simultaneously increasing code quality. The organizations that have already adopted .NET know that its going to have a long and happy life, especially as it gets pushed further and further into Microsofts own plans for the future of the Windows platform, both on the server and on the client. The primary server-side technology in .NET is ASP.NET, which provides the infrastructure needed to build web sites and web services. ASP.NET provides the reach to deploy web sites to anyone by aiming at the baseline of features provided by the middle generation web browsers. To provide the highest level of functionality possible, ASP.NET does most of the work on the server-side, leaving the client-side HTML as a thin wrapper to trigger server-side requests for new pages of data. The server-side handles practically everything, from data manipulation to user preferences to the rendering of simple things like menus and toolbars. This model provides the greatest availability across operating systems and browsers. If, on the other hand, your targeted customers are Windows users, an HTML-based experience limits the users to alowest-common denominator approach that is unnecessary. In fact, in an attempt to provide a richer client-side experience, many organizations that know theyre targeting Windows users require specific versions of Microsofts Internet Explorer (IE) web browser. However, as soon as that happens, IE becomes less of a browser and more of an HTML-based application runtime. And for that purpose, the HTML object model is fairly primitive, often requiring a lot of work to do things that are normally simple (like keeping track of a users session state). If youre going to be targeting Windows users, the .NET Framework provides a much richer set of objects for building interactive user interfaces. This brings me to the subject of this book: Windows Forms (WinForms). WinForms is the face of .NET on the client, providing a forms-based development environment meant to provide the best of the UI object models that have come before it. In addition, it provides one feature that no Windows-based development framework has provided to date - the deployment features of HTML-based web applications. The ability to combine the richness of Windows applications with the deployment of web applications signals a completely new world for Windows developers; one that makes me more than happy to give up the mess of unmanaged code. Audience When writing this book, I had two target audiences in mind. I wanted to provide real-world WinForms coverage for both the programmer that had already programmed in .NET as well as for the programmer that hadnt. Towards that end, I do briefly introduce core .NET topics as they come up. However, the .NET Framework itself is a large area that this book doesnt pretend to cover completely. Instead, when I think more information would be useful to the reader, I reference another work that provides the full details. In particular, I find that Ive referenced Essential .NET, by Don Box, with Chris Sells, a great deal, making it a good companion to this book. In this same category, I can also recommend Pragmatic ADO.NET, by Shawn Wildermuth, Advanced .NET Remoting, by Ingo Rammer, .NET Web Services, by Keith Ballinger and Applied Microsoft .NET Framework Programming, by Jeffrey Richter. Two core .NET topics are of special importance to WinForms programmers and I cover them in more detail in Appendix B: Delegates &amp; Events and Appendix C: Serialization Basics. The coverage of delegates and events is particularly important if youre new to .NET, although I dont recommend diving into that topic until youve got a WinForms-specific frame of reference (which is provided about 13rd of the way through Chapter 1: Hello, Windows Forms). Id like to provide one other note for potential readers. Many years ago, I wrote my first five-day training course. The topic was Windows 95 and included a few hours of coverage on the new controls; what they looked like, what their properties, methods and events were and how to program against them. Those hours seemed to take days for both me and for the students. The details of a particular control are only interesting when youre putting that control to use and when that time comes, the control-specific documentation and IntelliSense do a marvelous job of giving you the information you need. Towards that end, this book covers none of the standard controls completely. Instead, as each control is interesting the context of the current topic, like the DataGrid control in Chapter 13: Data Binding &amp; Data Grids, that control is covered appropriately. Also, Chapter 8: Controls and Chapter 9: Design-Time Integration introduces the broad range of categories of controls that WinForms provides, including the category of non-visual controls called components in .NET. Finally, to give you a visual to go with all of the controls and components and to introduce you to the major functionality of each of them, Appendix D: Standard WinForms Components &amp; Controls provides a list of the standard controls and components. I wouldnt think to waste your time by attempting to be more thorough that that reference documentation that comes with the .NET Framework SDK and Visual Studio .NET. Instead, this book focuses on the real-world scenarios that arent already covered in detail elsewhere. Conventions For those of you that have decided to take the plunge with this book, Id like to thank you for your faith and express my hope that I live up to in. To aid you in reading the following text, I want to let you in on some conventions I use in my writing. First and foremost, the wonderful thing about WinForms is how visual it is, which is why I use a lot of figures to illustrate its features. Some of those pictures really need to be color to make the point, so be sure to check the color pages at the center of this book for those figures. As useful as figures are, I think primarily in code. Code will be shown in mono-faced type: System.Console.WriteLine(Hello, WinForms.); Console application activation will also be shown in mono-faced type: C:&gt; csc.exe hello.cs When a part of a code snippet or a command line activation is of particular interest, I mark it in bold and often provide a comment: Notice the use of the .NET System namespaceSystem.Console.WriteLine(Hello, WinForms.); When I want to direct your attention to a piece of code even more fully, Ill replace superfluous code with ellipses: class MyForm : System.Windows.Forms.Form  ... fields private void MyForm_Load(object sender, System.ComponentModel.EventArgs e)  MessageBox.Show(Hello from MyForm);  Further, to make the printed code more readable, Ill often drop namespaces and protection keywords when they dont provide additional information: Shortened System.Windows.Forms.Form base class class MyForm : Form  ... fields Removed private specifier and System.ComponentModel namespace void MyForm_Load(object sender, EventArgs e)  MessageBox.Show(Hello from MyForm);  When showing .NET attributes, I use their full name: SerializableAttributeclass MyCustomType ... Some languages, like C#, allow the Attribute suffix to be dropped for convenience, but that makes it hard to find the details of the attribute class in the online documentation. Also, I sometimes take error checking out of the printed code for clarity, but try to leave it in the sample code that comes with this book.In the prose itself, I often put a word or phrase in italics to indicate a new term that Im about to define. As an example of this kind of term and its definition, hegemony is preponderant influence or authority, as well as a useful business practice. Finally, I often mention keyboard shortcuts because I find them convenient. The ones I mention are the default Visual Studio Developer key bindings. If youre not using those key bindings, youll need to map the keyboard shortcuts to your own settings.",
    "author": [
      {
        "family": "Sells"
      }
    ],
    "id": "10.5555/861497",
    "issued": {
      "date-parts": [
        [
          2003
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Windows forms programming in c#",
    "type": "book"
  },
  {
    "DOI": "10.1145/3545947.3573288",
    "ISBN": "9781450394338",
    "URL": "https://doi.org/10.1145/3545947.3573288",
    "abstract": "Quantum Machine Learning (QML) is an emerging field that involves training a parameterized quantum circuit in order to analyze quantum or classical datasets. QML has generated great excitement in recent years with the aim to develop Machine Learning (ML) models specifically designed for quantum computers that would allow exponential advantage in making accurate predictions on quantum data. Cybersecurity threats are evolving with the advancement of computing technology concurrently. Utilizing the concept of proactive prevention and early detection of security vulnerabilities may provide advantages to mitigate cybersecurity risk. In this paper, we adopt the Quantum Neural Network (QNN), a subset of QML for malware classification and detection. We use Google Collab as IDE and utilize an open-source ClaMP Dataset from Kaggle. We demonstrate our repository to classify and detect malware using a quantum neural network (QNN) and the result indicates that we achieved an accuracy of 94",
    "author": [
      {
        "family": "Hossain Faruk",
        "given": "Md Jobair"
      }
    ],
    "collection-title": "SIGCSE 2023",
    "container-title": "Proceedings of the 54th ACM technical symposium on computer science education v. 2",
    "id": "10.1145/3545947.3573288",
    "issued": {
      "date-parts": [
        [
          2023
        ]
      ]
    },
    "keyword": "quantum neural network, quantum machine learning, quantum computing, malware classification and detection, cybersecurity",
    "page": "1235",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Malware classification and detection using quantum neural network (QNN)",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/3626252.3630913",
    "ISBN": "9798400704239",
    "URL": "https://doi.org/10.1145/3626252.3630913",
    "abstract": "In this paper, we present an education-focused Python IDE and runtime library which can run entirely in desktop, laptop, tablet, and mobile device web browsers. Our solution provides features useful for an engaging CS1 course, and eliminates the need for a server-based runtime. We describe a new, open source, methodology for running interactive Python entirely in the browser by solving the \"WebAssembly blocking problem,\" a core technical challenge to a web-based Python solution.Because our method enables Python entirely in the browser, it unlocks many new features. For example, students can share their code with others, without incurring extra costs to the instructors or institutions. Other features include line by line code highlighting as a program executes, highly intuitive interactive graphics, mouse and touch integration, and use of a wide selection of Python modules such as Numpy and Pandas. Currently, our IDE has been used in 5 classes, covering more than 10,000 students and teachers, with over 350,000 projects created. We found that students and instructors appreciated the variety of tools and abilities the IDE made possible. We benchmark the performance of running code with our method against other online Python solutions and we discuss the benefits and additional possibilities that our method allows, such as mobile device and/or offline code execution. We provide full free public access to our IDE and open source the core libraries which enable the conversion of student written Python to WebAssembly.",
    "author": [
      {
        "family": "Jefferson",
        "given": "Thomas"
      },
      {
        "family": "Gregg",
        "given": "Chris"
      },
      {
        "family": "Piech",
        "given": "Chris"
      }
    ],
    "collection-title": "SIGCSE 2024",
    "container-title": "Proceedings of the 55th ACM technical symposium on computer science education v. 1",
    "id": "10.1145/3626252.3630913",
    "issued": {
      "date-parts": [
        [
          2024
        ]
      ]
    },
    "keyword": "cs1, ide, integrated development environment, mobile, python, web browser, webassembly",
    "page": "583-589",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "PyodideU: Unlocking python entirely in a browser for CS1",
    "title-short": "PyodideU",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130418048",
    "abstract": "From the Book: Preface Microsofts .NET is a revolutionary advance in programming technology that greatly simplifies application development. In addition to providing support for traditional desktop Windows applications, it provides tremendous support for Web-based services. Microsofts popular Visual Basic programming language has been upgraded to take advantage of the new .NET features. Visual Basic.NET, or simply VB.NET, has become a full object-oriented programming language with capabilities comparable to C++, Java, and Microsofts new language C# (pronounced C sharp). This book is a practical introduction to programming in VB.NET and using services provided by .NET. It emphasizes the VB.NET language and is part of The Integrated .NET Series from Object Innovations and Prentice Hall PTR. An important thrust of this book is to teach VB.NET programming from an object-oriented perspective. This book introduces object-oriented concepts early and includes a case study on object-oriented programming. The book is intended to be fully accessible to programmers who do not already have a background in object-oriented programming. Previous knowledge of Visual Basic is not essential. The book may also be read by more experienced programmers who desire a simple introduction to VB.NET with many example programs. Although designed for working professionals, the book includes enough detail, careful explanations, and sample programs so that it can be useful as a college textbook. VB.NET is now a fully object-oriented language. It supports classes, interfaces, interface and implementation inheritance, and polymorphism. It is also highly integrated with the .NETFramework. These features make VB.NET a compelling language for developing object-oriented and component-based systems. This book provides thorough coverage of all these features. One of the strengths of Visual Basic, and the reason it has enjoyed such widespread use, is the ease with which Windows application can be developed. Microsoft has revamped the way that Windows applications are built under .NET. Windows Forms, used by .NET languages, represents a class library that brings uniformity to the components of a Windows application. The book includes substantial coverage of using Windows Forms in VB.NET. VB.NET, as a language, is elegant and powerful. However, to fully utilize its capabilities, you must have a good understanding of how it works with the .NET Framework. The book examines several important interactions between VB.NET and the .NET Framework, and includes an introduction to major .NET classes for collections, files, databases, and threads. Organization of This Book This book is organized into five major parts and is structured to make it easy for you to isolate what you most need to know. Part 1, which everyone should read, begins with an introduction to the .NET Framework. The second chapter provides a short introduction to hands-on programming using VB.NET, so that you can start writing code on .NET right away. The third chapter introduces Visual Studio.NET. It is the latest version of Microsofts popular Visual Studio development environment and has many features that make application development easier and more pleasant. These chapters will equip you to use Visual Studio throughout the rest of the book. Part 2 covers the core features of VB.NET. If you know Visual Basic, you will have a definite leg up in learning VB.NET, and you can quickly skim this section, paying attention to the information in the sidebars. Sidebars alert you to either (1) the first time a concept new to VB.NET is introduced, or (2) a significant change to the VB.NET language that experienced VB programmers should note. If you are not familiar with Visual Basic, this section is for you. It will quickly bring you up to speed on the core topics of data types, operators, and control structures. Part 3 examines the object-oriented features of VB.NET. This language is now fully object-oriented, which is one of the most significant improvements in VB.NET. In this part, we begin by examine how classes are built. Subsequent chapters discuss implementation and interface inheritance. These topics are covered gradually and thoroughly, making this part of the book accessible to readers without previous object-oriented experience. Part 4 covers Windows programming in VB.NET. Microsoft has adopted a new approach to developing Windows applications that will be readily apparent to previous VB programmers. Systematic coverage is presented on the core topics in Windows Forms, including form design, controls, events, menus, toolbars, and dialogs. The rich variety of useful controls provided by Windows Forms is covered in detail. Part 5 explores the relationships between VB.NET and the .NET Framework. .NET collection classes are introduced. We also examine the .NET interfaces that classes must implement for fundamental operations such as copying and comparing objects. Delegates, a .NET callback mechanism, are discussed. We also introduce both VB.NET file IO and database programming using ADO.NET. We look at multiple thread programming and attributes. Attributes are powerful in .NET, enabling the programmer to accomplish tasks declaratively, even while writing very little code. You can implement custom attributes in VB.NET. You can read information about custom attributes, or any other metadata, by a mechanism known as reflection. The book concludes with an introduction to components and assemblies. Sample Programs The only way to really learn a programming language is to read and write many, many programs. This book provides many programs that illustrate features of VB.NET. The programs are clearly labeled in the text, and they can all be found in the software distribution that accompanies this book, available through our associated Web site. Also, a case study illustrates many features of VB.NET working together in combination, as they would in a practical application. We make a special point of demonstrating the object-oriented features of VB.NET. If you are new to OO, reading the case study is a must! The sample programs are provided in a self-extracting file. When expanded, a directory structure is created, rooted in C:OIIntroVb. The sample programs are in directories Chap01, Chap02, and so on. All the samples for a given chapter are in individual folders within the chapter directories. The names of the folders are clearly identified in the text. An icon in the margin alerts you to a code example. The case study is in a directory called CaseStudy, at the same level as the chapter directories. This book is part of The Integrated .NET Series. The sample programs for other books in the series are located in their own directories beneath OI, so all the .NET examples from all books in the series will be located in a common area as you install them. Web SiteHeres the Web site for the book series: A link is provided at that Web site for downloading the sample programs for this book. &lt;",
    "author": [
      {
        "family": "Wyatt",
        "given": "Dana L."
      },
      {
        "family": "Oberg",
        "given": "Robert J."
      }
    ],
    "id": "10.5555/579999",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Prentice Hall Professional Technical Reference",
    "title": "Introduction to programming visual basic using .net",
    "type": "book"
  },
  {
    "DOI": "10.1109/ICRA48506.2021.9561366",
    "URL": "https://doi.org/10.1109/ICRA48506.2021.9561366",
    "abstract": "For 25 years the Robotics Toolbox for MATLAB&lt;sup&gt;®&lt;/sup&gt; has been used for teaching and research worldwide. This paper describes its successor – the Robotics Toolbox for Python. More than just a port, it takes advantage of popular open-source packages and resources to provide platform portability, fast browser-based 3D graphics, quality documentation, fast numerical and symbolic operations, powerful IDEs, shareable and web-browseable notebooks all powered by GitHub and the open-source community. The new Toolbox provides well-known functionality for spatial mathematics (homogeneous transformations, quaternions, triple angles and twists), trajectories, kinematics (zeroth to second order), dynamics and a rich assortment of robot models. In addition, we’ve taken the opportunity to add new capabilities such as branched mechanisms, collision checking, URDF import, and interfaces to ROS. With familiar, simple yet powerful functions; the clarity of Python syntax; but without the complexity of ROS; users from beginner to advanced will find this a powerful open-source toolset for ongoing robotics education and research.",
    "author": [
      {
        "family": "Corke",
        "given": "Peter"
      },
      {
        "family": "Haviland",
        "given": "Jesse"
      }
    ],
    "container-title": "2021 IEEE international conference on robotics and automation (ICRA)",
    "id": "10.1109/ICRA48506.2021.9561366",
    "issued": {
      "date-parts": [
        [
          2021
        ]
      ]
    },
    "page": "11357-11363",
    "publisher": "IEEE Press",
    "publisher-place": "Xi’an, China",
    "title": "Not your grandmother’s toolbox – the robotics toolbox reinvented for python",
    "type": "paper-conference"
  },
  {
    "ISBN": "9783981080131",
    "abstract": "Welcome to the DATE 08 Conference Proceedings. DATE combines the world’s favourite electronic systems design conference and Europe’s leading international exhibition for electronic design, automation and test, from system level hardware and software implementation right down to integrated circuit design.The DATE 08 event features a technical program with 77 sessions covering the latest developments in system design and embedded software, IC design/test methodologies and EDA tools, together with an exhibition with the leading EDA, silicon and IP providers showing their new products and services. Challenges that you all face or soon will face in your daily practice are the increasing design complexity of highly integrated systems, the introduction of reconfigurability and embedded software, and the control of power and variability in nanometer IC designs. All these issues will be addressed in this year’s DATE event.For the 11th successive year DATE has prepared an exciting technical programme, with the help of the more than 400 members of the Technical Programme Committee, who dedicated their time to thoroughly review the 839 submissions in 37 topics, ranging from system level down to circuit design and covering all the most relevant application domains. The submissions are organised in 4 major areas:D — Design Methods, Tools, Algorithms and LanguagesA — Application DesignT — Test Methods, Tools and Innovative ExperiencesE — Embedded SoftwareAfter a thorough review and selection process (with an average of 5 reviews per paper), finally 198 regular papers were selected for presentation at the conference. Additionally, there are 46 Interactive Presentations that are organised in 5 IP sessions. Together with the invited special sessions (panels, embedded tutorials and hot topic sessions), this has resulted in a high-quality technical program. The technical program provides a wide but high-quality coverage of design, design automation and test topics, from the system level to the integrated circuit level. Compared with previous years, submissions in the Embedded Software track has increased by 50",
    "id": "10.1145/1403375",
    "issued": {
      "date-parts": [
        [
          2008
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "DATE ’08: Proceedings of the conference on design, automation and test in europe",
    "title-short": "DATE ’08",
    "type": "book"
  },
  {
    "ISBN": "0201703599",
    "abstract": "From the Book: XML: Its a cheese spread. No, its a floor wax. No, its two—two—two products in one! Or maybe its everything but the kitchen sink Say, did you hear the one about the XML Kitchen Sink Language (see http:blogspace.comxkitchensink) XML: What Its All About It has been said that XML, the Extensible Markup Language, will become the ASCII of the twenty-first century because it is rapidly becoming ubiquitous. XML is expected to have an impact on both the Web and application development comparable to that of Java and JavaScript because it has opened up a wide variety of new capabilities and has been embraced by so many sectors of human endeavor. XML is a metalanguage—a syntax for describing other languages. These languages span diverse vertical industries including accounting, advertising, aerospace, agriculture, astronomy, automotive products, biology, chemistry, database management, e-commerceEDI, education, financial institutions, health care, human resources, mathematics, publishing, real estate, software programs, supply chain management, and many more (for the many more, see http: ). In one sense, XML is really a very trivial thing—just a markup syntax for describing structured text using angle brackets. But in another sense, XML is a basic building block—an enabling technology that makes it possible to develop more complex, more interesting, and more powerful tools. In the Web arena, XML is facilitating exciting improvements such as user-controllable views and filtering of information, creation oftruly device-independent content that can be re-purposed for vastly different devices, highly focused searching based on element hierarchies, and more sophisticated and flexible linking mechanisms. In the business and application arena, XML makes it easier to deliver filtered content from databases, to more readily share data between applications and between companies, and to exchange EDI messages that describe complex transactions. In the scientific arena, XML is a natural fit for describing complex datasets, models, control of instruments, images, chemical compounds, and much more. Just as Java made data processing platform-independent, XML has done the same for data, making the exchange of information much easier than ever before. But, no, XML is not the kitchen sink; it is not the solution to all of the worlds problems in one tidy package; nor is it the solution to all your computer needs either, at least not alone. Rather, XML is a tool, or more accurately, a set of tools from the same toolbox. That toolbox is the XML family of specifications. This book will help you see what XML can and cannot do by describing how to use each tool. Although XML shares a number of concepts with its ancestor, SGML (Standard Generalized Markup Language), XML is said to yield 80 percent of the benefits of SGML, but with only 20 percent of the complexity. It is precisely this 8020 rule that has excited countless companies and developers, encouraging them to support the efforts of the World Wide Web Consortium (W3C) in the development of XML. A few of the more than 500 companies and organizations that actively support XML development as members of the W3C include IBM, Sun, Microsoft, Oracle, Commerce One, and NASA. Audience: Who Should Read This Book The book is intended for Web developers, which includes programmers, content writers, and designers. Depending on your background and interests, some chapters may be more relevant to you than others. Its intended for those who may be familiar with particular aspects of XML but who have not been formally exposed to all of the major W3C specifications, as well as those who have never dealt with XML before. Later in this preface, I provide a roadmap to help orient you. Ive assumed that most readers are familiar with HTML elements and syntax, although the XML and DTD syntax discussions in Chapters 3 and 4 pretty much cover the concepts of elements, attributes, types, entities, and content that carry over from HTML to XML. In other words, you can get by without knowing HTML, except the XHTML chapter, which will make much more sense to you if you do. For those who would like to brush up on HTML, see For Further Exploration: HTML and Java at the end of this preface. Some examples require programming knowledge, but for most examples, anyone with general Web development skills will find them beneficial. Generally, scope and breadth of treatment is favored over depth. On the other hand, some readers will find that the depth is more than they expected, but they should still be able to tread the water. My intent in writing this book was to cover a number of XML-related technologies in varying degrees of detail. Id like to make it clear that although there are three chapters containing Java examples, this is not a book about Java and XML. You dont need a Java background for the vast majority of whats in this book. Although I do assume the Windows operating system, this is not a statement of preference. My formative years were spent on UNIX (I still use UNIX utilities to maintain a ski club site) at the office and a Mac at home. Rather, since Windows tends to be somewhat ubiquitous, it seems appropriate to show Windows command lines and mention some Windows-only tools. UNIX and Mac users are encouraged to share their experiences with fellow readers via the books Web site. Personally, I have found cygwin—a UNIX environment for Windows developed by Red Hat—to be very handy (see http:cygwin.com). Whats Special About This Book There are several features that contribute to making this book an invaluable resource for anyone beginning to plunge into the somewhat turbulent seas of XML. XML Family of Specifications Big Picture —Since early 1998, Ive periodically updated a diagram I call The Big Picture of the XML Family of Specifications. This unique diagram (front inside cover) depicts virtually all of the key W3C efforts related to XML, with colors to indicate each specifications status (maturity); it includes related non-W3C efforts as well. Physical positioning denotes a relationship among neighboring specifications, as explained in Chapter 2. Best of all, the Big Picture diagram appears as an imagemap on the CD-ROM and on this books Web site, possibly as a more up-to-date version. The Big Picture imagemap on the Web site expands acronyms as your mouse hovers over a term. Clicking on the acronym or name connects you instantly to the actual specification or, in some cases, a collection of documents relating to that specification. History Timeline —A detailed History of the Web and XML in timeline form—the product of a considerable amount of research—is broken down into three time periods in Chapter 1, which should be interesting to many readers. Historical perspectives are also presented for particular specifications in their own chapters. A rather unique pullout at the back of the book shows, in bar chart format, the gestation periods of all of the XML specifications in this book, giving you a visual picture of what developments occurred in sequence andor in tandem. Coverage —Ive selected what are generally considered to be the most significant XML-related specifications from the W3C: XMLDTDs, XML Namespaces, XML Schema, the DOM, CSS, XSLT, XPath, XSLFO, XLink, XPointer, XHTML, and RDF. Several of the less frequently discussed specifications, such as XML Infoset, Canonical XML, XML Base, and XML Inclusions, are also covered. In addition, Ive included four topics that are not under the purview of the W3C: RDDL, SAX, JDOM, and JAXP. The focus is on breadth rather than depth of coverage because if you have a general understanding of a lot of XML topics, you can better appreciate which are most relevant to your needs and you can drill down to the details by following the links I provide. The hope is that as you become more familiar with each of the topics I present, youll know which areas youll want to explore by buying more specialized Addison-Wesley or Prentice Hall books (e.g., about XSLT, XML with Java, or XHTML). Ive tried hard to make the information current and have spent a good bit of time in the final months polishing and updating details here and there. All topics are as up-to-date as possible, except where noted otherwise. For Further Exploration —Each chapter ends with a section called For Further Exploration, which presents quite a few links that serve not only as my bibliography, but also points to resources that contain more details than what can be provided here without killing way more than my fair share of trees. Links are provided to the specifications themselves, to articles that explain the specs in more everyday language than the precision required for formal specifications, and to articles describing subtleties or nuances of the specs. Links to tutorials, books, software, special references, and so on are also supplied. My intention is that readers will use the links, so they all appear in HTML form on the books CD. Professors may wish to consider some of these links for students research assignments. Tables —Im a big fan of the use of tables. When I read a technical book, I seldom read it word for word, cover to cover. Often I want to locate some particular detail pretty quickly, so I look it up in the table of contents or index—I dont want to have to skim through paragraph after paragraph to find the little tidbit I need. Therefore, I feel that tables will help you do the same thing, maximizing the use of your time. The List of Tables is something with which you might want to familiarize yourself—let a table be your friend. CD-ROM —The CD that accompanies the book contains all the sample code presented in the text, as well as most of the software I used while writing this book, including the following: - Code Examples—every example that appears as a code listing plus a number of variations - XML Environment—batch files to simplify using XML with Java on Windows operation systems - For Further Exploration—all links from the end of each chapter - Big Picture of XML Family of Specifications Imagemap—links to more than 60 specifications, including many not covered in this book (see Chapter 2) - W3C XML Specifications in PDF Form—every W3C specification discussed in this book is available (unedited) for offline reading(hours and hours of fun for the whole family) - Glossary of terms - Chapter 12, Practical Formatting Using XSLFO by G. Ken Holman, in HTML format with two useful appendices which arent included in the printed book - Freeware and evaluation copies of commercial software (XMLDTDXML Schema editors, validators, parsers, XSLT processors, and more) Web Site —The books main Web site is hosted by Web Developers Virtual Library, an Internet.com site. I maintain the extensive XML section of WDVL.com. The books URL there is http:WDVL.Internet.comAuthoringLanguagesXMLXML-Family . There youll find all the links from the For Further Exploration sections organized by chapter, as well as the online version of the Big Picture imagemap, and of course the inevitable corrections to the text. While this material appears on the CD-ROM, the Web site versions may be more up-to-date. The Web site will be updated periodically; you can register to receive e-mail when the site is updated, if you wish. Organization and Roadmap: How You Should Read This BookThis book is divided into five conceptual parts. With the exception of a few chapters in Part I, it is not absolutely necessary to read this book chapter by chapter (and Ill tell you right up front: the butler did it). Chapter 1, History of the Web and XML, provides an interesting historical perspective of the development of XML, but some readers may prefer to skip it entirely, or at least defer reading it until theyve completed other chapters or find themselves on a long, boring plane flight with neither good movies nor readable magazines. Readers without a Java background may wish to gloss over the three chapters that contain Java examples, instead focusing on the concepts that are discussed in these chapters. The following describes the books organization and suggested reading emphasis. Introduction: History of the Web and XML —As mentioned, Chapter 1 provides an historical perspective. Its divided into three eras: Ancient History (1945 to 1984), Medieval History (1986 to 1994), and Modern History: From HTML to XML (1994 to 2001). Part I: Fundamental XML Concepts and Syntax —This part introduces XML Syntax, DTD Syntax, the XML Infoset abstraction, Canonical XML, Namespaces, RDDL (Resource Directory Description Language), and XML Schema, corresponding to Chapters 2 through 6, intended to be read in sequence. All readers should read these chapters, although if you wont be developing your own vocabularies, you might be able to skim the DTD and XML Schema chapters (4 and 6, respectively). Although XML Schema is expected to replace the use of DTDs in many applications, your own project needs may dictate sticking with DTDs, in which case you could skip the XML Schema chapter, although I still recommend that you read the sections in Chapters 4 and 6 that highlight DTD limitations and XML Schema advantages. If you are tempted to skip the chapter on Infoset, Canonical XML, Namespaces and RDDL (Chapter 5), be sure to at least read the Namespaces section because this concept is central to many XML specifications. All chapters following 5 assume you are familiar with XML Namespaces. Although RDDL is a recent grassroots effort as I write this, its bound to have gathered a lot of momentum by the time you read this. Part II: Parsing and Programming APIs —This part presents SAX (Simple API for XML), DOM (Document Object Model), JAXP (Java API for XML Processing) and JDOM—Chapters 7 through 9. All of these are application programming interfaces (APIs) to parsing and manipulating XML documents. This is the part of the book with the most Java examples. While all readers are encouraged to read the initial sections of the SAX and DOM chapters, non-Java developers can completely skip Chapter 9, which covers JAXP and JDOM, as well as the code examples in the SAX and DOM chapters. However, be sure to read the explanation of parsing at the beginning of Chapter 7 and study the comparison, SAX vs. DOM vs. JDOM vs. JAXP—Who Wins at the end of Chapter 9. Part III: Displaying and Transforming XML —This part covers CSS (Cascading Style Sheets), XSLT (Extensible Stylesheet Language Transformations), XPath (XML Path Language), XSLFO (Extensible Stylesheet Language Formatting Objects), presented in Chapters 10 to 12. Of these, the lengthy Chapter 11 on XSLT and XPath is essential reading for anyone who wishes to display or transform XML into other formats (including HTML, XHTML, text, or other kinds of XML, particularly in e-commerce applications). Chapter 10 on CSS is more important if your XML display needs are more modest and your transformation needs are nil. The chapter can be skimmed for XML hooks if you are already familiar with CSS. Chapter 12 concerns XSL Formatting Objects, sort of the next generation CSS for desktop publishing quality layout, PDF, and targeting your output for different devices. The XSLFO chapter was contributed by noted XSL expert and instructor, G. Ken Holman, chair of the OASIS XSLTXPath Conformance Technical Committee (see his home page at http: ). Part IV: Related Core XML Specifications —This part focuses on XLink (XML Link Language) and XPointer (XML Pointer Language)—Chapters 13 and 14. Most developers will benefit from reading about XLink and XPointer because they greatly extend the notion of linking and fragment access beyond what is possible in HTML 4.01, including one-to-many links, multidirectional links, links stored external to the documents, and linking to specific elements without hooks being provided by the original author. Part V: Specialized XML Vocabularies —This part presents two unrelated XML-based languages: XHTML (Extensible HyperText Markup Language) in Chapter 15 and RDF (Resource Description Framework) in Chapter 16. Please consider Chapter 15 on XHTML as essential reading for all developers. As youll see, XHTML is its own nuclear family of specifications that is currently replacing HTML, especially in the increasingly popular world of handheld devices, voice browsers, and other alternative Web interfaces. RDF should be of particular interest to developers and scientists with an interest in metadata (data about data), site descriptions, catalogs, intelligent software agents, and so on. RDF attempts to add semantics to the Web; related concepts are the recent XML Topic Maps (XTM) effort and the older Dublin Core work. The RDF chapter was contributed by Ora Lassila, co-author of the Resource Description Framework Model and Syntax Specification for the W3C and contributor to the RDF Core Working Group and Web-Ontology (WebOnt) Working Group (see his home page at http: ). This book does not cover XQuery, an XML Query language, nor Scalable Vector Graphics (SVG), except in passing. XQuery was still very much in flux at the time of this writing. As for SVG, with a more than 500-page specification, I felt I could not do the topic justice in the time I had left after writing the rest of this book. Well, theres always the Second Edition, I guess. What You Need to Get the Most Out of This Book All code examples have been developed on a Dell Dimension XPS R450 PC (a paltry 450 MHz) running Windows 98. DOS .bat files are provided to help you configure your environment so that you can run the examples on your own. UNIX developers should be able to study the .bat files and set environment variables accordingly, such as CLASSPATH for Java and variables that point to the location of XML parsers and XSLT processors. Im afraid I cant say much to Mac developers at this point (sadly, my own ancient PowerMac 710080 hasnt been used for the better part of three years), but if you contact me via the Web site and want me to share your experiences with others, I will gladly do so. Ill give you credit and a free copy of this book—it makes a great gift and keeps its flavor longer than fruitcake. XML and DTD examples are plain text, so they are viewable in their raw form on all platforms using any text editor. To process XML in a browser, however, youll need the most current generation of browsers, such as Netscape 6.x, Internet Explorer 5.5 or 6.x, Amaya 5.x, or Opera 5.x or higher. If youre not the type of reader who has to try out every example in his or her own browser, then perhaps the many screenshots in this book will be sufficient. Evaluation copies of commercial XML, DTD and XML Schema editors appear on the CD that accompanies this book; XML parsers and XSLT processors also appear there. The CD also contains a page of links to the current versions of all provided software, as well as links to software that couldnt be included on the CD for a variety of reasons. The Java code examples should compile and run fine with either JDK 1.2.x or 1.3.x, also known by other confusing names and numbers such as Java 2 SDK, J2EE, and J2SE—or their equivalent as provided with your favorite Java IDE (Integrated Development Environment). This book does not attempt to teach Java; on the other hand, you really dont need to know Java to follow most of the discussions. Interested readers who desire a better Java background should refer to the key Java resources listed in For Further Exploration: HTML and Java that follows. I truly hope you enjoy this book and find the XML family of specifications as fascinating as I do. Conventions Used in This Book The typographic conventions used in this book are as follows: Glosssary terms look like this where they are defined: node-set Code excerpts, code listings, command lines, filenames, element names, and attribute names look like this: &lt;xsl:template match=CD&gt; or collection8.xml. Quotations (material excerpted from another source) is indented both left and right and is set in a smaller type size. Notes, important information or things to watch out for, are set off by an arrow in the margin and rules above and below their text. For Further Exploration: HTML and JavaDave Raggetts Getting Started with HTML http: Web Design Groups HTML 4.0 Reference http: Googles HTML Tutorials category http:directory.google.comTopComputersData_FormatsMarkup_LanguagesHTMLTutorials Java Technology Products and APIs http:java.sun.comproducts The Java Tutorial http:java.sun.comdocsbookstutorial Google Web Directory: Java includes a Books category http:directory.google.comTopComputersProgrammingLanguagesJava Google Web Directory: Java IDEs http:directory.google.comTopComputersProgrammingLanguagesJavaDevelopment_ToolsIntegrated_Development_Environments Cafe au Lait Java FAQs, News, and Resources http:",
    "author": [
      {
        "family": "Sall",
        "given": "Kenneth B."
      }
    ],
    "id": "10.5555/515385",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Xml family of specifications",
    "type": "book"
  },
  {
    "ISBN": "0130911119",
    "abstract": "From the Book: Introducing BEA WebLogic Application Servers J2EE Applications and BEA WebLogic Server addresses the need for a practical, state-of-the art book on developing enterprise applications with the market-leading BEA WebLogic Java application servers. The BEA WebLogic family of application servers includes BEA WebLogic Server, BEA WebLogic Enterprise, BEA WebLogic Commerce Server, and BEA WebLogic Personalization Server. This book focuses on BEA WebLogic Server. BEA WebLogic Server (WebLogic Server) is a widely used Java application server for constructing multi-tier, secure, large-scale, distributed Web applications for e-commerce and other high-volume applications. Distributed applications require sophisticated, fast, fault-tolerant networked communication among application tiers and components. In a client-server application, client programs send requests and receive responses from a server system. With the advent of middleware and the Web revolution, many enterprise sites have moved from client-server application environments to n-tierusually, 3- or 4-tierarchitectures. In multi-level architectures, efficient network connectivity is paramount. In a multi-tier application, WebLogic Server provides the framework for developing and deploying server-side business logic, and supports a distributed programming model that hides the complexity of distributed programming from the application writer. The programming model provided by J2EE and the WebLogic Server extensions provides some level of transparency, so that writing a distributed application is similar to writing a local application. Although the programmer must still be concerned about error handling and efficiency, WebLogic Server’s implementation of the J2EE services provides an excellent development and execution environment for an enterprise-level distributed application. An application server such as BEA WebLogic Server handles server-side business logic and the administration of a multi-client, distributed application that uses a variety of clients and servers. Giving the responsibility for business logic and traffic control to an application server has the following benefits: Efficiency: Web browser and application clients can share the same business logic, rather than having to deploy business rules with each instance of a client. Performance: Locating server-side business logic with or near resource-intensive modules such as data stores can improve performance. Manageability: System administration and security issues are easier to address when business logic is centralized in an application server. History of BEA’s WebLogic Server Division WebLogic, Inc. was founded in 1995–when Java, still a \"think tank\" project of Sun Microsystems, was code-named \"Oak.\" In 1998, WebLogic merged with BEA Systems, Inc., a major vendor of transaction monitors and other tools for creating and managing enterprise-scale distributed systems. The BEA WebLogic Server product is a part of the BEA E-Business Platform. From the beginning, the WebLogic Server developers determined to use only Java, and to focus on server-side technologies: server support and middleware management of multi-tier applications. Using off-the-shelf Java development tools (and general-purpose text-editing tools such as emacs), the WebLogic Server developers implemented APIs for each new Java standard feature that Sun specified. As a result, WebLogic Server has not only kept current with Java standards development but has also had the capability to influence emerging Java standards. BEA WebLogic Server was an early implementer of each emerging Java Enterprise standard, including Enterprise JavaBeans (EJB), Remote Method Invocation (RMI), servlets, the Java Naming and Directory Interface (JNDI), and Java Database Connectivity (JDBC) for Oracle, Informix, Sybase, and Microsoft SQL Server. Each of these technologies is explained and illustrated in the chapters that follow. In July 2000, the BEA Systems family of application servers successfully completed Sun Microsystems Java 2 Enterprise Edition (J2EE) certification, becoming the first independent company to achieve official J2EE certification. BEA WebLogic Server has won several industry awards, including: Best Java Application Server ( JavaPro , June 2000) Product Excellence and Productivity Award ( Software Development Magazine , March 2000) Java World Reader’s Choice Award for best e-commerce application server, 1999 Infoworld ’s Product of the Year, 1999 Java Developers Journal Editor’s Choice Award in 1998 and 1999 Why We Wrote This Book BEA WebLogic Server has a growing installed base that has been supported by training classes and extensive documentation, but there has been no comprehensive, practical coverage of full-scale application development on the WebLogic Server platform. This step-by-step book explains where to start, and how to put all the pieces together. Planning for deployment and selecting the technologies that you’ll use for each tier of the application is as important as laying down code. Target Audience J2EE Applications and BEA WebLogic Server is targeted at intermediate to professional-level Java programmers developing applications for the BEA WebLogic Server platform, the market leader among application servers. This book focuses on best practices for developing enterprise applications using the WebLogic Server APIs. The WebAuction application, a complete sample e-commerce application, is explained and developed as an example in Chapter 14. An accompanying CD-ROM includes all software and code needed to implement the sample application in your own environment. After reading this book, Java developers will possess the skills and knowledge required to develop scalable and robust applications on the WebLogic platform. This book is targeted at programmers who know basic Java on at least an intermediate level and would like to learn WebLogic Server. We assume that readers know about standard Java programming concepts such as exceptions and threads. However, we do not assume that readers know much about J2EE or application servers. Brief Overview of the Book J2EE Applications and BEA WebLogic Server contains both a descriptive narrative and examples for each major J2EE API, and a sample application that concludes the book. Using a step-by-step approach, the book introduces each major J2EE API and uses it to build a component of the WebAuction application, which supports an online auction site. Building the WebAuction application gives users the opportunity to explore significant areas of building a distributed Enterprise Java application, including: Overview of J2EE technologies (Chapter 2) Building presentation logic with servlets or Java Server Pages (JSPs); (Chapters 3 and 4) Establishing database connectivity and using transactions (Chapter 5) Using Remote Method Invocation, and the Naming and Directory Interface (Chapter 6) Using a message-oriented middleware layer to coordinate all the components and operations in your multi-tier, distributed WebAuction application (Chapter 7) Creating Enterprise Java Beans (Chapters 8-10) Integrating Internet mail (Chapter 11) Adding security (Chapter 12) Designing a distributed deployment (Chapter 13) Building and deploying the completed application (Chapter 14) Performing a capacity-planning exercise to assess the performance of the deployed application (Chapter 15) Chapter 1 presents a detailed overview of the book, with a roadmap and chapter summaries. Chapter 1 also lists system requirements and conventions. Chapter 2 surveys the J2EE technologies that are described in depth, with examples, in Chapters 3-12. About the Authors Michael Girdley is the Senior Product Manager for the BEA WebLogic Server, a role in which he acts as marketing liaison to over 200 engineers. An experienced application developer in Java, HTML, C, and C++, Michael is a co-author of Web Programming with Java (Sams-net Publishing, 1996) and Java Unleashed, Second Edition (Sams-net Publishing, 1997). Michael holds a bachelor’s degree in computer science with honors from Lafayette College. Rob Woollen is a Senior Software Engineer at BEA Systems. He is currently the lead developer for the WebLogic Server EJB Container. Before joining BEA, Rob worked on UNIX kernel networking for Hewlett-Packard. Rob holds a bachelor’s degree in computer science from Princeton University. Sandra L. Emerson is a technical writer and consultant with 20 years’ experience in the software industry. She is a co-author of four computer trade books: The Business Guide to the UNIX System (Addison-Wesley); Database for the IBM PC (Addison-Wesley); Troff Typesetting for UNIX Systems (Prentice Hall PTR); and The Practical SQL Handbook (Addison-Wesley, Fourth Edition, 2001).",
    "author": [
      {
        "family": "Girdley",
        "given": "Michael"
      },
      {
        "family": "Emerson",
        "given": "Sandra L."
      },
      {
        "family": "Woollen",
        "given": "Rob"
      }
    ],
    "id": "10.5555/559265",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "J2EE applications and BEA WebLogic servers",
    "type": "book"
  },
  {
    "DOI": "10.1145/3510454.3516832",
    "ISBN": "9781450392235",
    "URL": "https://doi.org/10.1145/3510454.3516832",
    "abstract": "Natural Language (NL) programming, the concept of synthesizing code from natural language inputs, has garnered growing interest among the software community in recent years. Unfortunately, current solutions in the space all suffer from the same problem, they require many labeled training examples due to their data-driven nature. To address this issue, this paper proposes an NLU-driven approach that forgoes the need for large numbers of labeled training examples. Inspired by how humans learn programming, this solution centers around Natural Language Understanding and draws on a novel graph-based mapping algorithm. The resulting NL programming framework, HISyn, uses no training examples, but gives synthesis accuracies comparable to data-driven methods trained on hundreds of samples. HISyn meanwhile demonstrates advantages in terms of interpretability, error diagnosis support, and cross-domain extensibility. To encourage adoption of HISyn among developers, the tool is made available as an extension for the Visual Studio Code IDE, thereby allowing users to easily submit inputs to HISyn and insert the generated code expressions into their active programs. A demo of the HISyn Extension can be found at https://youtu.be/KKOqJS24FNo.",
    "author": [
      {
        "family": "Young",
        "given": "Mitchell"
      },
      {
        "family": "Nan",
        "given": "Zifan"
      },
      {
        "family": "Shen",
        "given": "Xipeng"
      }
    ],
    "collection-title": "ICSE ’22",
    "container-title": "Proceedings of the ACM/IEEE 44th international conference on software engineering: Companion proceedings",
    "id": "10.1145/3510454.3516832",
    "issued": {
      "date-parts": [
        [
          2022
        ]
      ]
    },
    "keyword": "program synthesis, natural language programming, code editor",
    "page": "110-114",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "IDE augmented with human-learning inspired natural language programming",
    "type": "paper-conference"
  },
  {
    "ISBN": "0130091189",
    "abstract": "From the Book: This book is a practical guide to optimizing performance of computationally intensive applications on Sun UltraSPARC platforms. It offers techniques for improving performance of applications that are predominantly compute-intensive or CPU-bound. We wrote this book with a general enough scope so that it would be useful to as many developers of technical applications on Sun platforms as possible. Also, we made the material practical by showing developers how to use each optimization method. For information on related topics such as system configuration and tuning, or improving the IO and network performance, we refer readers to other resources. This book differs from other books and technical documents written aboutperformance optimization of high performance computing (HPC) applications. In many cases, other resources either give a detailed description of a product or provide general recommendations that are sometimes difficult to apply to practical tasks. In addition, some older resources are not as useful because of changes in technology. Though many of the techniques we offer apply to other platforms, we limited the scope of this guide to Sun compilers and UltraSPARC-based Solaris systems. We address new features in Sun compilers and in the Solaris Operating Environment, and we show readers how to use these products to get maximum performance on Sun hardware. Who Should Read This Book This guide is primarily for developers of technical or HPC applications for Solaris. This audience includes both independent software vendor (ISV) developers and non-commercial developers. Developers creating or optimizing applications in the following fields may benefit from reading this book: Mechanical computer-aided engineering (MCAE) Electronic design automation (EDA) Computational chemistry Bioinformatics Operations research Financial modeling Reservoir simulation and seismic modeling Mechanical computer-aided design (MCAD) modeling Graphics rendering and imaging Climate and weather modeling This book may also be helpful to technical application end-users in understanding the principles of HPC and how an application utilizes system resources. We assume the reader has: familiarity with development basics in UNIX environments a working knowledge of programming in C and Fortran languages familiarity with computer architecture experience in parallel programming a basic knowledge of SPARC assembly (desirable) Unless otherwise noted, topics in this book are not limited to a programming language, parallelization method, or software version. However, emphasis is on techniques relevant to applications written in Fortran 77, Fortran 90, and C, because these languages are most commonly used in HPC and technical applications. Most topics can be applied to C++ programs; however, we do not address performance optimization issues for object oriented programming. We refer readers to other resources. How This Book Is Organized This book presents information so that it follows logical stages of the process for application development and optimization. We pay special attention to issues related to parallel applications and to using appropriate performance monitoring tools. Wherever applicable, sections are illustrated with code examples that show benefits of methods described. Part I - Getting Started Chapter 1 Introduction, introduces optimization for HPC applications. We describe the basics of the optimization process and illustrate it with flow charts for serial and parallel optimization. Chapter 2 Overview of Sun UltraSPARC Solaris Platforms, describes the available tools of trade for HPC developers using Solaris platforms. It gives an overview of Sun hardware and software products for technical computing. Also, the chapter introduces software development tools. Chapter 3 Application Development on Solaris, considers development and porting issues on Sun platforms. It includes sections on binary compatibility between platforms, standards conformance, code verification tools, language interoperability, and 64-bit porting issues. Part II - Optimizing Serial Applications Chapter 4 Measuring Program Performance, focuses on tools that measure application performance. Accurate measurement of performance is crucial in tuning. We describe accurate timers available on Solaris, profiling tools, Forte Developer 6 Performance Analyzer, hardware performance counter access tools on UltraSPARC processors, and other system monitoring tools. Chapter 5 Basic Compiler Optimizations, introduces basic compiler optimizations and how to use compiler flags correctly. Options covered in this chapter are safe and generally can be applied without knowledge of any specifics of the application. The impact of using these flags is illustrated with examples, and analysis of the generated code with and without the options is presented. Chapter 6 Advanced Compiler Optimizations, extends Chapter 5 and gives an overview of techniques that enable aggressive compiler optimizations. These often result in additional performance gains but may also lead to incorrect answers or spurious side-effects. Also, we cover performance related compiler pragmas and directives, which can be inserted in a program. Information about a program can be passed to the compiler, allowing additional optimizations. Chapter 7 Linker and Libraries in Performance Optimization, highlights optimized libraries and features of the Solaris linker that can be used for application optimization. We describe the platform-specific optimized math libraries whose use can result in significant performance gains. We show linker techniques that allow linking of these platform-specific libraries in a portable fashion. Chapter 8 Source Code Optimization, provides an overview of tuning techniques at the source code level. The techniques were selected from the point of view of better utilizing the underlying architectural features of UltraSPARC systems. We pay special attention to memory hierarchy utilization such as cache blocking and reducing the translation lookaside buffer (TLB) misses. We present ways of simplifying the code to allow better compiler optimizations, such as alias disambiguation in C programs, to take place. Chapter 9 Loop Optimization, focuses on optimizing loops, one of the most commonly used constructs in scientific and HPC programs. We discuss ways in which developers can help the compiler control loop fusion and fission, as well as perform loop peeling. We show examples of register-tiling and consider loops with branches. Part III - Optimizing Parallel Applications Chapter 10 Parallel Processing Models on Solaris, introduces concepts of parallel programming and different parallelization models available on SolarisSPARC systems: automatic compiler parallelization, directives-based parallelism, explicit multithreading, UNIX forkexec, message passing model, and hybrid programming (combined directives and message-passing). Chapter 11 Parallel Performance Measurement Tools, details the tools for performance measurement and monitoring of parallel programs. Similar to Chapter 4, we focus on accurate timers for timing parallel programs, tools for measuring synchronization and communication overheads, tools for measuring hardware counters, and tools for multiprocessor system monitoring. Chapter 12 Optimization of Explicitly Threaded Programs, provides an overview of explicit multithreading of programs using P-threads and Solaris threads. An overview of thread scheduling models in Solaris and their relevance to HPC programs is given and techniques for decreasing synchronization overheads are described. Chapter 13 Optimization of Programs Using Compiler Parallelization, covers support and optimization techniques for automatic and directive-based parallelization in Sun compilers. Special emphasis is given to tuning OpenMP programs using the Fortran 95 compiler. OpenMP programming styles and data-scoping issues are illustrated with examples. Comparisons between OpenMP and P-threads approaches are presented. Chapter 14 Optimization of Message-Passing Programs, describes message-passing models and how to tune MPI programs. We present an overview of message-passing programming models, compiling and linking programs using Sun MPI, and using Sun MPI environment variables. This chapter describes approaches for optimizing point-to-point and global communication with Sun MPI, using the S3L scientific library and using a hybrid OpenMPMPI model. Part IV - Appendices Appendix A Commands That Identify System Configuration Parameters, lists useful Solaris commands that identify system configuration parameters. Appendix B Architecture of UltraSPARC Microprocessor Family, gives an overview of architectural features of the UltraSPARC microprocessor family. Appendix C Architecture of UltraSPARC Interconnect Family, describes the architecture of interconnect technologies for UltraSPARC systems. Appendix D Hardware Counter Performance Metrics, shares some useful performance metrics that can be derived from hardware counters on UltraSPARC systems. Appendix E Interval Arithmetic Support in Forte Developer 6 Fortran 95 Compiler, gives an overview of interval arithmetic support in the Forte Developer 6 Fortran 95 compiler. Appendix F Differences in IO Performance, considers the performance of different IO techniques. Additional Resources To keep the scope of this book manageable, we intentionally omitted many subjects related to performance optimization. Our criteria was to omit subjects that were not applicable to a wide range of applications. Many of these subjects are presented in other documentation for Sun products. The following is a list of publications you may find useful for more narrowly focused subjects: Numerical Computation Guide Fortran Programming Guide Fortran User’s Guide Analyzing Program Performance with Sun Workshop C User’s Guide Forte 6 update 1 C User’s Guide Supplement Linker and Libraries Guide Sun Performance Library Reference Multithreaded Programming Guide Programming Utilities Guide 64-bit Developer’s Guide Solaris Tunable Parameters Reference Manual Sun HPC ClusterTools 3.1 Performance Guide Sun MPI 4.1 Programming and Reference Guide Prism 6.1 User’s Guide Sun HPC ClusterTools 3.1 Installation Guide All these publications are available online at http:docs.sun.com. We strongly recommend that developers visit this site, because nearly all published Sun documentation is available there. Printed versions are available from Sun Documentation Center at Fatbrain: http: The following publications are related to UltraSPARC microprocessors: UltraSPARC I and II User’s Manual UltraSPARC IIi User’s Manual These publications are available at: http: Other sites of great use for developers are http: and http:soldc.sun.com, which contains current information for the Sun developer community. A description of Sun product lines is available at http: and http: . Sun products and solutions for the HPC are listed at http: . For specialized books and additional theoretical information on application optimization, we refer readers to other sources. There are many excellent books on topics such as optimizing compilers, software tuning techniques, and efficient parallelization. The following are some helpful resources: J. Hennessy, D. Patterson - Computer Architecture: A Quantitative Approach , Second Edition; Morgan Kaufmann Publishing, 1996 K. Dowd, Ch. Severance - High Performance Computing , Second Edition; O’Reilly &amp; Associates, 1998 D. E. Culler, J. P. Singh, A. Gupta - Parallel Computer Architecture: A Hardware Software Approach , Morgan Kaufmann Publishing, 1999 S. S. Muchnick - Advanced Compiler Design and Implementation ; Morgan Kaufmann Publishing, 1997. S. Kleinman, D. Shah, B. Smaalders - Programming with Threads ; SunSoft Press, A Prentice Hall Title, 1996. W. Gropp, E. Lusk, A. Skjellum - Using MPI: Portable Parallel Programming with Message-Passing Interface (Scientific and Engineering Computation Series); Second Edition, MIT Press, 1999. R. Chandra, L. Dagum, D. Kohr, D. Maydan, J. McDonald, R. Menon - Parallel Programming in OpenMP ; Morgan Kaufmann Publishing, 2000. More resources are listed in the References section at the end of this book. Readers interested in hands on training should check with the Sun Educational Services to determine if a class is scheduled and enrollment is open. Code Examples Many sections in this book are illustrated with code examples that show benefits of optimization techniques and coding practices. The code examples can be downloaded from the Sun BluePrints site: http: A makefile is provided for each chapter so that the examples can be run with a single make command. Unless otherwise noted, all examples and results presented in this book use Forte Developer 6 compilers and the HPC 3.1 ClusterTools release. The results for serial runs were obtained on Sun Ultra 60, Sun Ultra 80, and Sun Blade 1000 systems. The results for parallel runs were performed on Sun Enterprise 4500, Sun Enterprise 10000 servers, and a Sun technical compute farm. The system parameters are listed in TABLE P-1 and TABLE P-2, respectively. More information about Sun platforms is in Chapter 2.",
    "author": [
      {
        "family": "Garg",
        "given": "Rajat P."
      },
      {
        "family": "Sharapov",
        "given": "Ilya"
      }
    ],
    "id": "10.5555/572441",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Prentice Hall Professional Technical Reference",
    "title": "Techniques for optimizing applications: High performance computing",
    "title-short": "Techniques for optimizing applications",
    "type": "book"
  },
  {
    "ISBN": "0130934763",
    "abstract": "From the Book: This book is a practical guide to optimizing performance of computationally intensive applications on Sun UltraSPARC platforms. It offers techniques for improving performance of applications that are predominantly compute-intensive or CPU-bound. We wrote this book with a general enough scope so that it would be useful to as many developers of technical applications on Sun platforms as possible. Also, we made the material practical by showing developers how to use each optimization method. For information on related topics such as system configuration and tuning, or improving the IO and network performance, we refer readers to other resources. This book differs from other books and technical documents written aboutperformance optimization of high performance computing (HPC) applications. In many cases, other resources either give a detailed description of a product or provide general recommendations that are sometimes difficult to apply to practical tasks. In addition, some older resources are not as useful because of changes in technology. Though many of the techniques we offer apply to other platforms, we limited the scope of this guide to Sun compilers and UltraSPARC-based Solaris systems. We address new features in Sun compilers and in the Solaris Operating Environment, and we show readers how to use these products to get maximum performance on Sun hardware. Who Should Read This Book This guide is primarily for developers of technical or HPC applications for Solaris. This audience includes both independent software vendor (ISV) developers and non-commercial developers. Developers creating or optimizing applications in the following fields may benefit from reading this book: Mechanical computer-aided engineering (MCAE) Electronic design automation (EDA) Computational chemistry Bioinformatics Operations research Financial modeling Reservoir simulation and seismic modeling Mechanical computer-aided design (MCAD) modeling Graphics rendering and imaging Climate and weather modeling This book may also be helpful to technical application end-users in understanding the principles of HPC and how an application utilizes system resources. We assume the reader has: familiarity with development basics in UNIX environments a working knowledge of programming in C and Fortran languages familiarity with computer architecture experience in parallel programming a basic knowledge of SPARC assembly (desirable) Unless otherwise noted, topics in this book are not limited to a programming language, parallelization method, or software version. However, emphasis is on techniques relevant to applications written in Fortran 77, Fortran 90, and C, because these languages are most commonly used in HPC and technical applications. Most topics can be applied to C++ programs; however, we do not address performance optimization issues for object oriented programming. We refer readers to other resources. How This Book Is Organized This book presents information so that it follows logical stages of the process for application development and optimization. We pay special attention to issues related to parallel applications and to using appropriate performance monitoring tools. Wherever applicable, sections are illustrated with code examples that show benefits of methods described. Part I - Getting Started Chapter 1 Introduction, introduces optimization for HPC applications. We describe the basics of the optimization process and illustrate it with flow charts for serial and parallel optimization. Chapter 2 Overview of Sun UltraSPARC Solaris Platforms, describes the available tools of trade for HPC developers using Solaris platforms. It gives an overview of Sun hardware and software products for technical computing. Also, the chapter introduces software development tools. Chapter 3 Application Development on Solaris, considers development and porting issues on Sun platforms. It includes sections on binary compatibility between platforms, standards conformance, code verification tools, language interoperability, and 64-bit porting issues. Part II - Optimizing Serial Applications Chapter 4 Measuring Program Performance, focuses on tools that measure application performance. Accurate measurement of performance is crucial in tuning. We describe accurate timers available on Solaris, profiling tools, Forte Developer 6 Performance Analyzer, hardware performance counter access tools on UltraSPARC processors, and other system monitoring tools. Chapter 5 Basic Compiler Optimizations, introduces basic compiler optimizations and how to use compiler flags correctly. Options covered in this chapter are safe and generally can be applied without knowledge of any specifics of the application. The impact of using these flags is illustrated with examples, and analysis of the generated code with and without the options is presented. Chapter 6 Advanced Compiler Optimizations, extends Chapter 5 and gives an overview of techniques that enable aggressive compiler optimizations. These often result in additional performance gains but may also lead to incorrect answers or spurious side-effects. Also, we cover performance related compiler pragmas and directives, which can be inserted in a program. Information about a program can be passed to the compiler, allowing additional optimizations. Chapter 7 Linker and Libraries in Performance Optimization, highlights optimized libraries and features of the Solaris linker that can be used for application optimization. We describe the platform-specific optimized math libraries whose use can result in significant performance gains. We show linker techniques that allow linking of these platform-specific libraries in a portable fashion. Chapter 8 Source Code Optimization, provides an overview of tuning techniques at the source code level. The techniques were selected from the point of view of better utilizing the underlying architectural features of UltraSPARC systems. We pay special attention to memory hierarchy utilization such as cache blocking and reducing the translation lookaside buffer (TLB) misses. We present ways of simplifying the code to allow better compiler optimizations, such as alias disambiguation in C programs, to take place. Chapter 9 Loop Optimization, focuses on optimizing loops, one of the most commonly used constructs in scientific and HPC programs. We discuss ways in which developers can help the compiler control loop fusion and fission, as well as perform loop peeling. We show examples of register-tiling and consider loops with branches. Part III - Optimizing Parallel Applications Chapter 10 Parallel Processing Models on Solaris, introduces concepts of parallel programming and different parallelization models available on SolarisSPARC systems: automatic compiler parallelization, directives-based parallelism, explicit multithreading, UNIX forkexec, message passing model, and hybrid programming (combined directives and message-passing). Chapter 11 Parallel Performance Measurement Tools, details the tools for performance measurement and monitoring of parallel programs. Similar to Chapter 4, we focus on accurate timers for timing parallel programs, tools for measuring synchronization and communication overheads, tools for measuring hardware counters, and tools for multiprocessor system monitoring. Chapter 12 Optimization of Explicitly Threaded Programs, provides an overview of explicit multithreading of programs using P-threads and Solaris threads. An overview of thread scheduling models in Solaris and their relevance to HPC programs is given and techniques for decreasing synchronization overheads are described. Chapter 13 Optimization of Programs Using Compiler Parallelization, covers support and optimization techniques for automatic and directive-based parallelization in Sun compilers. Special emphasis is given to tuning OpenMP programs using the Fortran 95 compiler. OpenMP programming styles and data-scoping issues are illustrated with examples. Comparisons between OpenMP and P-threads approaches are presented. Chapter 14 Optimization of Message-Passing Programs, describes message-passing models and how to tune MPI programs. We present an overview of message-passing programming models, compiling and linking programs using Sun MPI, and using Sun MPI environment variables. This chapter describes approaches for optimizing point-to-point and global communication with Sun MPI, using the S3L scientific library and using a hybrid OpenMPMPI model. Part IV - Appendices Appendix A Commands That Identify System Configuration Parameters, lists useful Solaris commands that identify system configuration parameters. Appendix B Architecture of UltraSPARC Microprocessor Family, gives an overview of architectural features of the UltraSPARC microprocessor family. Appendix C Architecture of UltraSPARC Interconnect Family, describes the architecture of interconnect technologies for UltraSPARC systems. Appendix D Hardware Counter Performance Metrics, shares some useful performance metrics that can be derived from hardware counters on UltraSPARC systems. Appendix E Interval Arithmetic Support in Forte Developer 6 Fortran 95 Compiler, gives an overview of interval arithmetic support in the Forte Developer 6 Fortran 95 compiler. Appendix F Differences in IO Performance, considers the performance of different IO techniques. Additional Resources To keep the scope of this book manageable, we intentionally omitted many subjects related to performance optimization. Our criteria was to omit subjects that were not applicable to a wide range of applications. Many of these subjects are presented in other documentation for Sun products. The following is a list of publications you may find useful for more narrowly focused subjects: Numerical Computation Guide Fortran Programming Guide Fortran User’s Guide Analyzing Program Performance with Sun Workshop C User’s Guide Forte 6 update 1 C User’s Guide Supplement Linker and Libraries Guide Sun Performance Library Reference Multithreaded Programming Guide Programming Utilities Guide 64-bit Developer’s Guide Solaris Tunable Parameters Reference Manual Sun HPC ClusterTools 3.1 Performance Guide Sun MPI 4.1 Programming and Reference Guide Prism 6.1 User’s Guide Sun HPC ClusterTools 3.1 Installation Guide All these publications are available online at http:docs.sun.com. We strongly recommend that developers visit this site, because nearly all published Sun documentation is available there. Printed versions are available from Sun Documentation Center at Fatbrain: http: The following publications are related to UltraSPARC microprocessors: UltraSPARC I and II User’s Manual UltraSPARC IIi User’s Manual These publications are available at: http: Other sites of great use for developers are http: and http:soldc.sun.com, which contains current information for the Sun developer community. A description of Sun product lines is available at http: and http: . Sun products and solutions for the HPC are listed at http: . For specialized books and additional theoretical information on application optimization, we refer readers to other sources. There are many excellent books on topics such as optimizing compilers, software tuning techniques, and efficient parallelization. The following are some helpful resources: J. Hennessy, D. Patterson - Computer Architecture: A Quantitative Approach , Second Edition; Morgan Kaufmann Publishing, 1996 K. Dowd, Ch. Severance - High Performance Computing , Second Edition; O’Reilly &amp; Associates, 1998 D. E. Culler, J. P. Singh, A. Gupta - Parallel Computer Architecture: A Hardware Software Approach , Morgan Kaufmann Publishing, 1999 S. S. Muchnick - Advanced Compiler Design and Implementation ; Morgan Kaufmann Publishing, 1997. S. Kleinman, D. Shah, B. Smaalders - Programming with Threads ; SunSoft Press, A Prentice Hall Title, 1996. W. Gropp, E. Lusk, A. Skjellum - Using MPI: Portable Parallel Programming with Message-Passing Interface (Scientific and Engineering Computation Series); Second Edition, MIT Press, 1999. R. Chandra, L. Dagum, D. Kohr, D. Maydan, J. McDonald, R. Menon - Parallel Programming in OpenMP ; Morgan Kaufmann Publishing, 2000. More resources are listed in the References section at the end of this book. Readers interested in hands on training should check with the Sun Educational Services to determine if a class is scheduled and enrollment is open. Code Examples Many sections in this book are illustrated with code examples that show benefits of optimization techniques and coding practices. The code examples can be downloaded from the Sun BluePrints site: http: A makefile is provided for each chapter so that the examples can be run with a single make command. Unless otherwise noted, all examples and results presented in this book use Forte Developer 6 compilers and the HPC 3.1 ClusterTools release. The results for serial runs were obtained on Sun Ultra 60, Sun Ultra 80, and Sun Blade 1000 systems. The results for parallel runs were performed on Sun Enterprise 4500, Sun Enterprise 10000 servers, and a Sun technical compute farm. The system parameters are listed in TABLE P-1 and TABLE P-2, respectively. More information about Sun platforms is in Chapter 2.",
    "author": [
      {
        "family": "Garg",
        "given": "Rajat P."
      },
      {
        "family": "Sharapov",
        "given": "Illya"
      }
    ],
    "id": "10.5555/558986",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Techniques for optimizing applications: High performance computing",
    "title-short": "Techniques for optimizing applications",
    "type": "book"
  },
  {
    "ISBN": "0201702525",
    "abstract": "From the Book: PREFACE: This book focuses on the most powerful approach available today to model and build industrial-strength Java applications: the Unified Modeling Language (UML) adopted in 1997 by the Object Management Group (OMG). A project lifecycle and software process model are demonstrated (Rational’s Unified Process) using a sample application from requirements gathering, using Use Cases, through implementation via the creation Java code from Class and Sequence diagrams. This sample application uses the latest Java technology frameworks such as Java Server Pages (JSP), Servlets, and most importantly, the Enterprise Java Bean 2.0 (EJB) server-side enabling technology for the implementation of the business rules. Products to implement these server-side solutions range from the Apache Tomcat server to commercial applications servers such as BEA’s Weblogic server. Reason for the Book It took me many years to understand that writing a program was nothing more than a learned tactical skill. To program in a language like Java is to be a journeyman. But to somehow capture someone’s requirements in an intelligent fashion and organize the necessary resources and resulting software into a cohesive deliverable, is the sign of a strategic craftsman. To me, the majority of Java books never consider Java in \"the large.\" They focus on the small view, covering single Java enabled extensions such as JavaBeans, Servlets and Java Server Pages. Although these views, too, are necessary, unfortunately no one seems to touch on project planning, software process, and the methodology for building enterprise-status Java applications. This is a difficult topic to explore andpresent as the whole subject of process stirs many heartfelt debates and opinions. At the urging of many of my colleagues and supportive readers of my first book, Developing Applications with Visual Basic and UML, I have undertaken a similar project for Java. Who Should Read This Book This book is for anyone who wants to successfully build Java applications that can stand up over time. It provides an accurate road map for anyone to achieve the following goals. Review two processes, one commercially available through Rational Software called the Unified Process (UP) and one from the author’s experiences called Synergy. The greatest emphasis will be placed on the Unified Process. Establish a sound project plan (presented in-depth in Appendix E). Estimate projects with confidence, rather than a rule-of-thumb approach. Understand and describe the requirements of the application using UML Use Cases. Create a sound design based UML Class and Sequence diagrams. Use a visual modeling tool such as, Rose, by Rational Software not only to create and track UML artifacts but also to generate skeletons for the component code. Although this author firmly believes that an automated code-generation process is a big factor contributing to successful projects, it by far is not mandatory. Use Java to build server-side Java functionality employing frameworks such as Java Server Pages (JSP), Servlets, and Enterprise JavaBeans 2.0 (EJB). Produce the code for the project using an evolutionary approach showing various technology options: 1). Servlets, JSP, and JavaBeans 2). Servlets, JSP, and Bean-Managed Persistence (BMP) 3). Servlets, JSP, and Container-Managed Persistence (CMP). Investigate the benefit of deploying Java applications on both open-source products like the Apache Tomcat server as well as using commercial Application Server products such as BEA’s Weblogic application server. Anyone building Java applications today needs this book. What You Need to Know to Use This Book Maybe it’s best to start out with what you don’t need to know to benefit from this book. First, you don’t need to know anything about the UML. I present the essential aspects of the UML and, more important, how they relate to Java deliverables. Although the UML is expressed with nine separate diagrams, you will benefit the most from a core set. Second, you don’t need a formal background in object-oriented concepts (but it certainly wouldn’t hurt). I discuss standard object constructs in the text in Chapter 2. Third, you should have some conversational understanding of what Enterprise JavaBeans are. For a really thorough treatment of Enterprise JavaBeans (EJB), you should focus on one of the many texts that cover them in more detail. A favorite book of mine is by Richard Monson-Haefel entitled Enterprise JavaBeans (O’Reilly). The reader would also benefit by having some exposure to Java Server Pages (JSP). A favorite book of mine is by Hans Bergsten entitled Java Server Pages (O’Reilly). This book does assume that you have a working knowledge of Java. Both the new Java programmer and the experienced Java programmer will benefit. However, I don’t cover the basics of simple Java constructs, assuming that you already know these. I do briefly review the tenets of Java’s support for object-oriented principals in Chapter 2, but only as a baseline for other topics related to the UML. If you have had no exposure to Java, buy this book anyway and open it after you have had some initial training in that programming language. This book places an emphasis on the most mainstream Java techniques and products that are used to build production applications. When I began this book I planned to cover all kinds of java technologies (i.e., applets, java applications talking to Servlets or JSPs). However, it quickly became apparent to me that the majority of my clients and my associate’s clients were all pretty much cut from the same mold when you looked at their architecture. They consist of a light client browser on the front-end (with minimal JavaScript for syntax editing) a web server intercepting those browser requests with either Servlets and/or Java Server Pages acting as a broker within some container product which houses the business rules. These business rules are either implemented as JavaBeans or Enterprise JavaBeans. The container products range from open-source solutions like Apache Tomcat to commercial products. The two biggest of the commercial application server players I run across are BEA with their Weblogic product and IBM with their Websphere product. This doesn’t mean there aren’t more good commercial container products but these two vendors have the lion’s share of the market. This book will utilize a light client-side technology (no applets or java applications), web server running Servlets and Java Server Pages who in turn message to either JavaBeans (Tomcat) or Enterprise JavaBeans (session and entity beans) residing in a commercial application server. In the case of the later, I have chosen to use BEA’s Weblogic as my application server. Don’t get discouraged if you are using another vendor’s application server product because this book’s coverage of EJB is based on the 2.0 specification. This release of EJB resolved many of the ambiguities that disallowed beans to be truly transportable across vendor implementations. So, regardless of your EJB vendor, you will be able to use the code built in this book. It would be unfair to say you will know, for instance, everything about EJBs after reading this book. If you already know about EJBs then this book will better help you put them into a sound design architecture. The emphasis is placed on the notation, UML, and the process, Unified Process and Synergy, in beginning, developing, and implementing, a software project using the Java language. The benefit of seeing an application from requirements gathering to implementation is the key to goal of this book. This is where I shall place my emphasis. Structure of the Book Following is a summary of the book’s chapters and contents. Chapter 1: The Project DilemmaThis chapter reviews the current state of software development and my reasoning regarding why it’s in the shape that it is today. It also reviews the concept of iterative and incremental software development and provides an overview of both the Unified Process from Rational Software and my Synergy methodology. It also touches on the primary components of the UML that will be covered in more depth later in the book. Chapter 2: Java, Object-Oriented, and the UMLThis chapter covers some of the benefits that result from the adoption of Java as a development environment. It presents these in the context of Java’s implementation of encapsulation, inheritance, and polymorphism. It then maps the UML to various Java deliverables. Highlights include mapping the UML class to Java classes and Java interfaces; mapping use case pathways to Java entity, interface, and controller types of classes; and mapping component diagrams to Java classes and Java packages. Chapter 3: Getting the Project StartedThis chapter explores the case study used in the book, Remulak Productions. This fictional company sells musical equipment and needs a new order entry system. It introduces a project charter, along with a tool, called the event table, to help quickly solidify the application’s features. Further, the chapter maps events to the first UML model, the use case. Chapter 4: Use CasesThis chapter reviews the use case, one of the central UML diagrams. Included is a template to document the use case. Actors and their roles in the use cases are defined. The chapter reviews the concept of use case pathways, as well as the project’s preliminary implementation architecture. Also reviewed is an approach to estimating projects that are built by using the use case approach. Chapter 5: ClassesThis chapter explores the class diagram, the king of UML diagrams. It offers tips on identifying good class selections and defines the various types of associations. It also covers business rule categorization and how these rules can be translated into both operations and attributes of the class. Finally, it discusses the utilization of a visual modeling tool as a means to better manage all UML artifacts. Chapter 6: Building a User Interface PrototypeThis chapter reviews unique user interface requirements of each use case. It develops an early U/I prototype flow and an eventual graphical prototype. Finally, it maps what was learned during the prototype to the UML artifacts. Chapter 7: The Dynamic Elements of the ApplicationThis chapter discusses the dynamic models supported by the UML, exploring in depth the two key diagrams, often referred to as the interaction diagrams, sequence and collaboration. These are then directly tied back to the pathways found in the use cases. Other dynamic diagrams discussed include the state and activity diagrams. Chapter 8: The Technology LandscapeThis chapter covers the importance of separating logical services that are compliant with a model that separates services. It explores technology solutions specific to the Remulak Productions case study, including distributed solutions and the Internet using HTML forms, JSP and Servlets. Both JavaBeans and Enterprise JavaBeans as a solution for housing the business rules are also be explored. Chapter 9: Data Persistence: Storing the ObjectsThis chapter explores the steps necessary to translate the class diagram into a relational design to be supported by both Microsoft SQL Server and Oracle databases. It offers rules-of-thumb regarding how to handle class inheritance and the resulting possible design alternatives when translating to an RDMBS. This book will deliver solutions that range from roll-your-own persistence using JavaBeans and JDBC, all the way to Container Managed Persistence (CMP) features of the EJB 2.0 specification. The later removes all the requirements of the application to write SQL or control transactions. This chapter introduces the concept of Value objects to reduce network traffic as well as Data Access Objects that encapsulate SQL calls. Chapter 10: Applying the InfrastructureThis chapter finalizes the design necessary to implement the various layers of the application. It also presents the communication mechanism utilized between the layers and possible alternatives. Each class is delegated to one of three types: entity, boundary, or control. These are used as the basis for the design implementation and as the solution to providing alternative deployment strategies. Chapter 11: Constructing a Solution: Servlets, JSP, and JavaBeansThis chapter builds the first Architectural Prototype for Remulak and does not rely on Enterprise JavaBeans. Using the Maintain Relationships use case as the base, the various components are constructed. The primary goal of the Architectural prototype is to reduce risk early by eliminating any unknowns with the architecture. This chapter uses the Apache Tomcat server and introduces the concepts of user interface and use case controller classes. Chapter 12: Constructing a Solution: Servlets, JSP, and Enterprise JavaBeansThis chapter initially uses Rational Rose to generate EJB components. A primer on EJB is offered along with a thorough discussion of the transaction management options in the EJB environment. Session beans are utilized as the use case controller. Both a Container Managed Persistence (CMP) and Bean Managed Persistence (BMP) are presented. Leveraging the Data Access Objects created in the previous chapter is paramount to the success of a BMP implementation. Updates and Information I have the good fortune to work with top companies and organizations not only in the United States, but also in Europe, Asia, and South America. In my many travels, I am always coming across inventive ideas regarding how to use and apply the UML to build more-resilient applications that use not only Java but also C, C# and Visual Basic. Please visit my Web site at www.jacksonreed.com, where you can get the latest on the training and consulting services that I offer, as well as all of the source code presented in this book. I welcome your input and encourage you to contact me at prreed@jacksonreed.com.",
    "author": [
      {
        "family": "Reed",
        "given": "Paul R."
      }
    ],
    "id": "10.5555/515925",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Developing applications with java and uml",
    "type": "book"
  },
  {
    "DOI": "10.1145/3159450.3162351",
    "ISBN": "9781450351034",
    "URL": "https://doi.org/10.1145/3159450.3162351",
    "abstract": "CS instructors are sometimes tasked with modifying CS1 courses to teach introductory programming for the Digital Humanities. Training computer science students in DH programming methods may also have some additional benefits, such as bringing more women into computing, and helping in the recruitment and retention of CS students overall. DH projects may also provide Service-Learning opportunities that will give students experiential learning opportunities not provided in industry. The presenters have developed six assignments in Python that are oriented towards DH topics while still providing CS students solid experiences in core programming concepts. This workshop introduces the participants to five of the assignments and gives them immersive abbreviated experiences in each. The topics include Computing Change over Time (calculating burials in a historic cemetery), Visualization of Change over Time (visualizing the burials in the historic cemetery), Textual Analysis (finding word frequencies and \"stop words\" in public domain texts), Stylometrics (comparing measured features of graphic images), and Social Network Analysis (analyzing extended relationships in historic social circles). A balance of direct coding experience and discussion of gotchas and best practices in classroom management will give workshop participants confidence in offering and managing these assignments in their own classrooms. Participants should bring a laptop/keying-friendly mobile device that has a Python 3.x IDE already installed, and some familiarity with the Python language.",
    "author": [
      {
        "family": "Kokensparger",
        "given": "Brian"
      },
      {
        "family": "Peyou",
        "given": "Wade"
      }
    ],
    "collection-title": "SIGCSE ’18",
    "container-title": "Proceedings of the 49th ACM technical symposium on computer science education",
    "id": "10.1145/3159450.3162351",
    "issued": {
      "date-parts": [
        [
          2018
        ]
      ]
    },
    "keyword": "python programming, humanities programming, digital humanities, CS1",
    "page": "1050",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Programming for the humanities: A whirlwind tour of assignments (abstract only)",
    "title-short": "Programming for the humanities",
    "type": "paper-conference"
  },
  {
    "ISBN": "0782128734",
    "abstract": "From the Publisher: Master the RAD Tool Designed Especially for Linux Development Kylix 2 promises great things for the world of Linux application development. Mastering Kylix 2 is the best possible way for you to take advantage of everything this powerful RAD tool has to offer. Co-written by internationally acclaimed Delphi expert Marco Cantù, this book provides authoritative, tutorial-style instruction along with tips and tricks available nowhere else. Begin with Kylix basics and advance confidently, developing the skills needed to use Kylix to meet real challenges-from sockets programming to XML processing to web services development. Coverage includes: Getting acquainted with the Kylix IDE Using Kylix’s object-oriented facilities Implementing Linux file management Working with the BaseCLX library Developing GUIs Using advanced components and controls Creating forms Building graphics features Writing Kylix components Using the ClientDataSet component and MyBase Handling interprocess communication Creating web programs with WebBroker and WebSnap Processing XML Developing SOAP-based web services Featured on the CD On the CD, you get complete and ready-to-use source code for the hundreds of examples presented in the book. You also get an electronic copy of Essential Pascal, Marco Cantù’s acclaimed introduction to the Pascal programming language, written from a Kylix perspective. Finally, you get the open source version of Kylix, FreeCLX, Interbase 6 Open Source Edition, and the Indy open-source web component suite. About the Authors Marco Cantù is the author of sixeditions of the best-selling Mastering Delphi 6. Beside writing and speaking at conferences, he teaches technical classes on both Delphi and XML technologies. Marco lives in Italy. Uberto Barbini is a teacher and consultant for the Italian university Politecnico di Milano. He has published a book on Delphi in Italy and is the developer of the open source program Fractal Forge.",
    "author": [
      {
        "family": "Cantu",
        "given": "Marco"
      },
      {
        "family": "Barbini",
        "given": "Uberto"
      }
    ],
    "edition": "1st",
    "id": "10.5555/582764",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "SYBEX Inc.",
    "publisher-place": "USA",
    "title": "Mastering kylix 2",
    "type": "book"
  },
  {
    "ISBN": "0130660612",
    "abstract": "From the Book: Preface Core ColdFusion 5 is the book I wish I’d had when I began writing applications. One way of teaching programming is for the author to entice you, gentle reader, into the Technicolor landscape of the programming language at handthe author is your friendly guide, pointing out the dazzling array of colors and scents, while you, the Maui-shirted, floppy-hatted tourist, peer dimly into your map as you stand gawking dead center at the intersection of 42nd and Broadway. You get your required caramel milkshake at Ellen’s Stardust Diner and move on to stand in line for Cats tickets. Or something like that. This is a different kind of book. I learned ColdFusion on the flydevouring websites and books devoted to the topic, nosing about in newsgroups and loitering on lists while I tried to get my first applications up and running. I learned by reading, by asking endless questions, by trying things over and over until something clicked. I learned from the generosity of hundreds of programmers it has been my pleasure to work with. I don’t view it as an academic subject. This learning process was all very glamorous, but I think I wasted a lot of time that I didn’t need to waste. The approach is this: programmers are, above all, problem solvers. That’s what they get paid to do. Therefore, the language is presented as a set of tools that are available to you to solve business problems. The code you will work with will consist of numerous non-trivial, practical examples that you can build on and incorporate into your own websites. My belief is that you can learn best how it all fits together by seeing it in action, working together. Forinstance, it’s fun to learn about cookies, and it’s great to know that by using the CFLOCATION tag in your templates you can quickly jump to another URL. This is the sort of thing one learns as a programming tourist. Only when discussing a real-world application where all the parts have to fit together do you discover that, because of HTTP headers, you can’t effectively set a cookie in the same template that you use CFLOCATION to get out of. But that’s exactly the sort of thing you need to know when you sit down to write ColdFusion. You are a person in the world where people live. This indicates a certain relationship with space and time. This book was designed with these key factors in mind. There is only so much space in a book, so what you’ve got in your hands is the set of tools with which to continue on your own: There’s the complete tag and function reference. There are lists of dozens of websites where you can get ColdFusion code, find more information on related topics, discover hundreds of places where you can host your ColdFusion website, and more. You get a list of the common ColdFusion errors you’ll run into when debugging your applications, what they mean, and how to fix them. You put together a ColdFusion application for Web-enabled cell phones and a working e-commerce site, complete with rotating banner ads. The idea is to save your walls from the repeated impact of your head. This book will give you everything you need to get up and running quickly, effectively, and with an understanding of the real-world implications of developing with ColdFusion. The remainder of this preface briefly illuminates key things you will need to start using this book, and ColdFusion, quickly. Who You Are This book was written for anybody who wants practical knowledge of how to make Web applications on an easy, scalable, powerful platform. You know HTML already. You do not need to know another application programming language. You do not need knowledge of Web servers or data servers. Maybe you know ASP or JSP and want to learn another language. This book is perfect for you. Maybe you just took an IT job at Symantec or Doctor Solomon’s or Bank of America or the University of Utah or the Recording Industry of America. Or maybe you were just elected Senator of your fine state, and, while browsing at http://www.Senate.gov noticed the little \".cfm\" extension on your website and wondered what it was. All of the above organizations entrust their Web transactions to ColdFusion. And with good reason. This book was also written for Web developers and for people who have done a static website or two and want to make their next one dynamic. The ability to create an online store, to interact with data warehouses via enterprise-level features such as stored procedures and data probing, lets you get really serious. The ability to personalize your website, catering its content to each individual visitor, will allow you to create truly compelling relationships with your users. The ability to search and share documents in just about any format will allow your organization to stay ahead of the information cycle. Project managers and sales engineers will benefit from this book’s discussions of planning an enterprise-level website and making all of the components come together. Despite a seemingly universal predilection toward Mountain Dew, Web programmers are a diverse species. Whether you are a pleasantly dressed co-ed working in a college computer lab with well-modulated air, or if you’re grinding out 18-hour days in a high-tech job shop and have recently started looking like the long-lost fourth member of ZZ Top, or whether you’re all by yourself in your basement playing gladiator with IIS and scramming the cat from chewing your cables, this is the right book for you. What You Need You will need several things to work successfully through the exercises in this book. You will need a computer with a text editor. You will need access to ColdFusion Server 5 software, a Web server, and an Internet connection. A 30-day evaluation version of ColdFusion 5 comes on the CD-ROM with the book, Notepad or Pico comes with your OS, and Apache is free, so you’re in pretty good shape. What You Get This is a practical book. Its purpose is to answer the questions you need answered by showing you how everything works together (HTTP 1.1 headers, the Web server, your applications, conditional logic, and so forth). Some of this may be old hat to you. I have therefore tried to flag you about beginner material that you may want to skip. Here is what you get: A clear, detailed explanation of the ColdFusion language and how you can leverage it to build fantastic Web applications. Information, tips, and tricks about becoming a ColdFusion Certified Developer. Thousands of lines of complete, working code. On the CD-ROM, you get 30-day evaluation versions of Macromedia ColdFusion Enterprise Server 5.0 for Windows, HP-UX, Sun Solaris, and Linux; ColdFusion Studio 4.5.1 optional development environment for creating ColdFusion templates); HomeSite 4.5.1, Macromedia’s award-winning HTML editor; The Harpoon Flash Toolkit; ColdFusion Express, the nonexpiring, limited-functionality product for serving ColdFusion pages; JRun 3.0.1, the award-winning server for Java Server Pages, Servlets, and Enterprise Java Beans; Macromedia Spectra 1.5 for Windows and Sun Solaris, the packaged application solution for content management, e-commerce, and personalizationwritten in ColdFusion! A website companion to the book filled with even more ColdFusion resources. The website is located at http://www.CoreColdFusion.com. Check out http://www.conditionallogic.com as well. How This Book Is Organized This book begins where HTML left off. We start with an overview of how the Internet works and an overview of what ColdFusion does. We then move into a discussion of SQL (the Structured Query Language), the language used to create and manipulate databases and their data. If you have a solid understanding of relational databases and SQL, you can probably skim Chapters 9 and 10. Each chapter will have roughly the same structure. You will be introduced to the key concepts in a general way, and quickly move into details as they pertain to ColdFusion or application development. You’ll come out of most chapters with a working example that you can take with you. Because each chapter builds on the last, it is a good idea to read the book from beginning to end. If you’re used to programming in another Web application language such as PHP, you might want to at least skim the introductory chapters on the World Wide We HTTP, as well as the SQL chapters, just so I don’t make unfortunate assumptions. As the book continues, and you’ve got the key concepts and a number of tags and functions under your belt, we’ll start putting together bigger applications with a number of pieces that have to fit together. That is the only way you can learn how to work with ColdFusion in large-scale websites. Many of the examples in this book were created with the ColdFusion Application Server running on a Windows 2000 with IIS 5. The database used in most cases is Microsoft SQL Server 2000. Oracle 8i is used in some examples. Access has generally been eschewed because, while it is inexpensive and therefore easier to get hold of, it is desktop software and unsuited to a production environment. You can make most of the examples in this book work with Access or Paradox with little or no modification. You can even use Excel spreadsheets and plain text files with some modification. That’s a fabulous aspect of ColdFusion, and just one demonstration of its flexibility. However, I try to discourage the use of desktop database software with ColdFusion for applications that are likely to have more than a couple of concurrent connections or any frequency of use. About the Website If you point your browser to http://www.CoreColdFusion.com, you will discover the companion website to this book. It is meant to provide you with a resource for taking your applications to the next level and continuing your work. Some features of the website include: Databases, files, and code from the book Code for creating the website Enhancements and expansions to discussions i book Links to ColdFusion hosting providers Resource links for ColdFusion User Groups and the most useful ColdFusion sites on the Web Information about becoming a Macromedia ColdFusion Certified Developer A newsletter with product and informational updates on ColdFusion and Spectra A forum for reader feedbacktell me what you think! A schedule of ColdFusion and Spectra training seminars happening every month, all over the United States Fun things like the ColdFusion challengea compendium of tips and tricks Security bulletins If I’ve done my job, this book will teach you what you need to know about ColdFusion in order to go do it in the real world. Hopefully it will also prove useful long after you know what you’re doingit has been organized to serve also as a reference. It’s got the complete language in it, updated for ColdFusion 5. And it’s got working examples that represent the most commonly needed tasks in Web programming today. You can give me feedback at writer@CoreColdFusion.com. I welcome your comments and suggestions for future editions. Thank you for picking this up. I really hope you like it.",
    "author": [
      {
        "family": "Hewitt",
        "given": "Eben"
      }
    ],
    "id": "10.5555/516065",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Core coldfusion 5.0 with cdrom",
    "type": "book"
  },
  {
    "DOI": "10.1145/77556.77557",
    "ISSN": "0001-0782",
    "URL": "https://doi.org/10.1145/77556.77557",
    "author": [
      {
        "family": "Frenkel",
        "given": "Karen A."
      }
    ],
    "container-title": "Commun. ACM",
    "id": "10.1145/77556.77557",
    "issue": "4",
    "issued": {
      "date-parts": [
        [
          1990,
          4
        ]
      ]
    },
    "keyword": "transborder data flow, statistics, standards, regulation",
    "page": "404-410",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "The european community and information technology",
    "type": "article-journal",
    "volume": "33"
  },
  {
    "ISBN": "0201752948",
    "abstract": "From the Book: Oracle SQL and PL/SQL Handbook: A Guide for Data Administrators, Developers, and Business Analysts is a book whose purpose is to teach you techniques that you can use to extract information from complex modern Oracle relational databases. The business world has constructed numerous on-line transaction processing (OLTP) systems, databases, and data warehouses over the past twenty years. Information from these databases is very important to the successful operation of businesses. Corporations have also discovered that it is important to have personnel who can understand and efficiently extract information from these databases. This is why developers, data administrators, and business analysts who can get information from complex databases are so valuable to their companies. The Structured Query Language (SQL), which is an ANSI standard language for interacting with relational databases, is the main tool for extracting the information. SQL is somewhat standard across most relational database products, however this book only covers Oracle’s version. Oracle is the largest database manufacturer in the world and has the most product installations. So this is a good place to start your education. There are other tools you will need to know about in order to produce business information. This includes the ability to read and understand the database blue print. This blue print is the Entity Relationship Drawing (ERD) or my own favorite tool, the Table Relationship Drawing. You will also need to be aware of database objects such as views, synonyms, and indexes. After you learn how to extract the information, you will want to know how to extract the informationquickly. The book contains a chapter that has some common techniques that can be used to enhance the performance of your SQL. This book also covers PL/SQL. This is Oracle’s programming language. This is an extremely useful language for accessing object attributes and performing special calculations. This book contains numerous examples of various SQL techniques. It also has practice questions at the end of most chapters. The questions will allow you to practice the skills immediately after studying them. Appendix B contains answers to the practice questions and provides you with another set of examples to study, copy, and adapt to your work. The book is meant to be a basic reference book and a how-to manual that covers the most important and common Oracle database topics. It is not the ultimate reference book. It is very difficult to learn SQL from these types of books. This book can be used as a reference book, but is does not totally eliminate the need for true reference books that cover the mundane, once used in five-year topics. The purpose of this book is to help you get the skills to analyze, understand, and efficiently extract information from an Oracle database. Developers, database administrators (DBAs), data administrators (DAs) and business analysts normally have a score of books in their work area. No single book can contain everything about all topics. I want this book to be the first book you go to for answers about the Oracle database because it contains the most frequently used information. The book is based upon courses I have taught at Iowa Western Community College, the University of Nebraska at Omaha, and on-site seminars I teach at many major companies. During the past four years I have helped many students understand the basics of Oracle SQL and the techniques used to extract information. The techniques I cover are the result of fifteen years of experience producing business information from relational databases. Students say my books and seminar workbooks are very practical. I believe in studying and identifying good design, copying it, modifying it, and calling it my own. Much of this good design is included in this book. I truly hope and believe that you will find the information in this book practical, and I hope you steal it and call it your own. WHAT IS ORACLE Oracle is the largest database manufacturer and the second largest software manufacturer in the world. The company began as a relational database manufacturer. In the beginning Oracle touted their software as being able to run on any platform. This openness has been most attractive to companies and Oracle has tried to maintain its image as an open product. Oracle was at a good place when industry became extremely interested in moving away from network databases and the mainframe. By allowing companies to use the client/server paradigm, Oracle had a competitive advantage. It also identified the Internet as the future paradigm. Oracle remains the premier database manufacturer due to its foresight. Oracle continues to increase the power of its database. The current version is called Oracle9i. Oracle9i is an object-relational database, which has features that allow developers to model objects within the database. The i in the name means that Oracle intends that its database can also support the Internet. To this end, Java programming functions can be placed within the database. Oracle can understand applications using the Java functions. Oracle has recognized that Java is an open product and is one of the more important languages of the Web. Oracle also has several other database products. Personal Oracle is a smaller version of the Oracle Enterprise Edition. It resides on the client (your PC) and is designed primarily as a stand-alone database. Oracle also has a small database called Oracle Lite9i. This product is designed for use on mobile PC’s and hand held devices. Oracle has very powerful application development, report writing, and database analysis software. The application development package is currently called the Internet Developer Suite. It consists of a number of products. Developer 6i Form Builder and Report Builder are two of its products. Developer6i Form Builder is Oracle’s rapid application development (RAD) software. Report Builder is Oracle’s main report writing software. Designer 6i is Oracle’s computer aided software engineering (CASE) product. It is one of the best selling CASE products in the country. In addition to performing database documentation and object creation, it can be used to generate forms (screens). It is integrated with the other Developer6i products. Even though it will not be covered in this book, Designer is used in many shops as a repository of database information. It is an important tool that can be used to develop and obtain ERDs and other database documentation. The last remaining development software is JDeveloper. This is a Java based application development product somewhat similar to Developer 6i Form Builder. It can be used to create Java based applications, both client/server and Web based. Borland supplied the core technology for this product. It has a strong resemblance to Borland’s Jbuilder. Oracle hopes that JDeveloper will someday be the dominant Web development tool. Discoverer is Oracle’s database analysis product. It is an on-line analytical processing (OLAP) tool. It has a very easy user interface. It is an extremely powerful tool for developing and analyzing business information. The success of this product is due to the ease of creating business objects for analysis and the easy use of the product by end users. I have actually had novice students using the product with less than 2 hours of training. It is a great tool for empowering your users and reducing the report writing load of the programmers, DAs, and business analysts. Finally, Oracle has an array of packaged products for businesses. An example of this type product is Oracle Financials. This product is an entity resource planning (ERP) type application used by companies to document work requests, purchase the materials, maintain inventory levels. and manage their fixed assets, accounts payable, and other financial concerns. Oracle also has an array of other entity packages. As you can see, Oracle has a large number of tools and products. WHO SHOULD USE THIS BOOK At Iowa Western and my seminars, I allow anyone with Windows (or UNIX) experience to enroll in the courses. I would expect that this is the minimum technical criterion to properly use this book. This is an Intro book and will cover most of the commonly used areas of Oracle SQL and PL/SQL. It will also have some elementary coverage of relational and object database components and terminology. This book will be of interest for the following people: Mainframe programmers wanting to upgrade or develop SQL skills. Systems analysts, developers, or business personnel interested in Data Administration. Students desiring the skills to enter the Oracle market. Oracle developers looking new techniques. Developers interested in implementing business objects for analysis. Business analysts interested in gaining the skills to analyze corporate databases You would expect a book such as this to be of interest to readers that desire a technical career. Increasingly it is of importance for accountants, financial analysts, and other non-technical people to have SQL, database, and on-line-analytical-processing (OLAP) skills. A case in point is the job description for accountants at the company for which I am employed. Accountant job descriptions request Oracle knowledge as a needed skill. With the proliferation of ERP type databases such as Oracle Financials, SAP, or People Soft, non-technical personnel are having derive information from these databases. Knowledge of SQL, PL/SQL, and Discoverer will greatly aid these people. This knowledge will give these personnel an edge over other co-workers. The worker that can furnish information to management is always a valuable asset. The worker that cannot is not as valuable. Another class of developers that may reap benefits from this book are Microsoft Access developers. Access is a low level database product that is highly automated. I have had many comments over the years that my courses on SQL and database object creation help students understand what Access is actually doing. HOW IS THIS BOOK ORGANIZED This book contains sixteen chapters, a glossary appendix, and an answer appendix. The book begins with a discussion of the logical data model. This model is used to determine what the database represents, to identify data elements, and to identify the data linkages. This information is needed to effectively extract business information using SQL. The book then discusses the various Oracle database objects. It is important for you to understand these objects. Many of them will affect the SQL that is written. However, it may not be necessary for you to read the later portions of Chapter 2 until after the SQL chapters. Chapter 2 covers the use of the Data Definition Language (DDL). This language is used create and maintain database objects such as tables or views. The chapter also discusses how to log on to the Oracle database and enter commands. This section is important for the reader new to Oracle. I only place the DDL section at the beginning of the book for the readers that want to understand the database engine components before running the engine. Chapters 4-9 cover the Select command. This is the language used to extract information from the database. Chapter 10 discusses the use of views and sequences. Views are a really important tool for creating run time virtual records. Chapter 11 discusses commands contained within the database that can be used to change the presentation of your information. The Oracle database has limited report-writing tools. There are many more powerful tools available, including some fine Oracle tools. However, if your company does not have any of these tools, you will always have the tools discussed in Chapter 11 available. Chapter 12 discusses performance-tuning techniques. This chapter covers the more common and often used techniques. Chapter 13 discusses business objects. Business objects are database objects that can be used for analysis or to increase the performance of reports. The final three chapters will cover Oracle’s PL/SQL language. This language is a must for the data administrator. It can be used to create business objects and entity attributes of interest to the user. The language is also used in Oracle’s Report Builder and Form Builder products. Appendix 1 of the book is a glossary. This appendix has definitions of important database words. Appendix 2 contains the answers to exercises that reside at the end of many of the chapters. These questions will allow you to practice the discussed topics. I strongly encourage you to perform the practice questions, before checking the answers. CONVENTIONS There are two conventions that will be used throughout this book. These are: Bolded Text The first occurrence of a keyword that will be defined in the glossary. ItalicsIdentifies places in a command syntax template that will require a user defined value. OTHER SOURCES OF INFORMATION Despite the best attempts by the technical editors, copy editors, and myself, errors and misunderstandings will exist in this book. It is extremely humbling for an author/teacher to have his students/readers interpret his writing differently from what he expected. I have tried to be as skilled a technical writer as possible; however, I am sure that I fail occasionally. To remedy this, I intend to maintain a Web site that you can use to raise questions and view the answers to previous inquiries. The site will contain corrections, explanations, and clarifications. I believe this will be a valuable aid to you. The following is my home site: www.oracle-trainer.com Another valuable site is the Oracle Developer Tools User Group (ODTUG). This is an organization to which I have belonged for several years. They have an annual conference, a quarterly newsletter, and a special site where members can post enhancement requests to Oracle. Of special importance are the organization’s list servers. At the present time access to the list servers is free to everyone. The list servers allow you to post, answer, and receive advice about a variety of Oracle topics including SQL. I belong to the SQL, Java, Developer6i and Discoverer list servers. I monitor the questions and answers all day. There are also a number of other highly skilled professionals (and authors) who monitor the list servers during the day. It is an excellent place to get the latest Oracle information or help with technical issues. The ODTUG site is at www.odtug.com. If you are truly interested in Oracle, you must visit their Web site frequently. The home page (www.oracle.com) can be very complex and often appears to change daily. However, it is important that you visit the site since it is the source of new Oracle information. Below are some of the Oracle pages I recommend. Before trying to access the pages you should know that many of them are only available to members of the Oracle Technology Network. This is a free membership and you may join using Oracle’s Web site. You will be able to access a great deal of information using this membership. The Oracle Store page is the site for purchasing CD packs of Oracle databases (Personal Oracle, one of these databases, can be used on your PC for course work) and for the Internet Development Suite. These tools include Developer 6i, JDeveloper, Discoverer, and Designer. I strongly encourage you to purchase the database pack and install Personal Oracle (It only runs on Windows NT/2000 at the present time). You can practice all of the techniques discussed in this book. It is one thing to read about Oracle and another to actually employ the techniques. The current site for the CD packs is: https://oraclestore.oracle.com/OA_HTML/ibeCCtpSctDspRte.jsp section=11536&amp;jfn=CAB2E7AB8B81E955A27B05 The database package is called: Oracle(R) 9i Release 1 (9.0.1) CD Pack for Microsoft Windows.Oracle Certified Professional Programs. Oracle has a variety of certifications. Certifications are a series of tests about Oracle topics. Two of the more popular are the DBA and Developer certifications. The certifications consist of five tests. The initial test for the both the DBA and Developer certifications concerns SQL and PL/SQL. This book is an excellent primer for this exam. To learn more about Oracle certifications, visit: http://www.oracle.com/education/certification/ Oracle Certified Professional Assessment Test Download. It is possible to download sample certification exams. You may be interested in how you would perform on a certification exam before and after reading this book. Visit: http://www.oracle.com/education/certification/index.html sts.html to obtain the sample exams.",
    "author": [
      {
        "family": "Palinski",
        "given": "John Adolph"
      }
    ],
    "id": "10.5555/579616",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Oracle SQL and PL/SQL handbook: A guide for data administrators, developers, and business analysts",
    "title-short": "Oracle SQL and PL/SQL handbook",
    "type": "book"
  },
  {
    "ISBN": "1430218916",
    "abstract": "OpenSolaris is a rapidly evolving operating system with roots in Solaris 10, suitable for deployment on laptops, desktop workstations, storage appliances, and data center servers from the smallest singlepurpose systems to the largest enterpriseclass systems. The growing OpenSolaris community now has hundreds of thousands of participants and users in government agencies, commercial businesses, and universities, with more than 100 user groups around the world contributing to the use and advancement of OpenSolaris. New releases of OpenSolaris become available every six months, with contributions from both Sun engineers and OpenSolaris community members; this book covers the OpenSolaris 2008.11 release. Pro OpenSolaris was written to demonstrate that you can host your open source applications and solutions on OpenSolaris, taking advantage of its advanced features such as containers and other forms of virtualization, the ZFS file system, and DTrace. It’s assumed that you are already fairly knowledgeable about developing on Linux systems, so the authors give an overview of the similarities and differences between Linux and OpenSolaris, and then present details on how to use the Service Management Facility (SMF), ZFS, zones, and even a bit of DTrace. They also provide pointers to the many project communities associated with new OpenSolaris features. Special focus is given to web development using familiar applications such as Apache, Tomcat, and MySQL, along with the NetBeans IDE, and showing you how to exploit some of OpenSolaris’s unique technologies. What youll learn Discover the secrets of the ZFS, the most powerful file system ever conceived Explore OpenSolaris AMP (Apache, MySQL, PHP) and GlassFish in the context of Web 2.0 and Linux/Solaris, respectively Familiarize yourself with the new security administration features of OpenSolaris, including changes in DTrace Who is this book for? Linux system administrators and programmers who would like to know what they have missed since Solaris became an open source operating system. About the Apress Pro Series The Apress Pro series books are practical, professional tutorials to keep you on and moving up the professional ladder. You have gotten the job, now you need to hone your skills in these tough competitive times. The Apress Pro series expands your skills and expertise in exactly the areas you need. Master the content of a Pro book, and you will always be able to get the job done in a professional development project. Written by experts in their field, Pro series books from Apress give you the hardwon solutions to problems you will face in your professional programming career.",
    "author": [
      {
        "family": "Foxwell",
        "given": "Harry"
      },
      {
        "family": "Tran",
        "given": "Christine"
      }
    ],
    "edition": "1st",
    "id": "10.5555/1540613",
    "issued": {
      "date-parts": [
        [
          2009
        ]
      ]
    },
    "publisher": "Apress",
    "publisher-place": "USA",
    "title": "Pro OpenSolaris",
    "type": "book"
  },
  {
    "ISBN": "0130122475",
    "abstract": "From the Book: PREFACE: Introduction: How to Use This Book What Makes This Book Unique This book is intended to be a comprehensive reference to Informix products. It provides a substantial amount of detail as well as reference information. You can find much of this information in the many Informix manuals, but this book organizes it into one place and helps you find additional information. In addition, the book works in conjunction with its CD and Web site (www.informixhandbook.com) to provide a complete and long-term, ongoing reference. We want this to be one reference that can be on the shelf of any Informix developer or administrator. The information is organized into various functional groups, simplifying the process of finding what you need. My vision in designing this book is this: Create one reference that will help every level of Informix database administrator, application developer, system administrator, and end user. Organize the information in an easy-to-find fashion for all major Informix product lines. In conjunction with the book, its CD, and Web site, provide appropriate examples and detail, directing the readers to additional places to look for information. Supply a reasonable amount of \"behind-the-scenes\" information but focus on functionality. Use authors that specialize in particular Informix products and are well known in the Informix world. Make this the book to choose if you would like one reference on Informix. That’s a pretty tall order, isn’t it This book does not claim to be \"everything to everybody\" but it can help you on many different levels. If it can’t provide a specific answer, it will tell youwhereto find the answer. One of the major values with this book is that its Web site (www.informixhandbook.com) provides updated reference material for each chapter as well as numerous links that help you find more information. Many comprehensive Informix references in the world just don’t exist–at least not one-volume references–and I’m one Informix devotee who wants to fill that gap. The book also spans different versions of Informix. We provide plenty of information to get you up and running with older versions of the product, including INFORMIX-SE and OnLine Server (version 5.x). We offer more of a focus on the family of Informix Dynamic Server (IDS) products, including IDS versions 7.x, IDS.2000, Informix Internet Foundation.2000, and the data warehouse products. You may already know the names of many of the authors of this book. They were chosen from the local and international user groups as well as Internet newsgroups, ensuring that you will learn from some of the most knowledgeable Informix experts in the world. When choosing authors, I considered critical the fact that they had a special focus in the areas about which they wrote. In addition, all authors worked within the design and vision of this book, helping provide a consistent look and feel. To ensure overall consistency, I read and edited all of the chapters after they were submitted. We make this book more enjoyable by sprinkling it with amusing stories from Informix employees and others in the industry. These stories help add spice and make your learning experience much more enjoyable. All the way from this introduction to the CD-ROM to the Web site, we are crafting this book to meet the needs of Informix users worldwide. Please learn how to use it and have fun with it! The Web Site: An Ongoing Reference This book was designed by technologists who believe in using the best tools for the job (I guess that’s why we choose Informix products!). One of the major values that I think you can find with this book is that it has a very useful Web site. The site is designed to enhance and supplement the book on an ongoing basis. Using it in conjunction with this book, you will always be \"current\" on what is going on with Informix and the particular products. The site is found at www.informixhandbook.com and includes the following: Many informational Web site links about Informix and its products Enhanced and current information for each chapterfor example, if a product has changed or enhanced, we discuss it Further Web site links for each chapter Errata (error corrections, if any!) for each chapter Ability to use our monthly e-newsletter, which provides news and information about Informix and the book The latest Informix announcements and product information When the next edition of the book is released, most of the updates for each chapter will be included in the book. I truly intend the site to make this book a long-term, complete reference for your Informix needs. Please be sure to view the site and learn how to use it. If you want monthly news and updates about Informix, be sure to subscribe to our e-newsletter. As you read through each chapter, be sure to check the Web site for any new or updated information. I think that the site will prove to be a great value you are receiving by purchasing this book. Our Target Readers This book is designed to be an excellent tool for all levels of Informix users, including: Application developers Database administrators Informix server administrators End users The information is designed and organized in such a way that it should be easily accessible by all of these groups. As you’ll soon see, the book is divided into six major functional sections, placing related information together. In addition, each chapter has numerous cross-references that help you know where to find more information. The book can help all types of users because it provides many levels of instructional information, detailed reference and review materials, and links for where to get more information. The remainder of this introduction explains how to use the book to its fullest capacity. What You Can Gain from This Book This book helps you understand current and future products and technologies related to Informix. We describe \"how Informix works\" and how to use Informix servers and their application development tools. We help you with database administration, server setup, and operating system interaction. We also discuss new technologies like Web/database applications and Informix Internet Foundation.2000 and how they fit into the future of Informix. As previously described, one of the main values of this book is its Web site. The site turns the book into an ongoing reference–it provides updated information on each chapter, errata (correction of errors in the book), and numerous Web site links that are grouped by functional category. The book provides references and working examples of the main functional areas of Informix. Our intent is to let you use the book in many different ways, each helping you find information for the Informix product lines. The extensive cross-referencing helps train you where to look for more complete answers. By consulting with many others in the Informix world, we believe that the organization of the book provides a long-desired \"one-stop shopping\" reference for Informix. This is accomplished by: Organizing the sections into major functional areas Creating a Web site that provides ongoing information about Informix and its products Selecting writers that are well known in the Informix world Providing examples that apply to major areas of Informix usage, spanning different products and servers Supplying excellent cross-references to finding more detailed information by using other reading materials and the World Wide Web Using the CD-ROM to efficiently allow searching and referencing information The design of this book follows these principles and should allow you to know exactly how to find the information you need, be it from this book or another reference. How to Use This Book, the CD, and the Web Site This book provides a unique way to get the information you need about Informix. From its beginnings, the book itself was structured to help you understand the core information about various aspects of Informix. But as the book progressed, so did the Web and other technologies. At that point, I decided to create an even better way to get the information to you. Here’s how it works: This book usually serves as your starting point. You can try to find the exact information that you need in the appropriate chapter. If you can’t, each chapter has references that direct you to more information elsewhere in the book, Informix manuals, the Web, or other books. If convenient, you can check the other books or manuals, or continue with the rest of this list. Check the book’s Web site for the specific chapter. You might find updated information about the material or Web site links to direct you to more information. In addition, you can use the site’s search feature to try to find an answer. After that, you can use the site’s \"Information about Informix\" links. Finally, the site offers an e-newsletter that will keep you updated on news about Informix and the book. Check the book’s CD-ROM for additional answers. You can use the well-organized information in the CD to find documentation or tools that you’ll need. Also, be sure to watch the Web site for CD-ROM upgrades and search capabilities for the CD. All in all, the book, its CD, and Web site should help you find the answers you need. The following sections provide detail about each of these items. How This Book Is Organized Let’s take a look at the organization of this book. The book is broken into six major functional sections. You will be able to easily determine where to look for answers. Within each of the six sections, chapters provide more detail. Here is a summary of the sections: I. Core Concepts of Informix This section describes the Informix Corporation, its products, and the future plans of Informix. We begin by giving a history of the Informix Corporation and how it evolved into what it is today. We describe the different types of Informix databases and tools and how they fit into your needs. Chapter 3 helps you get started; it teaches you how to use Informix’s sample stores database and its utilities. Chapter 4 provides an extremely detailed view of what’s behind the architecture of Informix, now and into the future. Chapter 5 describes the Informix version of SQL and how to use it. Finally, the last two chapters in this section show you how to access data in Informix databases and describe Informix’s data warehousing direction. II. Informix SQL In this section, we provide detail about how to use Informix’s version of SQL. We describe and show you how to create databases, tables, and indexes. We give detailed examples and tips about how to use the Informix SELECT, UPDATE, INSERT, and DELETE statements. Stored procedures and triggers are discussed, as well as other miscellaneous Informix commands. Finally, Chapter 16 explains some of the additions to Informix in version 7.30. All in all, this section gets you \"online\" with Informix and allows you to access data. III. Server Administration This section explains how to administer Informix database servers. The section is split into two sub-sections: Setting Up Informix and Ongoing Administration. We describe everything from simple INFORMIX-SE installations to detailed Informix Dynamic Server administration. We provide detail about how to set up and debug various servers on UNIX, NT, and Windows 2000, and describe how to work with the operating system. We help you set up your configuration parameters (the onconfig file, for example) and troubleshoot problems. We provide a comprehensive functional reference of the command-line utilities, such as onstat (complete syntax for this command is given in the appendix). Finally, we help you learn how to keep your servers up and running and how to back them up. As always, we tell you where to find more detailed information. IV. Performance Tuning The Performance Tuning section describes performance tuning both for application developers and Informix administrators. We explain how to use the tools that Informix provides, how to interpret the output, and how to make changes. For application developers, we offer a summary of fundamental design and tuning issues, and information about how to work with Informix tuning methodologies such as SET EXPLAIN and UPDATE STATISTICS. We give a detailed description of how to use the newer tuning tools, including SMI and the sysmaster database. For administrators, detailed sections explain how to work with a number of tools and methodologies and how to continue to monitor performance. V. Application Development This section explores the application development tools and methodologies available for Informix products. We explain how to make your databases work on a network by using Informix connectivity tools. We describe overall strategies for application development and how to plan for the future. Detailed sections are available about specific Informix tools like 4GL, Dynamic 4GL, Ace Reports, Perform Screens, and reporting tools. VI. Web Applications and Object Relational Databases This section focuses mostly on Web applications and how object relational database management systems (ORDBMSs) might fit into your future. Simply put, no one can deny that objects and the Web will enable database systems well into the 21st century. This section goes into detail about what these methodologies mean, how they are used, and how they might be used with Informix products. The first two chapters provide an overview of current Web technologies and how to use them in a database-enabled Web application. After that, we describe how to use Informix Internet Foundation.2000, its DataBlades, and other tools. Again, we help point you to the right resources so that you can remain on top of object technologies and how they fit into your future. VII. Appendices The appendices provides copies of many useful reference materials, Web site addresses, tools, and other information. The appendices alone will serve as an excellent desktop reference for just about any Informix user! We include Informix utilities (which are also on the CD-ROM) and describe how they work. We show you how to maximize the Informix resources like Informix Developer’s Network, user groups, newsgroups, and the Web. The appendices also provides a comprehensive glossary of Informix-related terms and a more complete reference on INFORMIX-SQL and command-line utilities. Don’t miss Appendix F, \"Quick Up-and-Running Guide,\" which provides a quick reference of how to install and configure Informix products from the box to being online. After that, a list of sample queries and command line utilities help you see how to implement various Informix commands. Finally, the extremely detailed Glossary explains a large number of Informix-related terms and concepts. As you can see, we have very carefully split the sections of this book so that information is easy to find. We fully intend to provide an excellent reference for your Informix needs and make it very easy to use, now and long into the future. Now, let’s find out about Informix and why we’re doing this in the first place. Structure of Each Chapter The chapters are formatted to make finding information easy. Here is a summary of the items in each chapter: Summary of the information in the chapter. At the beginning of each chapter is a brief overview followed by a list of the major topics that are included in the chapter. List of topics, split functionally into subcategories. Within each chapter are several small sections, each explaining a certain category of information. Within each of these sections are sub-sections, providing details. By looking at the table of contents, you should be able to quickly find what you need. Notes, tips, warnings, Web links, and other chapters, code listings, and diagrams. The chapters are rich with specific items of interest (notes, tips, warnings) and references to other chapters, books, and Web sites. In addition, many graphical figures and code samples are provided to help enhance your understanding. References to other chapters. At the end of each chapter is a section called \"For More Information.\" This points you to other chapters in the book that relate to the current chapter. Informix and Other References. Following the \"For More Information\" section, this tells you which Informix manuals and other books can further help you. I’m confident that you’ll find the structure of these chapters very easy to use. You may want to take a quick look through some of the chapters or the table of contents to better understand this structure. Contents of the Web Site The Web site is one of the core parts of this book’s solution. Because it is so important, I described it in the previous section, \"The Web Site: An Ongoing Reference.\" To summarize, the site will be constantly updated, providing additional information about each chapter, as well as current and useful Web site links. The idea is to use the book in conjunction with the site to provide a complete solution. The site can be found at www.informixhandbook.com. Contents of the CD The CD includes a Web browser-driven interface that allows you to easily locate information by using your Web browser. Simply insert the CD and open the index.html file in the root directory. The CD includes a plethora of utilities and SQL files, allowing you to copy commands and utilities that you can use. In addition, the CD includes the following: Informix Guide to SQL Syntax The Administrator’s Guide for Informix Dynamic Server (official Informix version for 7.3) A copy of Informix Dynamic Server for Linux and NT All of the book’s SQL statements, scripts, and programs (i.e., all that were included as Listings) A computer-based training (SmartForce) course entitled \"Managing the Instance\" Several whitepapers Easy-to-use links to the book’s Web siteif you are online when using the CD, you can use various links that send you directly to the proper portion of the Web site Hundreds of utilities for administering or programming for Informix products. Products are written in shell scripts, SQL, 4GL, and C. A trial copy of Server Studio from AGS (www.agsltd.com), a comprehensive GUI-based tool for Informix databases In addition, on the Web site we will offer enhanced search functionality and a possible upgrade for the CD. As you can see, the CD, Web site, and the book work together to give you the information you need about Informix. Considering the Future One of the goals of this book is to help you consider the future of technologyand Informixin your design and development of applications. We, the authors of this book, made a special effort to consider how database technology and application development will be evolving. And you should, too. What works now might not integrate or make use of upcoming technologies. This book and its Web site provide you with details about how technology is changing and how to take keep up with its evolution. Again, we provide many cross-references so that you’re sure that you have the latest information. We have dedicated an entire section to Web technologies and object-relational databases. Section VI, \"Web Applications and Object Relational Databases,\" describes object technology and how to use Web applications and Informix Internet Foundation.2000 as well as DataBlades. The Web is going to be a big part of the future of database and application development. Chapter 41, \"Web Application Overview,\" explains the concepts behind Web computing, and Chapter 42, \"Building Web/Database Applications,\" explains how to use Java and other tools to create an Informix-enabled Web application. Again, using the book along with its Web site should help you keep current about the best ways to create Informix applications. For More Information... This introduction provided an explanation of the goals and layout of this book. Please skim through the book so that you can really understand how and why we organized it the way we did. We’re hoping that you find this book extremely easy to use, providing detail, reference, and even some amusement. Don’t forget to use the Web site or the CD-ROM and its HTML-driven menu. Here are some other good places to start: To find many different tools and references, see this book’s CD. For complete and up-to-date information on the material in the chapters and current Informix information, see the book’s Web site at www.informixhandbook.com. For more history of Informix, see Chapter 1, \"Now and the Future,\" and Chapter 2, \"History of Informix: Live from Silicon Valley.\" For an explanation of Informix database servers and products, see Chapter 1, \"Now and the Future.\" To find out how to start using Informix now, see Chapter 3, \"Creating and Using the stores Database.\" For an explanation of Informix architecture, see Chapter 4, \"Understanding Informix Architecture.\" For a complete reference and examples of Informix SQL, see Section II, \"Using Informix SQL.\" For complete details about administration, see Section III, \"Server Administration.\" To find out how to tune your Informix servers and programs, see Section IV, \"Performance Tuning.\" To obtain a better understanding of how to develop applications in Informix, see Section V, \"Application Development.\" For many references about the Web and object relational technology, see Section VI, \"Web Applications and Object Relational Databases.\" For large amounts of reference material, see the book’s appendices. Don’t miss Appendix F, \"Quick Up-and-Running Guide,\" or the intensive Glossary.",
    "author": [
      {
        "family": "Flannery",
        "given": "Ron M."
      }
    ],
    "edition": "1st",
    "id": "10.5555/517956",
    "issued": {
      "date-parts": [
        [
          2000
        ]
      ]
    },
    "publisher": "Pearson Higher Education",
    "title": "The informix handbook with cdrom",
    "type": "book"
  },
  {
    "ISBN": "1576103498",
    "abstract": "From the Book: Introduction Introduction This book is about power, the growing power of databases, computers, and networks to slash costs and dramatically increase effectiveness of communications and management. Databases touch everyone’s lives in some way or another, and a clear understanding of what works and what doesn’t puts that power within reach. This book is aimed at everyone who must participate in a database project to ensure success: database designers, end users, database administrators, senior managers, front-line managers, as well as those who must wear all these hats at once. • For experienced database designers and administrators, this book contains complete coverage of Microsoft Access 2000 in easy-to-understand (and use) examples, with plenty of reusable code and screen shots. • For managers and end users, this book contains plain-English explanations of how databases are constructed, what the limitations are, and a broad, exciting view of the potential. • For those who must act as designer, manager, and user, this book takes you from the most basic fundamentals to the most advanced programming steps, without requiring a degree in computer science. In every sense of the word, this book is a practical, day-to-day guide for people involved in building database solutions. Not only does it guide you through the phases of successful database projects (large and small) and the pitfalls that have ruined some, it teaches you the language and terminology used on all sides as you go: project management, process reengineering, relational models, programming fundamentals, and so on. The emphasis throughout the book is on enhancing communications, because clear and timely communication is the primary attribute of a successful database solution. Communication takes work. Everyone must be working from the same playbook for a database application to be effective and achieve widespread use. Traditionally, databases have been designed by computer scientists far removed from the day-to-day activities of work. A team of systems analysts would show up one day, gather what information they could about a process, then spend a year or two in the ivory tower building the application. The application would be instituted, workers trained to fill out the forms, and the reports would print, all according to the now-dated but assuredly very accurate specifications. For some applications, this system worked quite well, but for others it failed miserably. Where failure occurred, the primary cause was rapid change: changes in processes, requirements, business conditions, even changes in computer literacy. Today, because change is constant and the pace of change continues to accelerate, only excellent communication among everyone involved can overcome the swirling confusion born of change. This book gives everyone the playbook that they need to achieve these implementation goals. It takes the best of all traditional methodologies for rebuilding an organization’s processes and for developing and constructing database solutions, explains them concisely, and blends them together into a powerful toolkit for building effective applications in a rapidly changing environment. The power of Microsoft Access 2000 combined with the proven methods outlined in this book increase the probability that your database application, no matter the size, will \"work\" from all perspectives. For the managing members of the team, the book helps you create a plan for effective and consistent implementation of your applications, whether destined for internal use throughout the enterprise or for public consumption. For those responsible for the creation of the implementation-the developers, power users, and users who will interact with the application on a regular basis-this book teaches you everything you need to know about making the application not only perform its tasks, but perform them well. No matter what environment you are developing for-from standalone databases at workstations to databases that will serve intranet and Internet users-this book teaches you how to address development issues in that environment and make sure your product not only works, but shines. Real-world examples, step-by-step explanations, and thousands of lines of program code all work together to ensure that you have all the tools you need to be successful. Contents Of This Book This book is divided into 8 parts, intended to guide you through the steps of database development with Access from beginning to end. Part I, \"Fundamentals Of Information,\" contains three chapters that consider the nature of information and how information relates to the design of databases. The three chapters in the section, Chapter 1, \"Foundations For Database Construction,\" Chapter 2, \"The Nature Of Information,\" and Chapter 3, \"Data Organization,\" guide you through the principles of information theory and the ways in which data is organized. Each chapter provides you with important information that you must understand to master effective techniques of database design. Part II, \"Database Fundamentals,\" takes the information theory that you learned about in the first three chapters and brings it to the level of database design theory and principles. Chapter 4, \"Relational Databases,\" introduces you to the principles of database design when working with relational databases like Access 2000. Chapter 5, \"Database Structures,\" looks at the overall theory of database design and reviews the principles of relational database design that you learned in Chapter 4. Chapter 6, \"Advanced Database Systems,\" considers the nature of advanced database architectures and the networks required to support them. By the time you finish Part II, you will have a solid knowledge base for database design-not only with Access, but with any relational database product. Part III, \"Modern Database Implementation,\" moves on to some of the specific types of database uses in business today. Chapter 7, \"Data Warehousing,\" covers the construction of data warehouses in depth. Chapter 8, \"Applications and Operating Systems,\" covers practical application and operating systems (OS) issues, namely, how to decide whether to buy or make apps and OSs, and how to find and use them if you do decide to buy. Chapter 9, \"Marketing,\" discusses the important considerations for you to keep in mind when preparing to distribute your Access products. From identifying your target market to measuring and adjusting your market strategy, effective marketing techniques can make a product successful or, if implemented poorly, can ensure it never sells a copy. Part IV, \"Microsoft Access 2000 Overview,\" contains four chapters that address the specific improvements and changes to Access 2000, and the specific purposes for which Microsoft designed the Access 2000 product. Chapter 10, \"Access 2000 Technologies,\" gives you a broad overview of some of the many component technologies that Access uses to simplify user access. Chapter 11, \"New Features And Trends In Access 2000,\" considers some of the directions in which Microsoft has moved the Access product, including a discussion of the new Jet 4 engine and new integration with Microsoft’s BackOffice products, specifically SQL Server. Chapter 12, \"Access Purchasing And Installation,\" discusses such important implementation issues as who needs Access installations and what level they need, what the different types of Microsoft Office suites are, and specific installation concerns to keep in mind when purchasing the new Access 2000 product. Chapter 13, \"Access 2000 Distribution And Training,\" addresses specific issues related to the deployment of the Access program in your enterprise. It also discusses built-in training support in the Access product and issues to consider when determining how and who to train. Part V, \"Microsoft Access 2000 Usage,\" contains three chapters, each of which considers a general category of the target market for the Access product and how to design databases for that market. Chapter 14, \"Access For Personal And Small Office/Home Office Use,\" addresses common uses of Access at home and in the small office setting. It discusses both common situations in which you might use Access databases and ways in which to create those databases. Chapter 15, \"Using Access In A Corporate Environment,\" addresses common techniques for Access deployment within companies. It also contains your first introduction to the new Access Data Projects (ADPs) and their use as a SQL Server database front-end. Chapter 16, \"Using Access For Scientific And Medical Purposes,\" considers common methods and implementations for Access in the scientific and medical communities. It also provides an introduction to the use of Access’s graphing capabilities and presents useful information in both types of deployment environments. Part VI, \"Database Application Design Reference,\" moves on to the creation of databases in Access 2000. The five chapters in this section provide you with a method that you can use to define and create databases to meet any need. Chapter 17, \"Problem Definition And Design Planning,\" discusses the specific steps you should take in planning the design of a database to solve a particular problem and walks you through an extended example of these crucial steps in the design process. Chapter 18, \"Planning And Design,\" moves on to the specific discussion of designing a database in accordance with the design planning that you performed in Chapter 17. Chapter 19, \"Database Construction,\" shows you how to take an actual design diagram and convert it into table and database definitions in Access. Chapter 20, \"Implementation-Beta Testing And Bug Checking,\" moves on to the testing and implementation phases of application design, including discussions of the testing process you should use and more. Chapter 21, \"Completing The Implementation,\" discusses post-release improvements you can make to the application, including optimization, compacting, and repair of the database, as well as using the Access-provided tools to analyze and improve performance of your application. Part VII, \"Microsoft Access 2000 GUI And VBA Programming Reference,\" covers the low-level, \"nuts and bolts\" of Access 2000 programming. The chapters take you from the initial creation of a database and its component tables through advanced programming with ActiveX Data Objects (ADO), Data Access Objects (DAO), and database management and security. Chapter 22, \"Installation, Setup, And Configuration,\" discusses the installation specifics of the Access product, including the options you have during setup. It also introduces you to some of the specifics of Access database design-both for the standalone and the client-server environment. Chapter 23, \"Developing Tables And Relationships,\" introduces you to the specifics of table creation and relationship definition, the core of database design. Chapter 24, \"Creating Queries,\" takes you into the heart of relational database work, by teaching you how to create the different types of queries that lie at the heart of SQL’s power. Chapter 25, \"Creating Forms And Reports,\" teaches you the knowledge you need to create user interfaces and design effective reports that output data in the most usable form. Chapter 26, \"Creating Macros And Modules,\" explains Access’s macro language and introduces you to modules, which will contain Visual Basic for Applications code-code which will, in turn, unlock significant additional power for your database applications. Chapter 27, \"Using Modules And Visual Basic For Applications,\" builds on the knowledge you gained in Chapter 26 to teach you what you need to know about writing VBA programs to \"power-up\" your Access applications. Chapter 28, \"Working With DAO And ADO,\" introduces you to the database objects that VBA lets you use to manipulate Access, SQL Server, Oracle, and other ODBC- and OLE DB-compliant databases. Chapter 29, \"Using Class Modules With Access,\" describes some basics of object-oriented programming and how you can use VBA class modules to implement custom objects within your Access 2000 applications. Chapter 30, \"Advanced Database Design Techniques,\" shows you how to take advantage of VBA and Access’s built-in features to make your applications more professional. It also focuses in-depth on the administration of security within your Access database. Part VIII, \"Microsoft Access 2000 And Client-Server Development,\" contains five chapters that teach you about client-server programming with Access 2000 and different server-based database products, as well as how to create World Wide Web front-ends for Access or server databases. Chapter 31, \"Client-Server Programming With Access 2000,\" introduces you to SQL Server and working with back-end products from Access. It also covers, in detail, important conceptual information about client-server design that is applicable to any back-end. Chapter 31 also introduces you to the Microsoft SQL Developer Engine (MSDE), a local implementation of SQL Server that you can use to design SQL Server databases on your development machine. Chapter 32, \"Using Oracle And Access For Client-Server,\" teaches you the fundamental concepts of Oracle database design and the differences in development between Access front-ends for SQL Server and Oracle. Chapter 33, \"Advanced Client-Server Techniques,\" takes the knowledge from Chapters 31 and 32 and sends it to the next level with important information about topics such as triggers and stored procedures, transaction processing, Access Data Projects (ADPs), and more. Chapter 34, \"Web Front-End Development,\" moves to the largest client-server environment in the world-the Internet. It covers historically proven and commonly used techniques for exposing databases through HTML pages. Chapter 35, \"Using Data Access Pages For Web Front Ends,\" moves on to Microsoft’s proprietary Access front-end technology, Data Access Pages (DAPs), which let you develop highly customized, highly responsive front ends for your Access databases, all from within the Access Interactive Development Environment (IDE). In addition to a complete index, the book also contains an appendix of additional resources. From the first 9 chapters that step you through the fundamentals of database design and relate them to good programming practice and business process reengineering, to the next 26 chapters that cover every detail about how Access 2000 works (including how it interacts with the Web and mainframe databases), the purpose of this book is to build a common ground on which all people, from the novice user to the most sophisticated IT developer, can work together. Remember, people in organizations today recognize how important it is to make the powerful software tools on their desktops useful, and they need a tool like this book to make it happen.",
    "author": [
      {
        "family": "Klander",
        "given": "Lars"
      },
      {
        "family": "Mercer",
        "given": "Dave"
      }
    ],
    "id": "10.5555/553611",
    "issued": {
      "date-parts": [
        [
          1999
        ]
      ]
    },
    "publisher": "Coriolis Group Books",
    "publisher-place": "USA",
    "title": "Access 2000 developer’s black book with cdrom",
    "type": "book"
  },
  {
    "ISBN": "0201758210",
    "abstract": "From the Book: Purpose of this Book The convenor of the OOSIG (object-oriented Special Interest Group) of the Australian Computer Society is occasionally referred to as Chairperson. For past two years, this honorary and honourable title has been conferred upon me and, as the title suggests, it provides me with — amongst other things — the unenviable job of moving and organising chairs before the monthly meeting starts and ensuring they are stacked back against the wall after the meeting in the societys office is over. Getting the flipcharts and whiteboard ready, booking the room, sending the invitations, organising coffee and keeping the data projector light bulb from blowing up are some things keep the adrenaline level of the chairperson always on high. However, I had no such challenges to face when Canada-based Bran Selic, kindly addressed my SIG. Many members turned up to listen to one of the original contributors to the Unified Modelling Languages meta-model, particularly to the behind-the-scene stories. One of the interesting features of Brans talk was the candid highlighting of the strengths and weaknesses of the UML. Couple of reasons for UMLs popularity, as emerged during the talk were: UML is a standard and therefore accepted within the larger IT community, and UML came on the IT scene at the right time. The UML fills the void that existed in software development — a modelling mechanism that enables capture and expression of requirements, documentation of design, facilitates architectural discussion and supports software implementation. The modelling capabilities of the UML, supported by CASE tools, are widely usedin numerous practical software projects. Further, professional training courses on business analysis, architecture, design and testing are routinely based on the UML standard. The UML is also popular in the academic world as many university courses use the standard notations and diagrams of the UML to teach the students principles of software engineering. Finally, through relatively less-technical and more business-focused works, object technology and the UML have shown to be capable of being used in non-software related work, such as modelling business processes (BPR), business workflows, and even software workflows. Despite its popularity, however, the UML literature still needs discussion on and application of quality with UML. While we have some excellent literature on the processes of software development it seems to fall short of separate and detailed discussions on quality. On the other hand, works like Binders focus on the technical aspects of testing, using the UML notations, do not provide the process-aspect of improving the quality of software development. Indeed, none of this literature deserves any criticism for the lack of quality discussion — because these literary works do not purport to be discussing quality. The focus of these respectable and popular works is either development or testing. This book is written with an aim of directly addressing the paucity of literature in the area of process quality assurance for UML-based projects. Good Quality is all about satisfying the needs of the user. However, good is a highly subjective term. The reference-point against which quality is judged depends on time, place, and situation — all of which can change! Hence, the essential ingredients in producing good quality are: A product that satisfies the changing needs of the user A process that enables creation, verification and validation of such a product A common mechanism to establish communication Continuous improvement of the process of producing product When applied to software development, these quality requirements translate into producing a software product that would evolve, scale and change, according to the needs of its users — primarily the business. Not only do we need a process for developing such a software product, we also need significant checking and crosschecking of the models and processes that have built the software product. There is a need to ensure the syntactical correctness, semantic consistency and aesthetic symmetry in the models that will be used to produce good quality software. There is also a need to create, follow and check all necessary process steps in order to achieve maturity of processes that will result in good quality software products. Furthermore, these process steps must be executed iteratively, incrementally and sufficiently. Process steps should also be malleable enough to suit various development environments, and various types and sizes of projects. The specific and significant areas of quality related work required in a process incorporating the UML are addressed in this book. The quality techniques discussed in this book include how to organize the overall quality function, the process steps to be followed in creation of UML diagrams, the steps in verification and validation of these diagrams, when to conduct such verificat how the interpret the results of quality activities, who should create and validate the UML diagrams, and how to create a quality control (testing) strategy. Because of the process focus in this book, the techniques of creation of UML diagrams is assumed to be known to the readers. Summary of the Book This book is divided into 6 chapters as summarized below. Chapter 1: The Quality Game In this background chapter on quality assurance we discuss the elusive nature of quality in the context of software. Modelling, particularly with the UML, is shown as means to improve communication and quality and is conducted in the three distinct yet related modelling spaces of Problem, Solution and Background. Process is discussed in the context of its three dimensions of technology (what), methodology (how) and sociology (who). This is followed by discussion on the various checks (syntax, semantics and aesthetics) needed to validate and verify UML-based models and the checks of necessity, sufficiency and malleability needed for a good quality process. Organization of the quality function, and its application to various types of projects (development, integration, package implementation, outsourcing, data warehousing, and educational) as well as various sizes (small, medium, large) of projects are also discussed here. Chapter 2: Quality Environment: Managing the Quality function Process aspect of quality encompasses the management functions of creating and managing a quality environment. This is because software quality is not just verifying and validating what has been produced but also a sustained effort at following the discipline of producing models and software. This discipline encompasses the process or the steps involved in producing good models and good software. This part of this book comprehensively considers organization and execution of the quality function with detailed emphasis on the process of developing UML based software. In other words we discuss how the quality function is organized and carried out in UML-based projects. The people issues (who) is also given due relevance in this part of the book. Chapter 3: Quality Process Architecture This chapter discusses what constitutes such a process, and how it will be helpful in enhancing quality in a UML-based project. This chapter does not propose a new process, but discusses a most generic Process including the Technological, Methodological and Sociological dimensions — what constitutes a process, and what are its major dimensions of a process is described here. The technological dimension of a process deal with the what, the methodological dimension with the how and the sociological dimension with the who, of an overall process. These dimensions are described with common workday examples. Furthermore, the generic process also describes the most commonly used activities and tasks that should be there in any process. These activities and tasks, and the related roles and deliverables, are described with the aim of improving the discipline in a process, resulting in enhanced quality of UML-based deliverables and eventually the software product. Chapter 4: Enacting the Quality Software Process In this chapter we discuss the enactment of an example process including practical issues of configuring an iterative, incremental and parallel project plan, based on the process-components discussed in the previous chapter, are discussed here. We also discuss practical issues of tracking the progress of a project as well as modifying the project plan based on that tracking. An iterative and incremental project plan will facilitate better absorption of changes than a sequential project plan. Creation and management of such a changing plan, derived from the malleability aspect of the process, are also discussed here. This chapter discusses what happens when the rubber hits the road in terms of application of a process. Chapter 5: Estimates and Metrics for UML-based Projects This chapter discusses the important issues of measurements and estimates in UML-based software projects. Starting with an argument for the need to make good estimates, and how good metrics help in making good estimates, this chapter delves into the importance of these measures and estimates in improving the quality of models and processes in the project. Technical measures related to sizes and complexities of the UML artefacts and diagrams is also discussed. Estimates for the example implementation project using the UML are shown with a view to demonstrate the application and significance of metrics in a practical project. Chapter 6: Testing the product This chapter will discuss in detail the quality control and testing aspect of a quality lifecycle. While we discussed process quality in previous chapters, quality control, or testing, is a major process-component dedicated to verifying and validating the results of our efforts thus far in creating models and following a process. Good quality control is inherently negative as it is aimed at breaking everything in a system — its logic, its execution, its performance. Thus, although Quality control is an integral part of quality assurance, but is not synonymous with it. This separation is given its due importance in this separate part of this book. CD &amp; Potential Web Support The CD contains details of the chapters, diagrams, and a set of templates that can be customised for use in projects. Suggested metrics for improving quality (e.g. size of use cases, effort in creating classes) are also incorporated in the CD. Evaluation copies of relevant process tools that deal with quality process have also been provided, with permissions. Literary Audience There are a large number of books written on UML and similarly on processes. Their scope encompasses both academic research and practical applications. This book attempts to synergies the application of quality processes in UML-based projects. With the process focus, the reader is expected to be familiar with UML and its modelling techniques as the book does not purport to discuss the modelling techniques of the UML. However, a person responsible for quality assurance will find this work self-sufficient and may even be encouraged after reading this material to extend their understanding further in to UML. Semantics This author firmly believes in gender-neuter language. Person is therefore used wherever possible. However, in order to maintain simplicity of reading he has been used as freely, and has been balanced by equal, if not more, use of she. Terms like programmer and quality manager, unless otherwise mentioned, represent roles performed by actors. These terms dont tie down real people like you and me who, in a short span of time, can jump from the role of a programmer to a quality manager to a director and back. It is also recognised that people may be playing more than one role at a time. For example, a business analyst may also be a part-time academic or a researcher. We throughout the text primarily refers to the reader and the author — you and me. Occasionally, we refers to the general IT community of which the author is a member. We also refers to the teams in which the author has worked. Therefore, although this is a single author book, you may encounter we as a reference by the author to himself, as well as to the IT community. Real conversations, as you and I are having through this work, cannot be statically typed. Mapping to a Workshop The practical aspects of UML and Quality, displayed in this book, have been popular in seminars and conferences. Amongst many presentation, particular noteworthy are its acceptance as a tutorial at the UML2001 conference in Toronto, Canada and the two-day seminar series in Mumbai, Bangalore and Delhi, in India. Here is a generic outline of the two-day workshop based on this book. For the education and academic community, each chapter in this book can correspond to a 3-hour lecture topic, with earlier part of the semester used in simply creating the UML-based models based on the case study. Acknowledgements Encouragement and support can take various forms —a word of encouragement here, hint of a smile there! And then there are those detailed discussions and arguments with honest reviewers of the manuscript on what should be included and how it should be presented. This is interspersed with the arduous task of typing sections of the manuscript, drawing the figures and the rather trying job of proofreading someone elses writing. All this has come to me through many wonderful people whom I acknowledge here gratefully: Anurag Agarwal Rajeev Arora Craig Bates Paul Becker Christopher Biltoft Bhargav Bhatt Graham Churchley Kamlesh Chaudhary Sandra Cormack Joanne Curry Sanjeev Dandekar Edward DSouza Con DiMeglio Julian Edwards Nandu Gangal Athula Ginige David Glanville Mark Glikson Nitin Gupta Brian Henderson-Sellers Murray Heke Ivar Jacobson Sudhir Joshi Ashish Kumar Vijay Khandelwal Akshay Kriplani Yi-chen Lan Chinar &amp; Girish Mamdapur Javed Matin Sid Mishra Rahul Mohod Navyug Mohnot Narayana Munagala Karin Ovari Les Parcell Chris Payne Andrew Powell Abhay Pradhan Amit Pradhan Anand Pradhan Prabhat Pradhan Rajesh Pradhan Tim Redrup Tracey Reeve Prashant Risbud James Ross Magdy Serour Bran Selic Ashish Shah Paresh Shah Prince &amp; Nithya Soundararajan Pinku Talati Amit Tiwary Murat Tanik Asha Unhelkar Sunil Vadnerkar Suresh Velgapudi John Warner Houman Younessi Paul Becker, my editor at Addison-Wesley, has provided invaluable support in this work and deserves special recognition. Bearing with my delayed submissions, passing encouraging comments when the progress was slow and accommodating my changes up to the last minute are some of the traits of this considerate editor that are gratefully acknowledged. Finally, my family makes all this possible by just being around me even, and especially, when I am mentally lost. I am grateful to my wife Asha, my daughter Sonki Priyadarshini whose view on quality took a jagged turn as she stepped into her teens, my son Keshav Raja who can appreciate quality in cars, bikes and planes — which is the ability of these tools of the kindergarten trade to withstand punishment meted out by rather tough 6 year olds. Finally, this work acknowledges all trademarks of respective organisations, whose names andor tools have been used in this book. Specifically, I acknowledge the trademarks of Rational (for ROSETM), TogetherSoft (for TogetherControlCenterTM), Object-oriented Pty Ltd (for ProcessMentorTM) and eTrackTM. Critiques It reflects a healthy state of affairs within the IT world, and especially the UML and process community, if work of this nature receives its due share of criticism. All criticisms have an underlying rationale and that they should all be accepted in a positive and constructive vein. All comments on this work, both positive and negative will be accepted positively. Thus, to all my prospective critics, whose criticisms will not only enrich my own knowledge and understanding of the quality topics discussed in this book, but which will also add to the general wealth of knowledge available to the IT community, I wish to say a big thank you in advance. Bhuvan UnhelkarSydney, July 2001",
    "author": [
      {
        "family": "Unhelkar",
        "given": "Bhuvan"
      }
    ],
    "id": "10.5555/579266",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Process quality assurance for uml-based projects",
    "type": "book"
  },
  {
    "ISBN": "1576102505",
    "abstract": "From the Book: As a programmer or budding developer of Oracle database applications, you’re starting at the right place and with the right product by reading this book. I’ll show you how you can become proficient in the use, design, and tuning of any Oracle database. This book is written to take anybody who has a basic grounding in the use of a PC and associated software through the maze of Oracle8. I say Oracle8, not Personal Oracle8, because while this book is based on Personal Oracle8, all of the features are exactly the same in every Oracle8 database, whether it’s running on Unix, VMS, Windows NT, or Windows 95. The main difference is that on Windows 95 and Windows NT, the product is more graphically oriented-for example, it uses wizards to create tables. For this reason, when any procedures in this book are shown using graphical tools, I’ll also describe how to do the procedure from the command line (which is sometimes the only way of doing things using such operating systems as Unix and VMS). By reading and understanding this book, you should accomplish four goals: • Design an efficient database from the ground up, using Oracle’s object technology • Write simple and efficient SQL and PL/SQL code to manipulate the data within a database • Gain a working knowledge of the Oracle8 database and all its object-oriented features • Receive a large salary increase Over the past eight years as a database administrator (DBA), I have looked for books associated with Oracle and have noticed that good books aimed at the intermediate level-those you can pick up and quicklybecome productive with-are few and far between. For this reason, I decided to write my own book, based on my own experience. Starting my programming experience with version 5 of Oracle, I came to realize that you have to learn by trying first, then reading later. Because most projects in the workplace are on fairly tight schedules, you need to be able to pick up a piece of software and become as productive as possible in as short a time as possible. This book will be the guide to Oracle8 that I wish had been available when I was learning. At the time of this writing, no other book is available commercially, outside of the Oracle manuals, that deals with Personal Oracle8 and associated tools from an intermediate perspective. The purpose of this book is to cover the development of applications using Personal Oracle8 in conjunction with the documentation on the Personal Oracle8 CD-ROM. What is Oracle Oracle is an extremely complex and high-powered database; in fact, it is the most widely used database in the world. For these and many other reasons, it is generally recognized by computer programmers worldwide as the best. The Oracle database is one of the most technically advanced pieces of software available. One of Oracle’s main selling points is that it and its applications are portable across any operating system. This means that an application developed using Personal Oracle8 could quite easily be scaled up and installed on a high-end Unix server with thousands of users accessing the data. One important point to make here is that the Oracle database will run on nearly any commercial operating system, using the same human interface, known as SQL*Plus or PL/SQL. First, let me take you through the progression of Oracle releases so you can visualize what the Oracle8 database is. Versions 6 and 7 of the Oracle database are relational, meaning that the data stored is referenced by unique identifiers and grouped by relationships. In technical speak, it uses primary and foreign keys (constraints) to enforce referential integrity. Version 8 is an object-relational database. This means that it still uses the relational theory, but has added extensions of object-oriented theory. In this book, these subjects will be dealt with in more detail, and you will use some of the object theory (even though you might not realize it). The extensions of object-oriented theory add further capability to the Oracle database, in some cases allowing the programmer to apply it more easily to real-life business applications. Intended Audience This book is aimed at the programmer or the home-computer hobbyist who wishes to find out more about Oracle. I have designed the book to be used in two different ways: • You can skim through chapters and just try the demos that appear throughout the book. This will give you a good understanding of how to use the product. You can later return to the related chapters to discover the theory behind the practice. • You can follow the chapters in order and gradually build up your expertise and overall knowledge, until you have a full working knowledge of how to build applications on Personal Oracle8. In writing this book, I have assumed that the reader has some knowledge of Windows 95 and has used a database (e.g., MS Access, FoxPro, or dBase). Other people who would benefit from reading this book are: • Oracle developers who wish to know more about developing/prototyping applications on Personal Oracle • College students who wish to get a good in-depth knowledge of relational databases • Other information technology professionals who wish to keep their skills up to date by using Personal Oracle8 Personal Oracle8 Personal Oracle8, a scaled-down version of Oracle’s popular database, is aimed primarily at the desktop market (rather than Oracle’s primary market, the high-end Unix or Windows NT servers). The Personal Oracle versions came about because Oracle wanted to give its customers a trial version of the software, which they could easily install and use. The primary difference between Oracle8 and Personal Oracle8 is that on the Personal version, only single-user access is available as a server-hence, the name Personal. Therefore, the software is ideally suited for use as a single-user prototyping tool. Again, because of Oracle’s portability, a Personal Oracle database can be easily exported and imported into a large multiuser Oracle platform. This gives users an ideal development platform, because all features available on a high-end server are available to the user on the desktop, including the ability to enable a database for the Web. Personal Oracle8 is designed to be used in conjunction with Oracle’s view of the future in information technology-the network computer (NC). Oracle8 (which according to its subtitle is \"The Database for Network Computing\") has been specifically designed with the NC architecture in mind. Some of the database’s key features are: • The ability to support any number of users (in the server versions) • The ability to support any amount of data • Faster application development • Increase in cost effectiveness In reality, what do you get on the Personal Oracle8 installation CD-ROM You get one of the most technically advanced pieces of software available today, as well as a ready-made development environment for any database application-all in a low-priced, cost-effective database package for Windows 95. The Personal Oracle8 database is way ahead of its competitors in the desktop market. This book will show you how easy it is to use and implement this software, and, more importantly, it will help you understand what is going on in the database and why. Oracle’s product suite Oracle Corporation produces a lot of software aimed at nearly every type of machine and operating system. A piece of software, which usually has a generic name such as Oracle Server, is available for virtually any type of operating system. The aim of this section is to give you an idea of where the Personal Oracle8 software sits in relation to other Oracle products. A list of Oracle’s main product areas follows. Oracle8 Universal Server The Oracle8 Universal Server is, as the name implies, a server that will encompass all. The server is the core database, and a number of add-ons provide even more functionality. Some of these add-ons are listed and described here: • WebServer Option-Allows access to your Oracle database from the Web. This will give anyone with a Web browser the ability to access your Web pages. Okay, you say, what’s so new about that This option allows you to tailor your Web pages to react differently to each user accessing them. For example, imagine having a Web page that realizes who you are and, accordingly, lets you access your information from the Internet. This is done by storing your information within the database; then, when you access the Web page, the database knows who you are and can show you relevant information. • Spatial Data Option-Widely used in very large databases, such as data warehouses. This option changes the way the data is stored, allowing for quicker access to data by using a different indexing strategy. • ConText-Basically, a text search engine embedded within the database. This allows you to search unstructured text within the database, because most information is of unstructured text format (e.g., newspaper articles). • OLAP-Stands for online analytical processing of data. This option allows you to store the data within the database in different dimensions. A dimension is the way the data is categorized. For a car dealership, for example, a dimension may be the customer name, the type of car purchased, or the amount of money spent. The OLAP option allows you to store your data in either a multidimensional or relational way. • Parallel Server-Allows you to have a single database that is accessed by multiple nodes. The database is stored on a shared disk array available to all nodes. This gives you more power, because a multiple-node database is more fault tolerant. If you have one machine and it fails, then you do not have access to the database. With Parallel Server, you have an instance of the database on each node, so if one goes down the other nodes will carry on. This is extremely useful if the database is mission critical. • Video Option-Allows you to store video and sound within the database. This video and sound can then be played back, in realtime, to anybody on the network. This is the technology behind \"video on demand.\" This will allow multiple users to view the same piece of video whenever they want. Personal Oracle8 And Personal Oracle Lite Personal Oracle and Oracle Lite are scaled-down versions of their big brother, Oracle8 Universal Server. They provide access to the Oracle database on the desktop. Oracle Lite is a \"lightweight relational database that runs in less than 1MB of RAM,\" according to Oracle. It is designed for use as a mobile application-i.e., to run on portable computers. Oracle Lite supports bidirectional replication with Oracle Universal Server. SQL*Plus All databases accept commands from the user in a common language: Structured Query Language (SQL). Oracle provides a tool, SQL*Plus, which is a standard SQL interpreter; the \"Plus\" is Oracle’s added functionality. SQL*Plus is Oracle’s command-line interface to the database. By using SQL*Plus, you can interrogate the database and format the output. SQL*Plus by itself is useful, but when you add the procedural capabilities of PL/SQL, you have a tool that can easily give you access to all of the features of Oracle8. SQL*Plus and PL/SQL are used in the creation of Oracle databases. The Personal Oracle8 database uses wizards to make tasks easier for you by converting your inputs into SQL commands, then executing them against the database. The procedural option allows you to use SQL*Plus type structures within procedures, giving you the flexibility needed to write simple or complex functions or packages. In this book, you’ll see exactly how SQL*Plus and PL/SQL are used to create such procedures and functions. Oracle8 Enterprise Manager The Oracle8 Enterprise Manager (OEM) is the tool for managing the whole Oracle environment. The Enterprise Manager includes tools to monitor and interact with the database, job scheduling, and automated backup management facilities. This tool is primarily for systems administration use. Oracle8 Enterprise Manager supports new features of Oracle8-e.g., object partitioning, server backups, and security management. OEM also handles the recovery of a corrupt database by using Recovery Manager. This speeds up the recovery of databases by the database administrator. Database administration tools are available through the Enterprise Manager. Designer/2000 Designer/2000 is a business-process modeling tool. It gives the user the ability to design complex business objects and rules in an easy-to-understand way. The rules can then be implemented on the server automatically. This data modeling tool allows the designer to model an application independently of the implementation, thus giving the power to implement on multiple platforms from a single model. Developer/2000 The Developer/2000 package has three main components: Reports, Forms, and Graphics. These components combine to create an easy-to-use application development package. The easy-to-use Reports tool enables the user to create detailed and complex reports from any Oracle database. You can use Oracle Reports against a Personal Oracle8 database to produce business standard reports quickly and easily. The reports can include embedded graphics and can easily be Web enabled. Forms is an extremely powerful tool for creating front-end data-input screens. The Forms tool allows the user to create applications very quickly. When this incorporates reports, you can quite easily create and produce a professional application in a relatively short time. The Graphics tool gives picture representations of data within a database. For example, creating a pie chart from data retrieved from the database is quite easy using Oracle Graphics. If you incorporate this with either Oracle Reports or Oracle Forms, you can build up graphical reports and forms from the database with very little effort. Object Database Designer Object Database Designer is aimed at anybody who designs and builds Oracle databases and is specifically helpful when creating object-relational databases, because it includes the ability to use user-defined types within the database model. Once the database model is designed, it can then be automatically implemented, because the Object Database Designer will create the required SQL statements and execute them for you. The advantage of this is that the design is viewed graphically and a change of design can quickly be implemented on the database. The designer is tightly integrated with C++, the most common object-oriented programming language. The next step This Introduction gives you an idea of Oracle’s history and product line. Now that you know where Personal Oracle is placed in the hierarchy of Oracle software, why not install it Chapter 1 covers the quick installation of Personal Oracle8.",
    "author": [
      {
        "family": "Fieldhouse",
        "given": "Richard"
      }
    ],
    "edition": "10th",
    "id": "10.5555/522237",
    "issued": {
      "date-parts": [
        [
          1998
        ]
      ]
    },
    "publisher": "Coriolis Group Books",
    "publisher-place": "USA",
    "title": "Personal Oracle8 explorer with cdrom",
    "type": "book"
  },
  {
    "ISBN": "0130337676",
    "author": [
      {
        "family": "Mullin",
        "given": "Eileen"
      },
      {
        "family": "Rubin",
        "given": "Jared T."
      }
    ],
    "id": "10.5555/558527",
    "issued": {
      "date-parts": [
        [
          2001
        ]
      ]
    },
    "publisher": "Prentice Hall PTR",
    "publisher-place": "USA",
    "title": "Free-commerce: The ultimate guide to e-business on a budget",
    "title-short": "Free-commerce",
    "type": "book"
  },
  {
    "DOI": "10.1145/76619.76644",
    "ISBN": "0897912853",
    "URL": "https://doi.org/10.1145/76619.76644",
    "abstract": "Advice is cheap, and we all know that you get what you pay for. There are many books, courses, and seminars on how to start a business. They have been written or are presented by professionals usually with far greater experience than I. While my general management background has been invaluable, the thing that best qualifies me to address this subject is the fact that we at Strictly Business Computer Systems have recently established an Ada programming shop.I’ll share with you our experiences, from inception to the present. I must preface my remarks with the comment that they represent only our single effort in this area. I was fortunate in that my primary associates had successfully established and were operating a profitable business in the computer field, and it was their proven philosophy of adding value that became the keynote of our Ada effort.Additionally, we had the good fortune to make some valuable acquaintances early on in the process — relationships which enabled us to avoid some potentially costly pitfalls. Perhaps we can do the same for some of you.Now, to the subject at hand.What would seem to be the obvious first step in establishing any business is worth stating and that is the conscious act of making a commitment to the project. In our experience, the commitment was initially made about three years ago — two full years before the project was actually initiated. The delay occurred because the computer system integration business in which Strictly Business was totally immersed was growing at a pace that precluded devoting the time required to explore the Ada market.Then, a file less than a year ago, I joined Strictly Business with the sole responsibility of researching the Ada shop possibilities, and then managing the shop if the research was positive — which it obviously was. The fact that Strictly Business was willing to add me to the staff, as pure overhead from the business standpoint, clearly demonstrates that a true commitment existed. That commitment is really three-fold because undertaking such a project requires a dedication of, and money. Beyond that, you must assume the posture that characterizes the entrepreneur, and that is a total immersion in the business. You must identify with it and make it the focus of all that you do.If you and your organization are unwilling to pledge a full-fledged effort, your chances of success substantially diminish.Secondly, since the first phase of this project should be a marketing study, you must select an underlying theme that will provide a framework and give specific direction to your research. From the outset, we were convinced that within the Ada market a definite need existed for additional systems design and coding capacity. The corollary is that this appeared to provide a significant business opportunity. Our research was active — not passive or neutral. We saw an opportunity, and our purpose was to objectively and concretely confirm our perceptions.At each step in the process we were looking at what value was being added by the person, business or agency that we were exploring. Strictly Business was founded and has flourished on two basic concepts — namely, adding value through our involvement in each transaction and providing quality products and service to our clients. We scrupulously avoid being hardware and software “brokers” collecting fees for merely placing products with customers. We consider ourselves as partners with our clients and work to enhance their businesses with the products and services we provide.Having made the commitment and articulated your role and objectives, you must now begin the real work. This part of my message may be preaching to the choir. The fact that you are involved in the Ada community indicates that you have or are beginning to acquire a knowledge of the Ada marketplace. That’s essential.Gather as much information as possible about every aspect of Ada. If you know the language, great. If not, that should not deter you from learning as much as you can exclusive of Ada per se. No one in our organization knew Ada before we began hiring our staff, yet several of us became knowledgeable and conversant enough to find our way around Ada circles — and in the Ada community, that’s essential.Regardless of how much you learn in your explorations, the input of people active in Ada is indispensable. One of the most gratifying things our research revealed was the generosity and willingness of Ada experts to share their knowledge. We knocked on a lot of doors and did not find one that was not opened wide for us.Let me share with you some of the avenues we explored in trying to determine whet her or not a real Ada opportunity existed. We first had the advantage of coming from West Virginia whose senior U.S. Senator is Robert C. Byrd who has seen the potential of Ada and has for some years been one of its strongest advocates. With the assistance of two of his staff members, we were directed to the Software Valley Corporation which has been very much involved in bringing the advantages of Ada and Ada-related ventures to our Mountain State.Bob Verhotz, the Executive Director of Software Valley Corporation, in addition to other helpful suggestions, recommended that we contact Mr. Ralph Crafts. Bob had worked with Ralph on a number of occasions and spoke highly of his credentials and performance. We have not been disappointed.Ralph knows his way around the Ada community as well as anyone, and better than most. Almost a year ago, we employed Ralph as our consultant to define the state of the Ada market and give initial direction to our study. During intensive meetings with him, we received a great deal of background information and recommendations of additional areas into which we should extend our Ada network.These three initial contacts — Ralph, Software Valley, and Senator Byrd — confirmed that quality-conscious and professional systems developers could definitely find a place in the Ada market.At this point I think you can begin to see two things. The more obvious is the snowball effect of Ada contacts. Your first contact leads to two others which each lead to two or three more, and so on. The second thing is that we were strongly encouraged by each of these contacts, and our perceptions that excellent opportunities existed in Ada were reinforced. If anything, the potential began to look even greater than we had at first anticipated.Our tentacles, at that point, began to extend into additional areas of the Ada community. We have come to share Ralph’s belief that the more people you know in this still relatively small group, the better off you are.We traveled to Washington to visit again with Senator Byrd’s office. While there, with an introduction from the senator’s staff, we also met with a number of people at the Ada Joint Programming Office, including the then-Air Force Deputy Director Major Al Kopp. More support and encouragement. On the same trip we cultivated an acquaintance at the Ada Information Clearinghouse. More support, encouragement, and a wealth of published information. We also briefly visited the STARS office and met with someone who was encouraging and informative about that extensive Ada project. Each of these organizations and individuals had a specific mission designed to enhance and increase the value of the Ada contribution.At that point we had begun to look at equipment and it was here that we found one of our more valuable allies and associates. From our initial contact with the personnel at RATIONAL we found them to be most helpful and open. Our sales representative made it possible for us to meet with two large firms handling major project work in Ada for the Defense Department.I don’t need to tell you how valuable it can be to speak with someone who is engaged in the type of work you are contemplating and who has no ax to grind or hidden agendas as far as discussing things with you. Other vendors may have been equally helpful, but I doubt that any could have been more so. We met people doing actual project work in Ada for the government, extending our network and also making some contacts we would later pursue as we sought to put together our Ada staff.In March of this year, we attended the SlGAda conference in Phoenix where we researched a number of vendors, but more importantly, met others in the Ada community — on the commercial as well as the governmental side. We, admittedly, understood very little of the technical content of the meeting, but our purpose in attending was not technical in nature. We were networking, and our network was rapidly expanding.This might be a good point at which to remind you of the three-fold commitment required in this undertaking — time, energy, and money. By March our exploratory had gotten into its fifth month and had occupied practically all of my time and a substantial portion of the time of two of my colleagues at Strictly Business. Our travels had included a couple of trips to Washington and the trip to Phoenix as well as visits to Morgantown, WV (where the Software Valley Corporation is located) and Pittsburgh where we met with an active Ada development firm and some folks at the Software Engineering Institute of Carnegie-Mellon University. For a small firm such as ours, the budget for this venture was becoming substantial, but we were making valuable progress toward our objective.Speaking of budgets, probably the largest single start-up expenditure will be the development system you select. Spend sufficient time in making this decision. In equipment, you have a myriad of choices. With the recent validation of a large number of compilers, Ada development can be done, in one form or another, on anything from PC’s to the much more sophisticated full-blown systems requiring major financial expenditures — and cost, at least in our case, was a significant consideration. But cost was only one factor.We also were concerned with other areas. Our initial plans called for a system to support ten (10) developers designing systems and/or writing code. Most hardware suppliers could accommodate that in one way or another. With our lack of experience in Ada, we were also looking for ease of familiarization and operation. And we were very much concerned with the level of support a supplier could provide. Who seemed most qualified and willing to “hold our hand,” as it were, until we gained some experience?The last major consideration was credibility. We knew that as a start-up operation gaining entree and establishing our credentials with potential contractors was critical. Our development system could say a lot about our commitment and dedication. Technical capabilities being a given, we were willing to pay some premium to project the most professional image. Bottom Line: find the system that will best enable us to efficiently and effectively develop software — to give our future clients value for their programming expenditures.We investigated three major suppliers — DEC and DG, both of whom seemed quite capable; and RATIONAL, whose development environment was written in and expressly for Ada.Weighing all the factors — system capabilities, support, ease of integration and use, reputation, cost, efficiency, etc. — we came down on the side of RATIONAL, and later decided that we would supplement them with SUN Microsystems work stations.We’re happy with our decision and believe, as I said at the outset about the cost of advice, that you get what you pay for. At this time, we are confident that our system configuration will satisfy our objectives and meet our expectations. Something similar mayor may not be right for you. Your situation and needs, not our experience, should dictate your direction on equipment selection. We can only recommend that you thoroughly explore the alternatives.So where were we? We had done a lot of reading and travelling; met a lot of people with whom we’d like to be professionally associated: gotten a tremendous amount of encouragement that had been tempered with some pragmatic cautions; and made some preliminary system selections. Now we were getting down to the nitty-gritty — putting our plans and a proposal down on paper so that we could launch a sales effort to put together the financing needed to make it go.In formalizing your proposal or business plan, be prepared to spend a lot of hours at a desk with all of your background notes, a dictionary, a thesaurus, calculator, plenty of paper and pencils with generous erasers. With access to a word processor and a good spreadsheet program, you are facing a formidable task; without these two tools, it will seem, and may actually be, virtually “undoable.”Your proposal or business plan can take any of several forms, and no one is necessarily more or less appropriate or effective than any other. The plan should reflect your corporate style and philosophy. But regardless of the form, there are some elements which are indispensable.Your presentation must inspire confidence in a potential investor, assuming that you, like we, have to seek outside capital to launch your effort. The plan must clearly demonstrate that you have done your homework and thoroughly researched the subject and the market. It should deal with the principal players in your scenario, their credentials, and what they can contribute to the success of the venture — what value can each add? If yours is to be an extension of an existing business, the proposal must provide business and financial history in a realistic light, yet do so as favorably as possible. Finally, the plan must provide business forecasts in the form of projected financial statements and balance sheets. Have your accountant or someone with a strong financial background assist with the financials if that is not an area in which you have experience and confidence.Ultimately, the plan must convince its readers that you have (a) identified a need in the market and (b) that you are prepared and positioned to meet it. Experienced business pros will be reviewing the plan, so make the effort, and do it right. In preparing all of this information, keep in mind that an investor who decides to participate based on the plan will view it as your commitment. He very likely will measure your success, or lack of it, by using the plan as his yardstick. So, be conservative or at least realistic. Don’t put anything into your plan that you might regret. if it were referenced some time later.One of our new acquaintances offered to review our proposal. He was doing Ada work so he could evaluate the presentation from that perspective. He was also very much involved with a managing board composed of experienced venture capitalists, so he could also take a look from that viewpoint. He gave us sound advice.My point is that you should have some disinterested parties whose opinions you value and respect, and who can freely and dispassionately critique your work, review it before you run with it. And, believe me, unless you are superhuman, you will go through several drafts and revisions before you submit the plan for outsider review. Our final plan was the sixth major revision, excluding the many internal changes and edits. Preparing an acceptable and effective plan is a humbling experience that will teach you the value of patience.One final note regarding your proposal — don’t overlook its appearance. A copy of the plan and an introductory letter may be your only exposure as you try to get personal appointments to market your idea. Prepare them with care and attention to detail. Ensure that they reflect the high degree of professionalism that went into their re-search and preparation and which will characterize your business efforts. The content of the plan may not even be considered if the plan itself is not attractively presented.Now that you have what you believe is a good marketing piece, where do you go with it?Our objective was to secure local financing (within our community or at least within the state of West Virginia). We drew on personal contacts, a list of local venture capitalists that we obtained from the chamber of commerce, and suggestions offered by the CEO of one of the banks with whom we had an on-going personal and business relationship.We thoroughly explored various loan, grant, and incentive programs offered by municipal, county and state governments to attract business. If you have a university near you, they may have an office that assists with business start-ups. They may be very helpful if you choose to apply for loans or grants since this is an art form in itself. Don’t overlook these potentially attractive sources of advice or capital; they could make the difference.Be prepared to make phone calls, personal visits and send written correspondence in cultivating potential investors. And be sure to have your ducks in line because most of these people did not accumulate their wealth or acquire their positions because they are fiscally naive or stupid. They are, by and large, very good business people who ask direct and probing questions and expect direct, succinct, supportable answers — and a wrong answer can quickly kill an opportunity.If local capital is not available, you will have to look farther afield. That’s an area in which we can’t offer much advice as we did not have to pursue it. We anticipated that if we had had to look elsewhere we would have to be even more on our toes, since we would give up the advantage of common ground. We would be negotiating on their turf rather than being from the same community as the people we were soliciting.One of the biggest difficulties we encountered was in selling something intangible. As sophisticated as many lenders and investors are, some are still uncomfortable with the computer field, and especially software, as an area of opportunity.Unless high tech businesses are already an established and accepted investment arena in your area, lenders may have difficulty grasping the concept of investing in intellectual property. Loans or investments for plant and equipment are a piece of cake — you can survey, touch, walk around or kick the tires of the collateral. In dealing with software, you lose that advantage, and many people are still wary of getting financially involved with something they can’t see, touch, taste, or smell.Anticipate some initial skepticism and prepare to overcome it. BEGIN NOW. This is one area where you can’t start sowing seeds and nurturing them too soon. Look for or create occasions to discuss with the financial powers in your community the role and advantages and success stories and opportunities in software development. When you come across a good article — one that’s not too technical — that supports your point, send copies to appropriate people. Most will be read, and you’ll be strengthening your case and laying a foundation you can build on later.Aside from the “intangibility factor,” we found that the key concern of potential investors is the make-up of your staff. If you have on board people with strong credentials and proven track records in Ada, your job will be much easier. We didn’t. In fact, we had the chicken-and-egg situation of having financiers citing staff as a prerequisite on the one hand; and our inability to recruit and hire a staff until we had secured financing on the other. It was one of the most frustrating aspects of the whole process.We leaned heavily on the proven track records of those of us who were organizing the venture, even though they included no Ada experience. Special expertise has to be addressed, but good basic management skills and experience are highly regarded, well-respected, and carry a lot of weight. We also capitalized on the credentials of our consultant with whom we had reached an agreement for his continuing services after our start-up, making him a legitimate member of our team. It was true that we had considerable background in computer sales, and had on our staff experienced programmers doing custom work for clients, though not in Ada. Many people perceive experience in one area of the computer field as qualification to perform in what we knew to be largely unrelated areas. Since it worked to our advantage, we did not discourage that perception.While we were putting together our financing, we did some preliminary recruiting. We secured resumes and expressions of interest from programmers by contacting the colleges and universities that were graduating students from computer science programs in our area. From the outset, our objective had been to get our programmers locally, if possible. We believe that local residents, particularly in an area like ours, are more easily attracted to job opportunities near home and are more likely to remain with us because of their ties to the area.We recognized, however, that it was critical for us to attract at least one highly experienced Ada professional to direct the programming effort. We drew on the contacts we had made and also secured the services of two firms specializing in Ada placements. Use every tool you can muster, because this is a difficult area with the explosive growth that Ada is enjoying. Experienced people are hard to find, and you must be prepared for a difficult search and the possibility that you may not have adequately budgeted for this position. This person is key, however, and if you find the right one: the time, effort, and money expended in the search will have been well worth it.Look into training, particularly if you do as we did and recruit most of your staff with little or no practical Ada experience. Budget the time and money to allow for proper training of your people and recognize that they will be unproductive for some period of time after they come on board. We completed the hiring of our staff in early Fall. Theirs is a ten-week-long training program. We anticipate beginning work on our first contract no earlier than the first of the year. Our staff will have been on the payroll for more than three months before they take their first steps toward providing a return on the investment in them.So things have finally come together. With financing secured, you have ordered and scheduled installation of your system; hired and are training your staff; and are ready to undertake some work!Getting that first contract may be a challenge. Use every means at your disposal. If you can hire a professional who can bring contracts with him, so to speak, great! If the contacts you have made in your investigations can’t help open doors for you, then you haven’t been contacting the right people. If you have a Senator Byrd to lend support, bravo! Get all the help you can. Don’t be bashful — most people are more than willing to lend as much help as they’re able. Don’t leave any stone unturned. And don’t wait too late to begin looking.If, somehow, you can get a contract before you configure your shop it will certainly make it easier to attract financing. We were unable to do that. Few people will let a contract to a non-existent shop. We began to actively seek a contract as soon as we had our financing in place and our hiring underway.Use every advantage to secure that first contract, but recognize that future work will be contingent on your performance and the reputation for quality that you establish. Personal relationships will become much less a factor. Don’t bite off more than you can chew on that first contract. Find something manageable that will give you some experience, allow you to establish some credibility, and is small enough to be completed in a reasonable length of time. And go all out to deliver the best product possible on or ahead of schedule. Then you’re on our own, and relying on your performance record — and that’s as it should be. The ball will be in your court and how you handle it will determine the flow of the game for the future.I’ve covered a lot of ground, and again I emphasize that this has been a review of our experience - a case study in which the last chapters are just now being written - and not a “how to” course, per se. In retrospect, I don’t believe that there is much that we would do differently if we were to do it again. We approached the project as a marketing problem and treated it accordingly, drawing on the expertise of others in technical and financial areas. Some of the things we learned would enable us to compress the timeframe to establish a new venture if we were to do it again, but we are relatively well satisfied with how things went.Let me close by just saying that you can become discouraged if you allow it to happen. If you are like we were, the potential of the opportunity is so enormous and so obvious that you won’t be able to easily accept the reluctance and skepticism of others. Why can’t they see what’s as plain as day to us? Why are things taking so long? Be patient and persist. If you’re committed, do your homework, lay the groundwork, and do a good selling job, things will ultimately work out. Don’t lose your sense of urgency; don’t allow your interest to flag; and be patient…be patient…be patient.If we have been able to give you any ideas, then we’ve accomplished our objective. We wish you well. Thank you.",
    "author": [
      {
        "family": "Mayer",
        "given": "P. J."
      }
    ],
    "collection-title": "TRI-ada ’88",
    "container-title": "Proceedings of the conference on TRI-ada ’88",
    "id": "10.1145/76619.76644",
    "issued": {
      "date-parts": [
        [
          1989
        ]
      ]
    },
    "page": "567-580",
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Entering the ada systems design and coding market",
    "type": "paper-conference"
  },
  {
    "DOI": "10.1145/1362702.1362708",
    "ISBN": "9781450378444",
    "URL": "https://doi.org/10.1145/1362702.1362708",
    "abstract": "The Interactive Media Lab (IML) builds shrink-wrapped educational software for medical professionals and first responders. We have teams focusing on media production, script-level authoring, and low-level engine development. Our most recent project is Virtual Terrorism Response Academy. VTRA uses 3D simulations to teach students about radiological, chemical and biological weapons. Our software is now undergoing trials at government training centers and metropolitan police departments. VTRA consists of approximately 60,000 lines of Scheme, and a similar amount of C++. All of our product-specific code is in Scheme, and we make extensive use of macros and domain-specific languages.From 1987 to 2002, we used a C++ multimedia engine scripted in 5L, the \"Lisp-Like Learning Lab Language\". This was Lisp-like in name only; it used a prefix syntax, but didn’t even support looping, recursion, or data structures. We needed something better for our next project! We ultimately chose to use Scheme, because (1) it was a well-known, general-purpose programming language, and (2) we could customize it extensively using macros. Migrating to Scheme proved tricky, because we needed to keep releasing products while we were building the new Scheme environment. We began by carefully refactoring our legacy codebase, allowing us to maintain our old and new interpreters in parallel. We then rewrote the front-end in a single, eight-day hacking session. But even once the Scheme environment was ready, few of our employees wanted to use it. In an effort to make Scheme programming more accessible, we invested significant effort in building an IDE. Today, our environment is much more popular—a third of our employees use it on a regular basis, including several professional artists.After migrating to Scheme, we added support for 3D simulations. And Scheme proved its worth almost immediately: we faced several hard technical problems, which we solved by building domain-specific languages using Scheme macros. First, we needed to simulate radiation meters. For this, we used a reactive programming language to implement a Model-View-Controller system. Second, we needed to guide students through the simulation and make teaching points. For this, we relied on a \"goal system\", which tracks what students need to accomplish and provides hints along the way. In both these cases, Scheme proved to be a significant competitive advantage. Not all problems have clean imperative solutions. A language which supports functional programming, macros, and combinator libraries allows us to do things our competitors can’t.This summer, we’ll be releasing our engine as open source, and starting work on a GUI editor. We welcome users and developers!",
    "author": [
      {
        "family": "Kidd",
        "given": "Eric"
      }
    ],
    "collection-title": "CUFP ’07",
    "container-title": "Proceedings of the 4th ACM SIGPLAN workshop on commercial users of functional programming",
    "id": "10.1145/1362702.1362708",
    "issued": {
      "date-parts": [
        [
          2007
        ]
      ]
    },
    "publisher": "Association for Computing Machinery",
    "publisher-place": "New York, NY, USA",
    "title": "Terrorism response training in scheme",
    "type": "paper-conference"
  },
  {
    "ISBN": "0201770180",
    "abstract": "From the Book: Introduction Developing large distributed software systems is a complex and interesting challenge. A number of architectures have been developed to simplify this task and distract developers from the many interoperability issues associated with developing such systems. This book is predominantly about one of those architectures, Microsoft’s .NET Framework. An often-asked question is \"so what is new in the .NET Framework \" On one level the answer is \"not much.\" To put this answer into context, the same may be said of most recent software advancements. As an example, C++ was a significant step forward but it was the amalgamation of the object oriented concepts of Simula 67 and the efficiency of C. Java also contained very little new science, with the concepts of virtual machines and class libraries having been commonplace for many years. So how then do these advancements contribute Often they contribute via synergy, the combination of known technologies in a new and different manner that allows developers to combine two powerful concepts in a single architecture. So it is with the .NET Framework. Although there are significant benefits to be gained by using the Framework, many readers will be relieved to see that many familiar concepts exist in the environment, although their implementation may have changed. For example, a major concept pervading the .NET Framework is object orientation. Recently this paradigm has seen enormous acceptance in many areas from Graphic User Interface (GUI) development through to network programming. The .NET Framework provides support for all of the object oriented concepts such as classification, information hiding, inheritance andpolymorphism. What is new in the .NET Framework is that language boundaries have been removed. The .NET Framework also extends these concepts in concert with other concepts. For example inheritance can be subject to security constraints; just because you can use a type it may not follow that you can subtype from that type. Audience It is important to understand the target audience that this book was written for in order to know if this book is for you. This book is targeted at software developers who wish to: Understand the philosophy and architecture of the .NET Framework, Produce generic frameworks, libraries, classes and tools to be used in the .NET Framework, and Use multiple languages to develop in the .NET Framework. As this book is targeted at software developers, it not only describes the goals and architecture of the .NET Framework but also demonstrates how the technology implements facilities and services to meet these goals. Understanding the philosophy and architecture of .NET is important for any distributed system developer even if they do not use the .NET Framework. Why The .NET Framework represents Microsoft’s vision of distributed system development for the Internet. By understanding the architecture of the .NET Framework developers gain an insight into the issues associated with distributed systems development and Microsoft’s solution to these issues. Once developers have an understanding of the .NET Framework’s architecture, the next step is to develop software that utilizes the framework. The .NET Framework is not an abstract programming model, it is a full-featured system that allows developers to implement their sol and then make them available to other developers in a robust and secure environment. As the .NET Framework is language agnostic, developers can use the right language to develop parts of a system and then incorporate these parts together at runtime regardless of language differences. So who is this book not for This book is not an introduction to programming; readers should have experience developing software before reading this book. This book is also not the definitive guide to all aspects of the .NET Framework nor any single aspect of the .NET Framework. A single book that covered in detail all aspects of the .NET Framework would be almost indigestible. There will be books devoted to a single part of the .NET Framework, such as ASP.NET. Hopefully this book is a solid overview of fundamental aspects of the .NET architecture but for individual aspects, such as the security system, readers will have to refer to other texts or specific documentation for a complete treatment of a specific topic. Book Structure The structure of the book is fairly straightforward: The Introduction Section of the book describes the basic concepts and gives background information on the issues involved in distributed system development. The Runtime Section describes the issues that can be thought of as \"Programming in the small.\" This section deals with issues such as defining types, storing metadata and executing programs. The Building and Deployment Section deals with the hard issues in distributed systems development. Issues such as assembling and developing software from components and deployment issues are covered here. This section also covers the B the libraries used to build applications. Finally the appendixes contain important peripheral information that does not fit into the first three sections of the book. This includes experience reports from people who have developed compliers for the .NET Framework. Our motivation for writing the book \"So why are we writing the book \" We have asked this question many times over. In late 1998 Monash University was asked if it would like to be involved with Microsoft in the development of the \"next generation of COM\", which was then known as the COM Object Runtime (COR). The invitation to join Project 7, the name for this multinational joint collaboration between Microsoft and a number of universities, came from James Plamondon at Microsoft Research. Why was Monash University chosen The major reason was because of our association with Bertrand Meyer and his object oriented programming language Eiffel. Even at this early stage Microsoft was firmly focused on having as many languages as possible supported by the runtime. Monash University accepted the invitation and Damien attend an overview in Atlanta during early 1999. The idea of writing this book was first discussed at that meeting. Having just attended the preview of COR, which was now known as Lightning at this time, Damien asked James Plamondon if he knew of anyone that was writing a book on Lightning. Even at this early stage it was clear that a number of books would be required to cover all of the aspects of Lightning but Damien also wanted to see that the small, but hopefully beneficial, involvement of Project 7 members was recorded. James encouraged Damien to consider writing such a book and, after a few years numerous changes, this book is the outcome of that conversation. The appendixes in this book are the acknowledgement of the work done by many people outside of Microsoft on Project 7. Mark Hammond has been involved in Python development since 1991, developing and maintaining the Win32 extensions for Python, which includes the PythonWin IDE and the support libraries for COM. Mark had been involved with Microsoft since the mid 1990s in Python related projects, most notably the ActiveScripting and ActiveDebugging extensions for the Python language. In 2000 Mark released his first book, Python Programming on Win32, co-authored with Andy Robinson. In 1998, due to the increasing popularity of the Python programming language, the Project 7 team decided that Python should be one of the initial languages ported to the platform. Mark’s history with Microsoft meant that he was the obvious choice and being located in Melbourne Australia along with two other initial participants, Melbourne and Monash Universities, meant that a core group of Project 7 participants formed almost exactly on the other side of the world from Seattle. This is how Damien and Mark met. Brad was fortunate to be around for the birth of the Common Language Runtime, cutting his teeth in API design and working on fundamental types such as System.Object and System.String. He participated in the earliest design decisions that would later reflect across the breadth of the .NET Framework and in fact all .NET code. Brad was very enthusiastic about the cross language support being built into the runtime while leading the team that developed the Common Language Specification. Early in 1998 Adam Smith, a developer from another team, asked if he exposed properties from his library could VB (and other languages) consume his API. Brad did what any respectable Program Manager at Microsoft would do and called a one hour meeting to decide what features of the CLR would be available in all languages. That meeting didn’t resolve the issue, in fact it took well over three years and thousands of hours from key architects inside of Microsoft such as Anders Hejlsberg, Peter Kukol, Paul Vick, Alan Carter, Scott Wiltamuth, George Bosworth, Lauren Feaux, Ian Ellison-Taylor, Herman Venter, Jonathan Caves, Francis Hogle, Mark Hall, Daryl Olander, Craig Symonds and Brian Harry to answer this question. Later we reviewed and honed the CLS with a group of key language innovators outside of Microsoft, the Project 7 members. It is through this effort that Brad met Damien and Mark. As a byproduct of working out what was to be included in the CLS many \"Best Practices\" were developed. Brad started writing these best practices down in what would later become the .NET Framework Design Guidelines document. This document lead the way in driving for consistency and usability across the APIs exposed in the .NET Framework. The work on the CLS and the Design Guidelines document lead Brad into a unifying role as we took disparate groups across Microsoft and formed the .NET Framework team. Through this effort Brad gained an appreciation for the value of the different parts of the .NET Framework as well as the need for consistent usage of concepts across them. In addition to his day job, Brad joined a very small team tasked with creating the CLI and C# Language standards first through ECMA and then through ISO. Again the CLS and Design Guidelines got a careful review and honing from this group and with great help from Jim Miller they were published as part of the International standards for the CLI standard. Brad loves to talk about the .NET Framework and how it simplifies the lives of developers so agreeing to do this book was a no-brainer! To partially complete the naming history of the .NET Framework it was known as Project 42 before COR and was subsequently called Lightning, COM+2.0 and NGWS (Next Generation Web Services) before finally being renamed to the .NET Framework only weeks before its launch at the PDC in Orlando in July 2000. From our personal viewpoint, the major satisfaction gained from working on Project 7, as with all experiences in life, has come not from developing a technology but from working with such a large, diverse and talented group of developers from all over the world. An interesting aside about the history of the .NET Framework is to look into each and every .NET Framework executable for the string \"BSJB\". This magic number refers to some of the original developers of the .NET Framework, Brain Harry, Susan Radke-Sproull, Jason Zander and Bill Evans. ECMA Standardization Core elements of the .NET Framework have been standardized by the European Computer Manufactures Association (ECMA.) A major reason for standardizing the .NET Framework is so that other implementations of the .NET Framework can be built. Apart from the commercial Windows based implementation, Microsoft has built a shared source implementations for Windows and BSD UNIX, hopefully other implementations from different groups will follow. For information on the standardization effort, interested readers should visit: http://www.ecma.ch and in particular the .NET Framework standardization effort at: http://www.ecma.ch/ecma1/STAND/ecma-335.htm The C# language standard is at: http://www.ecma.ch/ecma1/STAND/ECMA-334.htm You can find out more about the Shard Source Implementations at: http://msdn.microsoft.com/net/sscli",
    "author": [
      {
        "family": "Watkins",
        "given": "Damien"
      },
      {
        "family": "Hammond",
        "given": "Mark"
      },
      {
        "family": "Abrams",
        "given": "Brad"
      }
    ],
    "id": "10.5555/579355",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Addison-Wesley Longman Publishing Co., Inc.",
    "publisher-place": "USA",
    "title": "Programming in the .net environment",
    "type": "book"
  },
  {
    "ISBN": "0672323664",
    "abstract": "From the Book: Introduction By Daniel Brookshier When thinking about how to introduce this book, I thought I might start by welcoming you to a new concept in software. I have worked with many types of software, and I have programmed exclusively in Java since it was introduced in 1995. I’ve seen my share of new concepts and ideas that would change the world. Java has had the biggest impact in my life, and I believe the evidence shows that it has changed the computer world. What about JXTA Why should you or I use a technology that is so new and a departure from Web Services and client server technology When I started looking around, I found that JXTA is not so much a new concept as it is a revolution. Not a revolution in the sense of new or groundbreakinga revolution like the French Revolution. As with most situations where things go wrong, you blame those in power. The French had some rather large grievances with their government. Under Louis XIV and Louis XV, there was extravagant spending, unpopular wars on foreign soil, state bankruptcy, and high taxes imposed mostly on the common man. The French revolutionaries decided that the monarchy and the elite class all had to go. And, as they say, heads would roll. Peer-to-peer is a response to a sort of server-based tyranny. Client-server, multi-tier, and Web server technologies are like kings. Servers concentrate power and resources, limit access, and restrict an individual’s ability to access and control his or her own data. This is not exactly an affront to our civil rights, but it can mean that a corporation has my data on their servers. There is also a barrier to the entry. The rich and noble born and elite of France controlled resources, and only large organizations have the resources to buy and maintain large servers. With the rise of Linux, you can create a shoestring operation, but you still need to pay for bandwidth and other resources. Servers hold the applications and data we use, but we have no stake or control in them. As individuals and even large groups, we cannot muster the resources to create our own servers unless we were born rich like a noble or have the resources like a corporation. Oust the king and suddenly you are looking for someone else to govern. The French, while architecting their revolution, had some of the same thoughts as today’s JXTA developers. On August 26, 1789, the National Assembly of France approved a document, entitled Declaration of the Rights of Man and of the Citizen. They based it somewhat on the declaration of independence written in America. The French document seems to be more about individuals operating in a society and, thus, more like a peer-to-peer system. Let’s look at a few of the articles of the declaration to see where the French revolutionaries and JXTA agree. Men are born and remain free and equal in rights. Social distinctions may be founded only upon the general good (Article 1). Peers also achieve social status via the information or unique processing they contribute. In a server world, the server has almost all resources, while clients have little or none. The principle of all sovereignty resides essentially in the nation. No body nor individual may exercise any authority which does not proceed directly from the nation (Article 3). JXTA creates a community where no individual computer has the ability to affect the entire network unless other member peers allow it. In a sense, this is like a democracy but on a more personal level, because you vote by participation in a group or application. Rights of individual computers are also granted by the protocols that every computer on the peer-to-peer network must follow. In a server environment, the client must follow the rules of the server software and the owners of the server. When there are many servers, there are also many masters, causing the clients to follow too many different and conflicting rules. Liberty consists in the freedom to do everything which injures no one else; hence the exercise of the natural rights of each man has no limits except those which assure to the other members of the society the enjoyment of the same rights. These limits can only be determined by law (Article 4). Liberty in JXTA, like real liberty, is difficult to define. But the key difference from client/server technology is the ability to be an acting part of the application. The benefits are a bit ethereal, but imagine the ability to truly control your data. You can also process the data at any time. Is this freedom Hard to say, but it is a start. JXTA promotes freedom as well as the right to punish those that abuse it. Even a free society has laws. For a network to succeed, there needs to be some way to know when others are harmed and provide a consequence to those responsible. In a P2P network, the ability of one member to do harm is limited. The redundancy of the network reduces the impact on the society of peers but, like any society, there are criminals (or at least perceived to be). JXTA has the notion of a credential. If a peer fails to be a good citizen, its rights may be forfeited and the credential invalidated. Server environments are a bit different. Beyond denial of service attacks, being a good or a bad client is a gray area, mainly because the applications are very constrained for normal users. The server is often cast as the villain, as a hoarder of data and even breaking the trust of clients by allowing the sale of a client’s data. All the citizens have a right to decide, either personally or by their representatives, as to the necessity of the public contribution; to grant this freely; to know to what uses it is put; and to fix the proportion, the mode of assessment and of collection and the duration of the taxes (Article 14). Taxation should be compared to a service fee or cost to create a service. A JXTA peer determines the level of participation in the network and, thus, the cost of its hardware and other resources. Like a consumption tax, there is a tendency to pay more, the more you use the network. Due to redundancy and shared processing, all users benefit, rather than suffering because of poor hardware. Users make their own decisions on how they configure and use their P2P software. Inappropriate and draconian controls instituted by a server’s owners or chosen software are eliminated. In another way, article 14 also shows the difference between server and P2P technology. With servers, an infrastructure must be maintained. Server software, because of its costs, looks like a government that requires a tax to operate that is usually flat rather than based on participation. With a peer network, peers share resources and each peer pays its share by its existence and level of participation. A society in which the observance of the law is not assured, nor the separation of powers defined, has no constitution at all (Article 16). This is sort of an obvious statement for JXTA. If you don’t use JXTA protocols (our Constitution and basic laws), you cannot be a member of the community. If you are using JXTA and do abuse its community, you are usually just hurting yourself. Since property is an inviolable and sacred right, no one shall be deprived thereof except where public necessity, legally determined, shall clearly demand it, and then only on condition that the owner shall have been previously and equitably indemnified (Article 17). P2P started to become popular with the introduction of Napster. Sadly, the implication was that P2P was associated with piracy. Although Napster was originally formed with the idea that only valid owners of music would access digital versions, there was probably more piracy than legitimate use. Consequently, Napster has suffered in court with a severe reduction in the number of users. P2P networks, such as Gnutella, are also devoid of rights management. These systems cannot be taken to court as Napster was because they are truly distributed. However, because of their uncontrolled nature, corporations and ISPs are restricting their traffic, and individual users are being charged with crimes or losing rights to services. It is highly probable that these systems will be disabled or at least inconvenienced. The ultimate goal for JXTA is to be a good citizen and respect copyright and property laws. The reason is simple, without respectability, JXTA is seen as another Napster or Gnutella and will be filtered by ISPs and corporations. Respect others’ rights to their property and you will be treated as a fellow citizen and allowed to use the Internet and corporate infrastructures. Most of us live in a commercial society, and we deal with commercial entities. Where there is unfair trade or criminal activity, the system of government or those affected will tend to remove those who abuse the system. Although you may argue that entities like record companies are not acting fairly, the fact is that the laws are currently written to protect themnot those who dislike the law and protest it by circumvention. Napster and the newer incarnations have not changed any laws through their public protests and active breaking of laws. We still need to follow the rule of law to succeed. JXTA Scale Another revolutionary idea of JXTA is what it empowers you to build. Without a central server, with its costs and limits, much more is possible. This does not necessarily mean new types of applications, just a greater scale than was possible in a server environment. A good example of the scalability of JXTA applications is simple catalog for e-commerce. Normally, you would need a large number of clustered servers to handle a large number of transactions. With JXTA, the catalog and its software are distributed automatically among peer computers. Instead of a server that must show the same catalog to millions of users, you just need one PC to distribute the first copy and any updates. All that needs to be centralized is the final order acceptance and credit card transaction, and even that is distributable to some extent. There are many benefits of a P2P catalog from cost savings to the ability of a user to access the catalog offline. The application also runs faster because the user is not as limited to his or her connection speed or waiting in a queue of other users. Add to this 100 percent availability to most users, and you ensure that the verities of the Internet or of a server farm are no longer a part of the risk equation. Another scale feature is raw computing power. In a server environment, each client has access only to limited resources that must be shared by all users. With JXTA, each peer has all the power of the machine it is running on, plus the shared power of all the other peers with which it is collaborating. Is JXTA a New Concept Just by reading this far, you may have seen very familiar concepts. In the prior examples on scale, it is very easy to associate the same goals with distributed computing. The examples of P2P throughout the book are all possible using other methods. However, the point of JXTA is not necessarily to replace these methods. JXTA is a platform with specific protocols to talk to other JXTA platforms in a peer-to-peer network. It is not an application or a library created to build specific applications. The reason JXTA exists is to enable the refactoring of many different applications in a P2P environment. Like the catalog example, the idea is to move away from centralized infrastructures to gain the benefits of a distributed system. RMI, CORBA, and Web Services are distant cousins of JXTA. They are either oriented toward a client/server or limited point-to-point communications. JXTA may seem to provide similar services, but the framework beneath is very different. For example, you can implement remote method invocation. The key difference between JXTA and others is that the delivery of the command to execute can span barriers like firewalls. The remote command can be sent to groups of computers or just a single computer, depending on the type of task. JXTA Risks I think we can safely agree that JXTA is not like anything else. Is JXTA something to bet your time as well as your fortune on There are risks. Some are new and others are well known. Some are being fixed as you read this book, and others simply need to be implemented on the current JXTA platform. The largest risk now is that JXTA will be in flux over the next couple of years. The good news is that the community of developers will try to keep the network stable for the purpose of keeping their products working. When you reach a certain point, developers learn to hate change, even when the project is open source. It is not all a bed of roses in other areas. There are aspects to a P2P system that can be problematic. In our catalog example, it does take time to propagate the catalog to all users. The same time delay is true of updates and transactions. We are at the start of the JXTA revolution. It is time to think revolutionarily thoughts. The reign of client server is about to fall. Read on and join the revolution. Viva la revolution! Daniel Brookshier JXTA Community Member, Java Consultant January 2002, Dallas, Texas What This Book Covers This book will only cover the Java J2SE reference platform implementation of JXTA. We will not cover the C++, J2ME, Pearl, or other languages that are being used to create JXTA platforms. The J2SE version is the reference platform and best for experimentation or explanation of JXTA protocols. Java is also the most popular language for JXTA development at this time. This book is intended to introduce new developers to the JXTA API and selected applications and services. Our goal is for the reader to understand P2P concepts and be able to build useful applications using JXTA. We do not cover detailed aspects of how the JXTA platform is implemented unless it adds value to the explanation on how to use it. Who Should Use This Book This book is written for readers who need an introduction to P2P and for those who want to learn JXTA. You should already be comfortable with Java. You do not need to know anything about JXTA or peer-to-peer programming. By the end of the book, you should be able to create simple P2P applications using JXTA and the J2SE JXTA reference platform. How This Book is Organized This book is organized with two goals. The first goal is to explain P2P and JXTA in general terms. The second goal is to create applications that use JXTA. Finally, we cover specific applications with the aim of furthering an understanding of JXTA while showing how more complete applications are written. This arrangement was chosen so that the reader can get an overview of JXTA and then build an understanding of how to use its various parts. Web Resources and Example Code You can download the source code for examples presented in this book from http://www.samspublishing.com. When you reach that page, enter this book’s ISBN number (0672323664) in the search box to access information about the book and a Source Code link. The NetBeans IDE was used for much of the code that is found in the book. NetBeans is available at http://www.netbeans.org. Because Forte from Sun Microsystems is derived from NetBeans, it should work as well. You can also use your favorite editor or IDE, but the ANT scripts were created within NetBeans and Forte. Also on the site are files that can be used with MagicDraw from NoMagic at http://www.MagicDraw.com. The tool is written in Java and runs on most Java-compatible platforms. The demo version will allow you to browse and print the JXTA diagrams used in the book, but it will not allow you to save changes. The MagicDraw files follow the XMI standard for UML representation in XML, so other UML tools that support the standard should work (drawings may look different). © Copyright Pearson Education. All rights reserved.",
    "author": [
      {
        "family": "Brookshier",
        "given": "Daniel"
      },
      {
        "family": "Govoni",
        "given": "Darren"
      },
      {
        "family": "Krishnan",
        "given": "Navaneeth"
      },
      {
        "family": "Soto",
        "given": "Juan Carlos"
      }
    ],
    "id": "10.5555/560389",
    "issued": {
      "date-parts": [
        [
          2002
        ]
      ]
    },
    "publisher": "Sams",
    "publisher-place": "USA",
    "title": "JXTA: Java P2P programming",
    "title-short": "JXTA",
    "type": "book"
  }
]
